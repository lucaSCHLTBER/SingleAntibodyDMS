{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Antibody DMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading nessesary libraries\n",
    "import os\n",
    "import random\n",
    "from Bio import SeqIO\n",
    "from IPython.display import display, Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dmslogo\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U altair_viewer\n",
    "!pip install altair\n",
    "!pip install selenium\n",
    "!pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial loading and editing of counts table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "\n",
    "# Read Excel into a DataFrame\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Print first 5 rows with column titles\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_file = r'/Users/lucaschlotheuber/Desktop/ETH/RBD201_DMS1.fa'\n",
    "\n",
    "# Read the FASTA file\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    wuhan_sequence = str(record.seq)\n",
    "    break  # Assuming there's only one sequence in the FASTA file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "#Here we are using the modified DMS_file containing different identifiers such as immunization, conditions and immunization status\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "\n",
    "df_total = pd.read_excel(file_path, usecols=[\"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\", \"Amino_Acid\", \"Type_of_Mutation\", \"Enrichment_Ratio\", \"barcode\", \"immunization\", \"condition\", \"Total_Reads\"])\n",
    "\n",
    "#in the original calculation SARS-CoV-2 Spike positions were annoted incorrectly (+5 AA)\n",
    "df_total[\"Spike_AS_Position\"] = df_total[\"Spike_AS_Position\"] - 5\n",
    "\n",
    "#Removing ~5000 datapoints with \"inf\" values in the Enrichment_Ratio column and discarding reads with less than 10.000 total reads\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio','Amino_Acid'])\n",
    "\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 1000]\n",
    "\n",
    "immunization = \"Wuhan_Sequence\"\n",
    "barcode = \"Wuhan_Barcode\"\n",
    "\n",
    "data_wuhan = []\n",
    "for position, amino_acid in enumerate(wuhan_sequence, start=1):\n",
    "    data_wuhan.append({\n",
    "        'DMS_RBD_AS_position': position,\n",
    "        'Spike_AS_Position': position + 330,\n",
    "        'Amino_Acid': amino_acid,\n",
    "        'immunization': immunization,\n",
    "        'barcode': barcode,\n",
    "        'Enrichment_Ratio': 1,# Assuming an enrichment ratio of 1 for simplicity\n",
    "    })\n",
    "\n",
    "## Create a DataFrame\n",
    "df_wuhan = pd.DataFrame(data_wuhan)\n",
    "\n",
    "df_total = pd.concat([df_total, df_wuhan], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial averaging and grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the averages of Count_of_Base for the SYNOM and NON-SYNOM groups\n",
    "average_counts = df_total.groupby('Type_of_Mutation')['Count_of_Base'].mean()\n",
    "average_enrichment = df_total.groupby('Type_of_Mutation')['Enrichment_Ratio'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(\"Average Count_of_Base for SYNOM group:\", average_counts.get('SYNOM', 'N/A'))\n",
    "print(\"Average Count_of_Base for NON-SYNOM group:\", average_counts.get('NON-SYNOM', 'N/A'))\n",
    "\n",
    "print(\"Average Enrichment_Ratio for SYNOM group:\", average_enrichment.get('SYNOM', 'N/A'))\n",
    "print(\"Average Enrichment_Ratio for NON-SYNOM group:\", average_enrichment.get('NON-SYNOM', 'N/A'))\n",
    "\n",
    "# Further subset into different immunization groups\n",
    "immunization_groups = df_total['immunization'].unique()\n",
    "for group in immunization_groups:\n",
    "    if pd.notna(group):\n",
    "        group_df = df_total[df_total['immunization'] == group]\n",
    "        group_avg_counts = group_df.groupby('Type_of_Mutation')['Count_of_Base'].mean()\n",
    "        print(f\"\\nAverage Count_of_Base for {group} - SYNOM group:\", group_avg_counts.get('SYNOM', 'N/A'))\n",
    "        print(f\"Average Count_of_Base for {group} - NON-SYNOM group:\", group_avg_counts.get('NON-SYNOM', 'N/A'))\n",
    "\n",
    "# Calculate the standard deviations of Count_of_Base for the SYNOM and NON-SYNOM groups\n",
    "std_devs = df_total.groupby('Type_of_Mutation')['Count_of_Base'].std()\n",
    "\n",
    "# Print the results\n",
    "print(\"Standard Deviation of Count_of_Base for SYNOM group:\", std_devs.get('SYNOM', 'N/A'))\n",
    "print(\"Standard Deviation of Count_of_Base for NON-SYNOM group:\", std_devs.get('NON-SYNOM', 'N/A'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is generating line plots for each (grouped) conditions (Neutralizing Ab, Polyclonal Ab, \"Library\" and cells from mice immunized with either WT RBD or mutant RBD) - Single cell data is aggregated per condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Raw data without separating in Binding and Escape fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CODE FOR GENERATING LINEPLOTS WITH ENTIRE SEQUNCE, AND WITH HIGHLIGHTS\n",
    "#Swap out barcode for barcode to do individual droplet analysis \n",
    "\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')] #Removes the first 33 positions due to bad read quality\n",
    "\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "#The positions that have showed high enrichment ratios in the library droplets are discarded from the analysis (pos 33, 72, 81 and 151)\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    #[(i+331) for i in range(30, 200) if i not in [33, 72, 81, 151]] +  \n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] + #RBD-ACE2 interface according to article\n",
    "    list(range(394,414)) + #R21 peptide sequnce with high affinity\n",
    "    list(range(484, 505)) #R13 peptide sequence with high affinity\n",
    ")\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')#.query(\"show_site\")\n",
    "    \n",
    "    # Aggregate the data to ensure unique Spike_AS_Position values\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "    \n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(range(df_filtered_im['Spike_AS_Position'].min(), df_filtered['Spike_AS_Position'].max() + 1)).reset_index()\n",
    "    \n",
    "    # Merge the show_site column back into df_filtered\n",
    "    df_filtered_im = df_filtered_im.merge(df_filtered_agg[['Spike_AS_Position', 'show_site']], on='Spike_AS_Position', how='left')\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(20))  # Print first few rows to check if show_site is properly set\n",
    "\n",
    "    fig, ax = dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Enrichment_Ratio\",\n",
    "        title=immunization,\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Enrichment Ratio\",\n",
    "        show_col=\"show_site\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    \n",
    "    # Save the figure\n",
    "    #file_path = os.path.join(r\"C:\\Users\\au649453\\OneDrive - Aarhus universitet\\PhD\\Luca\\DMS_plots\\Enriched and targeted positions\", f\"{immunization}_lineplots.png\")\n",
    "    #plt.savefig(file_path, dpi = 300, bbox_inches = 'tight')\n",
    "    #plt.close(fig)\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial heatmaps (rawdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import altair as alt\n",
    "\n",
    "# Load FASTA sequence (Wuhan reference)\n",
    "fasta_file = r'/Users/lucaschlotheuber/Desktop/ETH/RBD201_DMS1.fa'\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    wuhan_sequence = str(record.seq)\n",
    "    break\n",
    "\n",
    "# Load and clean the Excel data\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "df_total = pd.read_excel(file_path, usecols=[\n",
    "    \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\",\n",
    "    \"Amino_Acid\", \"Type_of_Mutation\", \"Enrichment_Ratio\",\n",
    "    \"barcode\", \"immunization\", \"condition\", \"Total_Reads\"\n",
    "])\n",
    "df_total[\"Spike_AS_Position\"] -= 5  # Adjust for 336 -> 331\n",
    "\n",
    "# Clean up: remove NaNs, low reads, and stop codons\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio','Amino_Acid'])\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 1000]\n",
    "df_total = df_total[df_total[\"Amino_Acid\"] != '*']  # Exclude stop codons\n",
    "\n",
    "# Add Wuhan reference line (assume enrichment ratio of 1)\n",
    "immunization = \"Wuhan_Sequence\"\n",
    "barcode = \"Wuhan_Barcode\"\n",
    "data_wuhan = [{\n",
    "    'DMS_RBD_AS_position': pos,\n",
    "    'Spike_AS_Position': pos + 330,\n",
    "    'Amino_Acid': aa,\n",
    "    'immunization': immunization,\n",
    "    'barcode': barcode,\n",
    "    'Enrichment_Ratio': 1,\n",
    "} for pos, aa in enumerate(wuhan_sequence, start=1) if aa != '*']\n",
    "df_wuhan = pd.DataFrame(data_wuhan)\n",
    "df_total = pd.concat([df_total, df_wuhan], ignore_index=True)\n",
    "\n",
    "# Keep non-synonymous mutations and good regions only\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 364) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Mutation label (optional, not plotted here)\n",
    "df_filtered['mutation'] = df_filtered['Amino_Acid'] + df_filtered['Spike_AS_Position'].astype(str)\n",
    "\n",
    "# Aggregate for heatmap\n",
    "# Aggregate and log2-transform enrichment ratios\n",
    "df_heatmap = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'mean'})\n",
    "\n",
    "# Filter out zeros or negative values before log2\n",
    "df_heatmap = df_heatmap[df_heatmap['Enrichment_Ratio'] > 0]\n",
    "df_heatmap['log2_enrichment'] = df_heatmap['Enrichment_Ratio'].apply(lambda x: round(np.log2(x), 3))\n",
    "\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"heatmap_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Plot heatmap for each immunization\n",
    "for immun in df_heatmap['immunization'].unique():\n",
    "    df_im = df_heatmap[df_heatmap['immunization'] == immun].copy()\n",
    "\n",
    "    # Compute tick values every 5\n",
    "    tick_vals = sorted(df_im['Spike_AS_Position'].unique())\n",
    "    tick_vals = [x for x in tick_vals if x % 5 == 0]\n",
    "\n",
    "    # Create Altair heatmap\n",
    "    heatmap = alt.Chart(df_im).mark_rect().encode(\n",
    "        x=alt.X('Spike_AS_Position:O', title='Spike AA Position',\n",
    "                axis=alt.Axis(values=tick_vals)),\n",
    "        y=alt.Y('Amino_Acid:N', title='Mutated AA'),\n",
    "        color=alt.Color('log2_enrichment:Q',\n",
    "                        scale=alt.Scale(scheme='redblue'),\n",
    "                        title='log₂ Enrichment'),\n",
    "\n",
    "        tooltip=[\n",
    "            'Spike_AS_Position:O',\n",
    "            'Amino_Acid:N',\n",
    "            'Log2 Binding Ratio:Q'\n",
    "        ]\n",
    "    ).properties(\n",
    "        title=f\"Mutational Scanning Heatmap - {immun}\",\n",
    "        width=800,\n",
    "        height=400\n",
    "    ).configure_axis(\n",
    "        labelFontSize=12,\n",
    "        titleFontSize=14\n",
    "    ).configure_title(\n",
    "        fontSize=18,\n",
    "        anchor='start'\n",
    "    )\n",
    "\n",
    "    # Save HTML file\n",
    "    output_file = os.path.join(output_dir, f\"{immun}_heatmap.html\")\n",
    "    heatmap.save(output_file)\n",
    "\n",
    "    print(f\"Saved heatmap for {immun} to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load FASTA sequence (Wuhan reference)\n",
    "fasta_file = r'/Users/lucaschlotheuber/Desktop/ETH/RBD201_DMS1.fa'\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    wuhan_sequence = str(record.seq)\n",
    "    break\n",
    "\n",
    "# Load and clean the Excel data\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "df_total = pd.read_excel(file_path, usecols=[\n",
    "    \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\",\n",
    "    \"Amino_Acid\", \"Type_of_Mutation\", \"Enrichment_Ratio\",\n",
    "    \"barcode\", \"immunization\", \"condition\", \"Total_Reads\"\n",
    "])\n",
    "df_total[\"Spike_AS_Position\"] -= 5  # Adjust 336 -> 331\n",
    "\n",
    "# Clean up\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio', 'Amino_Acid'])\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 1000]\n",
    "df_total = df_total[df_total[\"Amino_Acid\"] != '*']  # Exclude stop codons\n",
    "\n",
    "# Add Wuhan reference\n",
    "immunization = \"Wuhan_Sequence\"\n",
    "barcode = \"Wuhan_Barcode\"\n",
    "data_wuhan = [{\n",
    "    'DMS_RBD_AS_position': pos,\n",
    "    'Spike_AS_Position': pos + 330,\n",
    "    'Amino_Acid': aa,\n",
    "    'immunization': immunization,\n",
    "    'barcode': barcode,\n",
    "    'Enrichment_Ratio': 1,\n",
    "} for pos, aa in enumerate(wuhan_sequence, start=1) if aa != '*']\n",
    "df_wuhan = pd.DataFrame(data_wuhan)\n",
    "df_total = pd.concat([df_total, df_wuhan], ignore_index=True)\n",
    "\n",
    "# Filter\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 364) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Aggregate\n",
    "df_heatmap = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'mean'})\n",
    "\n",
    "# Filter out zeros or negatives\n",
    "df_heatmap = df_heatmap[df_heatmap['Enrichment_Ratio'] > 0]\n",
    "\n",
    "# Invert values between 0 and 1 for log2 enrichment, leave others unchanged\n",
    "df_heatmap['Enrichment_Ratio_transformed'] = df_heatmap['Enrichment_Ratio'].apply(\n",
    "    lambda x: 1 / x if 0 < x < 1 else x\n",
    ")\n",
    "\n",
    "# Calculate log2 enrichment from transformed values\n",
    "df_heatmap['log2_enrichment'] = df_heatmap['Enrichment_Ratio_transformed'].apply(\n",
    "    lambda x: round(np.log2(x), 3)\n",
    ")\n",
    "\n",
    "# Split into log2 ranges\n",
    "df_low = df_heatmap[df_heatmap['log2_enrichment'] <= 0].copy()\n",
    "df_high = df_heatmap[df_heatmap['log2_enrichment'] > 0].copy()\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"heatmap_output_log2_split\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to generate and save log2-based heatmap as PNG\n",
    "# Function to generate and save log2-based heatmap as PNG\n",
    "def generate_heatmap(df_subset, enrichment_range_label):\n",
    "    for immun in df_subset['immunization'].unique():\n",
    "        df_im = df_subset[df_subset['immunization'] == immun].copy()\n",
    "\n",
    "        # Create a pivot table for heatmap\n",
    "        pivot_df = df_im.pivot(index=\"Amino_Acid\", columns=\"Spike_AS_Position\", values=\"log2_enrichment\")\n",
    "\n",
    "        # Create the heatmap using seaborn\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        sns.heatmap(pivot_df, cmap='RdBu_r', vmin=-3, vmax=3, cbar_kws={'label': 'log2 Enrichment'},\n",
    "                    annot=False, linewidths=0.5, linecolor='gray')\n",
    "\n",
    "        # Set labels and title\n",
    "        plt.title(f\"log₂ {enrichment_range_label} Heatmap - {immun}\", fontsize=18)\n",
    "        plt.xlabel('Spike AA Position', fontsize=14)\n",
    "        plt.ylabel('Mutated AA', fontsize=14)\n",
    "        plt.yticks(fontsize=8)\n",
    "\n",
    "        # Save as PNG\n",
    "        output_file_png = os.path.join(output_dir, f\"{immun}_heatmap_log2_{enrichment_range_label.replace(' ', '_')}.png\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_file_png)\n",
    "        plt.close()\n",
    "        print(f\"Saved log2 {enrichment_range_label} heatmap for {immun} to {output_file_png}\")\n",
    "\n",
    "\n",
    "# Generate both sets\n",
    "generate_heatmap(df_low, \"0_to_1\")\n",
    "generate_heatmap(df_high, \"1_to_max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load FASTA sequence (Wuhan reference)\n",
    "fasta_file = r'/Users/lucaschlotheuber/Desktop/ETH/RBD201_DMS1.fa'\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    wuhan_sequence = str(record.seq)\n",
    "    break\n",
    "\n",
    "# Load and clean the Excel data\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "df_total = pd.read_excel(file_path, usecols=[\n",
    "    \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\",\n",
    "    \"Amino_Acid\", \"Type_of_Mutation\", \"Enrichment_Ratio\",\n",
    "    \"barcode\", \"immunization\", \"condition\", \"Total_Reads\"\n",
    "])\n",
    "df_total[\"Spike_AS_Position\"] -= 5  # Adjust 336 -> 331\n",
    "\n",
    "# Clean up\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio', 'Amino_Acid'])\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 100]\n",
    "df_total = df_total[df_total[\"Amino_Acid\"] != '*']  # Exclude stop codons\n",
    "\n",
    "# Add Wuhan reference\n",
    "immunization = \"Wuhan_Sequence\"\n",
    "barcode = \"Wuhan_Barcode\"\n",
    "data_wuhan = [{\n",
    "    'DMS_RBD_AS_position': pos,\n",
    "    'Spike_AS_Position': pos + 330,\n",
    "    'Amino_Acid': aa,\n",
    "    'immunization': immunization,\n",
    "    'barcode': barcode,\n",
    "    'Enrichment_Ratio': 1,\n",
    "} for pos, aa in enumerate(wuhan_sequence, start=1) if aa != '*']\n",
    "df_wuhan = pd.DataFrame(data_wuhan)\n",
    "df_total = pd.concat([df_total, df_wuhan], ignore_index=True)\n",
    "\n",
    "# Filter\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 364)\n",
    "]\n",
    "\n",
    "# Aggregate\n",
    "df_heatmap = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'mean'})\n",
    "\n",
    "# Filter out zeros or negatives\n",
    "df_heatmap = df_heatmap[df_heatmap['Enrichment_Ratio'] > 0]\n",
    "\n",
    "# Invert values between 0 and 1 for log2 enrichment, leave others unchanged\n",
    "df_heatmap['Enrichment_Ratio_transformed'] = df_heatmap['Enrichment_Ratio'].apply(\n",
    "    lambda x: 1 / x if 0 < x < 1 else x\n",
    ")\n",
    "\n",
    "# Calculate log2 enrichment from transformed values\n",
    "df_heatmap['log2_enrichment'] = df_heatmap['Enrichment_Ratio_transformed'].apply(\n",
    "    lambda x: round(np.log2(x), 3)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"Heatmap_Combined\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def generate_heatmap_per_immunization(df_subset):\n",
    "    aa_order = ['R','K','H','D','E','Q','N','S','T','Y','W','F','A','I','L','M','V','G','P','C']\n",
    "\n",
    "    for immun in df_subset['immunization'].unique():\n",
    "        df_im = df_subset[df_subset['immunization'] == immun].copy()\n",
    "\n",
    "        # Group across all barcodes\n",
    "        df_grouped = df_im.groupby(\n",
    "            ['Spike_AS_Position', 'Amino_Acid'], as_index=False\n",
    "        ).agg({'log2_enrichment': 'mean'})\n",
    "\n",
    "        pivot_df = df_grouped.pivot(index=\"Amino_Acid\", columns=\"Spike_AS_Position\", values=\"log2_enrichment\")\n",
    "\n",
    "        # Reindex rows to match AA order and drop rows with all NaNs\n",
    "        pivot_df = pivot_df.reindex(aa_order).dropna(how='all')\n",
    "\n",
    "        # Skip empty heatmaps\n",
    "        if pivot_df.dropna(how='all').empty or pivot_df.isna().all().all():\n",
    "            print(f\"Skipped empty heatmap for immunization {immun}\")\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        sns.heatmap(\n",
    "            pivot_df,\n",
    "            cmap='RdBu_r',\n",
    "            vmin=-6, vmax=6,\n",
    "            cbar_kws={'label': 'log₂ Enrichment'},\n",
    "            annot=False,\n",
    "            linewidths=0,\n",
    "            linecolor='gray'\n",
    "        )\n",
    "\n",
    "        plt.title(f\"log₂ Enrichment Heatmap - {immun}\", fontsize=18)\n",
    "        plt.xlabel('Spike AA Position', fontsize=14)\n",
    "        plt.ylabel('Mutated AA', fontsize=14)\n",
    "        plt.yticks(fontsize=8)\n",
    "\n",
    "        output_file_png = os.path.join(\n",
    "            output_dir,\n",
    "            f\"immun_{immun}_heatmap_log2_combined.png\"\n",
    "        )\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(output_file_png)\n",
    "        plt.close()\n",
    "        print(f\"Saved combined log2 heatmap for immunization {immun} to {output_file_png}\")\n",
    "\n",
    "# Generate single heatmap per sample\n",
    "generate_heatmap_per_immunization(df_heatmap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total (df_total) is complete dataframe, while df_filtered referes to aggregates dataframes; aggregated dataframes \n",
    "#are pooled/ grouped using the mean, median or sum of a category (such as the Antibody binding ratio at a certain positon\n",
    "#across all barcodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_total.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_agg = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], \n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio': 'sum'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filtered_agg.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enrichment ratios are calculated from mutation frequencies and can be split into binding and escape fraction#\n",
    "#Binding fraction includes all Er > 1 as the frequency in the droplet is higher compared to the library\n",
    "#Escape or lost fraction includes all ER<1 as the frequency in the droplet is lower compared to the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to estimate the effect across a local epitope, rollowing windows can be applied. Too large smoothing will distort the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 1  # Increased window for more smoothing (you can adjust this further)\n",
    "ENRICHMENT_THRESHOLD = 50  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] + #RBD-ACE2 interface\n",
    "    list(range(394,414)) + #R21 peptide sequence\n",
    "    list(range(484, 505)) #R13 peptide sequence\n",
    ")\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values (linear interpolation)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Ensure High_Enrichment is still boolean\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Plot with highlighted clusters\n",
    "    fig, ax = dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=f\"{immunization} (Smoothed)\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"AB binding fraction \\n Er\",\n",
    "        show_col=\"High_Enrichment\"  # Highlight high enrichment clusters\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(390, df_filtered_im['Spike_AS_Position'].max())\n",
    "\n",
    "    # Get the current visible x-range (the range of 'Spike_AS_Position' currently shown on the plot)\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "\n",
    "    # Filter data based on the visible x-range\n",
    "    filtered_data = df_filtered_im[(df_filtered_im['Spike_AS_Position'] >= x_min) & (df_filtered_im['Spike_AS_Position'] <= x_max)]\n",
    "\n",
    "    # Now, calculate y_min and y_max based only on the visible (filtered) data\n",
    "    y_min = 0  # Always start y-axis at 0\n",
    "    y_max = filtered_data['Smoothed_Enrichment'].max() +30  # Max value of the visible data\n",
    "\n",
    "    # Set the y-axis limits based on the visible data\n",
    "    ax.set_ylim(y_min, 350)\n",
    "\n",
    "    # Optionally, print the limits to check\n",
    "    print(f\"Setting y-axis limits for visible data: min={y_min}, max={y_max}\")\n",
    "\n",
    "\n",
    "    # Save the plot as a PNG\n",
    "    png_file_path = os.path.join(output_dir, f\"{immunization}_plot.png\")\n",
    "    fig.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    print(f\"Saved plot to {png_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothing with AA region = 10 & high enrichers (> 50 fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Increased window for more smoothing (you can adjust this further)\n",
    "ENRICHMENT_THRESHOLD = 50  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] + #RBD-ACE2 interface\n",
    "    list(range(394,414)) + #R21 peptide sequence\n",
    "    list(range(484, 505)) #R13 peptide sequence\n",
    ")\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values (linear interpolation)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization\n",
    "    # Reindex for visualization (ensures continuous x-axis)\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Interpolate missing values to ensure continuous line\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "    \n",
    "    # Fill remaining NaNs with 0 to avoid gaps in the plot\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(0)\n",
    "    \n",
    "    # Ensure data is sorted before plotting\n",
    "    df_filtered_im = df_filtered_im.sort_values(by='Spike_AS_Position')\n",
    "\n",
    "\n",
    "    # Ensure High_Enrichment is still boolean\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Plot with highlighted clusters\n",
    "    fig, ax = dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=f\"{immunization} (Smoothed)\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"High_Enrichment\"  # Highlight high enrichment clusters\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(390, df_filtered_im['Spike_AS_Position'].max())\n",
    "\n",
    "    # Get the current visible x-range (the range of 'Spike_AS_Position' currently shown on the plot)\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "\n",
    "    # Filter data based on the visible x-range\n",
    "    filtered_data = df_filtered_im[(df_filtered_im['Spike_AS_Position'] >= x_min) & (df_filtered_im['Spike_AS_Position'] <= x_max)]\n",
    "\n",
    "    # Now, calculate y_min and y_max based only on the visible (filtered) data\n",
    "    y_min = 0  # Always start y-axis at 0\n",
    "    y_max = filtered_data['Smoothed_Enrichment'].max() +30  # Max value of the visible data\n",
    "\n",
    "    # Set the y-axis limits based on the visible data\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Optionally, print the limits to check\n",
    "    print(f\"Setting y-axis limits for visible data: min={y_min}, max={y_max}\")\n",
    "\n",
    "\n",
    "    # Save the plot as a PNG\n",
    "    png_file_path = os.path.join(output_dir, f\"{immunization}_plot.png\")\n",
    "    fig.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    print(f\"Saved plot to {png_file_path}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Antibody-Repertoire Line plots include all droplets sequenced from a specific, sampled repertoire and their variation across droplets\n",
    "#e.g. droplets generated with an anti-SARS-CoV-2 neutralizing clone\n",
    "#Following graphs compare line profiles of the complete, sampled repertoire of different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library_ctrl refers to a second library not used in binding experiments of these repertoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering and aggregation can be included (optonal)\n",
    "#Enrichment threshold to filter out escape fraction\n",
    "#Sum aggregation to plot the total antibody ER per position (Polyreactive repertoire often show higher sum ER compared to\n",
    "#repertoire with only speific mutations enriched\n",
    "# > 331 ensures that only reads/nts with high quality (thred score) and inside the DMS library are included\n",
    "# exclude synonomous mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  \n",
    "ENRICHMENT_THRESHOLD = 50  \n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create figure and axis for combined plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Loop through immunizations and plot each one\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(f\"Processing: {immunization}\")\n",
    "\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both'\n",
    "    )\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Ensure data is sorted before plotting\n",
    "    df_filtered_im = df_filtered_im.sort_values(by='Spike_AS_Position')\n",
    "\n",
    "    # Plot on the shared axis\n",
    "    ax.plot(df_filtered_im['Spike_AS_Position'], df_filtered_im['Smoothed_Enrichment'], label=immunization, linewidth=2)\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_xlim(390, df_filtered_im['Spike_AS_Position'].max())\n",
    "ax.set_ylim(0, 450)\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"Antibody Repertoire \\n Binding\")\n",
    "ax.set_title(\"Smoothed Enrichment Across Immunizations\")\n",
    "ax.legend(title=\"Immunization\")\n",
    "\n",
    "# Save the combined plot\n",
    "png_file_path = os.path.join(output_dir, \"combined_plot.png\")\n",
    "plt.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved combined plot to {png_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Define constants\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 50  # Unused in this version but can be included for threshold filtering\n",
    "POSITION_FOR_TESTING = 450  # Position to run Kruskal-Wallis test\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Group by Position, Immunization, Barcode\n",
    "df_per_pos = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'immunization', 'barcode'],\n",
    "    as_index=False\n",
    ")['Enrichment_Ratio'].sum()\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create figure and axis for combined plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# For statistical test\n",
    "position_test_data = {}\n",
    "\n",
    "# Loop through immunizations and compute stats\n",
    "for immunization in df_per_pos['immunization'].unique():\n",
    "    print(f\"Processing: {immunization}\")\n",
    "    \n",
    "    df_im = df_per_pos[df_per_pos['immunization'] == immunization]\n",
    "\n",
    "    # Group by Spike position: mean, std, count\n",
    "    stats_df = df_im.groupby('Spike_AS_Position').agg(\n",
    "        Mean_Enrichment=('Enrichment_Ratio', 'mean'),\n",
    "        Std_Enrichment=('Enrichment_Ratio', 'std'),\n",
    "        Count=('Enrichment_Ratio', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Smooth the curves\n",
    "    stats_df['Smoothed_Mean'] = stats_df['Mean_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    stats_df['Smoothed_Std'] = stats_df['Std_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    # Interpolate missing values\n",
    "    stats_df['Smoothed_Mean'] = stats_df['Smoothed_Mean'].interpolate(method='linear', limit_direction='both')\n",
    "    stats_df['Smoothed_Std'] = stats_df['Smoothed_Std'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_stats.csv\")\n",
    "    stats_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Plot line + shaded area\n",
    "    ax.plot(stats_df['Spike_AS_Position'], stats_df['Smoothed_Mean'], label=immunization, linewidth=2)\n",
    "    ax.fill_between(\n",
    "        stats_df['Spike_AS_Position'],\n",
    "        stats_df['Smoothed_Mean'] - stats_df['Smoothed_Std'],\n",
    "        stats_df['Smoothed_Mean'] + stats_df['Smoothed_Std'],\n",
    "        alpha=0.3\n",
    "    )\n",
    "\n",
    "    # Store data for statistical testing\n",
    "    if POSITION_FOR_TESTING in stats_df['Spike_AS_Position'].values:\n",
    "        val = df_im[df_im['Spike_AS_Position'] == POSITION_FOR_TESTING]['Enrichment_Ratio'].values\n",
    "        if len(val) > 0:\n",
    "            position_test_data[immunization] = val\n",
    "\n",
    "# Formatting plot\n",
    "ax.set_xlim(390, df_per_pos['Spike_AS_Position'].max())\n",
    "ax.set_ylim(0, 220)\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"Antibody Repertoire \\n Binding\")\n",
    "ax.set_title(\"Smoothed Enrichment Across Immunizations\")\n",
    "ax.legend(title=\"Immunization\")\n",
    "\n",
    "# Save plot\n",
    "png_file_path = os.path.join(output_dir, \"combined_plot.png\")\n",
    "plt.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Saved combined plot to {png_file_path}\")\n",
    "\n",
    "# Optional: Kruskal-Wallis test at specific position\n",
    "if len(position_test_data) > 1:\n",
    "    stat, p = kruskal(*position_test_data.values())\n",
    "    print(f\"Kruskal-Wallis test at position {POSITION_FOR_TESTING}: H={stat:.3f}, p={p:.3e}\")\n",
    "else:\n",
    "    print(f\"Not enough data at position {POSITION_FOR_TESTING} for statistical testing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compare regions across antibody repertoires, clusters can be defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define cluster size\n",
    "CLUSTER_SIZE = 20\n",
    "\n",
    "# Create clusters starting from minimum position to maximum\n",
    "min_pos = df_per_pos['Spike_AS_Position'].min()\n",
    "max_pos = df_per_pos['Spike_AS_Position'].max()\n",
    "clusters = [(start, start + CLUSTER_SIZE) for start in range(min_pos, max_pos, CLUSTER_SIZE)]\n",
    "\n",
    "print(\"\\n--- Pairwise Kruskal-Wallis Tests Across Immunizations in Each Cluster ---\\n\")\n",
    "\n",
    "# Prepare output directory for cluster results\n",
    "cluster_results_dir = os.path.join(output_dir, \"cluster_stats\")\n",
    "os.makedirs(cluster_results_dir, exist_ok=True)\n",
    "\n",
    "# Store results in a CSV\n",
    "results_list = []\n",
    "\n",
    "for start, end in clusters:\n",
    "    cluster_name = f\"{start}-{end}\"\n",
    "    cluster_data = df_per_pos[\n",
    "        (df_per_pos['Spike_AS_Position'] >= start) &\n",
    "        (df_per_pos['Spike_AS_Position'] < end)\n",
    "    ]\n",
    "    \n",
    "    if cluster_data.empty:\n",
    "        continue\n",
    "\n",
    "    # Gather enrichment values by immunization for the cluster\n",
    "    cluster_grouped = defaultdict(list)\n",
    "    for immunization in cluster_data['immunization'].unique():\n",
    "        values = cluster_data[cluster_data['immunization'] == immunization]['Enrichment_Ratio'].values\n",
    "        if len(values) > 0:\n",
    "            cluster_grouped[immunization] = values\n",
    "\n",
    "    # Perform pairwise Kruskal-Wallis tests\n",
    "    for (im1, val1), (im2, val2) in combinations(cluster_grouped.items(), 2):\n",
    "        stat, p_val = kruskal(val1, val2)\n",
    "        print(f\"Cluster {cluster_name} | {im1} vs {im2}: H={stat:.3f}, p={p_val:.3e}\")\n",
    "        results_list.append({\n",
    "            'Cluster': cluster_name,\n",
    "            'Immunization_1': im1,\n",
    "            'Immunization_2': im2,\n",
    "            'H_statistic': stat,\n",
    "            'p_value': p_val\n",
    "        })\n",
    "\n",
    "# Save all pairwise test results to CSV\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv(os.path.join(cluster_results_dir, \"pairwise_kruskal_results.csv\"), index=False)\n",
    "print(f\"\\nAll pairwise test results saved to: {os.path.join(cluster_results_dir, 'pairwise_kruskal_results.csv')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Define constants\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 50  # Unused in this version but can be included for threshold filtering\n",
    "POSITION_FOR_TESTING = 450  # Position to run Kruskal-Wallis test\n",
    "CLUSTER_SIZE = 20\n",
    "CONTROL_IMMUNIZATION = \"Library_ctrl\"\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Group by Position, Immunization, Barcode\n",
    "df_per_pos = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'immunization', 'barcode'],\n",
    "    as_index=False\n",
    ")['Enrichment_Ratio'].sum()\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create figure and axis for combined plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# For statistical test at specific position\n",
    "position_test_data = {}\n",
    "\n",
    "# Loop through immunizations and compute stats\n",
    "for immunization in df_per_pos['immunization'].unique():\n",
    "    print(f\"Processing: {immunization}\")\n",
    "    \n",
    "    df_im = df_per_pos[df_per_pos['immunization'] == immunization]\n",
    "\n",
    "    # Group by Spike position: mean, std, count\n",
    "    stats_df = df_im.groupby('Spike_AS_Position').agg(\n",
    "        Mean_Enrichment=('Enrichment_Ratio', 'mean'),\n",
    "        Std_Enrichment=('Enrichment_Ratio', 'std'),\n",
    "        Count=('Enrichment_Ratio', 'count')\n",
    "    ).reset_index()\n",
    "\n",
    "    # Smooth the curves\n",
    "    stats_df['Smoothed_Mean'] = stats_df['Mean_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    stats_df['Smoothed_Std'] = stats_df['Std_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    # Interpolate missing values\n",
    "    stats_df['Smoothed_Mean'] = stats_df['Smoothed_Mean'].interpolate(method='linear', limit_direction='both')\n",
    "    stats_df['Smoothed_Std'] = stats_df['Smoothed_Std'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_stats.csv\")\n",
    "    stats_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Plot line + shaded area\n",
    "    ax.plot(stats_df['Spike_AS_Position'], stats_df['Smoothed_Mean'], label=immunization, linewidth=2)\n",
    "    ax.fill_between(\n",
    "        stats_df['Spike_AS_Position'],\n",
    "        stats_df['Smoothed_Mean'] - stats_df['Smoothed_Std'],\n",
    "        stats_df['Smoothed_Mean'] + stats_df['Smoothed_Std'],\n",
    "        alpha=0.3\n",
    "    )\n",
    "\n",
    "    # Store data for statistical testing at specific position\n",
    "    if POSITION_FOR_TESTING in stats_df['Spike_AS_Position'].values:\n",
    "        val = df_im[df_im['Spike_AS_Position'] == POSITION_FOR_TESTING]['Enrichment_Ratio'].values\n",
    "        if len(val) > 0:\n",
    "            position_test_data[immunization] = val\n",
    "\n",
    "# --- Add Cluster-Based Annotations and Significance Testing ---\n",
    "\n",
    "def get_significance_stars(p):\n",
    "    if p < 1e-5:\n",
    "        return \"****\"\n",
    "    elif p < 1e-4:\n",
    "        return \"***\"\n",
    "    elif p < 1e-3:\n",
    "        return \"**\"\n",
    "    elif p < 0.01:\n",
    "        return \"*\"\n",
    "    else:\n",
    "        return \"n.s.\"\n",
    "\n",
    "# Define clusters\n",
    "min_pos = 390\n",
    "max_pos = df_per_pos['Spike_AS_Position'].max()\n",
    "clusters = [(start, start + CLUSTER_SIZE) for start in range(min_pos, max_pos, CLUSTER_SIZE)]\n",
    "\n",
    "for start, end in clusters:\n",
    "    cluster_mid = (start + end) / 2\n",
    "    ax.axvline(x=start, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Extract cluster data\n",
    "    cluster_data = df_per_pos[\n",
    "        (df_per_pos['Spike_AS_Position'] >= start) &\n",
    "        (df_per_pos['Spike_AS_Position'] < end)\n",
    "    ]\n",
    "    if cluster_data.empty:\n",
    "        continue\n",
    "\n",
    "    # Gather values by immunization\n",
    "    immunization_values = {}\n",
    "    for immunization in cluster_data['immunization'].unique():\n",
    "        values = cluster_data[cluster_data['immunization'] == immunization]['Enrichment_Ratio'].values\n",
    "        if len(values) > 0:\n",
    "            immunization_values[immunization] = values\n",
    "\n",
    "    # Compare each immunization to control\n",
    "    if CONTROL_IMMUNIZATION in immunization_values:\n",
    "        control_vals = immunization_values[CONTROL_IMMUNIZATION]\n",
    "        for immunization, vals in immunization_values.items():\n",
    "            if immunization == CONTROL_IMMUNIZATION:\n",
    "                continue\n",
    "            stat, p_val = kruskal(control_vals, vals)\n",
    "            stars = get_significance_stars(p_val)\n",
    "\n",
    "            # Determine annotation height\n",
    "            cluster_max = cluster_data['Enrichment_Ratio'].max()\n",
    "            y_pos = min(cluster_max + 10, ax.get_ylim()[1] - 5)\n",
    "\n",
    "            # Annotate\n",
    "            ax.text(\n",
    "                cluster_mid, y_pos, stars,\n",
    "                ha='center', va='bottom', fontsize=9,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.2\", edgecolor='none', facecolor='white', alpha=0.6)\n",
    "            )\n",
    "\n",
    "# --- Final Plot Formatting and Save ---\n",
    "ax.set_xlim(390, df_per_pos['Spike_AS_Position'].max())\n",
    "ax.set_ylim(0, 220)\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"AB Repertoire (all droplets) \\n\")\n",
    "ax.set_title(\"Smoothed Enrichment Across Immunizations\")\n",
    "ax.legend(title=\"Immunization\")\n",
    "\n",
    "# Save plot\n",
    "png_file_path = os.path.join(output_dir, \"combined_plot.png\")\n",
    "plt.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Saved combined plot to {png_file_path}\")\n",
    "\n",
    "# Optional: Kruskal-Wallis test at specific position\n",
    "if len(position_test_data) > 1:\n",
    "    stat, p = kruskal(*position_test_data.values())\n",
    "    print(f\"Kruskal-Wallis test at position {POSITION_FOR_TESTING}: H={stat:.3f}, p={p:.3e}\")\n",
    "else:\n",
    "    print(f\"Not enough data at position {POSITION_FOR_TESTING} for statistical testing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  \n",
    "ENRICHMENT_THRESHOLD = 50  \n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create figure and axis for combined plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Loop through immunizations and plot each one\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == \"Library_ctrl\":\n",
    "        continue  # Skip this sample\n",
    "\n",
    "    print(f\"Processing: {immunization}\")\n",
    "\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both'\n",
    "    )\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Ensure data is sorted before plotting\n",
    "    df_filtered_im = df_filtered_im.sort_values(by='Spike_AS_Position')\n",
    "\n",
    "    # Plot on the shared axis\n",
    "    ax.plot(df_filtered_im['Spike_AS_Position'], df_filtered_im['Smoothed_Enrichment'], label=immunization, linewidth=2)\n",
    "\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_xlim(390, df_filtered_im['Spike_AS_Position'].max())\n",
    "ax.set_ylim(0, 450)\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"AB Repertoire (all droplets) \\n \")\n",
    "ax.set_title(\"Smoothed Enrichment Across Immunizations\")\n",
    "ax.legend(title=\"Immunization\")\n",
    "\n",
    "# Save the combined plot\n",
    "png_file_path = os.path.join(output_dir, \"combined_plot.png\")\n",
    "plt.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved combined plot to {png_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "# Constants\n",
    "ROLLING_WINDOW = 10\n",
    "ENRICHMENT_THRESHOLD = 1\n",
    "CONTROL_IMMUNIZATION = \"Library_ctrl\"\n",
    "CLUSTER_SIZE = 20\n",
    "MIN_POS = 390\n",
    "\n",
    "# Label abbreviations\n",
    "IMMUNIZATION_LABELS = {\n",
    "    \"Polyclonal_Ab\": \"P\",\n",
    "    \"Neutralizing_Ab\": \"N\",\n",
    "    \"wildtype_RBD\": \"WT\",\n",
    "    \"Mutant_RBD\": \"MUT\"\n",
    "}\n",
    "\n",
    "# Color map\n",
    "color_map = {\n",
    "    \"Polyclonal_Ab\": \"red\",\n",
    "    \"Neutralizing_Ab\": \"orange\",\n",
    "    \"Mutant_RBD\": \"blue\",\n",
    "    \"wildtype_RBD\": \"green\"\n",
    "}\n",
    "\n",
    "# Filter and aggregate\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 364) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "df_filtered_agg = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ")['Enrichment_Ratio'].sum()\n",
    "\n",
    "# Output dir\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Store smoothed data\n",
    "smoothed_data = {}\n",
    "\n",
    "# Process each immunization\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == CONTROL_IMMUNIZATION:\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {immunization}\")\n",
    "    color = color_map.get(immunization, \"black\")\n",
    "\n",
    "    df_im = df_filtered_agg[df_filtered_agg['immunization'] == immunization]\n",
    "    df_im_grouped = df_im.groupby('Spike_AS_Position', as_index=False)['Enrichment_Ratio'].sum()\n",
    "    df_im_grouped['Smoothed_Enrichment'] = df_im_grouped['Enrichment_Ratio'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean().interpolate(method='linear', limit_direction='both')\n",
    "    df_im_grouped = df_im_grouped.sort_values(by='Spike_AS_Position')\n",
    "\n",
    "    df_im_grouped.to_csv(os.path.join(output_dir, f\"{immunization}_data.csv\"), index=False)\n",
    "\n",
    "    ax.plot(df_im_grouped['Spike_AS_Position'], df_im_grouped['Smoothed_Enrichment'],\n",
    "            label=immunization, color=color, linewidth=2)\n",
    "\n",
    "    smoothed_data[immunization] = df_im_grouped\n",
    "\n",
    "# Control group\n",
    "df_ctrl = df_filtered_agg[df_filtered_agg['immunization'] == CONTROL_IMMUNIZATION]\n",
    "df_ctrl_grouped = df_ctrl.groupby('Spike_AS_Position', as_index=False)['Enrichment_Ratio'].sum()\n",
    "\n",
    "# Cluster ranges\n",
    "max_pos = df_filtered_agg['Spike_AS_Position'].max()\n",
    "clusters = [(start, start + CLUSTER_SIZE) for start in range(MIN_POS, max_pos, CLUSTER_SIZE)]\n",
    "\n",
    "def get_significance_stars(p):\n",
    "    if p < 1e-5: return \"****\"\n",
    "    elif p < 1e-4: return \"***\"\n",
    "    elif p < 1e-3: return \"**\"\n",
    "    elif p < 0.01: return \"*\"\n",
    "    else: return \"n.s.\"\n",
    "\n",
    "# Statistical output\n",
    "print(\"\\n=== Statistical Comparison Summary ===\")\n",
    "print(\"Cluster\\tGroup\\tMean\\tStd\\tN\\tvs Library Mean\\tLibrary Std\\tLibrary N\\tp-value\\tStars\")\n",
    "\n",
    "for start, end in clusters:\n",
    "    cluster_mid = (start + end) / 2\n",
    "    ax.axvline(x=start, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    ctrl_vals = df_ctrl_grouped[\n",
    "        (df_ctrl_grouped['Spike_AS_Position'] >= start) &\n",
    "        (df_ctrl_grouped['Spike_AS_Position'] < end)\n",
    "    ]['Enrichment_Ratio'].values\n",
    "\n",
    "    if len(ctrl_vals) == 0:\n",
    "        continue\n",
    "\n",
    "    annotation_idx = 0\n",
    "    for immunization in IMMUNIZATION_LABELS.keys():\n",
    "        df_group = df_filtered_agg[\n",
    "            (df_filtered_agg['immunization'] == immunization) &\n",
    "            (df_filtered_agg['Spike_AS_Position'] >= start) &\n",
    "            (df_filtered_agg['Spike_AS_Position'] < end)\n",
    "        ]\n",
    "        group_vals = df_group['Enrichment_Ratio'].values\n",
    "\n",
    "        if len(group_vals) == 0:\n",
    "            continue\n",
    "\n",
    "        # Stats\n",
    "        stat, p_val = kruskal(ctrl_vals, group_vals)\n",
    "        stars = get_significance_stars(p_val)\n",
    "        label = IMMUNIZATION_LABELS[immunization]\n",
    "        y_pos = 390 - 10 * annotation_idx\n",
    "\n",
    "        # Text annotation\n",
    "        ax.text(cluster_mid, y_pos, f\"{label}: {stars}\",\n",
    "                ha='center', va='bottom', fontsize=8,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.2\", edgecolor='none', facecolor='white', alpha=0.6))\n",
    "\n",
    "        # Print comparison info\n",
    "        print(f\"{start}-{end}\\t{label}\\t\"\n",
    "              f\"{np.mean(group_vals):.1f}\\t{np.std(group_vals):.1f}\\t{len(group_vals)}\\t\"\n",
    "              f\"{np.mean(ctrl_vals):.1f}\\t{np.std(ctrl_vals):.1f}\\t{len(ctrl_vals)}\\t\"\n",
    "              f\"{p_val:.2e}\\t{stars}\")\n",
    "\n",
    "        annotation_idx += 1\n",
    "\n",
    "# Plot format\n",
    "ax.set_xlim(390, max_pos)\n",
    "ax.set_ylim(0, 600)\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"Er Ratio for (total) Ab repertoire \\n Binding fraction\")\n",
    "ax.set_title(\"Smoothed Enrichment Across Immunizations\")\n",
    "\n",
    "# Legend outside\n",
    "ax.legend(title=\"Immunization\", loc='upper left', bbox_to_anchor=(1.02, 1), borderaxespad=0.)\n",
    "\n",
    "# Save\n",
    "png_file_path = \"/Users/lucaschlotheuber/Desktop/combined_plot_with_area_colored.png\"\n",
    "plt.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Saved plot to: {png_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10\n",
    "ENRICHMENT_THRESHOLD = 1\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create figure and axis for combined plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define color map for immunization types\n",
    "color_map = {\n",
    "    \"Polyclonal_Ab\": \"red\", \n",
    "    \"Neutralizing_Ab\": \"orange\", \n",
    "    \"Mutant_RBD\": \"blue\", \n",
    "    \"wildtype_RBD\": \"green\"\n",
    "}\n",
    "\n",
    "# Loop through immunizations and plot each one, excluding \"Library_ctrl\"\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == \"Library_ctrl\":\n",
    "        continue  # Skip this sample\n",
    "\n",
    "    # Get the color based on immunization type\n",
    "    color = color_map.get(immunization, \"black\")  # Default to black if immunization type is unknown\n",
    "\n",
    "    print(f\"Processing: {immunization}\")\n",
    "\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both'\n",
    "    )\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Ensure data is sorted before plotting\n",
    "    df_filtered_im = df_filtered_im.sort_values(by='Spike_AS_Position')\n",
    "\n",
    "    # Plot line and fill the area under the line with the assigned color\n",
    "    # Replace non-positive values to avoid log2 issues\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].clip(lower=1e-5)\n",
    "    \n",
    "    # Apply log2 transform\n",
    "    df_filtered_im['Log2_Smoothed_Enrichment'] = np.log2(df_filtered_im['Smoothed_Enrichment'])\n",
    "    \n",
    "    # Plot the log2-transformed enrichment\n",
    "    ax.plot(df_filtered_im['Spike_AS_Position'], df_filtered_im['Log2_Smoothed_Enrichment'], label=immunization, color=color, linewidth=2)\n",
    "\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_xlim(390, df_filtered_im['Spike_AS_Position'].max())\n",
    "ax.set_ylim(2.4, 9)\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"Antibody Repertoire \\n Binding\")\n",
    "ax.set_title(\"Smoothed Enrichment Across Immunizations\")\n",
    "ax.legend(title=\"Immunization\")\n",
    "\n",
    "# Save the combined plot\n",
    "png_file_path = \"/Users/lucaschlotheuber/Desktop/combined_plot_with_area_colored.png\"\n",
    "plt.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f\"Saved combined plot to {png_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inversion can help visualize escape fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 50  \n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Inverting the Enrichment_Ratio to calculate escape (Escape = 1 / Enrichment_Ratio)\n",
    "df_filtered_agg['Escape_Ratio'] = df_filtered_agg['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create figure and axis for combined plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define color map for immunization types\n",
    "color_map = {\n",
    "    \"Polyclonal_Ab\": \"red\", \n",
    "    \"Neutralizing_Ab\": \"orange\", \n",
    "    \"Mutant_RBD\": \"blue\", \n",
    "    \"wildtype_RBD\": \"green\"\n",
    "}\n",
    "\n",
    "# Loop through immunizations and plot each one, excluding \"Library_ctrl\"\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == \"Library_ctrl\":\n",
    "        continue  # Skip this sample\n",
    "\n",
    "    # Get the color based on immunization type\n",
    "    color = color_map.get(immunization, \"black\")  # Default to black if immunization type is unknown\n",
    "\n",
    "    print(f\"Processing: {immunization}\")\n",
    "\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate escape ratios at each position (this will use the Escape_Ratio instead of Enrichment_Ratio)\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({'Escape_Ratio': 'mean'})\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Escape'] = df_filtered_im['Escape_Ratio'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values\n",
    "    df_filtered_im['Smoothed_Escape'] = df_filtered_im['Smoothed_Escape'].interpolate(\n",
    "        method='linear', limit_direction='both'\n",
    "    )\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_escape_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Ensure data is sorted before plotting\n",
    "    df_filtered_im = df_filtered_im.sort_values(by='Spike_AS_Position')\n",
    "\n",
    "    # Plot line and fill the area under the line with the assigned color\n",
    "    ax.plot(df_filtered_im['Spike_AS_Position'], df_filtered_im['Smoothed_Escape'], label=immunization, color=color, linewidth=2)\n",
    "    ax.fill_between(df_filtered_im['Spike_AS_Position'], 0, df_filtered_im['Smoothed_Escape'], color=color, alpha=0.3)\n",
    "\n",
    "# Formatting the plot\n",
    "ax.set_xlim(390, df_filtered_im['Spike_AS_Position'].max())\n",
    "ax.set_ylim(0, 15)  # Adjust this based on your data range for escape\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"Antibody Escape\")\n",
    "ax.set_title(\"Smoothed Escape Across Immunizations\")\n",
    "ax.legend(title=\"Immunization\")\n",
    "\n",
    "# Save the combined plot\n",
    "png_file_path = os.path.join(output_dir, \"combined_escape_plot_with_area_colored.png\")\n",
    "plt.savefig(png_file_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Saved combined escape plot to {png_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single cell/antibody plots can also be generated and compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Increased window for more smoothing (you can adjust this further)\n",
    "ENRICHMENT_THRESHOLD = 0.8  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position and barcode\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface according to article\n",
    "    list(range(394,414)) +  # R21 peptide sequence with high affinity\n",
    "    list(range(484, 505))  # R13 peptide sequence with high affinity\n",
    ")\n",
    "print(f\"Sites to show: {sites_to_show}\")\n",
    "print(df_filtered_agg.columns)  \n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(df_filtered_agg[['Spike_AS_Position', 'site_label', 'show_site']].head(20))\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "    print(df_filtered_im.head())  # Check if data exists before plotting\n",
    "    print(df_filtered_im.columns)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    print(\"Unique barcodes:\", df_filtered_im['barcode'].unique())  # Check if barcode values are correct\n",
    "\n",
    "\n",
    "        # Aggregate enrichment ratios at each position (across all barcodes)\n",
    "    df_grouped = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum'\n",
    "    })\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_grouped['Smoothed_Enrichment'] = df_grouped['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data by interpolating\n",
    "    df_grouped['Smoothed_Enrichment'] = df_grouped['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Plot the smoothed, summed enrichment\n",
    "    ax.plot(df_grouped['Spike_AS_Position'], df_grouped['Smoothed_Enrichment'], label=f'{immunization} Total', color='black', lw=2)\n",
    "\n",
    "\n",
    "# Formatting the shared plot\n",
    "ax.set_title(\"Antibody Repertoire Binding Across Immunizations\")\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"Antibody Repertoire \\n binding\")\n",
    "ax.legend()\n",
    "ax.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "ax.set_xlim(350, df_filtered_agg['Spike_AS_Position'].max())\n",
    "ax.set_ylim(0, 400)\n",
    "\n",
    "# Save single combined plot\n",
    "plt.tight_layout()\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop/\", \"Combined_Immunizations_Plot.png\")\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per barcode plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# Enable inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Adjust for more smoothing\n",
    "ENRICHMENT_THRESHOLD = 50  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position and barcode\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"barcode_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each barcode\n",
    "for barcode in df_filtered_agg['barcode'].unique():\n",
    "    print(f\"Processing barcode: {barcode}\")\n",
    "    df_filtered_bc = df_filtered_agg[df_filtered_agg['barcode'] == barcode]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    for immunization in df_filtered_bc['immunization'].unique():\n",
    "        df_filtered_im = df_filtered_bc[df_filtered_bc['immunization'] == immunization]\n",
    "\n",
    "        # Aggregate enrichment ratios at each position\n",
    "        df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "            'Enrichment_Ratio': 'sum',\n",
    "        })\n",
    "\n",
    "        # Apply rolling mean for smoothing\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "        # Handle missing data by interpolating missing values\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # Plot each immunization as a separate line\n",
    "        ax.plot(df_filtered_im['Spike_AS_Position'], df_filtered_im['Smoothed_Enrichment'], label=f'Immunization {immunization}', alpha=0.7)\n",
    "\n",
    "    # Formatting plot\n",
    "    ax.set_title(f\"Barcode {barcode}\")\n",
    "    ax.set_xlabel(\"Spike AA Position\")\n",
    "    ax.set_ylabel(\"Antibody Repertoire \\n Binding\")\n",
    "\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "    ax.set_xlim(350, df_filtered_bc['Spike_AS_Position'].max())\n",
    "\n",
    "    # Save plot\n",
    "    plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\", f\"Barcode_{barcode}_plot.png\")\n",
    "    fig.savefig(plot_file_path, format='png')\n",
    "    \n",
    "    # Show the plot inline in Jupyter\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import interpolate\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 5  # Increased window for more smoothing (you can adjust this further)\n",
    "ENRICHMENT_THRESHOLD = 0.8  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] + #RBD-ACE2 interface\n",
    "    list(range(394,414)) + #R21 peptide sequence\n",
    "    list(range(484, 505)) #R13 peptide sequence\n",
    ")\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values (linear interpolation)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Ensure High_Enrichment is still boolean\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Plot with highlighted clusters\n",
    "    fig, ax = dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=f\"{immunization} (Smoothed)\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"High_Enrichment\"  # Highlight high enrichment clusters\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(420, df_filtered_im['Spike_AS_Position'].max())\n",
    "\n",
    "    # Get the current visible x-range (the range of 'Spike_AS_Position' currently shown on the plot)\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "\n",
    "    # Filter data based on the visible x-range\n",
    "    filtered_data = df_filtered_im[(df_filtered_im['Spike_AS_Position'] >= x_min) & (df_filtered_im['Spike_AS_Position'] <= x_max)]\n",
    "\n",
    "    # Now, calculate y_min and y_max based only on the visible (filtered) data\n",
    "    y_min = 0  # Always start y-axis at 0\n",
    "    y_max = filtered_data['Smoothed_Enrichment'].max()  # Max value of the visible data\n",
    "\n",
    "    # Set the y-axis limits based on the visible data\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Optionally, print the limits to check\n",
    "    print(f\"Setting y-axis limits for visible data: min={y_min}, max={y_max}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 20  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0.8  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values (linear interpolation)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization (after interpolation to avoid issues)\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Ensure High_Enrichment is still boolean\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Plot with highlighted clusters\n",
    "    fig, ax = dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=f\"{immunization} (Smoothed)\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"High_Enrichment\"  # Highlight high enrichment clusters\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(420, df_filtered_im['Spike_AS_Position'].max())\n",
    "\n",
    "    # Get the current visible x-range (the range of 'Spike_AS_Position' currently shown on the plot)\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "\n",
    "    # Filter data based on the visible x-range\n",
    "    filtered_data = df_filtered_im[(df_filtered_im['Spike_AS_Position'] >= x_min) & (df_filtered_im['Spike_AS_Position'] <= x_max)]\n",
    "\n",
    "    # Now, calculate y_min and y_max based only on the visible (filtered) data\n",
    "    y_min = 0  # Always start y-axis at 0\n",
    "    y_max = filtered_data['Smoothed_Enrichment'].max()  # Max value of the visible data\n",
    "\n",
    "    # Set the y-axis limits based on the visible data\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Optionally, print the limits to check\n",
    "    print(f\"Setting y-axis limits for visible data: min={y_min}, max={y_max}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unseparated, overlayed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# Enable inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Adjust for more smoothing\n",
    "ENRICHMENT_THRESHOLD = 50  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position and barcode\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Separate plotting for overlay by immunization condition\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(f\"Processing immunization: {immunization}\")\n",
    "    df_filtered_im = df_filtered_agg[df_filtered_agg['immunization'] == immunization]\n",
    "\n",
    "    # Create a new figure for this immunization condition\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Plot each barcode as a separate line for this immunization condition\n",
    "    for barcode in df_filtered_im['barcode'].unique():\n",
    "        df_filtered_barcode = df_filtered_im[df_filtered_im['barcode'] == barcode]\n",
    "\n",
    "        # Aggregate enrichment ratios at each position\n",
    "        df_filtered_barcode = df_filtered_barcode.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "            'Enrichment_Ratio': 'sum',\n",
    "        })\n",
    "\n",
    "        # Apply rolling mean for smoothing\n",
    "        df_filtered_barcode['Smoothed_Enrichment'] = df_filtered_barcode['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "        # Handle missing data by interpolating missing values\n",
    "        df_filtered_barcode['Smoothed_Enrichment'] = df_filtered_barcode['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # Plot each barcode as a separate line\n",
    "        ax.plot(df_filtered_barcode['Spike_AS_Position'], df_filtered_barcode['Smoothed_Enrichment'], \n",
    "                label=f'Barcode {barcode}', alpha=0.7)\n",
    "\n",
    "    # Formatting plot\n",
    "    ax.set_title(f\"{immunization}\")\n",
    "    ax.set_xlabel(\"Spike AA Position\")\n",
    "    ax.set_ylabel(\"Antibody Repertoire \\n Binding\")\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "    ax.set_xlim(350, df_filtered_im['Spike_AS_Position'].max())\n",
    "\n",
    "    # Automatically adjust Y-axis to fit the data range\n",
    "    ax.relim()  # Recalculate limits based on the data\n",
    "    ax.autoscale_view()  # Automatically adjust the view\n",
    "\n",
    "    # Save plot\n",
    "    plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\", f\"{immunization}_overlay_plot.png\")\n",
    "    fig.savefig(plot_file_path, format='png')\n",
    "    \n",
    "    # Show the plot inline in Jupyter\n",
    "    plt.show()\n",
    "\n",
    "    # Close the plot to free memory\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 20  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'darkblue',\n",
    "    'Mutant_RBD': '#004c4c'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':  # Skip 'Library_ctrl'\n",
    "        continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    # Count unique barcodes and amino acids per position\n",
    "    df_counts = df_filtered_im.groupby('Spike_AS_Position').agg({\n",
    "        'barcode': pd.Series.nunique,\n",
    "        'Amino_Acid': pd.Series.nunique\n",
    "    }).rename(columns={'barcode': 'num_barcodes', 'Amino_Acid': 'num_amino_acids'})\n",
    "    \n",
    "    # Aggregate enrichment\n",
    "    df_sum = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "    \n",
    "    # Merge and normalize\n",
    "    df_filtered_im = df_sum.merge(df_counts, left_on='Spike_AS_Position', right_index=True)\n",
    "    df_filtered_im['Enrichment_Ratio'] = (\n",
    "        df_filtered_im['Enrichment_Ratio'] /\n",
    "        df_filtered_im['num_barcodes']\n",
    "    ) * df_filtered_im['num_amino_acids']\n",
    "\n",
    "    if df_filtered_im['Enrichment_Ratio'].isna().any():\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values (linear interpolation)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization (after interpolation to avoid issues)\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    print(f\"Target sites to highlight: {list(sites_to_show)}\")\n",
    "\n",
    "    # Check the data type of Spike_AS_Position and sites_to_show for comparison\n",
    "    print(f\"Data type of 'Spike_AS_Position': {df_filtered_agg['Spike_AS_Position'].dtype}\")\n",
    "    print(f\"Data type of 'sites_to_show': {type(sites_to_show)}\")\n",
    "\n",
    "    # Ensure High_Enrichment is still boolean\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "    # Use dmslogo.line.draw_line but plot on the same axes with specified color\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",  # Remove individual titles for each plot\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"show_site\",  # Highlight high enrichment clusters\n",
    "        ax=ax,  # Pass the same axes object for all plots\n",
    "        linewidth=2.5,\n",
    "        color=color_map.get(immunization, 'black')  # Get the color for the immunization (default to black)\n",
    "    )\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        # Use ax.hlines to draw horizontal lines only where there are sites to show\n",
    "        ax.hlines(\n",
    "            y=0,  # Set the y-position of the line to 0 (or a small value near the bottom of the plot)\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,  # Start of the line (slightly before the site)\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,  # End of the line (slightly after the site)\n",
    "            color='black',  # Line color\n",
    "            linestyle='-',  # Line style\n",
    "            linewidth=10  # Line width\n",
    "        )\n",
    "\n",
    "# Set the y-axis limit to 200\n",
    "ax.set_ylim(0, 400\n",
    "           )\n",
    "\n",
    "# After all lines are drawn, adjust plot settings\n",
    "plt.title('Smoothed Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Antibody Repertoire - Enrichment \\n (PerCell Polyreactivity)', fontsize=16)\n",
    "\n",
    "# Add the legend in the top right\n",
    "# Create a grouped legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# Group the legend as required\n",
    "group_1_labels = ['Polyclonal_Ab', 'Neutralizing_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles\n",
    "labels = group_1_labels + group_2_labels\n",
    "\n",
    "# Add the legend to the top right\n",
    "plt.legend(handles, labels, title=\"Single Droplet Repertoire\", loc='upper center', fontsize=11, frameon=False, handlelength=2, handleheight=1, title_fontsize=11, markerscale=8)\n",
    "\n",
    "# Set the x-axis ticks explicitly to 20 ticks across the range, and label every other one\n",
    "xticks = np.linspace(df_filtered_agg['Spike_AS_Position'].min(), df_filtered_agg['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "\n",
    "# Set the labels to only show for every other tick\n",
    "ax.set_xticklabels([str(x) if i % 2 == 0 else '' for i, x in enumerate(xticks)])\n",
    "\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, prune='lower', nbins=8))\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line3_plot.png\")\n",
    "fig.tight_layout() \n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 20\n",
    "ENRICHMENT_THRESHOLD = 1\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +\n",
    "    list(range(394,414)) +\n",
    "    list(range(484, 505))\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'darkblue',\n",
    "    'Mutant_RBD': '#004c4c'\n",
    "}\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    df_counts = df_filtered_im.groupby('Spike_AS_Position').agg({\n",
    "        'barcode': pd.Series.nunique,\n",
    "        'Amino_Acid': pd.Series.nunique\n",
    "    }).rename(columns={'barcode': 'num_barcodes', 'Amino_Acid': 'num_amino_acids'})\n",
    "    \n",
    "    df_sum = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "    \n",
    "    df_filtered_im = df_sum.merge(df_counts, left_on='Spike_AS_Position', right_index=True)\n",
    "    df_filtered_im['Enrichment_Ratio'] = (\n",
    "        df_filtered_im['Enrichment_Ratio'] /\n",
    "        df_filtered_im['num_barcodes']\n",
    "    ) * df_filtered_im['num_amino_acids']\n",
    "\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(f\"Target sites to highlight: {list(sites_to_show)}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2.5,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0,\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=10\n",
    "        )\n",
    "\n",
    "ax.set_ylim(0, 400)\n",
    "plt.title('Smoothed Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Antibody Repertoire - Enrichment \\n (PerCell Polyreactivity)', fontsize=16)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "group_1_labels = ['Polyclonal_Ab', 'Neutralizing_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "handles = group_1_handles + group_2_handles\n",
    "labels = group_1_labels + group_2_labels\n",
    "\n",
    "plt.legend(handles, labels, title=\"Single Droplet Repertoire\", loc='upper center', fontsize=11, frameon=False, handlelength=2, handleheight=1, title_fontsize=11, markerscale=8)\n",
    "\n",
    "# Full x-axis labels shown\n",
    "xticks = np.linspace(df_filtered_agg['Spike_AS_Position'].min(), df_filtered_agg['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels([str(x) for x in xticks])\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, prune='lower', nbins=8))\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line3_plot.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want the min/max of the raw filtered Enrichment_Ratio:\n",
    "print(\"Raw filtered enrichment min/max:\",\n",
    "      df_filtered['Enrichment_Ratio'].min(),\n",
    "      df_filtered['Enrichment_Ratio'].max())\n",
    "\n",
    "# Or, after you’ve aggregated by position (summing barcodes), use:\n",
    "agg = df_filtered_agg.groupby('Spike_AS_Position')['Enrichment_Ratio'].sum()\n",
    "print(\"Aggregated enrichment min/max:\",\n",
    "      agg.min(),\n",
    "      agg.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To analyse Binding Fraction (RBD Variants e.g. Y501 RBD increased in frequency after antibody binding in comparison to escape fraction (RBD variants disappearing from the pool of variants, escaped from binding), split Er values and plot separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Parameters\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Sites to highlight\n",
    "sites_to_show = list(map(str,\n",
    "    [455,456,472,473,484,485,486,490,496,499] +\n",
    "    list(range(394,414)) + list(range(484,505))\n",
    "))\n",
    "df_filtered = df_filtered.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Precompute global max of the POSITION‐MEDIAN binding values (>1)\n",
    "binding_meds = []\n",
    "for imm in df_filtered['immunization'].unique():\n",
    "    if imm == 'Library_ctrl': continue\n",
    "    sub = df_filtered[df_filtered['immunization']==imm]\n",
    "    med_series = sub[sub['Enrichment_Ratio']>1] \\\n",
    "                   .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "                   .median()\n",
    "    if not med_series.empty:\n",
    "        binding_meds.append(med_series.max())\n",
    "global_binding_max = max(binding_meds) if binding_meds else 2.0\n",
    "\n",
    "# Set up plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "color_map = {\n",
    "    'Polyclonal_Ab':'darkorange',\n",
    "    'Neutralizing_Ab':'red',\n",
    "    'wildtype_RBD':'darkblue',\n",
    "    'Mutant_RBD':'#004c4c'\n",
    "}\n",
    "\n",
    "for immunization in df_filtered['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    sub = df_filtered[df_filtered['immunization']==immunization]\n",
    "\n",
    "    # 1) median per position\n",
    "    esc = sub[sub['Enrichment_Ratio']<=1] \\\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "        .median()\n",
    "    bind = sub[sub['Enrichment_Ratio']>1] \\\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "        .median()\n",
    "\n",
    "    if esc.empty and bind.empty:\n",
    "        continue\n",
    "\n",
    "    # 2) smooth\n",
    "    esc = esc.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    bind = bind.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # 3) transform with three branches\n",
    "    def transform_val(y):\n",
    "        if y < 1:\n",
    "            return -(1 - y)          # 0 ≤ y < 1 → –(1–y)\n",
    "        elif y == 1:\n",
    "            return 0                 # y == 1 → 0\n",
    "        else:\n",
    "            return np.log10(y) / np.log10(2000)\n",
    "\n",
    "    esc_t  = esc.apply(transform_val)\n",
    "    bind_t = bind.apply(transform_val)\n",
    "\n",
    "    # 4) determine x range\n",
    "    positions = sorted(set(esc_t.index).union(bind_t.index))\n",
    "    pos_min, pos_max = positions[0], positions[-1]\n",
    "    idx = np.arange(pos_min, pos_max + 1)\n",
    "\n",
    "    # 5) assemble df_plot\n",
    "    df_plot = pd.DataFrame({'Spike_AS_Position': idx}).set_index('Spike_AS_Position')\n",
    "    df_plot['Escape']  = esc_t.reindex(idx, fill_value=0)\n",
    "    df_plot['Binding'] = bind_t.reindex(idx, fill_value=0)\n",
    "    df_plot = df_plot.reset_index()\n",
    "\n",
    "    # 6) save CSV\n",
    "    df_plot.to_csv(os.path.join(output_dir, f\"{immunization}_median_plot_data.csv\"),\n",
    "                   index=False)\n",
    "\n",
    "\n",
    "    # 7) plot as dots\n",
    "    ax.scatter(df_plot['Spike_AS_Position'], df_plot['Escape'],\n",
    "               color=color_map.get(immunization), s=10, label=f\"{immunization} escape\", alpha=0.8)\n",
    "    \n",
    "    ax.scatter(df_plot['Spike_AS_Position'], df_plot['Binding'],\n",
    "               color=color_map.get(immunization), s=10, label=f\"{immunization} binding\", marker='x', alpha=0.8)\n",
    "\n",
    "\n",
    "    # 8) highlight\n",
    "    for pos in df_plot.loc[\n",
    "        df_plot['Spike_AS_Position'].astype(str).isin(sites_to_show),\n",
    "        'Spike_AS_Position'\n",
    "    ]:\n",
    "        ax.hlines(y=-1, xmin=pos-0.5, xmax=pos+0.5,\n",
    "                  color='black', linewidth=10)\n",
    "\n",
    "# Final formatting\n",
    "ax.set_ylim(-1, 0.5)\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "plt.title('', fontsize=14)\n",
    "ax.set_xlabel('Spike AA Position', fontsize=16)\n",
    "ax.set_ylabel('Antibody Binding', fontsize=16)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "unique = dict(zip(labels, handles))  # deduplicate\n",
    "ax.legend(unique.values(), unique.keys(),\n",
    "          loc='center left', bbox_to_anchor=(1.01, 0.5),\n",
    "          frameon=False, fontsize=10)\n",
    "# X-ticks\n",
    "xt = np.linspace(df_filtered['Spike_AS_Position'].min(),\n",
    "                 df_filtered['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xt)\n",
    "ax.set_xticklabels([str(x) for x in xt])\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(nbins=9, prune='both'))\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(r\"/Users/lucaschlotheuber/Desktop\", \"escape_binding_plot.png\"),\n",
    "            dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Parameters\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Sites to highlight\n",
    "sites_to_show = list(map(str,\n",
    "    [455,456,472,473,484,485,486,490,496,499] +\n",
    "    list(range(394,414)) + list(range(484,505))\n",
    "))\n",
    "df_filtered = df_filtered.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define plotting function\n",
    "def plot_by_subset(sub_df, title, filename):\n",
    "    # Precompute global max of the POSITION‐MEDIAN binding values (>1)\n",
    "    binding_meds = []\n",
    "    for imm in sub_df['immunization'].unique():\n",
    "        if imm == 'Library_ctrl': continue\n",
    "        sub = sub_df[sub_df['immunization']==imm]\n",
    "        med_series = sub[sub['Enrichment_Ratio']>1] \\\n",
    "                       .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "                       .median()\n",
    "        if not med_series.empty:\n",
    "            binding_meds.append(med_series.max())\n",
    "    global_binding_max = max(binding_meds) if binding_meds else 2.0\n",
    "\n",
    "    # Set up plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    color_map = {\n",
    "        'Polyclonal_Ab':'darkorange',\n",
    "        'Neutralizing_Ab':'red',\n",
    "        'wildtype_RBD':'darkblue',\n",
    "        'Mutant_RBD':'#004c4c'\n",
    "    }\n",
    "\n",
    "    for immunization in sub_df['immunization'].unique():\n",
    "        if immunization == 'Library_ctrl':\n",
    "            continue\n",
    "\n",
    "        sub = sub_df[sub_df['immunization']==immunization]\n",
    "\n",
    "        # 1) median per position\n",
    "        esc = sub[sub['Enrichment_Ratio']<=1] \\\n",
    "            .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "            .median()\n",
    "        bind = sub[sub['Enrichment_Ratio']>1] \\\n",
    "            .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "            .median()\n",
    "\n",
    "        if esc.empty and bind.empty:\n",
    "            continue\n",
    "\n",
    "        # 2) smooth\n",
    "        esc = esc.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "        bind = bind.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "        # 3) transform\n",
    "        def transform_val(y):\n",
    "            if y < 1:\n",
    "                return -(1 - y)\n",
    "            elif y == 1:\n",
    "                return 0\n",
    "            else:\n",
    "                return np.log10(y) / np.log10(2000)\n",
    "\n",
    "        esc_t  = esc.apply(transform_val)\n",
    "        bind_t = bind.apply(transform_val)\n",
    "\n",
    "        # 4) determine x range\n",
    "        positions = sorted(set(esc_t.index).union(bind_t.index))\n",
    "        pos_min, pos_max = positions[0], positions[-1]\n",
    "        idx = np.arange(pos_min, pos_max + 1)\n",
    "\n",
    "        # 5) assemble df_plot\n",
    "        df_plot = pd.DataFrame({'Spike_AS_Position': idx}).set_index('Spike_AS_Position')\n",
    "        df_plot['Escape']  = esc_t.reindex(idx, fill_value=0)\n",
    "        df_plot['Binding'] = bind_t.reindex(idx, fill_value=0)\n",
    "        df_plot = df_plot.reset_index()\n",
    "\n",
    "        # 6) save CSV\n",
    "        df_plot.to_csv(os.path.join(output_dir, f\"{immunization}_{filename}_median_plot_data.csv\"),\n",
    "                       index=False)\n",
    "\n",
    "        # 7) plot\n",
    "        ax.scatter(df_plot['Spike_AS_Position'], df_plot['Escape'],\n",
    "                   color=color_map.get(immunization), s=10, label=f\"{immunization} escape\", alpha=0.8)\n",
    "        ax.scatter(df_plot['Spike_AS_Position'], df_plot['Binding'],\n",
    "                   color=color_map.get(immunization), s=10, label=f\"{immunization} binding\", marker='x', alpha=0.8)\n",
    "\n",
    "        # 8) highlight\n",
    "        for pos in df_plot.loc[\n",
    "            df_plot['Spike_AS_Position'].astype(str).isin(sites_to_show),\n",
    "            'Spike_AS_Position'\n",
    "        ]:\n",
    "            ax.hlines(y=-1, xmin=pos-0.5, xmax=pos+0.5, color='black', linewidth=10)\n",
    "\n",
    "    # Final formatting\n",
    "    ax.set_ylim(0, 0.5)\n",
    "    ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "    plt.title(title, fontsize=14)\n",
    "    ax.set_xlabel('Spike AA Position', fontsize=16)\n",
    "    ax.set_ylabel('Median mAB binding ratio', fontsize=16)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = dict(zip(labels, handles))\n",
    "    ax.legend(unique.values(), unique.keys(),\n",
    "              loc='center left', bbox_to_anchor=(1.01, 0.5),\n",
    "              frameon=False, fontsize=10)\n",
    "\n",
    "    xt = np.linspace(sub_df['Spike_AS_Position'].min(),\n",
    "                     sub_df['Spike_AS_Position'].max(), 20).astype(int)\n",
    "    ax.set_xticks(xt)\n",
    "    ax.set_xticklabels([str(x) for x in xt])\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=9, prune='both'))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(r\"/Users/lucaschlotheuber/Desktop\", filename + \".png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Call plot function twice ---\n",
    "\n",
    "# 1) Polyclonal vs Neutralizing\n",
    "plot_by_subset(\n",
    "    df_filtered[df_filtered['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    title=\"Calibration\",\n",
    "    filename=\"escape_binding_polyclonal_neutralizing\"\n",
    ")\n",
    "\n",
    "# 2) Wildtype vs Mutant\n",
    "plot_by_subset(\n",
    "    df_filtered[df_filtered['immunization'].isin(['wildtype_RBD', 'Mutant_RBD'])],\n",
    "    title=\"Immunization\",\n",
    "    filename=\"escape_binding_wildtype_mutant\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Parameters\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Sites to highlight\n",
    "sites_to_show = list(map(str,\n",
    "    [455,456,472,473,484,485,486,490,496,499] +\n",
    "    list(range(394,414)) + list(range(484,505))\n",
    "))\n",
    "df_filtered = df_filtered.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define plotting function\n",
    "def plot_by_subset(sub_df, title, filename):\n",
    "    # Precompute global max of the POSITION‐MEDIAN binding values (>1)\n",
    "    binding_meds = []\n",
    "    for imm in sub_df['immunization'].unique():\n",
    "        if imm == 'Library_ctrl': continue\n",
    "        sub = sub_df[sub_df['immunization']==imm]\n",
    "        med_series = sub[sub['Enrichment_Ratio']>1] \\\n",
    "                       .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "                       .median()\n",
    "        if not med_series.empty:\n",
    "            binding_meds.append(med_series.max())\n",
    "    global_binding_max = max(binding_meds) if binding_meds else 2.0\n",
    "\n",
    "    # Set up plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    color_map = {\n",
    "        'Polyclonal_Ab':'darkorange',\n",
    "        'Neutralizing_Ab':'red',\n",
    "        'wildtype_RBD':'darkblue',\n",
    "        'Mutant_RBD':'#004c4c'\n",
    "    }\n",
    "\n",
    "    for immunization in sub_df['immunization'].unique():\n",
    "        if immunization == 'Library_ctrl':\n",
    "            continue\n",
    "\n",
    "        sub = sub_df[sub_df['immunization']==immunization]\n",
    "\n",
    "        # 1) median per position\n",
    "        esc = sub[sub['Enrichment_Ratio']<=1] \\\n",
    "            .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "            .median()\n",
    "        bind = sub[sub['Enrichment_Ratio']>1] \\\n",
    "            .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "            .median()\n",
    "\n",
    "        if esc.empty and bind.empty:\n",
    "            continue\n",
    "\n",
    "        # 2) smooth\n",
    "        esc = esc.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "        bind = bind.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "        # 3) transform\n",
    "        def transform_val(y):\n",
    "            if y < 1:\n",
    "                return -(1 - y)\n",
    "            elif y == 1:\n",
    "                return 0\n",
    "            else:\n",
    "                return np.log10(y) / np.log10(2000)\n",
    "\n",
    "        esc_t  = esc.apply(transform_val)\n",
    "        bind_t = bind.apply(transform_val)\n",
    "\n",
    "        # ——— INSERTION: multiply by count of variants at each position ———\n",
    "        counts = sub.groupby('Spike_AS_Position')['Enrichment_Ratio'].count()\n",
    "        esc_t   = esc_t * counts.reindex(esc_t.index, fill_value=0)\n",
    "        bind_t  = bind_t * counts.reindex(bind_t.index, fill_value=0)\n",
    "        # ————————————————————————————————————————————————————————————————\n",
    "\n",
    "        # 4) determine x range\n",
    "        positions = sorted(set(esc_t.index).union(bind_t.index))\n",
    "        pos_min, pos_max = positions[0], positions[-1]\n",
    "        idx = np.arange(pos_min, pos_max + 1)\n",
    "\n",
    "        # 5) assemble df_plot\n",
    "        df_plot = pd.DataFrame({'Spike_AS_Position': idx}).set_index('Spike_AS_Position')\n",
    "        df_plot['Escape']  = esc_t.reindex(idx, fill_value=0)\n",
    "        df_plot['Binding'] = bind_t.reindex(idx, fill_value=0)\n",
    "        df_plot = df_plot.reset_index()\n",
    "\n",
    "        # 6) save CSV\n",
    "        df_plot.to_csv(os.path.join(output_dir, f\"{immunization}_{filename}_median_plot_data.csv\"),\n",
    "                       index=False)\n",
    "\n",
    "        # 7) plot\n",
    "        ax.scatter(df_plot['Spike_AS_Position'], df_plot['Escape'],\n",
    "                   color=color_map.get(immunization), s=10, label=f\"{immunization} escape\", alpha=0.8)\n",
    "        ax.scatter(df_plot['Spike_AS_Position'], df_plot['Binding'],\n",
    "                   color=color_map.get(immunization), s=10, label=f\"{immunization} binding\", marker='x', alpha=0.8)\n",
    "\n",
    "        # 8) highlight\n",
    "        for pos in df_plot.loc[\n",
    "            df_plot['Spike_AS_Position'].astype(str).isin(sites_to_show),\n",
    "            'Spike_AS_Position'\n",
    "        ]:\n",
    "            ax.hlines(y=-1, xmin=pos-0.5, xmax=pos+0.5, color='black', linewidth=10)\n",
    "\n",
    "    # Final formatting\n",
    "    ax.set_ylim(-90, 25)\n",
    "    ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "    plt.title(title, fontsize=14)\n",
    "    ax.set_xlabel('Spike AA Position', fontsize=16)\n",
    "    ax.set_ylabel('Median mAB binding ratio', fontsize=16)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = dict(zip(labels, handles))\n",
    "    ax.legend(unique.values(), unique.keys(),\n",
    "              loc='center left', bbox_to_anchor=(1.01, 0.5),\n",
    "              frameon=False, fontsize=10)\n",
    "\n",
    "    xt = np.linspace(sub_df['Spike_AS_Position'].min(),\n",
    "                     sub_df['Spike_AS_Position'].max(), 20).astype(int)\n",
    "    ax.set_xticks(xt)\n",
    "    ax.set_xticklabels([str(x) for x in xt])\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=9, prune='both'))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(r\"/Users/lucaschlotheuber/Desktop\", filename + \".png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Call plot function twice ---\n",
    "\n",
    "# 1) Polyclonal vs Neutralizing\n",
    "plot_by_subset(\n",
    "    df_filtered[df_filtered['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    title=\"Calibration\",\n",
    "    filename=\"escape_binding_polyclonal_neutralizing\"\n",
    ")\n",
    "\n",
    "# 2) Wildtype vs Mutant\n",
    "plot_by_subset(\n",
    "    df_filtered[df_filtered['immunization'].isin(['wildtype_RBD', 'Mutant_RBD'])],\n",
    "    title=\"Immunization\",\n",
    "    filename=\"escape_binding_wildtype_mutant\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Parameters\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Sites to highlight\n",
    "sites_to_show = list(map(str,\n",
    "    [455,456,472,473,484,485,486,490,496,499] +\n",
    "    list(range(394,414)) + list(range(484,505))\n",
    "))\n",
    "df_filtered = df_filtered.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define plotting function\n",
    "def plot_by_subset(sub_df, title, filename):\n",
    "    # Precompute global max of the POSITION‐MEDIAN binding values (>1)\n",
    "    binding_meds = []\n",
    "    for imm in sub_df['immunization'].unique():\n",
    "        if imm == 'Library_ctrl': continue\n",
    "        sub = sub_df[sub_df['immunization']==imm]\n",
    "        med_series = sub[sub['Enrichment_Ratio']>1] \\\n",
    "                       .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "                       .median()\n",
    "        if not med_series.empty:\n",
    "            binding_meds.append(med_series.max())\n",
    "    global_binding_max = max(binding_meds) if binding_meds else 2.0\n",
    "\n",
    "    # Set up plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    color_map = {\n",
    "        'Polyclonal_Ab':'darkorange',\n",
    "        'Neutralizing_Ab':'red',\n",
    "        'wildtype_RBD':'darkblue',\n",
    "        'Mutant_RBD':'#004c4c'\n",
    "    }\n",
    "\n",
    "    for immunization in sub_df['immunization'].unique():\n",
    "        if immunization == 'Library_ctrl':\n",
    "            continue\n",
    "\n",
    "        sub = sub_df[sub_df['immunization']==immunization]\n",
    "\n",
    "        # 1) median per position\n",
    "        esc = sub[sub['Enrichment_Ratio']<=1] \\\n",
    "            .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "            .median()\n",
    "        bind = sub[sub['Enrichment_Ratio']>1] \\\n",
    "            .groupby('Spike_AS_Position')['Enrichment_Ratio'] \\\n",
    "            .median()\n",
    "\n",
    "        if esc.empty and bind.empty:\n",
    "            continue\n",
    "\n",
    "        # 2) smooth\n",
    "        esc = esc.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "        bind = bind.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "        # 3) transform\n",
    "        def transform_val(y):\n",
    "            if y < 1:\n",
    "                return -(1 - y)\n",
    "            elif y == 1:\n",
    "                return 0\n",
    "            else:\n",
    "                return np.log10(y) / np.log10(2000)\n",
    "\n",
    "        esc_t  = esc.apply(transform_val)\n",
    "        bind_t = bind.apply(transform_val)\n",
    "\n",
    "        # ——— INSERTION: multiply by count of variants at each position ———\n",
    "        counts = sub.groupby('Spike_AS_Position')['Enrichment_Ratio'].count()\n",
    "        esc_t   = esc_t * counts.reindex(esc_t.index, fill_value=0)\n",
    "        bind_t  = bind_t * counts.reindex(bind_t.index, fill_value=0)\n",
    "        # ————————————————————————————————————————————————————————————————\n",
    "\n",
    "        # 4) determine x range\n",
    "        positions = sorted(set(esc_t.index).union(bind_t.index))\n",
    "        pos_min, pos_max = positions[0], positions[-1]\n",
    "        idx = np.arange(pos_min, pos_max + 1)\n",
    "\n",
    "        # 5) assemble df_plot\n",
    "        df_plot = pd.DataFrame({'Spike_AS_Position': idx}).set_index('Spike_AS_Position')\n",
    "        df_plot['Escape']  = esc_t.reindex(idx, fill_value=0)\n",
    "        df_plot['Binding'] = bind_t.reindex(idx, fill_value=0)\n",
    "        df_plot = df_plot.reset_index()\n",
    "\n",
    "        # 6) save CSV\n",
    "        df_plot.to_csv(os.path.join(output_dir, f\"{immunization}_{filename}_median_plot_data.csv\"),\n",
    "                       index=False)\n",
    "\n",
    "        # 7) plot\n",
    "        ax.scatter(df_plot['Spike_AS_Position'], df_plot['Escape'],\n",
    "                   color=color_map.get(immunization), s=10, label=f\"{immunization} escape\", alpha=0.8)\n",
    "        ax.scatter(df_plot['Spike_AS_Position'], df_plot['Binding'],\n",
    "                   color=color_map.get(immunization), s=10, label=f\"{immunization} binding\", marker='x', alpha=0.8)\n",
    "\n",
    "        # 8) highlight\n",
    "        for pos in df_plot.loc[\n",
    "            df_plot['Spike_AS_Position'].astype(str).isin(sites_to_show),\n",
    "            'Spike_AS_Position'\n",
    "        ]:\n",
    "            ax.hlines(y=-1, xmin=pos-0.5, xmax=pos+0.5, color='black', linewidth=10)\n",
    "\n",
    "    # Final formatting\n",
    "    # Final formatting - Dynamic y-limits\n",
    "    all_y_vals = pd.concat([df_plot['Escape'], df_plot['Binding']])\n",
    "    y_min, y_max = all_y_vals.min(), all_y_vals.max()\n",
    "    y_range = y_max - y_min\n",
    "    buffer = y_range * 0.1 if y_range > 0 else 1.0\n",
    "    ax.set_ylim(y_min - buffer, y_max + buffer)\n",
    "\n",
    "    ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "    plt.title(title, fontsize=14)\n",
    "    ax.set_xlabel('Spike AA Position', fontsize=16)\n",
    "    ax.set_ylabel('Median mAB binding ratio', fontsize=16)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = dict(zip(labels, handles))\n",
    "    ax.legend(unique.values(), unique.keys(),\n",
    "              loc='center left', bbox_to_anchor=(1.01, 0.5),\n",
    "              frameon=False, fontsize=10)\n",
    "\n",
    "    xt = np.linspace(sub_df['Spike_AS_Position'].min(),\n",
    "                     sub_df['Spike_AS_Position'].max(), 20).astype(int)\n",
    "    ax.set_xticks(xt)\n",
    "    ax.set_xticklabels([str(x) for x in xt])\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=9, prune='both'))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(r\"/Users/lucaschlotheuber/Desktop\", filename + \".png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Call plot function twice ---\n",
    "\n",
    "\n",
    "for barcode in df_filtered['barcode'].unique():\n",
    "    sub_df = df_filtered[df_filtered['barcode'] == barcode]\n",
    "    plot_by_subset(\n",
    "        sub_df,\n",
    "        title=f\"Escape and Binding - Barcode {barcode}\",\n",
    "        filename=f\"escape_binding_barcode_{barcode}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Parameters\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Sites to highlight\n",
    "sites_to_show = list(map(str,\n",
    "    [455,456,472,473,484,485,486,490,496,499] +\n",
    "    list(range(394,414)) + list(range(484,505))\n",
    "))\n",
    "df_filtered = df_filtered.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define plotting function\n",
    "def plot_by_subset(sub_df, title, filename):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    color_map = {\n",
    "        'Polyclonal_Ab':'darkorange',\n",
    "        'Neutralizing_Ab':'red',\n",
    "        'wildtype_RBD':'darkblue',\n",
    "        'Mutant_RBD':'#004c4c'\n",
    "    }\n",
    "\n",
    "    for immunization in sub_df['immunization'].unique():\n",
    "        if immunization == 'Library_ctrl':\n",
    "            continue\n",
    "\n",
    "        sub = sub_df[sub_df['immunization']==immunization]\n",
    "\n",
    "        # 1) Filter to non-synonymous only\n",
    "        sub_ns = sub[sub['Type_of_Mutation'] == 'NON-SYNOM']\n",
    "\n",
    "        if sub_ns.empty:\n",
    "            continue\n",
    "\n",
    "        # 2) Group: median & count\n",
    "        grouped = sub_ns.groupby('Spike_AS_Position')['Enrichment_Ratio']\n",
    "        median_er = grouped.median()\n",
    "        breadth = grouped.count()\n",
    "\n",
    "        # 3) Polyreactivity = median * count\n",
    "        poly = median_er * breadth\n",
    "\n",
    "        # 4) Smooth\n",
    "        poly = poly.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "        # 5) Prepare for plotting\n",
    "        idx = np.arange(poly.index.min(), poly.index.max() + 1)\n",
    "        df_plot = pd.DataFrame({'Spike_AS_Position': idx}).set_index('Spike_AS_Position')\n",
    "        df_plot['Polyreactivity'] = poly.reindex(idx, fill_value=0)\n",
    "        df_plot = df_plot.reset_index()\n",
    "\n",
    "        # 6) Save CSV\n",
    "        df_plot.to_csv(os.path.join(output_dir, f\"{immunization}_{filename}_median_plot_data.csv\"),\n",
    "                       index=False)\n",
    "\n",
    "        # 7) Plot\n",
    "        ax.scatter(df_plot['Spike_AS_Position'], df_plot['Polyreactivity'],\n",
    "                   color=color_map.get(immunization), s=10, label=f\"{immunization} polyreactivity\", alpha=0.8)\n",
    "\n",
    "        # 8) Highlight sites\n",
    "        for pos in df_plot.loc[\n",
    "            df_plot['Spike_AS_Position'].astype(str).isin(sites_to_show),\n",
    "            'Spike_AS_Position'\n",
    "        ]:\n",
    "            ax.hlines(y=0, xmin=pos-0.5, xmax=pos+0.5, color='black', linewidth=10)\n",
    "\n",
    "    # Final formatting\n",
    "    ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "    plt.title(title, fontsize=14)\n",
    "    ax.set_xlabel('Spike AA Position', fontsize=16)\n",
    "    ax.set_ylabel('Polyreactivity Score\\n(median × count)', fontsize=16)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = dict(zip(labels, handles))\n",
    "    ax.legend(unique.values(), unique.keys(),\n",
    "              loc='center left', bbox_to_anchor=(1.01, 0.5),\n",
    "              frameon=False, fontsize=10)\n",
    "\n",
    "    xt = np.linspace(sub_df['Spike_AS_Position'].min(),\n",
    "                     sub_df['Spike_AS_Position'].max(), 20).astype(int)\n",
    "    ax.set_xticks(xt)\n",
    "    ax.set_xticklabels([str(x) for x in xt])\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=9, prune='both'))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(r\"/Users/lucaschlotheuber/Desktop\", filename + \".png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Call plot function twice ---\n",
    "\n",
    "# 1) Polyclonal vs Neutralizing\n",
    "plot_by_subset(\n",
    "    df_filtered[df_filtered['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    title=\"Calibration\",\n",
    "    filename=\"escape_binding_polyclonal_neutralizing\"\n",
    ")\n",
    "\n",
    "# 2) Wildtype vs Mutant\n",
    "plot_by_subset(\n",
    "    df_filtered[df_filtered['immunization'].isin(['wildtype_RBD', 'Mutant_RBD'])],\n",
    "    title=\"Immunization\",\n",
    "    filename=\"escape_binding_wildtype_mutant\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Parameters\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Sites to highlight\n",
    "sites_to_show = list(map(str,\n",
    "    [455,456,472,473,484,485,486,490,496,499] +\n",
    "    list(range(394,414)) + list(range(484,505))\n",
    "))\n",
    "df_filtered = df_filtered.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define plotting function\n",
    "def plot_by_subset(sub_df, title, filename):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    color_map = {\n",
    "        'Polyclonal_Ab':'darkorange',\n",
    "        'Neutralizing_Ab':'red',\n",
    "        'wildtype_RBD':'darkblue',\n",
    "        'Mutant_RBD':'#004c4c'\n",
    "    }\n",
    "\n",
    "    for immunization in sub_df['immunization'].unique():\n",
    "        if immunization == 'Library_ctrl':\n",
    "            continue\n",
    "\n",
    "        sub = sub_df[sub_df['immunization']==immunization]\n",
    "\n",
    "        # 1) Filter to non-synonymous only\n",
    "        sub_ns = sub[sub['Type_of_Mutation'] == 'NON-SYNOM']\n",
    "\n",
    "        if sub_ns.empty:\n",
    "            continue\n",
    "\n",
    "        # 2) Group: median & count\n",
    "        grouped = sub_ns.groupby('Spike_AS_Position')['Enrichment_Ratio']\n",
    "        median_er = grouped.median()\n",
    "        breadth = grouped.count()\n",
    "\n",
    "        # 3) Smooth median and count separately\n",
    "        smoothed_median = median_er.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "        smoothed_count = breadth.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "        \n",
    "        # 4) Polyreactivity = smoothed_median * smoothed_count\n",
    "        poly = smoothed_median * smoothed_count\n",
    "\n",
    "\n",
    "        # 5) Prepare for plotting\n",
    "        idx = np.arange(poly.index.min(), poly.index.max() + 1)\n",
    "        df_plot = pd.DataFrame({'Spike_AS_Position': idx}).set_index('Spike_AS_Position')\n",
    "        df_plot['Polyreactivity'] = poly.reindex(idx, fill_value=0)\n",
    "        df_plot = df_plot.reset_index()\n",
    "\n",
    "        # 6) Save CSV\n",
    "        df_plot.to_csv(os.path.join(output_dir, f\"{immunization}_{filename}_median_plot_data.csv\"),\n",
    "                       index=False)\n",
    "\n",
    "        # 7) Plot\n",
    "        ax.scatter(df_plot['Spike_AS_Position'], df_plot['Polyreactivity'],\n",
    "                   color=color_map.get(immunization), s=10, label=f\"{immunization} polyreactivity\", alpha=0.8)\n",
    "\n",
    "        # 8) Highlight sites\n",
    "        for pos in df_plot.loc[\n",
    "            df_plot['Spike_AS_Position'].astype(str).isin(sites_to_show),\n",
    "            'Spike_AS_Position'\n",
    "        ]:\n",
    "            ax.hlines(y=0, xmin=pos-0.5, xmax=pos+0.5, color='black', linewidth=10)\n",
    "\n",
    "    # Final formatting\n",
    "    ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "    plt.title(title, fontsize=14)\n",
    "    ax.set_xlabel('Spike AA Position', fontsize=16)\n",
    "    ax.set_ylabel('Polyreactivity Score\\n(median × count)', fontsize=16)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    unique = dict(zip(labels, handles))\n",
    "    ax.legend(unique.values(), unique.keys(),\n",
    "              loc='center left', bbox_to_anchor=(1.01, 0.5),\n",
    "              frameon=False, fontsize=10)\n",
    "\n",
    "    xt = np.linspace(sub_df['Spike_AS_Position'].min(),\n",
    "                     sub_df['Spike_AS_Position'].max(), 20).astype(int)\n",
    "    ax.set_xticks(xt)\n",
    "    ax.set_xticklabels([str(x) for x in xt])\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=9, prune='both'))\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(r\"/Users/lucaschlotheuber/Desktop\", filename + \".png\"), dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# --- Call plot function twice ---\n",
    "\n",
    "# 1) Polyclonal vs Neutralizing\n",
    "plot_by_subset(\n",
    "    df_filtered[df_filtered['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    title=\"Calibration\",\n",
    "    filename=\"escape_binding_polyclonal_neutralizing\"\n",
    ")\n",
    "\n",
    "# 2) Wildtype vs Mutant\n",
    "plot_by_subset(\n",
    "    df_filtered[df_filtered['immunization'].isin(['wildtype_RBD', 'Mutant_RBD'])],\n",
    "    title=\"Immunization\",\n",
    "    filename=\"escape_binding_wildtype_mutant\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Parameters\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Sites to highlight\n",
    "sites_to_show = list(map(str,\n",
    "    [455,456,472,473,484,485,486,490,496,499] +\n",
    "    list(range(394,414)) + list(range(484,505))\n",
    "))\n",
    "df_filtered = df_filtered.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Compute global max of median binding (>1)\n",
    "binding_meds = []\n",
    "for imm in df_filtered['immunization'].unique():\n",
    "    if imm == 'Library_ctrl': continue\n",
    "    med_series = (\n",
    "        df_filtered[df_filtered['immunization']==imm]\n",
    "        .loc[lambda d: d['Enrichment_Ratio'] > 1]\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio']\n",
    "        .median()\n",
    "    )\n",
    "    if not med_series.empty:\n",
    "        binding_meds.append(med_series.max())\n",
    "global_binding_max = max(binding_meds) if binding_meds else 2.0\n",
    "\n",
    "# Prepare plotting\n",
    "immunizations = [imm for imm in df_filtered['immunization'].unique() if imm!='Library_ctrl']\n",
    "n_imms = len(immunizations)\n",
    "bar_width = 0.8 / n_imms  # total bar width per group\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "color_map = {\n",
    "    'Polyclonal_Ab':'darkorange',\n",
    "    'Neutralizing_Ab':'red',\n",
    "    'wildtype_RBD':'darkblue',\n",
    "    'Mutant_RBD':'#004c4c'\n",
    "}\n",
    "\n",
    "# Loop per immunization with offsets\n",
    "for i, immunization in enumerate(immunizations):\n",
    "    sub = df_filtered[df_filtered['immunization']==immunization]\n",
    "\n",
    "    # median per position\n",
    "    esc = sub[sub['Enrichment_Ratio']<=1]\\\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio']\\\n",
    "        .median()\\\n",
    "        .rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    bind = sub[sub['Enrichment_Ratio']>1]\\\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio']\\\n",
    "        .median()\\\n",
    "        .rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    if esc.empty and bind.empty:\n",
    "        continue\n",
    "\n",
    "    # transform\n",
    "    def transform_val(y):\n",
    "        if y < 1:\n",
    "            return -(1 - y)\n",
    "        elif y == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return (y - 1) / (global_binding_max - 1)\n",
    "        # Raw medians\n",
    "    esc_raw = sub[sub['Enrichment_Ratio'] <= 1]\\\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio']\\\n",
    "        .median()\n",
    "    bind_raw = sub[sub['Enrichment_Ratio'] > 1]\\\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio']\\\n",
    "        .median()\n",
    "\n",
    "    # Rolling smoothed\n",
    "    esc_smoothed = esc_raw.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    bind_smoothed = bind_raw.rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "\n",
    "    # x-range\n",
    "    positions = sorted(set(esc_t.index).union(bind_t.index))\n",
    "    pos_min, pos_max = positions[0], positions[-1]\n",
    "    idx = np.arange(pos_min, pos_max + 1)\n",
    "\n",
    "    # assemble df_plot\n",
    "    df_plot = pd.DataFrame({'Spike_AS_Position': idx}).set_index('Spike_AS_Position')\n",
    "    df_plot['Escape']  = esc_t.reindex(idx, fill_value=0)\n",
    "    df_plot['Binding'] = bind_t.reindex(idx, fill_value=0)\n",
    "    df_plot = df_plot.reset_index()\n",
    "\n",
    "    # save CSV\n",
    "    df_plot.to_csv(os.path.join(output_dir,\n",
    "                      f\"{immunization}_median_plot_data.csv\"),\n",
    "                   index=False)\n",
    "\n",
    "    # bar positions offset\n",
    "    offset = (i - n_imms/2) * bar_width + bar_width/2\n",
    "    x_vals = df_plot['Spike_AS_Position'] + offset\n",
    "    \n",
    "    # bars\n",
    "    ax.bar(x_vals,\n",
    "           df_plot['Escape'],\n",
    "           width=bar_width,\n",
    "           color=color_map[immunization],\n",
    "           alpha=0.8,\n",
    "           label=f\"{immunization} escape\")\n",
    "    ax.bar(x_vals,\n",
    "           df_plot['Binding'],\n",
    "           width=bar_width,\n",
    "           color=color_map[immunization],\n",
    "           alpha=0.4,\n",
    "           label=f\"{immunization} binding\")\n",
    "\n",
    "    # overlay lines connecting the ends of bars\n",
    "    ax.plot(x_vals, df_plot['Escape'], color=color_map[immunization], linewidth=1.5)\n",
    "    ax.plot(x_vals, df_plot['Binding'], color=color_map[immunization], linewidth=1.5, linestyle='--')\n",
    "\n",
    "\n",
    "# formatting\n",
    "ax.set_ylim(-1, 0.4)\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "plt.title('Escape (solid) vs Binding (faded) Bar Plot', fontsize=14)\n",
    "ax.set_xlabel('Spike AA Position', fontsize=16)\n",
    "ax.set_ylabel('Transformed Enrichment', fontsize=16)\n",
    "\n",
    "# legend outside right\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, title='Immunization',\n",
    "          loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "          frameon=False, fontsize=10)\n",
    "\n",
    "# x-ticks\n",
    "xt = np.linspace(df_filtered['Spike_AS_Position'].min(),\n",
    "                 df_filtered['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xt)\n",
    "ax.set_xticklabels([str(x) for x in xt])\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(nbins=9, prune='both'))\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.8)  # make room for legend\n",
    "fig.savefig(os.path.join(\n",
    "    r\"/Users/lucaschlotheuber/Desktop\", \"escape_binding_barplot.png\"),\n",
    "    dpi=300\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Parameters\n",
    "ROLLING_WINDOW = 5\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "\n",
    "# Filter dataset\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Sites to highlight\n",
    "sites_to_show = list(map(str,\n",
    "    [455,456,472,473,484,485,486,490,496,499] +\n",
    "    list(range(394,414)) + list(range(484,505))\n",
    "))\n",
    "df_filtered = df_filtered.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Compute global max of median binding (>1)\n",
    "binding_meds = []\n",
    "for imm in df_filtered['immunization'].unique():\n",
    "    if imm == 'Library_ctrl': continue\n",
    "    med_series = (\n",
    "        df_filtered[df_filtered['immunization']==imm]\n",
    "        .loc[lambda d: d['Enrichment_Ratio']>1]\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio']\n",
    "        .median()\n",
    "    )\n",
    "    if not med_series.empty:\n",
    "        binding_meds.append(med_series.max())\n",
    "global_binding_max = max(binding_meds) if binding_meds else 2.0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "base_colors = {\n",
    "    'Polyclonal_Ab':'darkorange',\n",
    "    'Neutralizing_Ab':'red',\n",
    "    'wildtype_RBD':'darkblue',\n",
    "    'Mutant_RBD':'#004c4c'\n",
    "}\n",
    "\n",
    "for immunization in df_filtered['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    sub = df_filtered[df_filtered['immunization']==immunization]\n",
    "    esc = sub[sub['Enrichment_Ratio']<=1]\\\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio']\\\n",
    "        .median()\\\n",
    "        .rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    bind = sub[sub['Enrichment_Ratio']>1]\\\n",
    "        .groupby('Spike_AS_Position')['Enrichment_Ratio']\\\n",
    "        .median()\\\n",
    "        .rolling(ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # transform\n",
    "    def transform_val(y):\n",
    "        if y < 1:\n",
    "            return -(1 - y)\n",
    "        elif y == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return (y - 1) / (global_binding_max - 1)\n",
    "\n",
    "    esc_t  = esc.apply(transform_val)\n",
    "    bind_t = bind.apply(transform_val)\n",
    "\n",
    "    # x-range\n",
    "    positions = sorted(set(esc_t.index).union(bind_t.index))\n",
    "    idx = np.arange(positions[0], positions[-1]+1)\n",
    "\n",
    "    df_plot = pd.DataFrame({'Spike_AS_Position': idx}).set_index('Spike_AS_Position')\n",
    "    df_plot['Escape']  = esc_t.reindex(idx, fill_value=0)\n",
    "    df_plot['Binding'] = bind_t.reindex(idx, fill_value=0)\n",
    "    df_plot = df_plot.reset_index()\n",
    "\n",
    "    # save CSV\n",
    "    df_plot.to_csv(os.path.join(output_dir,\n",
    "                    f\"{immunization}_median_plot_data.csv\"), index=False)\n",
    "\n",
    "    # get colors\n",
    "    base = colors.to_rgb(base_colors[immunization])\n",
    "    dark_escape = tuple(c * 0.5 for c in base)  # darker tone\n",
    "    light_binding = base\n",
    "\n",
    "    # plot\n",
    "    ax.plot(df_plot['Spike_AS_Position'], df_plot['Escape'],\n",
    "            color=dark_escape, linestyle='-', linewidth=1,\n",
    "            label=f\"{immunization} escape\")\n",
    "    ax.plot(df_plot['Spike_AS_Position'], df_plot['Binding'],\n",
    "            color=light_binding, linewidth=1,\n",
    "            label=f\"{immunization} binding\")\n",
    "\n",
    "    # highlight\n",
    "    for pos in df_plot.loc[\n",
    "        df_plot['Spike_AS_Position'].astype(str).isin(sites_to_show),\n",
    "        'Spike_AS_Position'\n",
    "    ]:\n",
    "        ax.hlines(y=-1, xmin=pos-0.5, xmax=pos+0.5,\n",
    "                  color='black', linewidth=10)\n",
    "\n",
    "# formatting\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.axhline(0, color='gray', linestyle='--', linewidth=1)\n",
    "plt.title('Escape (darker) vs Binding per Immunization', fontsize=14)\n",
    "ax.set_xlabel('Spike AA Position', fontsize=16)\n",
    "ax.set_ylabel('Transformed Enrichment', fontsize=16)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title='Immunization',\n",
    "           loc='upper center', ncol=2, frameon=False, fontsize=10)\n",
    "\n",
    "xt = np.linspace(df_filtered['Spike_AS_Position'].min(),\n",
    "                 df_filtered['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xt)\n",
    "ax.set_xticklabels([str(x) for x in xt])\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(nbins=9, prune='both'))\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(r\"/Users/lucaschlotheuber/Desktop\", \"escape_binding_plot.png\"), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import altair as alt\n",
    "\n",
    "# Load FASTA sequence (Wuhan reference)\n",
    "fasta_file = r'/Users/lucaschlotheuber/Desktop/ETH/RBD201_DMS1.fa'\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    wuhan_sequence = str(record.seq)\n",
    "    break\n",
    "\n",
    "# Load and clean the Excel data\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "df_total = pd.read_excel(file_path, usecols=[\n",
    "    \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\",\n",
    "    \"Amino_Acid\", \"Type_of_Mutation\", \"Enrichment_Ratio\",\n",
    "    \"barcode\", \"immunization\", \"condition\", \"Total_Reads\"\n",
    "])\n",
    "df_total[\"Spike_AS_Position\"] -= 5  # Adjust 336 -> 331\n",
    "\n",
    "# Clean up\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio', 'Amino_Acid'])\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 500]\n",
    "df_total = df_total[df_total[\"Amino_Acid\"] != '*']  # Exclude stop codons\n",
    "\n",
    "# Add Wuhan reference\n",
    "immunization = \"Wuhan_Sequence\"\n",
    "barcode = \"Wuhan_Barcode\"\n",
    "data_wuhan = [{\n",
    "    'DMS_RBD_AS_position': pos,\n",
    "    'Spike_AS_Position': pos + 330,\n",
    "    'Amino_Acid': aa,\n",
    "    'immunization': immunization,\n",
    "    'barcode': barcode,\n",
    "    'Enrichment_Ratio': 1,\n",
    "} for pos, aa in enumerate(wuhan_sequence, start=1) if aa != '*']\n",
    "df_wuhan = pd.DataFrame(data_wuhan)\n",
    "df_total = pd.concat([df_total, df_wuhan], ignore_index=True)\n",
    "\n",
    "# Filter\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 364) &\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM')\n",
    "]\n",
    "\n",
    "# Aggregate\n",
    "df_heatmap = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'mean'})\n",
    "\n",
    "# Filter out zeros or negatives\n",
    "df_heatmap = df_heatmap[df_heatmap['Enrichment_Ratio'] > 0]\n",
    "\n",
    "# Add log2 enrichment\n",
    "# Invert values between 0 and 1 for log2 enrichment, leave others unchanged\n",
    "df_heatmap['Enrichment_Ratio_transformed'] = df_heatmap['Enrichment_Ratio'].apply(\n",
    "    lambda x: 1 / x if 0 < x < 1 else x\n",
    ")\n",
    "\n",
    "# Calculate log2 enrichment from transformed values\n",
    "df_heatmap['log2_enrichment'] = df_heatmap['Enrichment_Ratio_transformed'].apply(\n",
    "    lambda x: round(np.log2(x), 3)\n",
    ")\n",
    "\n",
    "# Split into log2 ranges\n",
    "df_low = df_heatmap[df_heatmap['log2_enrichment'] <= 0].copy()   # log2 ≤ 0 → ratio ≤ 1\n",
    "df_high = df_heatmap[df_heatmap['log2_enrichment'] > 0].copy()   # log2 > 0  → ratio > 1\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"heatmap_output_log2_split\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Function to generate and save log2-based heatmap\n",
    "def generate_heatmap(df_subset, enrichment_range_label):\n",
    "    for immun in df_subset['immunization'].unique():\n",
    "        df_im = df_subset[df_subset['immunization'] == immun].copy()\n",
    "\n",
    "        # Tick marks every 5\n",
    "        tick_vals = sorted(df_im['Spike_AS_Position'].unique())\n",
    "        tick_vals = [x for x in tick_vals if x % 5 == 0]\n",
    "\n",
    "        heatmap = alt.Chart(df_im).mark_rect().encode(\n",
    "            x=alt.X('Spike_AS_Position:O', title='Spike AA Position',\n",
    "                    axis=alt.Axis(values=tick_vals)),\n",
    "            y=alt.Y('Amino_Acid:N', title='Mutated AA'),\n",
    "            color=alt.Color('Enrichment_Ratio:Q',\n",
    "                scale=alt.Scale(scheme='redblue', domain=[0.1, 12]),\n",
    "                title='Enrichment Ratio'),\n",
    "            tooltip=[\n",
    "                'Spike_AS_Position:O',\n",
    "                'Amino_Acid:N',\n",
    "                'log2_enrichment:Q'\n",
    "            ]\n",
    "        ).properties(\n",
    "            title=f\"log₂ {enrichment_range_label} Heatmap - {immun}\",\n",
    "            width=800,\n",
    "            height=400\n",
    "        ).configure_axis(\n",
    "            labelFontSize=12,\n",
    "            titleFontSize=14\n",
    "        ).configure_title(\n",
    "            fontSize=18,\n",
    "            anchor='start'\n",
    "        )\n",
    "\n",
    "        output_file = os.path.join(output_dir, f\"{immun}_heatmap_log2_{enrichment_range_label.replace(' ', '_')}.html\")\n",
    "        heatmap.save(output_file)\n",
    "        print(f\"Saved log2 {enrichment_range_label} heatmap for {immun} to {output_file}\")\n",
    "\n",
    "# Generate both sets\n",
    "generate_heatmap(df_low, \"0_to_1\")\n",
    "generate_heatmap(df_high, \"1_to_max\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "def transform_y(y, threshold=1, max_val=400):\n",
    "    \"\"\"\n",
    "    Piecewise linear transform:\n",
    "    - y in [0, threshold] maps to [0, 0.5]\n",
    "    - y in [threshold, max_val] maps to [0.5, 1]\n",
    "    \"\"\"\n",
    "    y = np.array(y)\n",
    "    y_new = np.empty_like(y, dtype=float)\n",
    "    mask_low = y <= threshold\n",
    "    y_new[mask_low] = 0.5 * (y[mask_low] / threshold)\n",
    "    mask_high = y > threshold\n",
    "    y_new[mask_high] = 0.5 + 0.5 * ((y[mask_high] - threshold) / (max_val - threshold))\n",
    "    return y_new\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "\n",
    "    # Fill missing enrichment values\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # No smoothing\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Enrichment_Ratio'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Transform enrichment for plotting\n",
    "    df_filtered_im['Transformed_Enrichment'] = transform_y(df_filtered_im['Enrichment_Ratio'], threshold=1, max_val=400)\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Transformed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=1.5,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0,\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=10\n",
    "        )\n",
    "\n",
    "# Set transformed y-axis\n",
    "ax.set_ylim(0, 1)\n",
    "yticks_original = [0, 0.2, 0.5, 1, 50, 100, 200, 400]\n",
    "yticks_transformed = transform_y(yticks_original, threshold=1, max_val=400)\n",
    "ax.set_yticks(yticks_transformed)\n",
    "ax.set_yticklabels([f\"{v}%\" if v <= 1 else f\"{int(v)}\" for v in yticks_original])\n",
    "\n",
    "ax.axhline(y=transform_y(1, threshold=1, max_val=400), color='grey', linestyle='--', linewidth=1)\n",
    "\n",
    "# Plot title, labels, legend\n",
    "plt.title('Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Antibody Repertoire - Enrichment \\n (Sum Polyreactivity)', fontsize=16)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "group_1_labels = ['Polyclonal_Ab', 'Neutralizing_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels if label in labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels if label in labels]\n",
    "handles = group_1_handles + group_2_handles\n",
    "labels = group_1_labels + group_2_labels\n",
    "plt.legend(handles, labels, title=\"Single Droplet Repertoire\", loc='upper center', fontsize=11, frameon=False, handlelength=2, handleheight=1, title_fontsize=11, markerscale=8)\n",
    "\n",
    "xticks = np.linspace(df_filtered_agg['Spike_AS_Position'].min(), df_filtered_agg['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels([str(x) if i % 2 == 0 else '' for i, x in enumerate(xticks)])\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, prune='lower', nbins=8))\n",
    "\n",
    "all_vals = []\n",
    "for imm in df_filtered_agg['immunization'].unique():\n",
    "    if imm == \"Library_ctrl\": continue\n",
    "    tmp = (\n",
    "        df_filtered_agg.query(f'immunization == \"{imm}\"')\n",
    "        .groupby(\"Spike_AS_Position\", as_index=False)[\"Enrichment_Ratio\"]\n",
    "        .sum()\n",
    "        .fillna(method=\"bfill\").fillna(method=\"ffill\")[\"Enrichment_Ratio\"]\n",
    "        .values\n",
    "    )\n",
    "    all_vals.append(tmp)\n",
    "all_vals = np.concatenate(all_vals)\n",
    "YMIN, YMAX = all_vals.min(), all_vals.max()\n",
    "\n",
    "# 2) Recompute and reset all y-ticks and limits using the real range\n",
    "#    so that 0→1→YMAX maps to 0→0.5→1\n",
    "yticks_original = [YMIN, 0.2, 0.5, 1, 50, 100, 200, YMAX]\n",
    "yticks_transformed = transform_y(yticks_original, threshold=1, max_val=YMAX)\n",
    "\n",
    "ax.set_yticks(yticks_transformed)\n",
    "ax.set_yticklabels(\n",
    "    [f\"{v:.1f}\" if v <= 1 else f\"{int(v)}\" for v in yticks_original]\n",
    ")\n",
    "\n",
    "# 3) Set the exact transformed limits\n",
    "ax.set_ylim(transform_y(YMIN, threshold=1, max_val=YMAX),\n",
    "            transform_y(YMAX, threshold=1, max_val=YMAX))\n",
    "\n",
    "# 4) Draw the \"x-axis\" at y=1 (transformed)\n",
    "ax.axhline(\n",
    "    y=transform_y(1, threshold=1, max_val=YMAX),\n",
    "    color=\"grey\", linestyle=\"--\", linewidth=1\n",
    ")\n",
    "\n",
    "# 5) Redraw and save\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# You need to have dmslogo installed and imported properly\n",
    "import dmslogo.line\n",
    "\n",
    "# Set pandas option\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Constants\n",
    "ROLLING_WINDOW = 20  # smoothing window size\n",
    "ENRICHMENT_THRESHOLD = 1  # threshold for high enrichment\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Assuming df_total is your initial DataFrame loaded somewhere before this code.\n",
    "\n",
    "# Filter dataset for quality and mutation type\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 364) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position, amino acid, barcode, immunization\n",
    "df_filtered_agg = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False).agg({'Enrichment_Ratio': 'mean'})\n",
    "\n",
    "# Define target sites (positions to highlight)\n",
    "sites_to_show = list(map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))    # R13 peptide sequence\n",
    "))\n",
    "\n",
    "# Annotate with site label and flag to show site\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Create figure and axes for combined plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Color mapping for immunizations\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'darkblue',\n",
    "    'Mutant_RBD': '#004c4c'\n",
    "}\n",
    "\n",
    "# Loop through immunizations and plot\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue  # skip control\n",
    "    if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "        continue\n",
    "    if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing immunization: {immunization}\")\n",
    "\n",
    "    # Filter for this immunization\n",
    "    df_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratio by position (sum over amino acid/barcode)\n",
    "    df_im = df_im.groupby('Spike_AS_Position', as_index=False).agg({'Enrichment_Ratio': 'mean'})\n",
    "\n",
    "    # Fill any NaNs in Enrichment_Ratio\n",
    "    df_im['Enrichment_Ratio'] = df_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Smooth using rolling mean\n",
    "    df_im['Smoothed_Enrichment'] = df_im['Enrichment_Ratio'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Interpolate missing smoothed values\n",
    "    df_im['Smoothed_Enrichment'] = df_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Show summary stats after smoothing\n",
    "    print(f\"  Smoothed_Enrichment range: min = {df_im['Smoothed_Enrichment'].min():.2f}, \"\n",
    "          f\"max = {df_im['Smoothed_Enrichment'].max():.2f}, \"\n",
    "          f\"mean = {df_im['Smoothed_Enrichment'].mean():.2f}, \"\n",
    "          f\"95th percentile = {np.percentile(df_im['Smoothed_Enrichment'].dropna(), 95):.2f}\")\n",
    "\n",
    "\n",
    "    # Identify high enrichment positions\n",
    "    df_im['High_Enrichment'] = df_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_im['High_Enrichment'] = df_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Special filling for 'Neutralizing_Ab' if needed\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_im['Smoothed_Enrichment'] = df_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV for this immunization\n",
    "    csv_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_im.to_csv(csv_path, index=False)\n",
    "\n",
    "    # Reindex to cover full range of positions for visualization\n",
    "    full_range = range(df_im['Spike_AS_Position'].min(), df_im['Spike_AS_Position'].max() + 1)\n",
    "    df_im = df_im.set_index('Spike_AS_Position').reindex(full_range).reset_index()\n",
    "\n",
    "    # Re-assign show_site based on sites_to_show\n",
    "    df_im = df_im.assign(\n",
    "        show_site=lambda x: x['Spike_AS_Position'].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "    df_im['High_Enrichment'] = df_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Plot using dmslogo.line.draw_line on the shared axis\n",
    "    dmslogo.line.draw_line(\n",
    "        df_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",  # no individual title\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2.5,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "\n",
    "    # Add empty plot to generate legend entry\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites on the x-axis with thick horizontal lines at y=0\n",
    "    highlight_sites = df_im[df_im['show_site']]\n",
    "    for _, site_row in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0,\n",
    "            xmin=site_row['Spike_AS_Position'] - 0.5,\n",
    "            xmax=site_row['Spike_AS_Position'] + 0.5,\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=10\n",
    "        )\n",
    "\n",
    "# Set y limits\n",
    "ax.set_ylim(0, 40)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title('Smoothed Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Antibody Repertoire - Enrichment \\n (Average Polyreactivity)', fontsize=16)\n",
    "\n",
    "# Legend - order and grouping\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "#group_1_labels = ['Polyclonal_Ab', 'Neutralizing_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "#group_1_handles = [handles[labels.index(label)] for label in group_1_labels if label in labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels if label in labels]\n",
    "\n",
    "#handles = group_1_handles + group_2_handles\n",
    "#labels = group_1_labels + group_2_labels\n",
    "\n",
    "handles =  group_2_handles\n",
    "labels = group_2_labels\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Single Droplet Repertoire\",\n",
    "    loc='upper center',\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    title_fontsize=11,\n",
    "    markerscale=8\n",
    ")\n",
    "\n",
    "# Set x-axis ticks: 20 ticks across the range, label every other one\n",
    "xticks = np.linspace(df_filtered_agg['Spike_AS_Position'].min(), df_filtered_agg['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels([str(x) if i % 2 == 0 else '' for i, x in enumerate(xticks)])\n",
    "\n",
    "# Set y-axis major locator for better integer ticks\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, prune='lower', nbins=8))\n",
    "\n",
    "# Save figure\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", \"combined_Immunization_Enrichment_plot.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Summary statistics for {immunization}:\")\n",
    "print(df_im[['Enrichment_Ratio', 'Smoothed_Enrichment']].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all Smoothed_Enrichment data for histogram\n",
    "all_smoothed = []\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization in ['Library_ctrl', 'Polyclonal_Ab', 'Neutralizing_Ab']:\n",
    "        continue\n",
    "    df_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "    df_im = df_im.groupby('Spike_AS_Position', as_index=False).agg({'Enrichment_Ratio': 'mean'})\n",
    "    df_im['Smoothed_Enrichment'] = df_im['Enrichment_Ratio'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    all_smoothed.extend(df_im['Smoothed_Enrichment'].dropna().tolist())\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(all_smoothed, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title(\"Distribution of Smoothed Enrichment Values\")\n",
    "plt.xlabel(\"Smoothed Enrichment\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 20  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & \n",
    "                       (df_total['Enrichment_Ratio'] > 1)]  # Only include Enrichment_Ratio > 1\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':  # Skip 'Library_ctrl'\n",
    "        continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    # Count number of unique barcodes in this immunization\n",
    "    num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "    \n",
    "    # Aggregate and normalize by barcode count\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "    df_filtered_im['Enrichment_Ratio'] /= num_barcodes  # Normalize\n",
    "    if df_filtered_im['Enrichment_Ratio'].isna().any():\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values (linear interpolation)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization (after interpolation to avoid issues)\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    print(f\"Target sites to highlight: {list(sites_to_show)}\")\n",
    "\n",
    "    # Check the data type of Spike_AS_Position and sites_to_show for comparison\n",
    "    print(f\"Data type of 'Spike_AS_Position': {df_filtered_agg['Spike_AS_Position'].dtype}\")\n",
    "    print(f\"Data type of 'sites_to_show': {type(sites_to_show)}\")\n",
    "\n",
    "    # Ensure High_Enrichment is still boolean\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "    # Use dmslogo.line.draw_line but plot on the same axes with specified color\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",  # Remove individual titles for each plot\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"show_site\",  # Highlight high enrichment clusters\n",
    "        ax=ax,  # Pass the same axes object for all plots\n",
    "        linewidth=2.5,\n",
    "        color=color_map.get(immunization, 'black')  # Get the color for the immunization (default to black)\n",
    "    )\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        # Use ax.hlines to draw horizontal lines only where there are sites to show\n",
    "        ax.hlines(\n",
    "            y=0,  # Set the y-position of the line to 0 (or a small value near the bottom of the plot)\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,  # Start of the line (slightly before the site)\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,  # End of the line (slightly after the site)\n",
    "            color='black',  # Line color\n",
    "            linestyle='-',  # Line style\n",
    "            linewidth=10  # Line width\n",
    "        )\n",
    "\n",
    "# Set the y-axis limit to 200\n",
    "ax.set_ylim(0, 25)\n",
    "\n",
    "# After all lines are drawn, adjust plot settings\n",
    "plt.title('Smoothed Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Antibody Repertoire - Enrichment \\n (Median per-cell Polyreactivity)', fontsize=16)\n",
    "\n",
    "# Add the legend in the top right\n",
    "# Create a grouped legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "#group_1_labels = ['Polyclonal_Ab', 'Neutralizing_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "#group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "#handles = group_1_handles + group_2_handles\n",
    "#labels = group_1_labels + group_2_labels\n",
    "\n",
    "handles = group_2_handles\n",
    "labels = group_2_labels\n",
    "\n",
    "# Add the legend to the top right\n",
    "plt.legend(handles, labels, title=\"Single Droplet Repertoire\", loc='upper right', fontsize=11, frameon=False, handlelength=2, handleheight=1, title_fontsize=11, markerscale=8)\n",
    "\n",
    "# Set the x-axis ticks explicitly to 20 ticks across the range, and label every other one\n",
    "xticks = np.linspace(df_filtered_agg['Spike_AS_Position'].min(), df_filtered_agg['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "\n",
    "# Set the labels to only show for every other tick\n",
    "ax.set_xticklabels([str(x) if i % 2 == 0 else '' for i, x in enumerate(xticks)])\n",
    "\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, prune='lower', nbins=8))\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot.png\")\n",
    "fig.tight_layout() \n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "\n",
    "# Display the combined plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 1)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.3\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'mean'\n",
    "    })\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Apply smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].apply(\n",
    "        lambda x: np.log10(x) if x > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "    # Plot\n",
    "    \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0.76,  # set near bottom\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=10\n",
    "        )\n",
    "\n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=0.7,\n",
    "            top=np.nanmax(df_filtered_im['Smoothed_Enrichment']) + 0.3)\n",
    "\n",
    "plt.title('Smoothed Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Single-cell Polyreactivity\\n Log10 average binding ratio', fontsize=16)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "\n",
    "\n",
    "plt.legend(handles, labels, title=\"Immunization\",\n",
    "           loc='upper right', fontsize=11, frameon=False,\n",
    "           handlelength=2, handleheight=1, title_fontsize=11, markerscale=1)\n",
    "\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "xtick_start = int(np.floor(df_filtered_agg['Spike_AS_Position'].min() / 10.0) * 10)\n",
    "xtick_end = int(np.ceil(df_filtered_agg['Spike_AS_Position'].max() / 10.0) * 10)\n",
    "xticks = np.arange(xtick_start, xtick_end + 1, 10)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels([str(x) for x in xticks], rotation=0)\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, prune='lower', nbins=8))\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Enrichment_Ratio'] >= 1) &\n",
    "    (df_total['Amino_Acid'] != \"*\")\n",
    "].copy()\n",
    "\n",
    "# Define sites to show (as strings for consistent matching later)\n",
    "sites_to_show = list(map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    "))\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered.groupby(\n",
    "    ['immunization', 'Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "\n",
    "# Add useful columns for plotting\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create figure and axis for plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Immunizations to fade in plot\n",
    "faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "faint_alpha = 0.3\n",
    "\n",
    "# Loop through each immunization excluding 'Library_ctrl' and 'Neutralizing_Ab' (skip Neutralizing_Ab twice? Possibly intentional)\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization in ['Library_ctrl', 'Neutralizing_Ab']:\n",
    "        continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Group by position to get median enrichment ratio\n",
    "    df_im_pos = df_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'mean'\n",
    "    })\n",
    "\n",
    "    # Fill NaNs forward/backward\n",
    "    df_im_pos['Enrichment_Ratio'] = df_im_pos['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log2 transform, ignoring zero or negative values\n",
    "    df_im_pos['Log2_Enrichment'] = df_im_pos['Enrichment_Ratio'].apply(lambda x: np.log2(x) if x > 0 else np.nan)\n",
    "    print(df_im_pos[['Spike_AS_Position', 'Enrichment_Ratio']].head(20))\n",
    "\n",
    "    # Smooth the log2 enrichment with rolling mean\n",
    "    df_im_pos['Smoothed_Enrichment'] = df_im_pos['Log2_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_im_pos['Smoothed_Enrichment'] = df_im_pos['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "    print(df_im_pos[['Spike_AS_Position', 'Smoothed_Enrichment']].head(20))\n",
    "\n",
    "    # Flag positions with high enrichment\n",
    "    df_im_pos['High_Enrichment'] = df_im_pos['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_im_pos['High_Enrichment'] = df_im_pos['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Save CSV for this immunization\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_im_pos.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex to fill missing positions (to ensure continuous x-axis)\n",
    "    df_im_pos = df_im_pos.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_im_pos['Spike_AS_Position'].min(), df_im_pos['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Fill missing 'High_Enrichment' and assign 'show_site' again for reindexed dataframe\n",
    "    df_im_pos['High_Enrichment'] = df_im_pos['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_im_pos['show_site'] = df_im_pos['Spike_AS_Position'].astype(str).isin(sites_to_show)\n",
    "\n",
    "    print(df_im_pos[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "    # Calculate rolling min and max for shaded range plot\n",
    "    df_im_pos['Smoothed_Enrichment_min'] = df_im_pos['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    df_im_pos['Smoothed_Enrichment_max'] = df_im_pos['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "\n",
    "    # Plot shaded area\n",
    "    ax.fill_between(\n",
    "        df_im_pos['Spike_AS_Position'],\n",
    "        df_im_pos['Smoothed_Enrichment_min'],\n",
    "        df_im_pos['Smoothed_Enrichment_max'],\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot line (using dmslogo.line.draw_line - assuming dmslogo is imported and available)\n",
    "    dmslogo.line.draw_line(\n",
    "        df_im_pos,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "\n",
    "    # Apply transparency if immunization in faint list\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Print smoothed enrichment every 20th position\n",
    "    print(f\"\\nSmoothed Enrichment values for immunization '{immunization}':\")\n",
    "    positions_to_print = range(df_im_pos['Spike_AS_Position'].min(),\n",
    "                               df_im_pos['Spike_AS_Position'].max() + 1, 20)\n",
    "    for pos in positions_to_print:\n",
    "        val_row = df_im_pos[df_im_pos['Spike_AS_Position'] == pos]\n",
    "        if not val_row.empty:\n",
    "            val = val_row['Smoothed_Enrichment'].values[0]\n",
    "            print(f\"Position {pos}: {val:.3f}\")\n",
    "        else:\n",
    "            print(f\"Position {pos}: (no data)\")\n",
    "\n",
    "    # Highlight specific sites\n",
    "    highlight_sites = df_im_pos[df_im_pos['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0.2,  # set near bottom of plot\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=10\n",
    "        )\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(bottom=0.7, top=np.nanmax(df_im_pos['Smoothed_Enrichment']+1.1))\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Polyreactivity\\n Log2 AB Variant binding', fontsize=16)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create legend patch for epitopes\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels if label in labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels if label in labels]\n",
    "\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels if label in label_map] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='upper left',\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks setup\n",
    "major_locator = MultipleLocator(10)\n",
    "minor_locator = MultipleLocator(2)\n",
    "\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "ax.yaxis.set_major_locator(MaxNLocator(prune='lower', nbins=15))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "\n",
    "# Save plot\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[\n",
    "    (df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "    (df_total['Enrichment_Ratio'] >= 1) &\n",
    "    (df_total['Amino_Acid'] != \"*\")\n",
    "].copy()\n",
    "\n",
    "# Define sites to show (as strings for consistent matching later)\n",
    "sites_to_show = list(map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    "))\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered.groupby(\n",
    "    ['immunization', 'Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Add useful columns for plotting\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create figure and axis for plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Immunizations to fade in plot\n",
    "faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "faint_alpha = 0.3\n",
    "\n",
    "# Loop through each immunization excluding 'Library_ctrl' and 'Neutralizing_Ab' (skip Neutralizing_Ab twice? Possibly intentional)\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization in ['Library_ctrl', 'Neutralizing_Ab']:\n",
    "        continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Group by position to get median enrichment ratio\n",
    "    df_im_pos = df_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'mean'\n",
    "    })\n",
    "\n",
    "    # Fill NaNs forward/backward\n",
    "    df_im_pos['Enrichment_Ratio'] = df_im_pos['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log2 transform, ignoring zero or negative values\n",
    "    df_im_pos['Log2_Enrichment'] = df_im_pos['Enrichment_Ratio'].apply(lambda x: np.log2(x) if x > 0 else np.nan)\n",
    "    print(df_im_pos[['Spike_AS_Position', 'Enrichment_Ratio']].head(20))\n",
    "\n",
    "    # Smooth the log2 enrichment with rolling mean\n",
    "    df_im_pos['Smoothed_Enrichment'] = df_im_pos['Log2_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_im_pos['Smoothed_Enrichment'] = df_im_pos['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "    print(df_im_pos[['Spike_AS_Position', 'Smoothed_Enrichment']].head(20))\n",
    "\n",
    "    # Flag positions with high enrichment\n",
    "    df_im_pos['High_Enrichment'] = df_im_pos['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_im_pos['High_Enrichment'] = df_im_pos['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Save CSV for this immunization\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_im_pos.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex to fill missing positions (to ensure continuous x-axis)\n",
    "    df_im_pos = df_im_pos.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_im_pos['Spike_AS_Position'].min(), df_im_pos['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Fill missing 'High_Enrichment' and assign 'show_site' again for reindexed dataframe\n",
    "    df_im_pos['High_Enrichment'] = df_im_pos['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_im_pos['show_site'] = df_im_pos['Spike_AS_Position'].astype(str).isin(sites_to_show)\n",
    "\n",
    "    print(df_im_pos[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "    # Calculate rolling min and max for shaded range plot\n",
    "    df_im_pos['Smoothed_Enrichment_min'] = df_im_pos['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    df_im_pos['Smoothed_Enrichment_max'] = df_im_pos['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "\n",
    "    # Plot shaded area\n",
    "    ax.fill_between(\n",
    "        df_im_pos['Spike_AS_Position'],\n",
    "        df_im_pos['Smoothed_Enrichment_min'],\n",
    "        df_im_pos['Smoothed_Enrichment_max'],\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot line (using dmslogo.line.draw_line - assuming dmslogo is imported and available)\n",
    "    dmslogo.line.draw_line(\n",
    "        df_im_pos,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "\n",
    "    # Apply transparency if immunization in faint list\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Print smoothed enrichment every 20th position\n",
    "    print(f\"\\nSmoothed Enrichment values for immunization '{immunization}':\")\n",
    "    positions_to_print = range(df_im_pos['Spike_AS_Position'].min(),\n",
    "                               df_im_pos['Spike_AS_Position'].max() + 1, 20)\n",
    "    for pos in positions_to_print:\n",
    "        val_row = df_im_pos[df_im_pos['Spike_AS_Position'] == pos]\n",
    "        if not val_row.empty:\n",
    "            val = val_row['Smoothed_Enrichment'].values[0]\n",
    "            print(f\"Position {pos}: {val:.3f}\")\n",
    "        else:\n",
    "            print(f\"Position {pos}: (no data)\")\n",
    "\n",
    "    # Highlight specific sites\n",
    "    highlight_sites = df_im_pos[df_im_pos['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0.2,  # set near bottom of plot\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=10\n",
    "        )\n",
    "\n",
    "# Set y-axis limits\n",
    "ax.set_ylim(bottom=0.7, top=np.nanmax(df_im_pos['Smoothed_Enrichment']+1.1))\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Polyreactivity\\n Log2 AB Variant binding', fontsize=16)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create legend patch for epitopes\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels if label in labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels if label in labels]\n",
    "\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels if label in label_map] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='upper left',\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks setup\n",
    "major_locator = MultipleLocator(10)\n",
    "minor_locator = MultipleLocator(2)\n",
    "\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "ax.yaxis.set_major_locator(MaxNLocator(prune='lower', nbins=15))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "\n",
    "# Save plot\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 1)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_total[df_total['Amino_Acid'] != \"*\"].copy()\n",
    "df_filtered_agg['Enrichment_Ratio'] = df_aa_agg['Enrichment_Ratio'].clip(lower=1e-3)\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.3\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'median'\n",
    "    })\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log2_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "        lambda x: np.log2(x) if x > 0 else np.nan\n",
    "    )\n",
    "    \n",
    "    # Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log2_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "        # Rolling min and max for range area\n",
    "    # Fixed (aligned min/max with smoothed mean)\n",
    "    df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "\n",
    "\n",
    "    # Plot shaded area for range\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        df_filtered_im['Smoothed_Enrichment_min'],\n",
    "        df_filtered_im['Smoothed_Enrichment_max'],\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0.23,  # set near bottom\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=10\n",
    "        )\n",
    "\n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=2.8,\n",
    "            top=np.nanmax(df_filtered_im['Smoothed_Enrichment']) + 0.5)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Polyreactivity\\n Log2 AB Variant binding', fontsize=16)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='upper left',\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "ax.yaxis.set_major_locator(MaxNLocator(prune='lower', nbins=15))  # no integer=True\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))  \n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.3\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = barcode_counts.get(immunization, 0)\n",
    "    #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "\n",
    "    print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "    print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "    \n",
    "    #df_filtered_im_agg = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "    #'Enrichment_Ratio': 'median'\n",
    "    #})\n",
    "   \n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "        lambda x: np.log10(x) if x > 0 else np.nan\n",
    "    )\n",
    "    \n",
    "    # Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "\n",
    "        #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "        # Rolling min and max for range area\n",
    "    # Fixed (aligned min/max with smoothed mean)\n",
    "    df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "\n",
    "\n",
    "    # Plot shaded area for range\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        df_filtered_im['Smoothed_Enrichment_min'],\n",
    "        df_filtered_im['Smoothed_Enrichment_max'],\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    #for _, site_data in highlight_sites.iterrows():\n",
    "     #   ax.hlines(\n",
    "     #       y=0,  # set near bottom\n",
    "     #       xmin=site_data['Spike_AS_Position'] - 0.1,\n",
    "     #       xmax=site_data['Spike_AS_Position'] + 0.1,\n",
    "     #       color='black',\n",
    "     #       linestyle='-',\n",
    "     #       linewidth=6\n",
    "     #   )\n",
    "    print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "    print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "    print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "    print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "    print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "\n",
    "    if immunization == 'wildtype_RBD':\n",
    "        print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "        print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "            ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "        ])\n",
    "\n",
    "\n",
    "    immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.15,\n",
    "            top=np.nanmax(df_filtered_im['Smoothed_Enrichment']) + 0.1)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 Antibody binding (Mean)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='upper left',\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "\n",
    "# Only label 0.0, 0.3, 0.6\n",
    "# Major ticks every 0.2 (labels show every 2nd 0.1 tick)\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f\"{y:.1f}\"))\n",
    "\n",
    "# Minor ticks every 0.1 or 0.05 (no labels)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "# Label every 2nd minor tick (every 0.04) similarly or skip labeling minor ticks entirely\n",
    "# If you want to label every 2nd minor tick:\n",
    "\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final_log10.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation and plotting with Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.3\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = barcode_counts.get(immunization, 0)\n",
    "    #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "\n",
    "    print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "    print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "    \n",
    "    #df_filtered_im_agg = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "    #'Enrichment_Ratio': 'median'\n",
    "    #})\n",
    "   \n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    \n",
    "    # Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "\n",
    "        #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "        # Rolling min and max for range area\n",
    "    # Fixed (aligned min/max with smoothed mean)\n",
    "    #df_filtered_im['Log10_Enrichment_min'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    #df_filtered_im['Log10_Enrichment_max'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    \n",
    "    # Calculate rolling mean and rolling std dev for Log10_Enrichment\n",
    "    df_filtered_im['Rolling_Mean'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Rolling_Std'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).std()\n",
    "    \n",
    "    # Define upper and lower bounds for shaded region\n",
    "    lower_bound = df_filtered_im['Rolling_Mean'] - df_filtered_im['Rolling_Std']\n",
    "    upper_bound = df_filtered_im['Rolling_Mean'] + df_filtered_im['Rolling_Std']\n",
    "\n",
    "    # Plot shaded area for range\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        #df_filtered_im['Log10_Enrichment_min'],\n",
    "        #df_filtered_im['Log10_Enrichment_max'],\n",
    "        lower_bound,\n",
    "        upper_bound,\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        #show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    #for _, site_data in highlight_sites.iterrows():\n",
    "     #   ax.hlines(\n",
    "     #       y=0,  # set near bottom\n",
    "     #       xmin=site_data['Spike_AS_Position'] - 0.1,\n",
    "     #       xmax=site_data['Spike_AS_Position'] + 0.1,\n",
    "     #       color='black',\n",
    "     #       linestyle='-',\n",
    "     #       linewidth=6\n",
    "     #   )\n",
    "    print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "    print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "    print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "    print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "    print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "\n",
    "    if immunization == 'wildtype_RBD':\n",
    "        print(\"\\n[DEBUG] Wildtype enrichment values (360–510):\")\n",
    "        print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "            ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "        ])\n",
    "\n",
    "\n",
    "    immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.3,\n",
    "            top=0.1)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 Antibody binding (Median)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "#plt.legend(\n",
    " #   handles, labels,\n",
    " #   title=\"Immunization\",\n",
    " #   title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    " #   loc='lower left',\n",
    " #   fontsize=11,\n",
    " #   frameon=False,\n",
    "  #  handlelength=2,\n",
    " #   handleheight=1,\n",
    "  #  markerscale=1\n",
    "#)\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "ax.set_xlim(right=510)\n",
    "\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f\"{y:.1f}\"))\n",
    "\n",
    "# Minor ticks every 0.1 or 0.05 (no labels)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.01))\n",
    "\n",
    "# Label every 2nd minor tick (every 0.04) similarly or skip labeling minor ticks entirely\n",
    "# If you want to label every 2nd minor tick:\n",
    "\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final_log10.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DMSpub Split by axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance (Shaded area) is calculated as the MINMAX of medians across the rolling circle (across 10 AA stretches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "from matplotlib import gridspec, font_manager\n",
    "from matplotlib.patches import Patch\n",
    "%matplotlib inline\n",
    "\n",
    "# -----------------------------\n",
    "# Utility function\n",
    "# -----------------------------\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "ROLLING_WINDOW = 10\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Filter dataset\n",
    "# -----------------------------\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Target sites\n",
    "sites_to_show = list(map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +\n",
    "    list(range(394, 414)) +\n",
    "    list(range(484, 505))\n",
    "))\n",
    "\n",
    "# Count barcodes\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Aggregate by immunization and position\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str)\n",
    ").groupby(['immunization', 'Spike_AS_Position'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# Color map\n",
    "# -----------------------------\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "faint_alpha = 0.3\n",
    "\n",
    "# -----------------------------\n",
    "# Create figure with split axes\n",
    "# -----------------------------\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1], hspace=0.15)\n",
    "ax_top = fig.add_subplot(gs[0])\n",
    "ax_bottom = fig.add_subplot(gs[1], sharex=ax_top)\n",
    "plt.setp(ax_top.get_xticklabels(), visible=False)\n",
    "\n",
    "# Track global y-limits\n",
    "top_y_max_global = -np.inf\n",
    "bottom_y_min_global = np.inf\n",
    "\n",
    "# -----------------------------\n",
    "# Loop over immunizations\n",
    "# -----------------------------\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization in ['Library_ctrl', 'Neutralizing_Ab']:\n",
    "        continue\n",
    "\n",
    "    df_filtered_im = df_filtered_agg[df_filtered_agg['immunization'] == immunization].copy()\n",
    "\n",
    "    # Use bfill/ffill to avoid FutureWarning\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    # Split positive and negative BEFORE smoothing/interpolation\n",
    "    df_top = df_filtered_im[df_filtered_im['Log10_Enrichment'] > 0].copy()\n",
    "    df_bottom = df_filtered_im[df_filtered_im['Log10_Enrichment'] < 0].copy()\n",
    "    split_dfs = {'top': df_top, 'bottom': df_bottom}\n",
    "\n",
    "    # Reindex split DataFrames to full Spike_AS_Position range\n",
    "    full_range = range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "                       df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    for key in split_dfs:\n",
    "        df = split_dfs[key]\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        # Reindex to full Spike_AS_Position range\n",
    "        df = df.set_index('Spike_AS_Position').reindex(full_range)\n",
    "\n",
    "        # Ensure numeric before interpolation\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # Smooth enrichment\n",
    "        df['Smoothed_Enrichment'] = df['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        ).mean().interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        df = df.dropna(subset=['Smoothed_Enrichment'])\n",
    "\n",
    "        # Rolling std for shading\n",
    "        df['Rolling_Min'] = df['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        ).min()\n",
    "        \n",
    "        df['Rolling_Max'] = df['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        ).max()\n",
    "        \n",
    "        #df['Rolling_Std'] = df['Log10_Enrichment'].rolling(\n",
    "         #   window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        #).std().fillna(0)\n",
    "\n",
    "        df = df.reset_index()\n",
    "        split_dfs[key] = df\n",
    "    # --- Update global y-limits using the smoothed values ---\n",
    "    if not split_dfs['top'].empty:\n",
    "        top_y_max_global = max(top_y_max_global, split_dfs['top']['Smoothed_Enrichment'].max())\n",
    "    if not split_dfs['bottom'].empty:\n",
    "        bottom_y_min_global = min(bottom_y_min_global, split_dfs['bottom']['Smoothed_Enrichment'].min())\n",
    "\n",
    " \n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Plot split\n",
    "    # -----------------------------\n",
    "    for key, df in split_dfs.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        ax_current = ax_top if key == 'top' else ax_bottom\n",
    "\n",
    "                # Calculate rolling standard deviation for shading (±1 SD)\n",
    "        df['Rolling_Std'] = df['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        ).std().fillna(0)\n",
    "\n",
    "        # Shaded region with ±1 SD around smoothed enrichment\n",
    "        ax_current.fill_between(\n",
    "            df['Spike_AS_Position'],\n",
    "            df['Smoothed_Enrichment'] - df['Rolling_Std'],\n",
    "            df['Smoothed_Enrichment'] + df['Rolling_Std'],\n",
    "            color=color_map.get(immunization, 'black'),\n",
    "            alpha=0.1\n",
    "        )\n",
    "\n",
    "        # Shaded region\n",
    "        #ax_current.fill_between(\n",
    "        #    df['Spike_AS_Position'],\n",
    "        #    df['Rolling_Min'],\n",
    "        #    df['Rolling_Max'],\n",
    "        #    color=color_map.get(immunization, 'black'),\n",
    "        #    alpha=0.1\n",
    "        #)\n",
    "        #ax_current.fill_between(\n",
    "        #    df['Spike_AS_Position'],\n",
    "        #    df['Smoothed_Enrichment'] - df['Rolling_Std'],\n",
    "        #    df['Smoothed_Enrichment'] + df['Rolling_Std'],\n",
    "        #color=color_map.get(immunization, 'black'),\n",
    "        #alpha=0.1\n",
    "        #)\n",
    "\n",
    "        # Smoothed line\n",
    "        line_color = color_map.get(immunization, 'none')\n",
    "        dmslogo.line.draw_line(\n",
    "            df,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            height_col=\"Smoothed_Enrichment\",\n",
    "            ax=ax_current,\n",
    "            linewidth=2,\n",
    "            color=line_color\n",
    "        )\n",
    "\n",
    "        if immunization in faint_immunizations:\n",
    "            ax_current.lines[-1].set_alpha(faint_alpha)\n",
    "\n",
    "        ax_current.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "# -----------------------------\n",
    "# Axis formatting\n",
    "# -----------------------------\n",
    "ax_top.set_ylabel(\" \", fontsize=12)\n",
    "ax_bottom.set_ylabel(\" \", fontsize=12)\n",
    "ax_bottom.set_xlabel(\"Spike AA Position\", fontsize=12)\n",
    "ax_bottom.axhline(y=0, color='black', linewidth=2)\n",
    "\n",
    "ax_top.set_ylim(bottom=0, top=0.08)\n",
    "ax_bottom.set_ylim(bottom=-0.28, top=0)\n",
    "ax_bottom.set_xlim(right=510)\n",
    "\n",
    "# X-axis ticks\n",
    "ax_bottom.xaxis.set_major_locator(MultipleLocator(10))\n",
    "ax_bottom.xaxis.set_minor_locator(MultipleLocator(2))\n",
    "plt.setp(ax_bottom.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "\n",
    "# Y-axis ticks\n",
    "# Y-axis ticks with separate spacing\n",
    "ax_top.yaxis.set_major_locator(MultipleLocator(0.05))   # Top axis major ticks\n",
    "ax_top.yaxis.set_minor_locator(MultipleLocator(0.01))   # Top axis minor ticks\n",
    "\n",
    "ax_bottom.yaxis.set_major_locator(MultipleLocator(0.1)) # Bottom axis major ticks\n",
    "ax_bottom.yaxis.set_minor_locator(MultipleLocator(0.05)) # Bottom axis minor ticks\n",
    "\n",
    "# Tick parameters\n",
    "ax_top.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax_top.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax_bottom.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax_bottom.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "bottom_ticks = ax_bottom.get_yticks()\n",
    "bottom_labels = [\"\" if t == 0 else str(round(t, 2)) for t in bottom_ticks]\n",
    "ax_bottom.set_yticklabels(bottom_labels)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Legend\n",
    "# -----------------------------\n",
    "#epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "handles, labels = ax_top.get_legend_handles_labels()\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "#ax_top.legend(handles=handles, labels=labels, fontsize=10, frameon=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Save figure\n",
    "# -----------------------------\n",
    "plot_file_path = os.path.join(\"/Users/lucaschlotheuber/Desktop\", \"split_top_bottom_plot.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance (Shaded area) is calculated as the CI95 interval from the line plot Log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "from matplotlib import gridspec, font_manager\n",
    "from matplotlib.patches import Patch\n",
    "%matplotlib inline\n",
    "\n",
    "# -----------------------------\n",
    "# Utility function\n",
    "# -----------------------------\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "ROLLING_WINDOW = 10\n",
    "ENRICHMENT_THRESHOLD = 0\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Filter dataset\n",
    "# -----------------------------\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Target sites\n",
    "sites_to_show = list(map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +\n",
    "    list(range(394, 414)) +\n",
    "    list(range(484, 505))\n",
    "))\n",
    "\n",
    "# Count barcodes\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Aggregate by immunization and position\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str)\n",
    ").groupby(['immunization', 'Spike_AS_Position'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# Color map\n",
    "# -----------------------------\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "faint_alpha = 0.6\n",
    "\n",
    "# -----------------------------\n",
    "# Create figure with split axes\n",
    "# -----------------------------\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1], hspace=0.15)\n",
    "ax_top = fig.add_subplot(gs[0])\n",
    "ax_bottom = fig.add_subplot(gs[1], sharex=ax_top)\n",
    "plt.setp(ax_top.get_xticklabels(), visible=False)\n",
    "\n",
    "# Track global y-limits\n",
    "top_y_max_global = -np.inf\n",
    "bottom_y_min_global = np.inf\n",
    "\n",
    "# -----------------------------\n",
    "# Loop over immunizations\n",
    "# -----------------------------\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization in ['Library_ctrl', 'Neutralizing_Ab']:\n",
    "        continue\n",
    "\n",
    "    df_filtered_im = df_filtered_agg[df_filtered_agg['immunization'] == immunization].copy()\n",
    "\n",
    "    # Use bfill/ffill to avoid FutureWarning\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    # Split positive and negative BEFORE smoothing/interpolation\n",
    "    df_top = df_filtered_im[df_filtered_im['Log10_Enrichment'] > 0].copy()\n",
    "    df_bottom = df_filtered_im[df_filtered_im['Log10_Enrichment'] < 0].copy()\n",
    "    split_dfs = {'top': df_top, 'bottom': df_bottom}\n",
    "\n",
    "    # Compute 95% CI across barcodes for shading\n",
    "    df_im_raw = df_filtered[df_filtered['immunization'] == immunization].copy()\n",
    "    df_im_raw['Log10_Enrichment'] = df_im_raw['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "    grouped = df_im_raw.groupby('Spike_AS_Position')['Log10_Enrichment']\n",
    "    std_per_pos = grouped.std()\n",
    "    count_per_pos = grouped.count()\n",
    "    sem_per_pos = std_per_pos / np.sqrt(count_per_pos)\n",
    "    dof = count_per_pos - 1\n",
    "    dof[dof < 1] = 1\n",
    "    t_critical = dof.apply(lambda df: stats.t.ppf(0.975, df))\n",
    "    margin_of_error = t_critical * sem_per_pos\n",
    "\n",
    "    # Smooth the margin across positions\n",
    "    smoothed_margin = margin_of_error.rolling(window=ROLLING_WINDOW, center=True, min_periods=1).median()\n",
    "    smoothed_margin = smoothed_margin.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Reindex split DataFrames to full Spike_AS_Position range\n",
    "    full_range = range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "                       df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    for key in split_dfs:\n",
    "        df = split_dfs[key]\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df = df.set_index('Spike_AS_Position').reindex(full_range)\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # Smooth enrichment\n",
    "        df['Smoothed_Enrichment'] = df['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        ).mean().interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # Add CI margin for shading\n",
    "        df['Smoothed_CI_Margin'] = smoothed_margin.reindex(df.index).fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "        df = df.dropna(subset=['Smoothed_Enrichment'])\n",
    "        df = df.reset_index()\n",
    "        split_dfs[key] = df\n",
    "\n",
    "    # --- Update global y-limits using the smoothed values ---\n",
    "    if not split_dfs['top'].empty:\n",
    "        top_y_max_global = max(top_y_max_global, split_dfs['top']['Smoothed_Enrichment'].max())\n",
    "    if not split_dfs['bottom'].empty:\n",
    "        bottom_y_min_global = min(bottom_y_min_global, split_dfs['bottom']['Smoothed_Enrichment'].min())\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Plot split\n",
    "    # -----------------------------\n",
    "    for key, df in split_dfs.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        ax_current = ax_top if key == 'top' else ax_bottom\n",
    "\n",
    "        # --- 95% CI shading ---\n",
    "        ax_current.fill_between(\n",
    "            df['Spike_AS_Position'],\n",
    "            df['Smoothed_Enrichment'] - df['Smoothed_CI_Margin'],\n",
    "            df['Smoothed_Enrichment'] + df['Smoothed_CI_Margin'],\n",
    "            color=color_map.get(immunization, 'black'),\n",
    "            alpha=0.1\n",
    "        )\n",
    "\n",
    "        # Smoothed line\n",
    "        line_color = color_map.get(immunization, 'none')\n",
    "        dmslogo.line.draw_line(\n",
    "            df,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            height_col=\"Smoothed_Enrichment\",\n",
    "            ax=ax_current,\n",
    "            linewidth=2,\n",
    "            color=line_color\n",
    "        )\n",
    "\n",
    "        if immunization in faint_immunizations:\n",
    "            ax_current.lines[-1].set_alpha(faint_alpha)\n",
    "\n",
    "        ax_current.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Axis formatting\n",
    "# -----------------------------\n",
    "ax_top.set_ylabel(\" \", fontsize=12)\n",
    "ax_bottom.set_ylabel(\" \", fontsize=12)\n",
    "ax_top.set_xlabel(\"\")\n",
    "ax_bottom.axhline(y=0, color='black', linewidth=2)\n",
    "\n",
    "ax_top.set_ylim(bottom=0, top=0.15)\n",
    "ax_bottom.set_ylim(bottom=-0.3, top=0)\n",
    "ax_bottom.set_xlim(right=510)\n",
    "\n",
    "# X-axis ticks\n",
    "ax_bottom.xaxis.set_major_locator(MultipleLocator(10))  # or 1, 2, whatever spacing you want\n",
    "ax_bottom.set_xticklabels(\n",
    "    [str(int(tick)) for tick in ax_bottom.get_xticks()],  # convert tick positions to strings\n",
    "    rotation=0,\n",
    "    fontsize=10\n",
    ")\n",
    "ax_bottom.tick_params(axis='x', labelbottom=True)\n",
    "ax_bottom.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "\n",
    "\n",
    "# Y-axis ticks\n",
    "# Y-axis ticks with separate spacing\n",
    "ax_top.yaxis.set_major_locator(MultipleLocator(0.05))   # Top axis major ticks\n",
    "ax_top.yaxis.set_minor_locator(MultipleLocator(0.01))   # Top axis minor ticks\n",
    "\n",
    "ax_bottom.yaxis.set_major_locator(MultipleLocator(0.05)) # Bottom axis major ticks\n",
    "ax_bottom.yaxis.set_minor_locator(MultipleLocator(0.01)) # Bottom axis minor ticks\n",
    "\n",
    "# Tick parameters\n",
    "ax_top.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax_top.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax_bottom.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax_bottom.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "bottom_ticks = ax_bottom.get_yticks()\n",
    "bottom_labels = [\"\" if t == 0 else str(round(t, 2)) for t in bottom_ticks]\n",
    "ax_bottom.set_yticklabels(bottom_labels)\n",
    "\n",
    "# Hide top plot x-axis tick labels and ticks\n",
    "ax_top.tick_params(axis='x', labelbottom=False, length=7)\n",
    "\n",
    "# Bottom axis: show tick labels and tick marks\n",
    "ax_bottom.tick_params(axis='x', labelbottom=True, length=7)\n",
    "ax_bottom.set_xlabel(\"Spike AA Position\", fontsize=15)\n",
    "# Bottom axis: show tick marks and labels\n",
    "# Bottom axis: show tick marks and labels\n",
    "ax_bottom.tick_params(axis='x', labelbottom=True, length=7)  # turn labels on and keep tick marks\n",
    "ax_bottom.set_xlabel(\"Spike AA Position\", fontsize=15)\n",
    "fig.canvas.draw()\n",
    "\n",
    "# -----------------------------\n",
    "# Legend\n",
    "# -----------------------------\n",
    "#epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "handles, labels = ax_top.get_legend_handles_labels()\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "#ax_top.legend(handles=handles, labels=labels, fontsize=10, frameon=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Save figure\n",
    "# -----------------------------\n",
    "plot_file_path = os.path.join(\"/Users/lucaschlotheuber/Desktop\", \"AllABsplit_top_bottom_plot.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "from matplotlib import gridspec, font_manager\n",
    "from matplotlib.patches import Patch\n",
    "%matplotlib inline\n",
    "\n",
    "# -----------------------------\n",
    "# Utility function\n",
    "# -----------------------------\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "ROLLING_WINDOW = 15\n",
    "ENRICHMENT_THRESHOLD = 1\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Filter dataset\n",
    "# -----------------------------\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Target sites\n",
    "sites_to_show = list(map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +\n",
    "    list(range(394, 414)) +\n",
    "    list(range(484, 505))\n",
    "))\n",
    "\n",
    "# Count barcodes\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Aggregate by immunization and position\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str)\n",
    ").groupby(['immunization', 'Spike_AS_Position'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# -----------------------------\n",
    "# Color map\n",
    "# -----------------------------\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "faint_alpha = 0.6\n",
    "\n",
    "# -----------------------------\n",
    "# Create figure with split axes\n",
    "# -----------------------------\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1], hspace=0.15)\n",
    "ax_top = fig.add_subplot(gs[0])\n",
    "ax_bottom = fig.add_subplot(gs[1], sharex=ax_top)\n",
    "plt.setp(ax_top.get_xticklabels(), visible=False)\n",
    "\n",
    "# Track global y-limits\n",
    "top_y_max_global = -np.inf\n",
    "bottom_y_min_global = np.inf\n",
    "\n",
    "# -----------------------------\n",
    "# Loop over immunizations\n",
    "# -----------------------------\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization in ['Library_ctrl', 'Neutralizing_Ab']:\n",
    "        continue\n",
    "\n",
    "    df_filtered_im = df_filtered_agg[df_filtered_agg['immunization'] == immunization].copy()\n",
    "\n",
    "    # Use bfill/ffill to avoid FutureWarning\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    # Split positive and negative BEFORE smoothing/interpolation\n",
    "    df_top = df_filtered_im[df_filtered_im['Log10_Enrichment'] > 0].copy()\n",
    "    df_bottom = df_filtered_im[df_filtered_im['Log10_Enrichment'] < 0].copy()\n",
    "    split_dfs = {'top': df_top, 'bottom': df_bottom}\n",
    "\n",
    "    # Compute 95% CI across barcodes for shading\n",
    "    df_im_raw = df_filtered[df_filtered['immunization'] == immunization].copy()\n",
    "    df_im_raw['Log10_Enrichment'] = df_im_raw['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "    grouped = df_im_raw.groupby('Spike_AS_Position')['Log10_Enrichment']\n",
    "    std_per_pos = grouped.std()\n",
    "    count_per_pos = grouped.count()\n",
    "    sem_per_pos = std_per_pos / np.sqrt(count_per_pos)\n",
    "    dof = count_per_pos - 1\n",
    "    dof[dof < 1] = 1\n",
    "    t_critical = dof.apply(lambda df: stats.t.ppf(0.975, df))\n",
    "    margin_of_error = t_critical * sem_per_pos\n",
    "\n",
    "    # Smooth the margin across positions\n",
    "    smoothed_margin = margin_of_error.rolling(window=ROLLING_WINDOW, center=True, min_periods=1).median()\n",
    "    smoothed_margin = smoothed_margin.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Reindex split DataFrames to full Spike_AS_Position range\n",
    "    full_range = range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "                       df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    for key in split_dfs:\n",
    "        df = split_dfs[key]\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df = df.set_index('Spike_AS_Position').reindex(full_range)\n",
    "        df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # Smooth enrichment\n",
    "        df['Smoothed_Enrichment'] = df['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        ).mean().interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # Add CI margin for shading\n",
    "        df['Smoothed_CI_Margin'] = smoothed_margin.reindex(df.index).fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "        df = df.dropna(subset=['Smoothed_Enrichment'])\n",
    "        df = df.reset_index()\n",
    "        split_dfs[key] = df\n",
    "\n",
    "    # --- Update global y-limits using the smoothed values ---\n",
    "    if not split_dfs['top'].empty:\n",
    "        top_y_max_global = max(top_y_max_global, split_dfs['top']['Smoothed_Enrichment'].max())\n",
    "    if not split_dfs['bottom'].empty:\n",
    "        bottom_y_min_global = min(bottom_y_min_global, split_dfs['bottom']['Smoothed_Enrichment'].min())\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "    # Plot split\n",
    "    # -----------------------------\n",
    "    for key, df in split_dfs.items():\n",
    "        if df.empty:\n",
    "            continue\n",
    "    \n",
    "        ax_current = ax_top if key == 'top' else ax_bottom\n",
    "    \n",
    "        # Compute rolling min and max for shading\n",
    "        df['Rolling_Min'] = df['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        ).min()\n",
    "        df['Rolling_Max'] = df['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "        ).max()\n",
    "    \n",
    "        # --- Shaded min-max area ---\n",
    "        ax_current.fill_between(\n",
    "            df['Spike_AS_Position'],\n",
    "            df['Rolling_Min'],\n",
    "            df['Rolling_Max'],\n",
    "            color=color_map.get(immunization, 'black'),\n",
    "            alpha=0.1\n",
    "        )\n",
    "    \n",
    "        # Smoothed line\n",
    "        line_color = color_map.get(immunization, 'none')\n",
    "        dmslogo.line.draw_line(\n",
    "            df,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            height_col=\"Smoothed_Enrichment\",\n",
    "            ax=ax_current,\n",
    "            linewidth=2,\n",
    "            color=line_color\n",
    "        )\n",
    "    \n",
    "        if immunization in faint_immunizations:\n",
    "            ax_current.lines[-1].set_alpha(faint_alpha)\n",
    "    \n",
    "        ax_current.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "# -----------------------------\n",
    "# Axis formatting\n",
    "# -----------------------------\n",
    "ax_top.set_ylabel(\" \", fontsize=12)\n",
    "ax_bottom.set_ylabel(\" \", fontsize=12)\n",
    "ax_bottom.set_xlabel(\"Spike AA Position\", fontsize=12)\n",
    "ax_bottom.axhline(y=0, color='black', linewidth=2)\n",
    "\n",
    "ax_top.set_ylim(bottom=0, top=0.2)\n",
    "ax_bottom.set_ylim(bottom=-0.4, top=0)\n",
    "ax_bottom.set_xlim(right=510)\n",
    "\n",
    "# X-axis ticks\n",
    "ax_bottom.xaxis.set_major_locator(MultipleLocator(10))\n",
    "ax_bottom.xaxis.set_minor_locator(MultipleLocator(2))\n",
    "plt.setp(ax_bottom.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "\n",
    "# Y-axis ticks\n",
    "# Y-axis ticks with separate spacing\n",
    "ax_top.yaxis.set_major_locator(MultipleLocator(0.05))   # Top axis major ticks\n",
    "ax_top.yaxis.set_minor_locator(MultipleLocator(0.01))   # Top axis minor ticks\n",
    "\n",
    "ax_bottom.yaxis.set_major_locator(MultipleLocator(0.05)) # Bottom axis major ticks\n",
    "ax_bottom.yaxis.set_minor_locator(MultipleLocator(0.01)) # Bottom axis minor ticks\n",
    "\n",
    "# Tick parameters\n",
    "ax_top.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax_top.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax_bottom.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax_bottom.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "bottom_ticks = ax_bottom.get_yticks()\n",
    "bottom_labels = [\"\" if t == 0 else str(round(t, 2)) for t in bottom_ticks]\n",
    "ax_bottom.set_yticklabels(bottom_labels)\n",
    "\n",
    "# -----------------------------\n",
    "# Legend\n",
    "# -----------------------------\n",
    "#epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "handles, labels = ax_top.get_legend_handles_labels()\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "#ax_top.legend(handles=handles, labels=labels, fontsize=10, frameon=False)\n",
    "\n",
    "# -----------------------------\n",
    "# Save figure\n",
    "# -----------------------------\n",
    "plot_file_path = os.path.join(\"/Users/lucaschlotheuber/Desktop\", \"split_top_bottom_plot.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation and plotting with Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.3\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = barcode_counts.get(immunization, 0)\n",
    "    #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "\n",
    "    print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "    print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "    \n",
    "    #df_filtered_im_agg = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "    #'Enrichment_Ratio': 'median'\n",
    "    #})\n",
    "   \n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    \n",
    "    # Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "\n",
    "        #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "        # Rolling min and max for range area\n",
    "    # Fixed (aligned min/max with smoothed mean)\n",
    "    #df_filtered_im['Log10_Enrichment_min'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    #df_filtered_im['Log10_Enrichment_max'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    \n",
    "    # Calculate rolling mean and rolling std dev for Log10_Enrichment\n",
    "    df_filtered_im['Rolling_Mean'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Rolling_Std'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).std()\n",
    "    \n",
    "    # Define upper and lower bounds for shaded region\n",
    "    lower_bound = df_filtered_im['Rolling_Mean'] - df_filtered_im['Rolling_Std']\n",
    "    upper_bound = df_filtered_im['Rolling_Mean'] + df_filtered_im['Rolling_Std']\n",
    "\n",
    "    # Plot shaded area for range\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        #df_filtered_im['Log10_Enrichment_min'],\n",
    "        #df_filtered_im['Log10_Enrichment_max'],\n",
    "        lower_bound,\n",
    "        upper_bound,\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        #show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    #for _, site_data in highlight_sites.iterrows():\n",
    "     #   ax.hlines(\n",
    "     #       y=0,  # set near bottom\n",
    "     #       xmin=site_data['Spike_AS_Position'] - 0.1,\n",
    "     #       xmax=site_data['Spike_AS_Position'] + 0.1,\n",
    "     #       color='black',\n",
    "     #       linestyle='-',\n",
    "     #       linewidth=6\n",
    "     #   )\n",
    "    print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "    print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "    print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "    print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "    print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "\n",
    "    if immunization == 'wildtype_RBD':\n",
    "        print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "        print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "            ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "        ])\n",
    "\n",
    "\n",
    "    immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.5,\n",
    "            top=0.6)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 Antibody binding (Mean)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='lower left',\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f\"{y:.1f}\"))\n",
    "\n",
    "# Minor ticks every 0.1 or 0.05 (no labels)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "# Label every 2nd minor tick (every 0.04) similarly or skip labeling minor ticks entirely\n",
    "# If you want to label every 2nd minor tick:\n",
    "\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final_log10.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean with CI instead of SD as shaded range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.3\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = barcode_counts.get(immunization, 0)\n",
    "    #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "\n",
    "    print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "    print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "    \n",
    "    #df_filtered_im_agg = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "    #'Enrichment_Ratio': 'median'\n",
    "    #})\n",
    "   \n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    \n",
    "    # Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "\n",
    "        #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "        # Rolling min and max for range area\n",
    "    # Fixed (aligned min/max with smoothed mean)\n",
    "    #df_filtered_im['Log10_Enrichment_min'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    #df_filtered_im['Log10_Enrichment_max'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    \n",
    "    # Calculate rolling mean and rolling std dev for Log10_Enrichment\n",
    "    rolling_mean = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    rolling_std = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).std()\n",
    "    n = ROLLING_WINDOW  # Or count actual points per window if needed\n",
    "    \n",
    "    ci_upper = rolling_mean + 1.96 * (rolling_std / np.sqrt(n))\n",
    "    ci_lower = rolling_mean - 1.96 * (rolling_std / np.sqrt(n))\n",
    "\n",
    "    # Plot shaded area for range\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        #df_filtered_im['Log10_Enrichment_min'],\n",
    "        #df_filtered_im['Log10_Enrichment_max'],\n",
    "        ci_lower,\n",
    "        ci_upper,\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0,  # set near bottom\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.1,\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.1,\n",
    "            color='orange',\n",
    "            linestyle='-',\n",
    "            linewidth=4\n",
    "        )\n",
    "    print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "    print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "    print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "    print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "    print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "\n",
    "    if immunization == 'wildtype_RBD':\n",
    "        print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "        print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "            ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "        ])\n",
    "\n",
    "\n",
    "    immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.4,\n",
    "            top=0.8)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 Antibody binding (Mean)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='orange', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='lower left',\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f\"{y:.1f}\"))\n",
    "\n",
    "# Minor ticks every 0.1 or 0.05 (no labels)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "ax.grid(True, axis='y')   # Turn ON horizontal gridlines only\n",
    "ax.grid(False, axis='x')  # Turn OFF vertical gridlines\n",
    "\n",
    "# Label every 2nd minor tick (every 0.04) similarly or skip labeling minor ticks entirely\n",
    "# If you want to label every 2nd minor tick:\n",
    "\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final_log10.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean with CI but rolled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.scale import ScaleBase\n",
    "from matplotlib.transforms import Transform\n",
    "from matplotlib.ticker import FixedLocator, FuncFormatter\n",
    "import matplotlib.scale as mscale\n",
    "\n",
    "\n",
    "class PiecewiseLinearScale(mscale.ScaleBase):\n",
    "    name = 'piecewise_linear'   # <--- Add this line\n",
    "\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        super().__init__(axis)\n",
    "        self.vmin_neg = kwargs.get('vmin_neg', -0.8)\n",
    "        self.vmax_pos = kwargs.get('vmax_pos', 0.1)\n",
    "\n",
    "    def get_transform(self):\n",
    "        return self.PiecewiseLinearTransform(self.vmin_neg, self.vmax_pos)\n",
    "\n",
    "    def set_default_locators_and_formatters(self, axis):\n",
    "        # Set tick locations evenly spaced on both sides of zero\n",
    "        neg_ticks = np.linspace(self.vmin_neg, 0, 5)\n",
    "        pos_ticks = np.linspace(0, self.vmax_pos, 5)[1:]  # exclude zero duplicate\n",
    "        axis.set_major_locator(FixedLocator(np.concatenate([neg_ticks, pos_ticks])))\n",
    "        axis.set_major_formatter(FuncFormatter(lambda x, _: f\"{x:.3f}\"))\n",
    "\n",
    "    class PiecewiseLinearTransform(Transform):\n",
    "        input_dims = 1\n",
    "        output_dims = 1\n",
    "        is_separable = True\n",
    "\n",
    "        def __init__(self, vmin_neg, vmax_pos):\n",
    "            super().__init__()\n",
    "            self.vmin_neg = vmin_neg\n",
    "            self.vmax_pos = vmax_pos\n",
    "            self.len_neg = abs(vmin_neg)\n",
    "            self.len_pos = vmax_pos\n",
    "\n",
    "        def transform_non_affine(self, y):\n",
    "            y = np.array(y)\n",
    "            res = np.empty_like(y, dtype=float)\n",
    "            neg_mask = (y <= 0)\n",
    "            pos_mask = (y > 0)\n",
    "\n",
    "            # Map negative part linearly to [0, 0.5]\n",
    "            res[neg_mask] = 0.5 * (y[neg_mask] - self.vmin_neg) / self.len_neg\n",
    "            # Map positive part linearly to [0.5, 1]\n",
    "            res[pos_mask] = 0.5 + 0.5 * y[pos_mask] / self.len_pos\n",
    "            return res\n",
    "\n",
    "        def inverted(self):\n",
    "            return PiecewiseLinearScale.InvertedPiecewiseLinearTransform(self.vmin_neg, self.vmax_pos)\n",
    "\n",
    "    class InvertedPiecewiseLinearTransform(Transform):\n",
    "        input_dims = 1\n",
    "        output_dims = 1\n",
    "        is_separable = True\n",
    "\n",
    "        def __init__(self, vmin_neg, vmax_pos):\n",
    "            super().__init__()\n",
    "            self.vmin_neg = vmin_neg\n",
    "            self.vmax_pos = vmax_pos\n",
    "            self.len_neg = abs(vmin_neg)\n",
    "            self.len_pos = vmax_pos\n",
    "\n",
    "        def transform_non_affine(self, y):\n",
    "            y = np.array(y)\n",
    "            res = np.empty_like(y, dtype=float)\n",
    "            neg_mask = (y <= 0.5)\n",
    "            pos_mask = (y > 0.5)\n",
    "\n",
    "            res[neg_mask] = self.vmin_neg + (y[neg_mask] / 0.5) * self.len_neg\n",
    "            res[pos_mask] = ((y[pos_mask] - 0.5) / 0.5) * self.len_pos\n",
    "            return res\n",
    "\n",
    "        def inverted(self):\n",
    "            return PiecewiseLinearScale.PiecewiseLinearTransform(self.vmin_neg, self.vmax_pos)\n",
    "\n",
    "# Register the custom scale with matplotlib\n",
    "from matplotlib.scale import register_scale\n",
    "register_scale(PiecewiseLinearScale)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.3\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = barcode_counts.get(immunization, 0)\n",
    "    #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "\n",
    "    print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "    print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "   \n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    \n",
    "    #Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "\n",
    "        #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "    # Interpolate final smoothed enrichment values to fill NaNs\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    n = 10  # rolling window for smoothing std dev\n",
    "    \n",
    "    # First, compute per-position std dev of Log10_Enrichment from raw replicate data for this immunization\n",
    "    df_im_raw = df_filtered[df_filtered['immunization'] == immunization].copy()\n",
    "    \n",
    "    # Make sure to transform enrichment ratio to log10 scale safely\n",
    "    df_im_raw['Log10_Enrichment'] = df_im_raw['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "    print(f\"[DEBUG] Raw Log10 enrichment values (first 20 rows):\\n{df_im_raw[['Spike_AS_Position', 'Log10_Enrichment']].head(20)}\\n\")\n",
    "\n",
    "    # Compute std dev per position across replicates/barcodes\n",
    "    std_per_pos = df_im_raw.groupby('Spike_AS_Position')['Log10_Enrichment'].std()\n",
    "    print(f\"[DEBUG] Raw std dev per position (first 20 values):\\n{std_per_pos.head(20)}\\n\")\n",
    "\n",
    "    \n",
    "    # Smooth the std dev values across positions\n",
    "    smoothed_std = std_per_pos.rolling(window=n, center=True, min_periods=1).median()\n",
    "    print(f\"[DEBUG] Smoothed std dev (first 20 values):\\n{smoothed_std.head(20)}\\n\")\n",
    "\n",
    "    \n",
    "    # Fill NaNs at edges if any\n",
    "    smoothed_std = smoothed_std.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Join this smoothed std dev back to df_filtered_im by position\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position')\n",
    "    df_filtered_im['Smoothed_StdDev'] = smoothed_std\n",
    "    df_filtered_im = df_filtered_im.reset_index()\n",
    "    \n",
    "    # Fill any remaining NaNs for the new column if needed\n",
    "    df_filtered_im['Smoothed_StdDev'] = df_filtered_im['Smoothed_StdDev'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Use ±1 standard deviation around the smoothed mean\n",
    "    std_upper = df_filtered_im['Smoothed_Enrichment'] + df_filtered_im['Smoothed_StdDev']\n",
    "    std_lower = df_filtered_im['Smoothed_Enrichment'] - df_filtered_im['Smoothed_StdDev']\n",
    "    \n",
    "    # Plot shaded standard deviation area\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        std_lower,\n",
    "        std_upper,\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.2,\n",
    "        zorder=5\n",
    "    )\n",
    "\n",
    "    #df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    #df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    # First, create a rolling max and min on original (non-log) Enrichment_Ratio\n",
    "     # Compute rolling 25th and 75th percentiles from the raw Enrichment_Ratio\n",
    "    # Calculate min and max Enrichment_Ratio for each position\n",
    "\n",
    "    \n",
    "    # Use your already calculated smoothed mean as center for CI\n",
    "    #ci_upper = df_filtered_im['Smoothed_Enrichment'] + 1.96 * (rolling_std / np.sqrt(n))\n",
    "    #ci_lower = df_filtered_im['Smoothed_Enrichment'] - 1.96 * (rolling_std / np.sqrt(n))\n",
    "    \n",
    "    ## Plot shaded CI area\n",
    "    #ax.fill_between(\n",
    "    #    df_filtered_im['Spike_AS_Position'],\n",
    "    #    ci_lower,\n",
    "    #    ci_upper,\n",
    "    #    color=color_map.get(immunization, 'black'),\n",
    "    #    alpha=0.2,\n",
    "    #    step='mid'\n",
    "   # )\n",
    "\n",
    "    # Plot\n",
    "    \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        #show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    highlight_mask = df_filtered_im['show_site'].apply(lambda x: 1.0 if x else np.nan) # 1.0 where True, 0.0 where False\n",
    "    bar_height = 0.002  # adjust the height of the bars here\n",
    "\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        -0.005,\n",
    "        highlight_mask * bar_height,\n",
    "        color='black',\n",
    "        where=highlight_mask,\n",
    "        alpha=0.5,\n",
    "        step='mid'  # aligns fill to the positions nicely\n",
    "    )\n",
    "\n",
    "    print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "    print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "    print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "    print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "    print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "\n",
    "    if immunization == 'wildtype_RBD':\n",
    "        print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "        print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "            ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "        ])\n",
    "\n",
    "\n",
    "    immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.4,\n",
    "            top=0.04)\n",
    "\n",
    "plt.title('', fontsize=16)\n",
    "plt.xlabel('Spike AA Position', fontsize=18)\n",
    "plt.ylabel('Log10 AB binding (Mean) \\n All antibodies', fontsize=16)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='orange', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "fig.subplots_adjust(right=0.8)\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='center left',          # Legend inside figure but on the left side of bbox_to_anchor\n",
    "    bbox_to_anchor=(1, 0.5),    # Outside plot area on right, vertically centered\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "\n",
    "\n",
    "# Minor ticks every 0.1 or 0.05 (no labels)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.01))\n",
    "ax.grid(False, axis='y')   # Turn ON horizontal gridlines only\n",
    "ax.grid(False, axis='x')  # Turn OFF vertical gridlines\n",
    "\n",
    "# Label every 2nd minor tick (every 0.04) similarly or skip labeling minor ticks entirely\n",
    "# If you want to label every 2nd minor tick:  # wider figure to fit legend on right\n",
    "# Add a single horizontal gridline at y=0.3\n",
    "#ax.axhline(y=0.3, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "#ax.axhline(y=0.1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "ax.set_xlim(right=510)\n",
    "\n",
    "# Set limits to your observed data range or desired axis range\n",
    "vmin_neg = -0.75  # from your code\n",
    "vmax_pos = 0.6\n",
    "\n",
    "# Set numeric limits for your data range\n",
    "ax.set_ylim(vmin_neg, vmax_pos)\n",
    "\n",
    "# Set your custom scale on the y-axis with these limits\n",
    "ax.set_yscale('piecewise_linear', vmin_neg=vmin_neg, vmax_pos=vmax_pos)\n",
    "\n",
    "# Save\n",
    "\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_log10_Mean_AllAntibodies.png\")\n",
    "fig.set_size_inches(10, 4)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')  # Save after resizing/layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For publication Median across all barcodes and 95% confidence interval variance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.5\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = barcode_counts.get(immunization, 0)\n",
    "    #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "\n",
    "    print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "    print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "   \n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    #Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "\n",
    "        #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "    # Interpolate final smoothed enrichment values to fill NaNs\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "    n = 10  # rolling window for smoothing\n",
    "    \n",
    "    # Filter raw data for immunization\n",
    "    df_im_raw = df_filtered[df_filtered['immunization'] == immunization].copy()\n",
    "    \n",
    "    # Transform enrichment ratio safely\n",
    "    df_im_raw['Log10_Enrichment'] = df_im_raw['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "    print(f\"[DEBUG] Raw Log10 enrichment values (first 20 rows):\\n{df_im_raw[['Spike_AS_Position', 'Log10_Enrichment']].head(20)}\\n\")\n",
    "    \n",
    "    # Calculate std dev and count per position\n",
    "    grouped = df_im_raw.groupby('Spike_AS_Position')['Log10_Enrichment']\n",
    "    std_per_pos = grouped.std()\n",
    "    count_per_pos = grouped.count()\n",
    "    \n",
    "    print(f\"[DEBUG] Raw std dev per position (first 20 values):\\n{std_per_pos.head(20)}\\n\")\n",
    "    print(f\"[DEBUG] Counts per position (first 20 values):\\n{count_per_pos.head(20)}\\n\")\n",
    "    \n",
    "    # Calculate standard error of the mean (SEM)\n",
    "    sem_per_pos = std_per_pos / np.sqrt(count_per_pos)\n",
    "    \n",
    "    # Calculate t-critical value for 95% confidence interval (two-tailed)\n",
    "    # Degrees of freedom = count - 1, minimum 1 to avoid div by zero\n",
    "    dof = count_per_pos - 1\n",
    "    dof[dof < 1] = 1\n",
    "    t_critical = dof.apply(lambda df: stats.t.ppf(0.975, df))  # 0.975 for two-tailed 95%\n",
    "    \n",
    "    # Margin of error = t-critical * SEM\n",
    "    margin_of_error = t_critical * sem_per_pos\n",
    "    \n",
    "    # Smooth the margin of error across positions\n",
    "    smoothed_margin = margin_of_error.rolling(window=n, center=True, min_periods=1).median()\n",
    "    print(f\"[DEBUG] Smoothed margin of error (first 20 values):\\n{smoothed_margin.head(20)}\\n\")\n",
    "    \n",
    "    # Fill NaNs at edges if any\n",
    "    smoothed_margin = smoothed_margin.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Join smoothed margin of error back to df_filtered_im\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position')\n",
    "    df_filtered_im['Smoothed_CI_Margin'] = smoothed_margin\n",
    "    df_filtered_im = df_filtered_im.reset_index()\n",
    "    \n",
    "    # Fill any remaining NaNs\n",
    "    df_filtered_im['Smoothed_CI_Margin'] = df_filtered_im['Smoothed_CI_Margin'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Use ± margin of error around smoothed mean\n",
    "    std_upper = df_filtered_im['Smoothed_Enrichment'] + df_filtered_im['Smoothed_CI_Margin']\n",
    "    std_lower = df_filtered_im['Smoothed_Enrichment'] - df_filtered_im['Smoothed_CI_Margin']\n",
    "    \n",
    "    # Plot shaded 95% CI area\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        std_lower,\n",
    "        std_upper,\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1,\n",
    "        zorder=5\n",
    "    )\n",
    "\n",
    "    #df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    #df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    # First, create a rolling max and min on original (non-log) Enrichment_Ratio\n",
    "     # Compute rolling 25th and 75th percentiles from the raw Enrichment_Ratio\n",
    "    # Calculate min and max Enrichment_Ratio for each position\n",
    "\n",
    "    \n",
    "    # Use your already calculated smoothed mean as center for CI\n",
    "    #ci_upper = df_filtered_im['Smoothed_Enrichment'] + 1.96 * (rolling_std / np.sqrt(n))\n",
    "    #ci_lower = df_filtered_im['Smoothed_Enrichment'] - 1.96 * (rolling_std / np.sqrt(n))\n",
    "    \n",
    "    ## Plot shaded CI area\n",
    "    #ax.fill_between(\n",
    "    #    df_filtered_im['Spike_AS_Position'],\n",
    "    #    ci_lower,\n",
    "    #    ci_upper,\n",
    "    #    color=color_map.get(immunization, 'black'),\n",
    "    #    alpha=0.2,\n",
    "    #    step='mid'\n",
    "   # )\n",
    "\n",
    "    # Plot\n",
    "    line_color = color_map.get(immunization, 'none') \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        #show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2.5,\n",
    "        color=line_color\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    #highlight_mask = df_filtered_im['show_site'].apply(lambda x: 1.0 if x else np.nan) # 1.0 where True, 0.0 where False\n",
    "    #bar_height = 0.002  # adjust the height of the bars here\n",
    "\n",
    "    #ax.fill_between(\n",
    "    #    df_filtered_im['Spike_AS_Position'],\n",
    "    #    -0.005,\n",
    "    #    highlight_mask * bar_height,\n",
    "    #    color='black',\n",
    "    #    where=highlight_mask,\n",
    "    #    alpha=0.5,\n",
    "    #    step='mid'  # aligns fill to the positions nicely\n",
    "    #)\n",
    "\n",
    "    print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "    print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "    print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "    print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "    print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "\n",
    "    if immunization == 'wildtype_RBD':\n",
    "        print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "        print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "            ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "        ])\n",
    "\n",
    "\n",
    "    immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.4,\n",
    "            top=0.04)\n",
    "\n",
    "plt.title('', fontsize=16)\n",
    "plt.xlabel('Spike AA Position', fontsize=14)\n",
    "plt.ylabel('Log10 AB binding (Median) \\n All antibodies', fontsize=14)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='orange', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "fig.subplots_adjust(right=0.8)\n",
    "\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(15)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "\n",
    "\n",
    "# Minor ticks every 0.1 or 0.05 (no labels)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.grid(False, axis='y')   # Turn ON horizontal gridlines only\n",
    "ax.grid(False, axis='x')  # Turn OFF vertical gridlines\n",
    "\n",
    "# Label every 2nd minor tick (every 0.04) similarly or skip labeling minor ticks entirely\n",
    "# If you want to label every 2nd minor tick:  # wider figure to fit legend on right\n",
    "# Add a single horizontal gridline at y=0.3\n",
    "#ax.axhline(y=0.3, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "#ax.axhline(y=0.1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "ax.set_xlim(right=510)\n",
    "\n",
    "# Set limits to your observed data range or desired axis range\n",
    "vmin_neg = -1  # from your code\n",
    "vmax_pos = 1\n",
    "\n",
    "# Set numeric limits for your data range\n",
    "ax.set_ylim(vmin_neg, vmax_pos)\n",
    "\n",
    "# Set your custom scale on the y-axis with these limits\n",
    "ax.set_yscale('piecewise_linear', vmin_neg=vmin_neg, vmax_pos=vmax_pos)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.axhline(y=0, color=\"black\", linewidth=1.2)\n",
    "\n",
    "# Save\n",
    "\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_log10_Median_AllAntibodies.png\")\n",
    "fig.set_size_inches(8, 5)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')  # Save after resizing/layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as before but instead of 95 CI range of smoothed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "def symmetric_log10(x, epsilon=1e-8, max_cap=1e8):\n",
    "    x_clipped = np.clip(np.abs(x), epsilon, max_cap)\n",
    "    return np.sign(x) * np.log10(x_clipped)\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.5\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = barcode_counts.get(immunization, 0)\n",
    "    #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "\n",
    "    print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "    print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "   \n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "\n",
    "    #Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "\n",
    "        #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "    # Interpolate final smoothed enrichment values to fill NaNs\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "    n = 10  # rolling window for smoothing\n",
    "    \n",
    "    # Filter raw data for immunization\n",
    "    df_im_raw = df_filtered[df_filtered['immunization'] == immunization].copy()\n",
    "    \n",
    "    # Transform enrichment ratio safely\n",
    "    df_im_raw['Log10_Enrichment'] = df_im_raw['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "    print(f\"[DEBUG] Raw Log10 enrichment values (first 20 rows):\\n{df_im_raw[['Spike_AS_Position', 'Log10_Enrichment']].head(20)}\\n\")\n",
    "    \n",
    "    # Calculate std dev and count per position\n",
    "    grouped = df_im_raw.groupby('Spike_AS_Position')['Log10_Enrichment']\n",
    "    std_per_pos = grouped.std()\n",
    "    count_per_pos = grouped.count()\n",
    "    \n",
    "    print(f\"[DEBUG] Raw std dev per position (first 20 values):\\n{std_per_pos.head(20)}\\n\")\n",
    "    print(f\"[DEBUG] Counts per position (first 20 values):\\n{count_per_pos.head(20)}\\n\")\n",
    "    \n",
    "    # Calculate standard error of the mean (SEM)\n",
    "    sem_per_pos = std_per_pos / np.sqrt(count_per_pos)\n",
    "    \n",
    "    # Calculate t-critical value for 95% confidence interval (two-tailed)\n",
    "    # Degrees of freedom = count - 1, minimum 1 to avoid div by zero\n",
    "    dof = count_per_pos - 1\n",
    "    dof[dof < 1] = 1\n",
    "    t_critical = dof.apply(lambda df: stats.t.ppf(0.975, df))  # 0.975 for two-tailed 95%\n",
    "    \n",
    "    # Margin of error = t-critical * SEM\n",
    "    margin_of_error = t_critical * sem_per_pos\n",
    "    \n",
    "    # Smooth the margin of error across positions\n",
    "    smoothed_margin = margin_of_error.rolling(window=n, center=True, min_periods=1).median()\n",
    "    print(f\"[DEBUG] Smoothed margin of error (first 20 values):\\n{smoothed_margin.head(20)}\\n\")\n",
    "    \n",
    "    # Fill NaNs at edges if any\n",
    "    smoothed_margin = smoothed_margin.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Join smoothed margin of error back to df_filtered_im\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position')\n",
    "    df_filtered_im['Smoothed_CI_Margin'] = smoothed_margin\n",
    "    df_filtered_im = df_filtered_im.reset_index()\n",
    "    \n",
    "    # Fill any remaining NaNs\n",
    "    df_filtered_im['Smoothed_CI_Margin'] = df_filtered_im['Smoothed_CI_Margin'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Calculate rolling min and max of the smoothed enrichment values\n",
    "    rolling_min = df_filtered_im['Smoothed_Enrichment'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    rolling_max = df_filtered_im['Smoothed_Enrichment'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    \n",
    "    # Fill any NaNs at edges\n",
    "    rolling_min = rolling_min.fillna(method='bfill').fillna(method='ffill')\n",
    "    rolling_max = rolling_max.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Plot shaded range area using rolling min/max\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        rolling_min,\n",
    "        rolling_max,\n",
    "        color=color_map.get(immunization, ),\n",
    "        alpha=0.1,\n",
    "        zorder=5\n",
    "    )\n",
    "    #df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    #df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "    #window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    # First, create a rolling max and min on original (non-log) Enrichment_Ratio\n",
    "     # Compute rolling 25th and 75th percentiles from the raw Enrichment_Ratio\n",
    "    # Calculate min and max Enrichment_Ratio for each position\n",
    "\n",
    "    \n",
    "    # Use your already calculated smoothed mean as center for CI\n",
    "    #ci_upper = df_filtered_im['Smoothed_Enrichment'] + 1.96 * (rolling_std / np.sqrt(n))\n",
    "    #ci_lower = df_filtered_im['Smoothed_Enrichment'] - 1.96 * (rolling_std / np.sqrt(n))\n",
    "    \n",
    "    ## Plot shaded CI area\n",
    "    #ax.fill_between(\n",
    "    #    df_filtered_im['Spike_AS_Position'],\n",
    "    #    ci_lower,\n",
    "    #    ci_upper,\n",
    "    #    color=color_map.get(immunization, 'black'),\n",
    "    #    alpha=0.2,\n",
    "    #    step='mid'\n",
    "   # )\n",
    "\n",
    "    # Plot\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        #show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2.5,\n",
    "        color=color_map.get(immunization, )\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    #highlight_mask = df_filtered_im['show_site'].apply(lambda x: 1.0 if x else np.nan) # 1.0 where True, 0.0 where False\n",
    "    #bar_height = 0.002  # adjust the height of the bars here\n",
    "\n",
    "    #ax.fill_between(\n",
    "        #df_filtered_im['Spike_AS_Position'],\n",
    "        #-0.005,\n",
    "        #highlight_mask * bar_height,\n",
    "        #color='black',\n",
    "       # where=highlight_mask,\n",
    "      #  alpha=0.5,\n",
    "     #   step='mid'  # aligns fill to the positions nicely\n",
    "    #)\n",
    "\n",
    "    print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "    print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "    print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "    print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "    print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "\n",
    "    if immunization == 'wildtype_RBD':\n",
    "        print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "        print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "            ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "        ])\n",
    "\n",
    "\n",
    "    immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.4,\n",
    "            top=0.04)\n",
    "\n",
    "plt.title('', fontsize=16)\n",
    "plt.xlabel('Spike AA Position', fontsize=14)\n",
    "plt.ylabel('Log10 AB binding (Median) \\n All antibodies', fontsize=14)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='orange', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "fig.subplots_adjust(right=0.8)\n",
    "\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.2))\n",
    "\n",
    "\n",
    "# Minor ticks every 0.1 or 0.05 (no labels)\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
    "ax.grid(False, axis='y')   # Turn ON horizontal gridlines only\n",
    "ax.grid(False, axis='x')  # Turn OFF vertical gridlines\n",
    "\n",
    "# Label every 2nd minor tick (every 0.04) similarly or skip labeling minor ticks entirely\n",
    "# If you want to label every 2nd minor tick:  # wider figure to fit legend on right\n",
    "# Add a single horizontal gridline at y=0.3\n",
    "#ax.axhline(y=0.3, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "#ax.axhline(y=0.1, color='gray', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "ax.set_xlim(right=510)\n",
    "\n",
    "# Set limits to your observed data range or desired axis range\n",
    "vmin_neg = -1  # from your code\n",
    "vmax_pos = 1\n",
    "\n",
    "# Set numeric limits for your data range\n",
    "ax.set_ylim(vmin_neg, vmax_pos)\n",
    "\n",
    "# Set your custom scale on the y-axis with these limits\n",
    "#ax.set_yscale('piecewise_linear', vmin_neg=vmin_neg, vmax_pos=vmax_pos)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.axhline(y=0, color=\"black\", linewidth=1.2)\n",
    "\n",
    "# Save\n",
    "\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_log10_Median_AllAntibodies.png\")\n",
    "fig.set_size_inches(7, 4)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')  # Save after resizing/layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for legend printing\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='center left',          # Legend inside figure but on the left side of bbox_to_anchor\n",
    "    bbox_to_anchor=(1, 0.5),    # Outside plot area on right, vertically centered\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE FOR generating median +CI/SD plots from all individual droplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#median and ER>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-antibody, put together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 1)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "\n",
    "    immunization_df = df_filtered[df_filtered['immunization'] == immunization]\n",
    "\n",
    "    barcodes = list(immunization_df['barcode'].unique())[:5]\n",
    "    print(f\"[INFO] Plotting first 5 barcodes for immunization '{immunization}': {barcodes}\")\n",
    "    \n",
    "    for barcode in barcodes:\n",
    "        df_filtered_im = df_filtered_agg.query(\n",
    "            f'immunization == \"{immunization}\" and barcode == \"{barcode}\"'\n",
    "        ).copy()\n",
    "    \n",
    "        if df_filtered_im.empty:\n",
    "            continue  # Skip empty\n",
    "    \n",
    "        # Now each barcode-immunization pair has one row per Spike_AS_Position\n",
    "        df_filtered_im = df_filtered_im.drop_duplicates(subset='Spike_AS_Position')\n",
    "        faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "        faint_alpha = 0.3\n",
    "        faint_linewidth = 1.5\n",
    "    \n",
    "        #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "         #   continue\n",
    "        #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "         #   continue\n",
    "\n",
    "    \n",
    "        # Normalize by number of barcodes\n",
    "        num_barcodes = barcode_counts.get(immunization, 0)\n",
    "        #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "    \n",
    "        print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "        print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "        print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "        \n",
    "        #df_filtered_im_agg = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        #'Enrichment_Ratio': 'median'\n",
    "        #})\n",
    "       \n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "        # Safe log transform (ignore or remove zero/negative values)\n",
    "        df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "            lambda x: np.log10(x) if x > 0 else np.nan\n",
    "        )\n",
    "        \n",
    "        # Apply smoothing on the log2 transformed values\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "            method='linear', limit_direction='both')\n",
    "    \n",
    "        # Identify high enrichment\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    \n",
    "        if immunization == 'Neutralizing_Ab':\n",
    "            df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "    \n",
    "            #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "        # Save CSV\n",
    "        csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "        df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "        # Reindex\n",
    "        # Ensure uniqueness by aggregating duplicates\n",
    "        df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "            'Smoothed_Enrichment': 'median',\n",
    "            'High_Enrichment': 'any',\n",
    "            'Log10_Enrichment': 'median',\n",
    "            'Enrichment_Ratio': 'median'\n",
    "        })\n",
    "        \n",
    "        # Now reindex safely\n",
    "        df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "            range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "                  df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "        ).reset_index()\n",
    "        \n",
    "        # Mark sites to highlight\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "        df_filtered_im = df_filtered_im.assign(\n",
    "            show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "        )\n",
    "    \n",
    "        print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "    \n",
    "        # Rolling min and max for range area\n",
    "        # Fixed (aligned min/max with smoothed mean)\n",
    "        df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "        df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    \n",
    "    \n",
    "        # Plot shaded area for range\n",
    "        ax.fill_between(\n",
    "            df_filtered_im['Spike_AS_Position'],\n",
    "            df_filtered_im['Smoothed_Enrichment_min'],\n",
    "            df_filtered_im['Smoothed_Enrichment_max'],\n",
    "            color=color_map.get(immunization, 'black'),\n",
    "            alpha=0.1\n",
    "        )\n",
    "    \n",
    "        # Plot\n",
    "        \n",
    "        dmslogo.line.draw_line(\n",
    "            df_filtered_im,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            height_col=\"Smoothed_Enrichment\",\n",
    "            title=\"\",\n",
    "            xlabel=\"Spike AA Position\",\n",
    "            ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "            show_col=\"show_site\",\n",
    "            ax=ax,\n",
    "            linewidth=2,\n",
    "            color=color_map.get(immunization, 'black')\n",
    "        )\n",
    "        if immunization in faint_immunizations:\n",
    "            ax.lines[-1].set_alpha(faint_alpha)\n",
    "        ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "    \n",
    "        # Highlight sites\n",
    "        #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "        #for _, site_data in highlight_sites.iterrows():\n",
    "         #   ax.hlines(\n",
    "         #       y=0,  # set near bottom\n",
    "         #       xmin=site_data['Spike_AS_Position'] - 0.1,\n",
    "         #       xmax=site_data['Spike_AS_Position'] + 0.1,\n",
    "         #       color='black',\n",
    "         #       linestyle='-',\n",
    "         #       linewidth=6\n",
    "         #   )\n",
    "        print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "        print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "        print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "        print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "        print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "    \n",
    "        if immunization == 'wildtype_RBD':\n",
    "            print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "            print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "                ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "            ])\n",
    "    \n",
    "    \n",
    "        immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.05,\n",
    "            top=np.nanmax(df_filtered_im['Smoothed_Enrichment']) + 0.8)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 Antibody binding (Mean)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='center left',          # Legend inside figure but on the left side of bbox_to_anchor\n",
    "    bbox_to_anchor=(1, 0.5),    # Outside plot area on right, vertically centered\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "# Only label 0.0, 0.3, 0.6\n",
    "label_positions = [-0.1,0,0.1,0.2,0.4, 0.6, 0.8]\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:.1f}\" if any(np.isclose(y, lp, atol=1e-3) for lp in label_positions) else \"\"))\n",
    "\n",
    "# Optional minor ticks every 0.05\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line3_plot_final_log10.png\")\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')  # Save after resizing/layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 1)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "\n",
    "    immunization_df = df_filtered[df_filtered['immunization'] == immunization]\n",
    "\n",
    "    barcodes = np.random.choice(immunization_df['barcode'].unique(), size=min(3, immunization_df['barcode'].nunique()), replace=False)\n",
    "    print(f\"[INFO] Randomly selected 5 barcodes for immunization '{immunization}': {list(barcodes)}\")\n",
    "\n",
    "    \n",
    "    for barcode in barcodes:\n",
    "        df_filtered_im = df_filtered_agg.query(\n",
    "            f'immunization == \"{immunization}\" and barcode == \"{barcode}\"'\n",
    "        ).copy()\n",
    "    \n",
    "        if df_filtered_im.empty:\n",
    "            continue  # Skip empty\n",
    "    \n",
    "        # Now each barcode-immunization pair has one row per Spike_AS_Position\n",
    "        df_filtered_im = df_filtered_im.drop_duplicates(subset='Spike_AS_Position')\n",
    "        faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "        faint_alpha = 0.3\n",
    "        faint_linewidth = 1.5\n",
    "    \n",
    "        #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "         #   continue\n",
    "        #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "         #   continue\n",
    "\n",
    "    \n",
    "        # Normalize by number of barcodes\n",
    "        num_barcodes = barcode_counts.get(immunization, 0)\n",
    "        #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "    \n",
    "        print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "        print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "        print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "        \n",
    "        #df_filtered_im_agg = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        #'Enrichment_Ratio': 'median'\n",
    "        #})\n",
    "       \n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "        # Safe log transform (ignore or remove zero/negative values)\n",
    "        df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "            lambda x: np.log10(x) if x > 0 else np.nan\n",
    "        )\n",
    "        \n",
    "        # Apply smoothing on the log2 transformed values\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "            method='linear', limit_direction='both')\n",
    "    \n",
    "        # Identify high enrichment\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    \n",
    "        if immunization == 'Neutralizing_Ab':\n",
    "            df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "    \n",
    "            #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "        # Save CSV\n",
    "        csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "        df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "        # Reindex\n",
    "        # Ensure uniqueness by aggregating duplicates\n",
    "        df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "            'Smoothed_Enrichment': 'median',\n",
    "            'High_Enrichment': 'any',\n",
    "            'Log10_Enrichment': 'median',\n",
    "            'Enrichment_Ratio': 'median'\n",
    "        })\n",
    "        \n",
    "        # Now reindex safely\n",
    "        df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "            range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "                  df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "        ).reset_index()\n",
    "\n",
    "        # Interpolate numeric columns linearly\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "        \n",
    "        # For other relevant numeric columns you use for plotting, interpolate or fill as needed:\n",
    "        df_filtered_im['Log10_Enrichment'] = df_filtered_im['Log10_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].interpolate(method='linear', limit_direction='both')\n",
    "        \n",
    "        # For boolean columns, fill missing with False (or appropriate default)\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "        \n",
    "        # If you want, you can also do forward/backward fill to be more conservative:\n",
    "        # df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        \n",
    "        # Mark sites to highlight\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "        df_filtered_im = df_filtered_im.assign(\n",
    "            show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "        )\n",
    "    \n",
    "        print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "    \n",
    "        # Rolling min and max for range area\n",
    "        # Fixed (aligned min/max with smoothed mean)\n",
    "        df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "        df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    \n",
    "    \n",
    "        # Plot shaded area for range\n",
    "        ax.fill_between(\n",
    "            df_filtered_im['Spike_AS_Position'],\n",
    "            df_filtered_im['Smoothed_Enrichment_min'],\n",
    "            df_filtered_im['Smoothed_Enrichment_max'],\n",
    "            color=color_map.get(immunization, 'black'),\n",
    "            alpha=0.1\n",
    "        )\n",
    "    \n",
    "        # Plot\n",
    "        \n",
    "        dmslogo.line.draw_line(\n",
    "            df_filtered_im,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            height_col=\"Smoothed_Enrichment\",\n",
    "            title=\"\",\n",
    "            xlabel=\"Spike AA Position\",\n",
    "            ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "            show_col=\"show_site\",\n",
    "            ax=ax,\n",
    "            linewidth=2,\n",
    "            color=color_map.get(immunization, 'black')\n",
    "        )\n",
    "        if immunization in faint_immunizations:\n",
    "            ax.lines[-1].set_alpha(faint_alpha)\n",
    "        ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "    \n",
    "        # Highlight sites\n",
    "        #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "        #for _, site_data in highlight_sites.iterrows():\n",
    "         #   ax.hlines(\n",
    "         #       y=0,  # set near bottom\n",
    "         #       xmin=site_data['Spike_AS_Position'] - 0.1,\n",
    "         #       xmax=site_data['Spike_AS_Position'] + 0.1,\n",
    "         #       color='black',\n",
    "         #       linestyle='-',\n",
    "         #       linewidth=6\n",
    "         #   )\n",
    "        print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "        print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "        print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "        print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "        print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "    \n",
    "        if immunization == 'wildtype_RBD':\n",
    "            print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "            print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "                ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "            ])\n",
    "    \n",
    "    \n",
    "        immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.05,\n",
    "            top=np.nanmax(df_filtered_im['Smoothed_Enrichment']) + 0.8)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 Antibody binding (Mean)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='center left',          # Legend inside figure but on the left side of bbox_to_anchor\n",
    "    bbox_to_anchor=(1, 0.5),    # Outside plot area on right, vertically centered\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2, labelsize=14)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out', labelsize=14)\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "# Only label 0.0, 0.3, 0.6\n",
    "label_positions = [-0.1,0,0.1,0.2,0.4, 0.6, 0.8]\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:.1f}\" if any(np.isclose(y, lp, atol=1e-3) for lp in label_positions) else \"\"))\n",
    "\n",
    "# Optional minor ticks every 0.05\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line3_plot_final_log10.png\")\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')  # Save after resizing/layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median and ER >1 and With check for degree of interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 1)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    immunization_data = {}\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "\n",
    "    immunization_df = df_filtered[df_filtered['immunization'] == immunization]\n",
    "\n",
    "    barcodes = np.random.choice(immunization_df['barcode'].unique(), size=min(3, immunization_df['barcode'].nunique()), replace=False)\n",
    "    print(f\"[INFO] Randomly selected 5 barcodes for immunization '{immunization}': {list(barcodes)}\")\n",
    "\n",
    "    \n",
    "    for barcode in barcodes:\n",
    "        df_filtered_im = df_filtered_agg.query(\n",
    "            f'immunization == \"{immunization}\" and barcode == \"{barcode}\"'\n",
    "        ).copy()\n",
    "    \n",
    "        if df_filtered_im.empty:\n",
    "            continue  # Skip empty\n",
    "    \n",
    "        # Now each barcode-immunization pair has one row per Spike_AS_Position\n",
    "        df_filtered_im = df_filtered_im.drop_duplicates(subset='Spike_AS_Position')\n",
    "        faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "        faint_alpha = 0.3\n",
    "        faint_linewidth = 1.5\n",
    "    \n",
    "        #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "         #   continue\n",
    "        #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "         #   continue\n",
    "\n",
    "    \n",
    "        # Normalize by number of barcodes\n",
    "        num_barcodes = barcode_counts.get(immunization, 0)\n",
    "        #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "    \n",
    "        print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "        print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "        print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "        \n",
    "        #df_filtered_im_agg = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        #'Enrichment_Ratio': 'median'\n",
    "        #})\n",
    "       \n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "        # Safe log transform (ignore or remove zero/negative values)\n",
    "        df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "            lambda x: np.log10(x) if x > 0 else np.nan\n",
    "        )\n",
    "        \n",
    "        # Apply smoothing on the log2 transformed values\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "            method='linear', limit_direction='both')\n",
    "    \n",
    "        # Identify high enrichment\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    \n",
    "        if immunization == 'Neutralizing_Ab':\n",
    "            df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "    \n",
    "            #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "        # Save CSV\n",
    "        csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "        df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "        # Reindex\n",
    "        # Ensure uniqueness by aggregating duplicates\n",
    "        df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "            'Smoothed_Enrichment': 'median',\n",
    "            'High_Enrichment': 'any',\n",
    "            'Log10_Enrichment': 'median',\n",
    "            'Enrichment_Ratio': 'median'\n",
    "        })\n",
    "\n",
    "        # Reindex to get full range of positions expected\n",
    "        full_pos_range = range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "        \n",
    "        # Count number of actual data points (before interpolation/filling)\n",
    "        actual_positions = df_filtered_im['Spike_AS_Position'].nunique()\n",
    "        \n",
    "        # Total positions in full range\n",
    "        total_positions = len(full_pos_range)\n",
    "        \n",
    "        # Calculate coverage ratio\n",
    "        coverage_ratio = actual_positions / total_positions\n",
    "        \n",
    "        # Define minimum coverage threshold, e.g. 50%\n",
    "        MIN_COVERAGE = 0.5\n",
    "        \n",
    "        if coverage_ratio < MIN_COVERAGE:\n",
    "            print(f\"Skipping barcode {barcode} due to low coverage ({coverage_ratio:.2f})\")\n",
    "            continue  # Skip plotting this barcode\n",
    "\n",
    "        \n",
    "        # Now reindex safely\n",
    "        df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "            range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "                  df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "        ).reset_index()\n",
    "\n",
    "        # Interpolate numeric columns linearly\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "        \n",
    "        # For other relevant numeric columns you use for plotting, interpolate or fill as needed:\n",
    "        df_filtered_im['Log10_Enrichment'] = df_filtered_im['Log10_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].interpolate(method='linear', limit_direction='both')\n",
    "        \n",
    "        # For boolean columns, fill missing with False (or appropriate default)\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "        \n",
    "        # If you want, you can also do forward/backward fill to be more conservative:\n",
    "        # df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "        \n",
    "        # Mark sites to highlight\n",
    "        df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "        df_filtered_im = df_filtered_im.assign(\n",
    "            show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "        )\n",
    "    \n",
    "        print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "    \n",
    "        # Rolling min and max for range area\n",
    "        # Fixed (aligned min/max with smoothed mean)\n",
    "        df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "        df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "            window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "    \n",
    "    \n",
    "        # Plot shaded area for range\n",
    "        ax.fill_between(\n",
    "            df_filtered_im['Spike_AS_Position'],\n",
    "            df_filtered_im['Smoothed_Enrichment_min'],\n",
    "            df_filtered_im['Smoothed_Enrichment_max'],\n",
    "            color=color_map.get(immunization, 'black'),\n",
    "            alpha=0.1\n",
    "        )\n",
    "    \n",
    "        # Plot\n",
    "        \n",
    "        dmslogo.line.draw_line(\n",
    "            df_filtered_im,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            height_col=\"Smoothed_Enrichment\",\n",
    "            title=\"\",\n",
    "            xlabel=\"Spike AA Position\",\n",
    "            ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "            show_col=\"show_site\",\n",
    "            ax=ax,\n",
    "            linewidth=2,\n",
    "            color=color_map.get(immunization, 'black')\n",
    "        )\n",
    "        if immunization in faint_immunizations:\n",
    "            ax.lines[-1].set_alpha(faint_alpha)\n",
    "        ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "    \n",
    "        # Highlight sites\n",
    "        #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "        #for _, site_data in highlight_sites.iterrows():\n",
    "         #   ax.hlines(\n",
    "         #       y=0,  # set near bottom\n",
    "         #       xmin=site_data['Spike_AS_Position'] - 0.1,\n",
    "         #       xmax=site_data['Spike_AS_Position'] + 0.1,\n",
    "         #       color='black',\n",
    "         #       linestyle='-',\n",
    "         #       linewidth=6\n",
    "         #   )\n",
    "        print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "        print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "        print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "        print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "        print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "    \n",
    "        if immunization == 'wildtype_RBD':\n",
    "            print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "            print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "                ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "            ])\n",
    "    \n",
    "    \n",
    "        immunization_data[immunization] = df_filtered_im.copy()\n",
    "    \n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.05,\n",
    "            top=np.nanmax(df_filtered_im['Smoothed_Enrichment']) + 0.8)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 Antibody binding (Mean)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='center left',          # Legend inside figure but on the left side of bbox_to_anchor\n",
    "    bbox_to_anchor=(1, 0.5),    # Outside plot area on right, vertically centered\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "# Only label 0.0, 0.3, 0.6\n",
    "label_positions = [-0.1,0,0.1,0.2,0.4, 0.6, 0.8]\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:.1f}\" if any(np.isclose(y, lp, atol=1e-3) for lp in label_positions) else \"\"))\n",
    "\n",
    "# Optional minor ticks every 0.05\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line3_plot_final_log10.png\")\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')  # Save after resizing/layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To create 2x2 tile with 4 subplots. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With interpolation, 3 random barcodes, smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with marker for which plots are interpolated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting specific replicates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "png_dir = r\"/Users/lucaschlotheuber/Desktop/DMSnew\"\n",
    "\n",
    "filenames = [\n",
    "    \"replicate1_2x2_log10_median.png\",\n",
    "    \"replicate2_2x2_log10_median.png\",\n",
    "    \"replicate3_2x2_log10_median.png\",\n",
    "    \"replicate4_2x2_log10_median.png\"\n",
    "]\n",
    "\n",
    "images = []\n",
    "for fname in filenames:\n",
    "    path = os.path.join(png_dir, fname)\n",
    "    if os.path.isfile(path):\n",
    "        images.append(Image.open(path))\n",
    "    else:\n",
    "        print(f\"Warning: File not found {path}\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(images):\n",
    "        ax.imshow(images[i])\n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('equal')  # or 'equal'\n",
    "\n",
    "        ax.margins(0) \n",
    "    else:\n",
    "        ax.axis('off')  # Hide empty plots\n",
    "\n",
    "# Define legend handles and labels\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "\n",
    "handles = [\n",
    "    Patch(color=color_map['Polyclonal_Ab'], label=label_map['Polyclonal_Ab']),\n",
    "    Patch(color=color_map['wildtype_RBD'], label=label_map['wildtype_RBD']),\n",
    "    Patch(color=color_map['Mutant_RBD'], label=label_map['Mutant_RBD']),\n",
    "    Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "]\n",
    "\n",
    "# Add legend outside the right side of the figure\n",
    "fig.legend(\n",
    "    handles=handles,\n",
    "    loc='center left',\n",
    "    bbox_to_anchor=(0.85, 0.5),\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "fig.subplots_adjust(hspace=0.01)  # reduce space between rows (default ~0.2)\n",
    "\n",
    "# Reduce vertical space and tighten layout, leave room on right for legend\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])  # leave 15% space on the right for legend\n",
    "\n",
    "combined_path = os.path.join(png_dir, \"combined_2x2_plot.png\")\n",
    "plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting all replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "png_dir = r\"/Users/lucaschlotheuber/Desktop/DMSnew\"\n",
    "\n",
    "# Define groups: 5 groups of 4 replicates each\n",
    "replicate_groups = [list(range(i, i+5)) for i in range(1, 21, 4)]\n",
    "\n",
    "# Legend setup\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "\n",
    "legend_handles = [\n",
    "    Patch(color=color_map['Polyclonal_Ab'], label=label_map['Polyclonal_Ab']),\n",
    "    Patch(color=color_map['wildtype_RBD'], label=label_map['wildtype_RBD']),\n",
    "    Patch(color=color_map['Mutant_RBD'], label=label_map['Mutant_RBD']),\n",
    "    Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "]\n",
    "\n",
    "# Loop through each group and make a 2x2 plot\n",
    "for group_idx, replicate_range in enumerate(replicate_groups, start=1):\n",
    "    images = []\n",
    "    filenames = [f\"replicate{r}_2x2_log10_median.png\" for r in replicate_range]\n",
    "\n",
    "    for fname in filenames:\n",
    "        path = os.path.join(png_dir, fname)\n",
    "        if os.path.isfile(path):\n",
    "            images.append(Image.open(path))\n",
    "        else:\n",
    "            print(f\"Warning: File not found: {path}\")\n",
    "\n",
    "    # Create 2x2 grid\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < len(images):\n",
    "            ax.imshow(images[i])\n",
    "            ax.axis('off')\n",
    "            ax.set_aspect('equal')\n",
    "            ax.margins(0)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "    # Add legend\n",
    "    fig.legend(\n",
    "        handles=legend_handles,\n",
    "        loc='center left',\n",
    "        bbox_to_anchor=(0.85, 0.5),\n",
    "        title=\"Immunization\",\n",
    "        title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "        fontsize=11,\n",
    "        frameon=False,\n",
    "        handlelength=2,\n",
    "        handleheight=1,\n",
    "        markerscale=1\n",
    "    )\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.01)\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "    # Save\n",
    "    combined_path = os.path.join(png_dir, f\"combined_2x2_group{group_idx}.png\")\n",
    "    plt.savefig(combined_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "    print(f\"[✓] Saved: {combined_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Directory where replicate images are stored\n",
    "png_dir = r\"/Users/lucaschlotheuber/Desktop\"\n",
    "\n",
    "# Custom list of replicate numbers\n",
    "replicates_to_plot = [2, 5, 6, 7]  # Custom 2x2\n",
    "\n",
    "# Generate corresponding filenames\n",
    "filenames = [f\"replicate{r}_2x2_log10_median.png\" for r in replicates_to_plot]\n",
    "\n",
    "# Load images\n",
    "images = []\n",
    "for fname in filenames:\n",
    "    path = os.path.join(png_dir, fname)\n",
    "    if os.path.isfile(path):\n",
    "        images.append(Image.open(path))\n",
    "    else:\n",
    "        print(f\"Warning: File not found: {path}\")\n",
    "\n",
    "# Define legend\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "\n",
    "legend_handles = [\n",
    "    Patch(color=color_map['Polyclonal_Ab'], label=label_map['Polyclonal_Ab']),\n",
    "    Patch(color=color_map['wildtype_RBD'], label=label_map['wildtype_RBD']),\n",
    "    Patch(color=color_map['Mutant_RBD'], label=label_map['Mutant_RBD']),\n",
    "    Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "]\n",
    "\n",
    "# Create 2x2 plot\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    if i < len(images):\n",
    "        ax.imshow(images[i])\n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('equal')\n",
    "        ax.margins(0)\n",
    "    else:\n",
    "        ax.axis('off')\n",
    "\n",
    "# Add legend to the right\n",
    "fig.legend(\n",
    "    handles=legend_handles,\n",
    "    loc='center left',\n",
    "    bbox_to_anchor=(0.85, 0.5),\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(hspace=0.01)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "# Save figure\n",
    "output_path = os.path.join(png_dir, \"custom_2x2_replicates_11_12_18_8.png\")\n",
    "plt.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"[✓] Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "NUM_REPLICATES = 30\n",
    "\n",
    "for replicate_idx in range(1, NUM_REPLICATES + 1):\n",
    "    print(f\"Generating replicate {replicate_idx}\")\n",
    "\n",
    "    y_min_global = np.inf\n",
    "    y_max_global = -np.inf\n",
    "    \n",
    "    # Set seed for reproducibility but different sample each replicate\n",
    "    #np.random.seed(42 + replicate_idx)\n",
    "    \n",
    "    # Create new figure and axis per replicate\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Define color mapping\n",
    "    color_map = {\n",
    "        'Polyclonal_Ab': 'darkorange',\n",
    "        'Neutralizing_Ab': 'red',\n",
    "        'wildtype_RBD': 'green',\n",
    "        'Mutant_RBD': 'darkblue'\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "    for immunization in df_filtered_agg['immunization'].unique():\n",
    "        immunization_data = {}\n",
    "        if immunization == 'Library_ctrl':\n",
    "            continue\n",
    "    \n",
    "        if immunization == 'Neutralizing_Ab':\n",
    "            continue\n",
    "    \n",
    "        immunization_df = df_filtered[df_filtered['immunization'] == immunization]\n",
    "    \n",
    "        barcodes = np.random.choice(immunization_df['barcode'].unique(), size=min(1, immunization_df['barcode'].nunique()), replace=False)\n",
    "        print(f\"[INFO] Randomly selected 5 barcodes for immunization '{immunization}': {list(barcodes)}\")\n",
    "    \n",
    "        \n",
    "        for barcode in barcodes:\n",
    "            df_filtered_im = df_filtered_agg.query(\n",
    "                f'immunization == \"{immunization}\" and barcode == \"{barcode}\"'\n",
    "            ).copy()\n",
    "        \n",
    "            if df_filtered_im.empty:\n",
    "                continue  # Skip empty\n",
    "        \n",
    "            # Now each barcode-immunization pair has one row per Spike_AS_Position\n",
    "            df_filtered_im = df_filtered_im.drop_duplicates(subset='Spike_AS_Position')\n",
    "            faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "            faint_alpha = 0.4\n",
    "            faint_linewidth = 1.5\n",
    "        \n",
    "            #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "             #   continue\n",
    "            #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "             #   continue\n",
    "    \n",
    "        \n",
    "            # Normalize by number of barcodes\n",
    "            num_barcodes = barcode_counts.get(immunization, 0)\n",
    "            #num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "        \n",
    "            print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "            print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "            print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "            \n",
    "            #df_filtered_im_agg = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "            #'Enrichment_Ratio': 'median'\n",
    "            #})\n",
    "           \n",
    "            df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "        \n",
    "            # Safe log transform (ignore or remove zero/negative values)\n",
    "            df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "                lambda x: np.log10(x) if x > 0 else np.nan\n",
    "            )\n",
    "            \n",
    "            # Apply smoothing on the log2 transformed values\n",
    "            df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "                window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "            df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "                method='linear', limit_direction='both')\n",
    "        \n",
    "            # Identify high enrichment\n",
    "            df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "            df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "        \n",
    "            if immunization == 'Neutralizing_Ab':\n",
    "                df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].bfill().ffill()\n",
    "        \n",
    "                #df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "        \n",
    "            # Save CSV\n",
    "            csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "            df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "        \n",
    "            # Reindex\n",
    "            # Ensure uniqueness by aggregating duplicates\n",
    "            df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "                'Smoothed_Enrichment': 'median',\n",
    "                'High_Enrichment': 'any',\n",
    "                'Log10_Enrichment': 'median',\n",
    "                'Enrichment_Ratio': 'median'\n",
    "            })\n",
    "    \n",
    "            # Reindex to get full range of positions expected\n",
    "            full_pos_range = range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "            \n",
    "            # Count number of actual data points (before interpolation/filling)\n",
    "            actual_positions = df_filtered_im['Spike_AS_Position'].nunique()\n",
    "            \n",
    "            # Total positions in full range\n",
    "            total_positions = len(full_pos_range)\n",
    "            \n",
    "            # Calculate coverage ratio\n",
    "            coverage_ratio = actual_positions / total_positions\n",
    "            \n",
    "            # Define minimum coverage threshold, e.g. 50%\n",
    "            MIN_COVERAGE = 0.5\n",
    "            \n",
    "            if coverage_ratio < MIN_COVERAGE:\n",
    "                print(f\"Skipping barcode {barcode} due to low coverage ({coverage_ratio:.2f})\")\n",
    "                continue  # Skip plotting this barcode\n",
    "    \n",
    "            \n",
    "            # Now reindex safely\n",
    "            df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "                range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "                      df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "            ).reset_index()\n",
    "    \n",
    "            # Interpolate numeric columns linearly\n",
    "            df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "            \n",
    "            # For other relevant numeric columns you use for plotting, interpolate or fill as needed:\n",
    "            df_filtered_im['Log10_Enrichment'] = df_filtered_im['Log10_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "            df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].interpolate(method='linear', limit_direction='both')\n",
    "            \n",
    "            # For boolean columns, fill missing with False (or appropriate default)\n",
    "            df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "            \n",
    "            # If you want, you can also do forward/backward fill to be more conservative:\n",
    "            # df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='ffill').fillna(method='bfill')\n",
    "    \n",
    "            \n",
    "            # Mark sites to highlight\n",
    "            df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "            df_filtered_im = df_filtered_im.assign(\n",
    "                show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "            )\n",
    "        \n",
    "            print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "        \n",
    "            n = 10  # rolling window for smoothing\n",
    "            \n",
    "            # Filter raw data for immunization\n",
    "            df_im_raw = df_filtered[df_filtered['immunization'] == immunization].copy()\n",
    "            \n",
    "            # Transform enrichment ratio safely\n",
    "            df_im_raw['Log10_Enrichment'] = df_im_raw['Enrichment_Ratio'].apply(symmetric_log10)\n",
    "            print(f\"[DEBUG] Raw Log10 enrichment values (first 20 rows):\\n{df_im_raw[['Spike_AS_Position', 'Log10_Enrichment']].head(20)}\\n\")\n",
    "            \n",
    "            # Calculate std dev and count per position\n",
    "            grouped = df_im_raw.groupby('Spike_AS_Position')['Log10_Enrichment']\n",
    "            std_per_pos = grouped.std()\n",
    "            count_per_pos = grouped.count()\n",
    "            \n",
    "            print(f\"[DEBUG] Raw std dev per position (first 20 values):\\n{std_per_pos.head(20)}\\n\")\n",
    "            print(f\"[DEBUG] Counts per position (first 20 values):\\n{count_per_pos.head(20)}\\n\")\n",
    "            \n",
    "            # Calculate standard error of the mean (SEM)\n",
    "            sem_per_pos = std_per_pos / np.sqrt(count_per_pos)\n",
    "            \n",
    "            # Calculate t-critical value for 95% confidence interval (two-tailed)\n",
    "            # Degrees of freedom = count - 1, minimum 1 to avoid div by zero\n",
    "            dof = count_per_pos - 1\n",
    "            dof[dof < 1] = 1\n",
    "            t_critical = dof.apply(lambda df: stats.t.ppf(0.975, df))  # 0.975 for two-tailed 95%\n",
    "            \n",
    "            # Margin of error = t-critical * SEM\n",
    "            margin_of_error = t_critical * sem_per_pos\n",
    "            \n",
    "            # Smooth the margin of error across positions\n",
    "            smoothed_margin = margin_of_error.rolling(window=n, center=True, min_periods=1).median()\n",
    "            print(f\"[DEBUG] Smoothed margin of error (first 20 values):\\n{smoothed_margin.head(20)}\\n\")\n",
    "            \n",
    "            # Fill NaNs at edges if any\n",
    "            smoothed_margin = smoothed_margin.fillna(method='bfill').fillna(method='ffill')\n",
    "            \n",
    "            # Join smoothed margin of error back to df_filtered_im\n",
    "            df_filtered_im = df_filtered_im.set_index('Spike_AS_Position')\n",
    "            df_filtered_im['Smoothed_CI_Margin'] = smoothed_margin\n",
    "            df_filtered_im = df_filtered_im.reset_index()\n",
    "            \n",
    "            # Fill any remaining NaNs\n",
    "            df_filtered_im['Smoothed_CI_Margin'] = df_filtered_im['Smoothed_CI_Margin'].fillna(method='bfill').fillna(method='ffill')\n",
    "            \n",
    "            # Use ± margin of error around smoothed mean\n",
    "            std_upper = df_filtered_im['Smoothed_Enrichment'] + df_filtered_im['Smoothed_CI_Margin']\n",
    "            std_lower = df_filtered_im['Smoothed_Enrichment'] - df_filtered_im['Smoothed_CI_Margin']\n",
    "            \n",
    "            # Plot shaded 95% CI area\n",
    "            ax.fill_between(\n",
    "                df_filtered_im['Spike_AS_Position'],\n",
    "                std_lower,\n",
    "                std_upper,\n",
    "                color=color_map.get(immunization, 'black'),\n",
    "                alpha=0.1,\n",
    "                zorder=5\n",
    "            )\n",
    "\n",
    "\n",
    "            current_min = df_filtered_im['Smoothed_Enrichment'].min()\n",
    "            current_max = df_filtered_im['Smoothed_Enrichment'].max()\n",
    "            if current_min < y_min_global:\n",
    "                y_min_global = current_min\n",
    "            if current_max > y_max_global:\n",
    "                y_max_global = current_max\n",
    "        \n",
    "            # Plot\n",
    "            \n",
    "            dmslogo.line.draw_line(\n",
    "                df_filtered_im,\n",
    "                x_col=\"Spike_AS_Position\",\n",
    "                height_col=\"Smoothed_Enrichment\",\n",
    "                title=\"\",\n",
    "                xlabel=\"Spike AA Position\",\n",
    "                ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "                #show_col=\"show_site\",\n",
    "                ax=ax,\n",
    "                linewidth=3,\n",
    "                color=color_map.get(immunization, 'black')\n",
    "            )\n",
    "            if immunization in faint_immunizations:\n",
    "                ax.lines[-1].set_alpha(faint_alpha)\n",
    "            ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "        \n",
    "            #Highlight sites\n",
    "    \n",
    "            print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "            print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "            print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "            print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "            print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "        \n",
    "            if immunization == 'wildtype_RBD':\n",
    "                print(\"\\n[DEBUG] Wildtype enrichment values (360–540):\")\n",
    "                print(df_filtered_im[df_filtered_im['Spike_AS_Position'].between(360, 540)][\n",
    "                    ['Spike_AS_Position', 'Enrichment_Ratio', 'Log10_Enrichment', 'Smoothed_Enrichment']\n",
    "                ])\n",
    "        \n",
    "        \n",
    "            immunization_data[immunization] = df_filtered_im.copy()\n",
    "\n",
    "    # Get y-axis limits\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    highlight_y = y_min + 0.05 * (y_max - y_min)  # 5% above bottom\n",
    "    \n",
    "    highlight_positions = [int(pos) for pos in sites_to_show]\n",
    "    \n",
    "    for pos in highlight_positions:\n",
    "        ax.vlines(\n",
    "            x=pos,\n",
    "            ymin=-0.015,\n",
    "            ymax=0,\n",
    "            color='black',\n",
    "            linewidth=3.5,\n",
    "            alpha=0.9,\n",
    "            zorder=10\n",
    "        )\n",
    "    # Y-axis limit (adjust if needed for log scale)\n",
    "    #ax.set_ylim(bottom=-0.5,\n",
    "    #            top=np.nanmax(df_filtered_im['Smoothed_Enrichment']) + 0.2)\n",
    "    \n",
    "    plt.title('', fontsize=14)\n",
    "    plt.xlabel('Spike AA Position', fontsize=16)\n",
    "    plt.ylabel('Log10 AB binding (Median)', fontsize=18)\n",
    "    \n",
    "    from matplotlib.patches import Patch\n",
    "    \n",
    "    # Create a square patch for the legend entry\n",
    "    epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "    \n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    # Legend (subset only to certain labels)\n",
    "    group_1_labels = ['Polyclonal_Ab']\n",
    "    group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "    \n",
    "    group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "    group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "    \n",
    "    # Combine handles and labels with a custom order\n",
    "    handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "    \n",
    "    label_map = {\n",
    "        'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "        'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "        'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "    }\n",
    "    labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "    # X-axis ticks\n",
    "    # Set x-ticks every 10 positions\n",
    "    # Major ticks every 10 positions\n",
    "    major_locator = MultipleLocator(10)\n",
    "    ax.xaxis.set_major_locator(major_locator)\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "    \n",
    "    # Minor ticks every 2 positions (sub-ticks without labels)\n",
    "    minor_locator = MultipleLocator(2)\n",
    "    ax.xaxis.set_minor_locator(minor_locator)\n",
    "    \n",
    "    # Enable minor ticks\n",
    "    ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "    ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "    \n",
    "    ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "    ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "    \n",
    "    # Optionally rotate x labels\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "    # Tick marks every 0.1\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.05))\n",
    "    \n",
    "    # Only label 0.0, 0.3, 0.6\n",
    "    label_positions = [-0.6,-0.5,-0.4,-0.3,-0.2,-0.1,0,0.1,0.2, 0.3, 0.4]\n",
    "    ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:.1f}\" if any(np.isclose(y, lp, atol=1e-3) for lp in label_positions) else \"\"))\n",
    "\n",
    "    padding = 0.01\n",
    "    ax.set_ylim(bottom=y_min_global - padding, top=y_max_global + padding)\n",
    "    \n",
    "    # Optional minor ticks every 0.05\n",
    "    ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "    ax.grid(True, axis='y')   # Turn ON horizontal gridlines only\n",
    "    ax.grid(False, axis='x')  # Turn OFF vertical gridlines\n",
    "    ax.set_xlim(right=510)\n",
    "    # Save\n",
    "    plot_file_path = os.path.join(\n",
    "        r\"/Users/lucaschlotheuber/Desktop\",f\"replicate{replicate_idx}_2x2_log10_median.png\"\n",
    "    )\n",
    "    fig.set_size_inches(8, 5) \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_file_path, format='png')  # Save after resizing/layout\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual Log10 Median antibody binding fraction and escape fraction split plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with split logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, MultipleLocator, FuncFormatter\n",
    "from matplotlib import font_manager\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "from matplotlib.patches import Patch\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +\n",
    "    list(range(394, 414)) +\n",
    "    list(range(484, 505))\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    #show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Aggregate filtered data by position and immunization\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'median'})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "NUM_REPLICATES = 30\n",
    "\n",
    "for replicate_idx in range(1, NUM_REPLICATES + 1):\n",
    "    print(f\"Generating replicate {replicate_idx}\")\n",
    "\n",
    "    y_min_global = np.inf\n",
    "    y_max_global = -np.inf\n",
    "\n",
    "    # Create stacked subplots\n",
    "    fig = plt.figure(figsize=(7, 5))\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[1, 1], hspace=0.15)\n",
    "    ax_top = fig.add_subplot(gs[0])\n",
    "    ax_bottom = fig.add_subplot(gs[1], sharex=ax_top)\n",
    "    plt.setp(ax_top.get_xticklabels(), visible=False)\n",
    "\n",
    "    color_map = {\n",
    "        'Polyclonal_Ab': 'darkorange',\n",
    "        'Neutralizing_Ab': 'red',\n",
    "        'wildtype_RBD': 'green',\n",
    "        'Mutant_RBD': 'darkblue'\n",
    "    }\n",
    "    \n",
    "    top_y_min_global = np.inf\n",
    "    top_y_max_global = -np.inf\n",
    "    bottom_y_min_global = np.inf\n",
    "    bottom_y_max_global = -np.inf\n",
    "\n",
    "\n",
    "    for immunization in df_filtered_agg['immunization'].unique():\n",
    "        immunization_data = {}\n",
    "        if immunization in ['Library_ctrl']:\n",
    "            continue\n",
    "\n",
    "        immunization_df = df_filtered[df_filtered['immunization'] == immunization]\n",
    "\n",
    "        barcodes = np.random.choice(\n",
    "            immunization_df['barcode'].unique(),\n",
    "            size=min(1, immunization_df['barcode'].nunique()),\n",
    "            replace=False\n",
    "        )\n",
    "        print(f\"[INFO] Randomly selected barcodes for '{immunization}': {list(barcodes)}\")\n",
    "\n",
    "        for barcode in barcodes:\n",
    "            df_filtered_im = df_filtered_agg.query(\n",
    "                f'immunization == \"{immunization}\" and barcode == \"{barcode}\"'\n",
    "            ).copy()\n",
    "\n",
    "            if df_filtered_im.empty:\n",
    "                continue\n",
    "\n",
    "            df_filtered_im = df_filtered_im.drop_duplicates(subset='Spike_AS_Position')\n",
    "            faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "            faint_alpha = 0.4\n",
    "            faint_linewidth = 1.5\n",
    "\n",
    "            df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "            df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "                lambda x: np.log10(x) if x > 0 else np.nan\n",
    "            )\n",
    "\n",
    "            # Split into top/bottom\n",
    "            df_top = df_filtered_im[df_filtered_im['Log10_Enrichment'] > 0].copy()\n",
    "            df_bottom = df_filtered_im[df_filtered_im['Log10_Enrichment'] < 0].copy()\n",
    "            split_dfs = {'top': df_top, 'bottom': df_bottom}\n",
    "\n",
    "\n",
    "\n",
    "            for key, df in split_dfs.items():\n",
    "                if df.empty:\n",
    "                    continue\n",
    "\n",
    "                # Smooth enrichment\n",
    "                df['Smoothed_Enrichment'] = df['Log10_Enrichment'].rolling(\n",
    "                    window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "                ).mean().interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "                # Flag high enrichment\n",
    "                df['High_Enrichment'] = (df['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD).fillna(False).astype(bool)\n",
    "\n",
    "                # Aggregate duplicates per Spike_AS_Position\n",
    "                df_agg = df.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "                    'Smoothed_Enrichment': 'median',\n",
    "                    'High_Enrichment': 'any',\n",
    "                    'Log10_Enrichment': 'median',\n",
    "                    'Enrichment_Ratio': 'median'\n",
    "                })\n",
    "\n",
    "                # Reindex to full Spike position range\n",
    "                full_range = range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "                df_agg = df_agg.set_index('Spike_AS_Position').reindex(full_range).interpolate(method='linear', limit_direction='both').reset_index()\n",
    "\n",
    "                split_dfs[key] = df_agg\n",
    "\n",
    "                       # Update global min/max\n",
    "            if not df_top.empty:\n",
    "                top_y_min_global = min(top_y_min_global, df_top['Smoothed_Enrichment'].min())\n",
    "                top_y_max_global = max(top_y_max_global, df_top['Smoothed_Enrichment'].max())\n",
    "    \n",
    "            if not df_bottom.empty:\n",
    "                bottom_y_min_global = min(bottom_y_min_global, df_bottom['Smoothed_Enrichment'].min())\n",
    "                bottom_y_max_global = max(bottom_y_max_global, df_bottom['Smoothed_Enrichment'].max())\n",
    "\n",
    "            df_top = split_dfs['top']\n",
    "            df_bottom = split_dfs['bottom']\n",
    "\n",
    "            # Save CSV (original df)\n",
    "            csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "            df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "            # Calculate confidence intervals\n",
    "            df_im_raw = df_filtered[df_filtered['immunization'] == immunization].copy()\n",
    "            df_im_raw['Log10_Enrichment'] = df_im_raw['Enrichment_Ratio'].apply(lambda x: np.log10(x) if x > 0 else np.nan)\n",
    "            grouped = df_im_raw.groupby('Spike_AS_Position')['Log10_Enrichment']\n",
    "            std_per_pos = grouped.std()\n",
    "            count_per_pos = grouped.count()\n",
    "            sem_per_pos = std_per_pos / np.sqrt(count_per_pos)\n",
    "            dof = count_per_pos - 1\n",
    "            dof[dof < 1] = 1\n",
    "            t_critical = dof.apply(lambda df: stats.t.ppf(0.975, df))\n",
    "            margin_of_error = t_critical * sem_per_pos\n",
    "            smoothed_margin = margin_of_error.rolling(window=ROLLING_WINDOW, center=True, min_periods=1).median().fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "            df_filtered_im = df_filtered_im.set_index('Spike_AS_Position')\n",
    "            df_filtered_im['Smoothed_CI_Margin'] = smoothed_margin\n",
    "            df_filtered_im = df_filtered_im.reset_index().fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "            # Plot top/bottom separately\n",
    "            for df, ax in zip([df_top, df_bottom], [ax_top, ax_bottom]):\n",
    "                if df.empty:\n",
    "                    continue\n",
    "\n",
    "                ax.fill_between(\n",
    "                    df['Spike_AS_Position'],\n",
    "                    df['Smoothed_Enrichment'] - df_filtered_im['Smoothed_CI_Margin'],\n",
    "                    df['Smoothed_Enrichment'] + df_filtered_im['Smoothed_CI_Margin'],\n",
    "                    color=color_map.get(immunization, 'black'),\n",
    "                    alpha=0.07,\n",
    "                    zorder=5\n",
    "                )\n",
    "\n",
    "                # Use your existing plotting function\n",
    "                dmslogo.line.draw_line(\n",
    "                    df,\n",
    "                    x_col='Spike_AS_Position',\n",
    "                    height_col='Smoothed_Enrichment',\n",
    "                    ax=ax,\n",
    "                    linewidth=3.5,\n",
    "                    color=color_map.get(immunization, 'black')\n",
    "                )\n",
    "            # Top axis limits\n",
    " \n",
    "            # Top: arrow pointing up\n",
    "            ax_top.set_ylabel(\n",
    "                \"Increased by IgG-binding\\n(Enriched Fraction) →\",\n",
    "                fontsize=11,\n",
    "                rotation=90,\n",
    "                labelpad=15,  # adjust distance from axis\n",
    "                ha='left',\n",
    "                y=0.02\n",
    "            )\n",
    "            \n",
    "            # Bottom: arrow pointing down\n",
    "            ax_bottom.set_ylabel(\n",
    "                \"Decreased by IgG-binding\\n← (Escape Fraction)\",\n",
    "                fontsize=11,\n",
    "                rotation=90,\n",
    "                labelpad=4,\n",
    "                ha='left',\n",
    "                y=0\n",
    "            )\n",
    "            ax_bottom.set_xlabel(\"Spike AA Position\", fontsize=12)\n",
    "\n",
    "            if immunization in faint_immunizations:\n",
    "                ax_top.lines[-1].set_alpha(faint_alpha)\n",
    "            ax_top.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "            immunization_data[immunization] = df_filtered_im.copy()\n",
    "\n",
    "\n",
    "    # --- AFTER plotting all barcodes for all immunizations ---\n",
    "    top_padding = 0.15\n",
    "    bottom_padding = 0.15\n",
    "    \n",
    "    # Top always starts at 0\n",
    "    if np.isfinite(top_y_max_global):\n",
    "        ax_top.set_ylim(bottom=0, top=0.5)\n",
    "    \n",
    "    # Bottom always ends at 0\n",
    "    if np.isfinite(bottom_y_min_global):\n",
    "        ax_bottom.set_ylim(bottom=bottom_y_min_global - bottom_padding, top=0)\n",
    "\n",
    "\n",
    "    # Highlight positions\n",
    "    #highlight_positions = [int(pos) for pos in sites_to_show]\n",
    "    #for ax in [ax_top, ax_bottom]:\n",
    "     #  for pos in highlight_positions:\n",
    "      #      ax.vlines(x=pos, ymin=-0.015, ymax=0, color='black', linewidth=3.5, alpha=0.9, zorder=10)\n",
    "    ax_bottom.axhline(y=0, color='black', linewidth=2) \n",
    "    # X and Y axis formatting\n",
    "    for ax in [ax_top]:\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(10))\n",
    "        ax.xaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "        ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "        ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        ax.grid(True, axis='y')\n",
    "        ax.grid(False, axis='x')\n",
    "\n",
    "    for ax in [ax_bottom]:\n",
    "        ax.xaxis.set_major_locator(MultipleLocator(10))\n",
    "        ax.xaxis.set_major_formatter(FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "        ax.xaxis.set_minor_locator(MultipleLocator(2))\n",
    "        ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "        ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "        ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "        ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "        ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "        ax.grid(True, axis='y')\n",
    "        ax.grid(False, axis='x')\n",
    "\n",
    "    plt.setp(ax_top.xaxis.get_majorticklabels(), visible=False)\n",
    "    plt.setp(ax_bottom.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "    # Only show y=0 tick label on bottom axis\n",
    "    for tick in ax_top.get_yticklabels():\n",
    "        if tick.get_text() == '0':\n",
    "            tick.set_visible(False)\n",
    "\n",
    "    top_ticks = ax_top.get_yticks()\n",
    "    # Hide only 0 for top axis\n",
    "    top_tick_labels = [\"\" if t == 0 else str(round(t, 2)) for t in top_ticks]\n",
    "    ax_top.set_yticklabels(top_tick_labels)\n",
    "        \n",
    "    ax_bottom.set_xlim(right=510)\n",
    "    ax_top.set_xlabel(\"\")   # Remove any top axis label\n",
    "    ax_bottom.set_xlabel(\"Spike AA Position\", fontsize=12)  # Only bottom\n",
    "    plt.setp(ax_top.get_xticklabels(), visible=False)\n",
    "\n",
    "    # Legend\n",
    "    #epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "    #handles, labels = ax_top.get_legend_handles_labels()\n",
    "    #group_1_labels = ['Polyclonal_Ab']\n",
    "    #group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "    #group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "    #group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "    #handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "    #label_map = {\n",
    "    #    'Polyclonal_Ab': 'antiRBD pAB',\n",
    "    #    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    #    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "    #}\n",
    "    #labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "    #ax_top.legend(handles=handles, labels=labels, fontsize=10)\n",
    "\n",
    "    # Save\n",
    "    plot_file_path = os.path.join(\n",
    "        r\"/Users/lucaschlotheuber/Desktop/DMSnew\", f\"replicate{replicate_idx}_2x2_log10_median.png\"\n",
    "    )\n",
    "    fig.subplots_adjust(left=0.16) \n",
    "    fig.tight_layout()\n",
    "    fig.savefig(plot_file_path, format='png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for 5 other random barcodes/dropets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "from itertools import chain\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered = df_filtered[df_filtered['Amino_Acid'] != \"*\"].copy()\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "barcode_counts = df_filtered.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "df_filtered_agg = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "# Aggregate filtered data by position and immunization before plotting\n",
    "df_filtered_agg = df_filtered_agg.groupby(\n",
    "    ['immunization', 'Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "\n",
    "# Filter immunizations once\n",
    "immunization_data = {}\n",
    "immunizations = [imm for imm in df_filtered_agg['immunization'].unique()\n",
    "                 if imm not in ('Library_ctrl', 'Neutralizing_Ab')][:4]\n",
    "\n",
    "\n",
    "\n",
    "for i, immunization in enumerate(immunizations[:4]):  # Limit to 4 immunizations for 2x2 grid\n",
    "    ax = axs[i]\n",
    "    immunization_df = df_filtered_agg[df_filtered_agg['immunization'] == immunization]\n",
    "\n",
    "    # Get barcodes for this immunization\n",
    "    barcodes = immunization_df['barcode'].unique()\n",
    "    if len(barcodes) == 0:\n",
    "        print(f\"[WARN] No barcodes for {immunization}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Pick one random barcode per immunization\n",
    "    barcode = np.random.choice(barcodes)\n",
    "    print(f\"[INFO] Randomly selected barcode for immunization '{immunization}': {barcode}\")\n",
    "\n",
    "    df_filtered_im = immunization_df[immunization_df['barcode'] == barcode].copy()\n",
    "    if df_filtered_im.empty:\n",
    "        print(f\"[WARN] No data for barcode {barcode} of immunization {immunization}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "    df_filtered_im = df_filtered_im.drop_duplicates(subset='Spike_AS_Position')\n",
    "\n",
    "    # Normalize by number of barcodes (for potential later use)\n",
    "    num_barcodes = barcode_counts.get(immunization, 0)\n",
    "\n",
    "    print(f\"Spike_AS_Position sample before aggregation:\\n{df_filtered_im['Spike_AS_Position'].head()}\")\n",
    "    print(f\"\\nRows for immunization {immunization}: {df_filtered_im.shape[0]}\")\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'Enrichment_Ratio']].head(10))\n",
    "\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "        lambda x: np.log10(x) if x > 0 else np.nan\n",
    "    )\n",
    "\n",
    "    # Smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both'\n",
    "    )\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Aggregate to one value per position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Smoothed_Enrichment': 'median',\n",
    "        'High_Enrichment': 'any',\n",
    "        'Log10_Enrichment': 'median',\n",
    "        'Enrichment_Ratio': 'median'\n",
    "    })\n",
    "\n",
    "    # Coverage check\n",
    "    full_pos_range = range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    actual_positions = df_filtered_im['Spike_AS_Position'].nunique()\n",
    "    total_positions = len(full_pos_range)\n",
    "    coverage_ratio = actual_positions / total_positions\n",
    "\n",
    "    if coverage_ratio < 0.5:\n",
    "        print(f\"Skipping barcode {barcode} due to low coverage ({coverage_ratio:.2f})\")\n",
    "        continue\n",
    "\n",
    "    # Reindex and interpolate\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(full_pos_range).reset_index()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Log10_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].interpolate(method='linear', limit_direction='both')\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    # Rolling min/max for shading\n",
    "    df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "\n",
    "    # Shaded background\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        df_filtered_im['Smoothed_Enrichment_min'],\n",
    "        df_filtered_im['Smoothed_Enrichment_max'],\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot line\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "\n",
    "    if immunization in {'Polyclonal_Ab', 'Neutralizing_Ab'}:\n",
    "        ax.lines[-1].set_alpha(0.3)\n",
    "\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "    ax.set_title(f\"{immunization} - Barcode {barcode}\", fontsize=12)\n",
    "    ax.set_xlabel('Spike AA Position')\n",
    "    ax.set_ylabel('Log10 Antibody binding')\n",
    "    ax.set_xlim(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max())\n",
    "\n",
    "    # Optional debug info\n",
    "    print(f\"\\n[INFO] Immunization: {immunization}\")\n",
    "    print(f\"→ Positions: {df_filtered_im['Spike_AS_Position'].min()} to {df_filtered_im['Spike_AS_Position'].max()}\")\n",
    "    print(f\"→ Mean Enrichment: {df_filtered_im['Enrichment_Ratio'].mean():.3f}\")\n",
    "    print(f\"→ Mean Log10 Enrichment: {df_filtered_im['Log10_Enrichment'].mean():.3f}\")\n",
    "    print(f\"→ Mean Smoothed Log10 Enrichment: {df_filtered_im['Smoothed_Enrichment'].mean():.3f}\")\n",
    "\n",
    "    immunization_data[immunization] = df_filtered_im.copy()\n",
    "\n",
    "# Get y-axis limits\n",
    "y_min, y_max = ax.get_ylim()\n",
    "highlight_y = y_min + 0.05 * (y_max - y_min)  # 5% above bottom\n",
    "\n",
    "highlight_positions = [int(pos) for pos in sites_to_show]\n",
    "\n",
    "ax.hlines(\n",
    "    y=highlight_y,\n",
    "    xmin=min(highlight_positions),\n",
    "    xmax=max(highlight_positions),\n",
    "    color='black',\n",
    "    linewidth=6,  # thick line\n",
    "    alpha=0.8,\n",
    "    zorder=10\n",
    ")\n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.5,\n",
    "            top=0.5)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 Antibody binding (Mean)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='black', edgecolor='black', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "all_handles_labels = [ax.get_legend_handles_labels() for ax in axs]\n",
    "all_handles, all_labels = zip(*all_handles_labels)\n",
    "\n",
    "# Flatten lists\n",
    "handles = list(chain.from_iterable(all_handles))\n",
    "labels = list(chain.from_iterable(all_labels))\n",
    "\n",
    "\n",
    "print(\"[DEBUG] Available legend labels:\", labels)\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['SARS-CoV-2 Spike antibody epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='center left',          # Legend inside figure but on the left side of bbox_to_anchor\n",
    "    bbox_to_anchor=(1, 0.5),    # Outside plot area on right, vertically centered\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "# Only label 0.0, 0.3, 0.6\n",
    "label_positions = [-0.6,-0.4,-0.2,0,0.2,0.4, 0.6, 0.8]\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:.1f}\" if any(np.isclose(y, lp, atol=1e-3) for lp in label_positions) else \"\"))\n",
    "\n",
    "# Optional minor ticks every 0.05\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line3_plot_final_log10.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')  # Save after resizing/layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics to confirm binding ratios and transformation: Tables with raw-data, log10, Gaussian-smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "\n",
    "target_positions = list(range(360, 541, 15))\n",
    "\n",
    "for immunization, df_im in immunization_data.items():\n",
    "    print(f\"\\n[INFO] Generating table values for: {immunization}\")\n",
    "    \n",
    "    for target_pos in target_positions:\n",
    "        row_match = df_im[df_im['Spike_AS_Position'] == target_pos]\n",
    "        if row_match.empty:\n",
    "            print(f\"  → Skipping position {target_pos} (not in data)\")\n",
    "            continue\n",
    "\n",
    "        row = row_match.iloc[0]\n",
    "        summary_rows.append({\n",
    "            'Immunization': immunization,\n",
    "            'Target_Spike_Position': target_pos,\n",
    "            'Actual_Position_Used': row['Spike_AS_Position'],\n",
    "            'Enrichment_Ratio': round(row['Enrichment_Ratio'], 3),\n",
    "            'Log10_Enrichment': round(row['Log10_Enrichment'], 3),\n",
    "            'Smoothed_Enrichment': round(row['Smoothed_Enrichment'], 3)\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame(summary_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "target_positions = list(range(360, 541, 15))\n",
    "\n",
    "for immunization, df_im in immunization_data.items():\n",
    "    print(f\"\\n[INFO] Generating table values for: {immunization}\")\n",
    "    \n",
    "    for target_pos in target_positions:\n",
    "        row_match = df_im[df_im['Spike_AS_Position'] == target_pos]\n",
    "        if row_match.empty:\n",
    "            print(f\"  → Skipping position {target_pos} (not in data)\")\n",
    "            continue\n",
    "\n",
    "        row = row_match.iloc[0]\n",
    "        summary_rows.append({\n",
    "            'Immunization': immunization,\n",
    "            'Target_Spike_Position': target_pos,\n",
    "            'Actual_Position_Used': int(row['Spike_AS_Position']),\n",
    "            'Enrichment_Ratio': round(row['Enrichment_Ratio'], 3),\n",
    "            'Log10_Enrichment': round(row['Log10_Enrichment'], 3),\n",
    "            'Smoothed_Enrichment': round(row['Smoothed_Enrichment'], 3)\n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "print(\"\\n✅ Final Summary Table:\")\n",
    "print(summary_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"[DEBUG] immunization_data keys:\", list(immunization_data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', None)            # Show all rows\n",
    "pd.set_option('display.max_columns', None)         # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)        # Show full content in each cell (no truncation)\n",
    "pd.set_option('display.width', None)               # Auto detect width of console for wrapping\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to multiple lines\n",
    "\n",
    "# Define which positions you want in the table\n",
    "target_positions = list(range(360, 541, 1))\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "def shorten_raw_values(vals):\n",
    "    if isinstance(vals, list):\n",
    "        if len(vals) > 100:\n",
    "            return str(vals[:100])[:-1] + \", ...]\"\n",
    "        else:\n",
    "            return str(vals)\n",
    "    return vals\n",
    "\n",
    "for immunization, df_im in immunization_data.items():\n",
    "    print(f\"[INFO] Adding table rows for: {immunization}\")\n",
    "    \n",
    "    for pos in target_positions:\n",
    "        row_match = df_im[df_im['Spike_AS_Position'] == pos]\n",
    "        if row_match.empty:\n",
    "            continue\n",
    "\n",
    "        row = row_match.iloc[0]\n",
    "        \n",
    "        # Raw enrichment values: pull from original (unsmoothed) df_total\n",
    "        raw_vals = df_total[\n",
    "            (df_total['immunization'] == immunization) &\n",
    "            (df_total['Spike_AS_Position'] == pos) &\n",
    "            (df_total['Amino_Acid'] != \"*\")\n",
    "        ]['Enrichment_Ratio'].clip(lower=1e-3).tolist()\n",
    "\n",
    "        summary_rows.append({\n",
    "            'Immunization': immunization,\n",
    "            'Target_Spike_Position': pos,\n",
    "            'Actual_Position_Used': int(row['Spike_AS_Position']),\n",
    "            'Raw_Enrichment_Short': shorten_raw_values(raw_vals),\n",
    "            'Mean_Enrichment': round(np.median(raw_vals), 3),\n",
    "            'Log10_Enrichment': round(np.log10(np.median(raw_vals)), 3) if np.median(raw_vals) > 0 else np.nan,\n",
    "            'Smoothed_Enrichment': round(row['Smoothed_Enrichment'], 3)\n",
    "        })\n",
    "\n",
    "# Final DataFrame\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Style with column widths\n",
    "styled_summary = summary_df.style.set_table_styles([\n",
    "    {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]},\n",
    "    {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]},\n",
    "    {\"selector\": \"thead th.col0\", \"props\": [(\"min-width\", \"90px\")]},   # Immunization\n",
    "    {\"selector\": \"thead th.col1\", \"props\": [(\"min-width\", \"60px\")]},   # Target_Spike_Position\n",
    "    {\"selector\": \"thead th.col2\", \"props\": [(\"min-width\", \"60px\")]},   # Actual_Position_Used\n",
    "    {\"selector\": \"thead th.col3\", \"props\": [(\"min-width\", \"450px\")]},  # Raw_Enrichment_Short\n",
    "    {\"selector\": \"thead th.col4\", \"props\": [(\"min-width\", \"80px\")]},   # Mean_Enrichment\n",
    "    {\"selector\": \"thead th.col5\", \"props\": [(\"min-width\", \"100px\")]},  # Log10_Enrichment\n",
    "    {\"selector\": \"thead th.col6\", \"props\": [(\"min-width\", \"130px\")]}   # Smoothed_Enrichment\n",
    "])\n",
    "\n",
    "print(\"\\n✅ Final Summary Table:\")\n",
    "display(styled_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_rows', None)            # Show all rows\n",
    "pd.set_option('display.max_columns', None)         # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)        # Show full content in each cell (no truncation)\n",
    "pd.set_option('display.width', None)               # Auto detect width of console for wrapping\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to multiple lines\n",
    "\n",
    "# Define which positions you want in the table\n",
    "target_positions = list(range(360, 541, 1))\n",
    "\n",
    "summary_rows = []\n",
    "\n",
    "def shorten_raw_values(vals):\n",
    "    if isinstance(vals, list):\n",
    "        if len(vals) > 100:\n",
    "            return str(vals[:100])[:-1] + \", ...]\"\n",
    "        else:\n",
    "            return str(vals)\n",
    "    return vals\n",
    "\n",
    "for immunization, df_im in immunization_data.items():\n",
    "    print(f\"[INFO] Adding table rows for: {immunization}\")\n",
    "    \n",
    "    for pos in target_positions:\n",
    "        row_match = df_im[df_im['Spike_AS_Position'] == pos]\n",
    "        if row_match.empty:\n",
    "            continue\n",
    "\n",
    "        row = row_match.iloc[0]\n",
    "        \n",
    "        # Raw enrichment values: pull from original (unsmoothed) df_total\n",
    "        raw_vals = df_total[\n",
    "            (df_total['immunization'] == immunization) &\n",
    "            (df_total['Spike_AS_Position'] == pos) &\n",
    "            (df_total['Amino_Acid'] != \"*\")\n",
    "        ]['Enrichment_Ratio'].clip(lower=1e-3).tolist()\n",
    "\n",
    "        summary_rows.append({\n",
    "            'Immunization': immunization,\n",
    "            'Target_Spike_Position': pos,\n",
    "            'Actual_Position_Used': int(row['Spike_AS_Position']),\n",
    "            'Raw_Enrichment_Short': shorten_raw_values(raw_vals),\n",
    "            'Median_Enrichment': round(np.median(raw_vals), 3),\n",
    "            'Log10_Enrichment': round(np.log10(np.median(raw_vals)), 3) if np.median(raw_vals) > 0 else np.nan,\n",
    "            'Smoothed_Enrichment': round(row['Smoothed_Enrichment'], 3)\n",
    "        })\n",
    "\n",
    "# Final DataFrame\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "# Style with column widths\n",
    "styled_summary = summary_df.style.set_table_styles([\n",
    "    {\"selector\": \"th\", \"props\": [(\"text-align\", \"center\")]},\n",
    "    {\"selector\": \"td\", \"props\": [(\"text-align\", \"center\")]},\n",
    "    {\"selector\": \"thead th.col0\", \"props\": [(\"min-width\", \"90px\")]},   # Immunization\n",
    "    {\"selector\": \"thead th.col1\", \"props\": [(\"min-width\", \"60px\")]},   # Target_Spike_Position\n",
    "    {\"selector\": \"thead th.col2\", \"props\": [(\"min-width\", \"60px\")]},   # Actual_Position_Used\n",
    "    {\"selector\": \"thead th.col3\", \"props\": [(\"min-width\", \"450px\")]},  # Raw_Enrichment_Short\n",
    "    {\"selector\": \"thead th.col4\", \"props\": [(\"min-width\", \"80px\")]},   # Mean_Enrichment\n",
    "    {\"selector\": \"thead th.col5\", \"props\": [(\"min-width\", \"100px\")]},  # Log10_Enrichment\n",
    "    {\"selector\": \"thead th.col6\", \"props\": [(\"min-width\", \"130px\")]}   # Smoothed_Enrichment\n",
    "])\n",
    "\n",
    "print(\"\\n✅ Final Summary Table:\")\n",
    "display(styled_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control table with raw data and transformed data (all values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define region\n",
    "region_start = 500\n",
    "region_end = 510\n",
    "region_name = f\"{region_start}-{region_end}\"\n",
    "\n",
    "summary_rows_barcode = []\n",
    "\n",
    "# Filter data for region, non-stop codons, positive enrichment\n",
    "df_region = df_total[\n",
    "    (df_total['Spike_AS_Position'] >= region_start) &\n",
    "    (df_total['Spike_AS_Position'] <= region_end) &\n",
    "    (df_total['Enrichment_Ratio'] > 0) &\n",
    "    (df_total['Amino_Acid'] != \"*\")\n",
    "].copy()\n",
    "\n",
    "# Get unique immunizations and barcodes\n",
    "immunizations = df_region['immunization'].unique()\n",
    "\n",
    "for immunization in immunizations:\n",
    "    df_im = df_region[df_region['immunization'] == immunization]\n",
    "    barcodes = df_im['barcode'].unique()\n",
    "\n",
    "    # Calculate mean enrichment per barcode in region\n",
    "    for barcode in barcodes:\n",
    "        df_bc = df_im[df_im['barcode'] == barcode]\n",
    "\n",
    "        # Mean enrichment (raw) over region for barcode\n",
    "        median_enrich = df_bc['Enrichment_Ratio'].median()\n",
    "\n",
    "        # Log10 mean enrichment\n",
    "        log10_median_enrich = np.log10(median_enrich) if median_enrich > 0 else np.nan\n",
    "\n",
    "        summary_rows_barcode.append({\n",
    "            'Immunization': immunization,\n",
    "            'Barcode': barcode,\n",
    "            'Region': region_name,\n",
    "            'Median_Enrichment': round(median_enrich, 3),\n",
    "            'Log10_Median_Enrichment': round(log10_median_enrich, 3)\n",
    "        })\n",
    "\n",
    "# Create DataFrame for barcode means\n",
    "df_barcode_summary = pd.DataFrame(summary_rows_barcode)\n",
    "\n",
    "# Calculate median over barcodes per immunization\n",
    "median_summary = df_barcode_summary.groupby('Immunization').agg({\n",
    "    'Median_Enrichment': 'median',\n",
    "    'Log10_Median_Enrichment': 'median'\n",
    "}).rename(columns={\n",
    "    'Median_Enrichment': 'Median_Median_Enrichment_across_Barcodes',\n",
    "    'Log10_Median_Enrichment': 'Median_Log10_Median_Enrichment_across_Barcodes'\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"\\n✅ Per-barcode mean enrichment stats for region {region_name}:\")\n",
    "print(df_barcode_summary.head(100))\n",
    "\n",
    "print(f\"\\n✅ Median mean enrichment across barcodes per immunization for region {region_name}:\")\n",
    "print(median_summary)\n",
    "\n",
    "# Optionally, merge or display both tables side by side\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define region\n",
    "region_start = 500\n",
    "region_end = 510\n",
    "region_name = f\"{region_start}-{region_end}\"\n",
    "\n",
    "summary_rows_barcode_region = []\n",
    "summary_rows_barcode_position = []\n",
    "\n",
    "# Filter data for region, non-stop codons, positive enrichment\n",
    "df_region = df_total[\n",
    "    (df_total['Spike_AS_Position'] >= region_start) &\n",
    "    (df_total['Spike_AS_Position'] <= region_end) &\n",
    "    (df_total['Enrichment_Ratio'] > 0) &\n",
    "    (df_total['Amino_Acid'] != \"*\")\n",
    "].copy()\n",
    "\n",
    "# Get unique immunizations and barcodes\n",
    "immunizations = df_region['immunization'].unique()\n",
    "\n",
    "for immunization in immunizations:\n",
    "    df_im = df_region[df_region['immunization'] == immunization]\n",
    "    barcodes = df_im['barcode'].unique()\n",
    "\n",
    "    for barcode in barcodes:\n",
    "        df_bc = df_im[df_im['barcode'] == barcode]\n",
    "\n",
    "        # Median enrichment over the entire region per barcode\n",
    "        median_enrich_region = df_bc['Enrichment_Ratio'].median()\n",
    "        log10_median_enrich_region = np.log10(median_enrich_region) if median_enrich_region > 0 else np.nan\n",
    "\n",
    "        summary_rows_barcode_region.append({\n",
    "            'Immunization': immunization,\n",
    "            'Barcode': barcode,\n",
    "            'Region': region_name,\n",
    "            'Median_Enrichment': round(median_enrich_region, 3),\n",
    "            'Log10_Median_Enrichment': round(log10_median_enrich_region, 3)\n",
    "        })\n",
    "\n",
    "        # Median enrichment per position for this barcode\n",
    "        for position in range(region_start, region_end + 1):\n",
    "            df_bc_pos = df_bc[df_bc['Spike_AS_Position'] == position]\n",
    "\n",
    "            if not df_bc_pos.empty:\n",
    "                median_enrich_pos = df_bc_pos['Enrichment_Ratio'].median()\n",
    "                log10_median_enrich_pos = np.log10(median_enrich_pos) if median_enrich_pos > 0 else np.nan\n",
    "            else:\n",
    "                median_enrich_pos = np.nan\n",
    "                log10_median_enrich_pos = np.nan\n",
    "\n",
    "            summary_rows_barcode_position.append({\n",
    "                'Immunization': immunization,\n",
    "                'Barcode': barcode,\n",
    "                'Position': position,\n",
    "                'Median_Enrichment': round(median_enrich_pos, 3) if not np.isnan(median_enrich_pos) else np.nan,\n",
    "                'Log10_Median_Enrichment': round(log10_median_enrich_pos, 3) if not np.isnan(log10_median_enrich_pos) else np.nan\n",
    "            })\n",
    "\n",
    "# Create DataFrames\n",
    "df_barcode_summary_region = pd.DataFrame(summary_rows_barcode_region)\n",
    "df_barcode_summary_position = pd.DataFrame(summary_rows_barcode_position)\n",
    "\n",
    "# Sort the position summary by Immunization then by Position ascending\n",
    "df_barcode_summary_position = df_barcode_summary_position.sort_values(by=['Immunization', 'Position']).reset_index(drop=True)\n",
    "\n",
    "# Final summary: median of medians\n",
    "median_summary_region = df_barcode_summary_region.groupby('Immunization').agg({\n",
    "    'Median_Enrichment': 'median',\n",
    "    'Log10_Median_Enrichment': 'median'\n",
    "}).rename(columns={\n",
    "    'Median_Enrichment': 'Median_Enrichment_across_Barcodes',\n",
    "    'Log10_Median_Enrichment': 'Median_Log10_Enrichment_across_Barcodes'\n",
    "}).reset_index()\n",
    "\n",
    "median_summary_position = df_barcode_summary_position.groupby(['Immunization', 'Position']).agg({\n",
    "    'Median_Enrichment': 'median',\n",
    "    'Log10_Median_Enrichment': 'median'\n",
    "}).rename(columns={\n",
    "    'Median_Enrichment': 'Median_Enrichment_across_Barcodes',\n",
    "    'Log10_Median_Enrichment': 'Median_Log10_Enrichment_across_Barcodes'\n",
    "}).reset_index()\n",
    "\n",
    "# Output\n",
    "print(f\"\\n✅ Per-barcode **median** enrichment stats for region {region_name}:\")\n",
    "print(df_barcode_summary_region.head(1000))\n",
    "\n",
    "print(f\"\\n✅ Median enrichment across barcodes per immunization for region {region_name}:\")\n",
    "print(median_summary_region)\n",
    "\n",
    "print(f\"\\n✅ Per-barcode **median** enrichment stats per position for region {region_name} (sorted by position):\")\n",
    "print(df_barcode_summary_position.head(1000))\n",
    "\n",
    "print(f\"\\n✅ Median enrichment across barcodes per immunization per position for region {region_name}:\")\n",
    "print(median_summary_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"From df_filtered_agg:\", df_filtered_agg['immunization'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_rows = []\n",
    "\n",
    "print(\"Available immunizations in df_total:\")\n",
    "print(df_total['immunization'].dropna().unique())\n",
    "\n",
    "# Define fixed target positions (every 15th position from 360 to 540)\n",
    "target_positions = list(range(360, 541, 15))\n",
    "\n",
    "valid_immunizations = df_total['immunization'].dropna().unique()\n",
    "\n",
    "for immunization in valid_immunizations:\n",
    "    \n",
    "    if immunization in ['Library_ctrl', 'Neutralizing_Ab']:\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n[INFO] Processing immunization: '{immunization}'\")\n",
    "    df_im = df_total[df_total['immunization'] == immunization].copy()\n",
    "    print(f\"  → Raw rows: {len(df_im)}\")\n",
    "\n",
    "    df_im = df_im[df_im['Amino_Acid'] != \"*\"]\n",
    "    print(f\"  → After filtering '*': {len(df_im)}\")\n",
    "\n",
    "    df_im['Enrichment_Ratio'] = df_im['Enrichment_Ratio'].clip(lower=1e-3)\n",
    "\n",
    "    if df_im.empty:\n",
    "        print(f\"[WARN] No data for {immunization} after filtering.\")\n",
    "        continue\n",
    "\n",
    "    grouped = df_im.groupby('Spike_AS_Position')['Enrichment_Ratio']\n",
    "    mean_enrichment = grouped.mean()\n",
    "    raw_enrichment = grouped.apply(list)\n",
    "\n",
    "    log10_enrichment = mean_enrichment.apply(lambda x: np.log10(x) if x > 0 else np.nan)\n",
    "    smoothed = log10_enrichment.rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    summary_data = pd.DataFrame({\n",
    "        'Mean_Enrichment': mean_enrichment,\n",
    "        'Raw_Enrichment_Values': raw_enrichment,\n",
    "        'Log10_Enrichment': log10_enrichment,\n",
    "        'Smoothed_Enrichment': smoothed\n",
    "    }).reset_index()\n",
    "\n",
    "    print(f\"  → Positions in summary_data: {summary_data['Spike_AS_Position'].min()} to {summary_data['Spike_AS_Position'].max()}\")\n",
    "\n",
    "    for target_pos in target_positions:\n",
    "        if summary_data.empty:\n",
    "            continue\n",
    "\n",
    "        # Find closest actual position\n",
    "        diffs = (summary_data['Spike_AS_Position'] - target_pos).abs()\n",
    "        min_diff = diffs.min()\n",
    "        closest_idx = diffs.idxmin()\n",
    "        closest_row = summary_data.loc[closest_idx]\n",
    "\n",
    "        # Debug print for each appended row\n",
    "        print(f\"    Target pos {target_pos} → Closest actual pos {closest_row['Spike_AS_Position']} (diff {min_diff})\")\n",
    "\n",
    "        row = {\n",
    "            'Immunization': immunization,\n",
    "            'Target_Spike_Position': target_pos,\n",
    "            'Actual_Position_Used': int(closest_row['Spike_AS_Position']),\n",
    "            'Raw_Enrichment_Values': closest_row['Raw_Enrichment_Values'],\n",
    "            'Mean_Enrichment': round(closest_row['Mean_Enrichment'], 3),\n",
    "            'Log10_Enrichment': round(closest_row['Log10_Enrichment'], 3),\n",
    "            'Smoothed_Enrichment': round(closest_row['Smoothed_Enrichment'], 3)\n",
    "        }\n",
    "        summary_rows.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "\n",
    "print(\"\\nImmunizations included in summary_df:\", summary_df['Immunization'].unique())\n",
    "print(summary_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)            # Show all rows\n",
    "pd.set_option('display.max_columns', None)         # Show all columns\n",
    "pd.set_option('display.max_colwidth', None)        # Show full content in each cell (no truncation)\n",
    "pd.set_option('display.width', None)                # Auto detect width of console for wrapping\n",
    "pd.set_option('display.expand_frame_repr', False)  # Do not wrap to multiple lines\n",
    "from IPython.display import display\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific check for WT values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def shorten_raw_values(lst):\n",
    "    if isinstance(lst, list):\n",
    "        if len(lst) > 3:\n",
    "            return str(lst[:3])[:-1] + \", ...]\"\n",
    "        else:\n",
    "            return str(lst)\n",
    "    return lst\n",
    "\n",
    "summary_df['Raw_Enrichment_Short'] = summary_df['Raw_Enrichment_Values'].apply(shorten_raw_values)\n",
    "\n",
    "# Now display with the shortened column instead of the full list\n",
    "display(summary_df.drop(columns=['Raw_Enrichment_Values']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line plot version with Double-aggregation: Median and Mean (not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.ticker import MultipleLocator, FuncFormatter\n",
    "\n",
    "%matplotlib inline\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "print(\"Files in output_dir:\", os.listdir(output_dir))\n",
    "\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 15  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33 + 331) &\n",
    "                       (df_total['Enrichment_Ratio'] > 0)]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_aa_agg = df_total[df_total['Amino_Acid'] != \"*\"].copy()\n",
    "df_aa_agg['Enrichment_Ratio'] = df_aa_agg['Enrichment_Ratio'].clip(lower=1e-3)\n",
    "df_aa_agg = df_aa_agg.groupby(['Spike_AS_Position', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'median'\n",
    "})\n",
    "\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':\n",
    "        continue\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        continue\n",
    "    faint_immunizations = {'Polyclonal_Ab', 'Neutralizing_Ab'}\n",
    "    faint_alpha = 0.3\n",
    "    faint_linewidth = 1.5\n",
    "\n",
    "    #if immunization == 'Polyclonal_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "    #if immunization == 'Neutralizing_Ab':  # Skip 'Library_ctrl'\n",
    "     #   continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Normalize by number of barcodes\n",
    "    num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'mean'\n",
    "    })\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Safe log transform (ignore or remove zero/negative values)\n",
    "    df_filtered_im['Log10_Enrichment'] = df_filtered_im['Enrichment_Ratio'].apply(\n",
    "        lambda x: np.log10(x) if x > 0 else np.nan\n",
    "    )\n",
    "    \n",
    "    # Apply smoothing on the log2 transformed values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log10_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(\n",
    "        method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "    # Print what's being plotted\n",
    "    print(f\"\\n[Every 5th Position Smoothed Enrichment for {immunization}]\")\n",
    "    subset = df_filtered_im[df_filtered_im['Spike_AS_Position'] % 5 == 0][['Spike_AS_Position', 'Smoothed_Enrichment']]\n",
    "    print(subset.to_string(index=False))\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(),\n",
    "              df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "    # Mark sites to highlight\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "        # Rolling min and max for range area\n",
    "    # Fixed (aligned min/max with smoothed mean)\n",
    "    df_filtered_im['Smoothed_Enrichment_min'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).min()\n",
    "    df_filtered_im['Smoothed_Enrichment_max'] = df_filtered_im['Smoothed_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1).max()\n",
    "\n",
    "\n",
    "    # Plot shaded area for range\n",
    "    ax.fill_between(\n",
    "        df_filtered_im['Spike_AS_Position'],\n",
    "        df_filtered_im['Smoothed_Enrichment_min'],\n",
    "        df_filtered_im['Smoothed_Enrichment_max'],\n",
    "        color=color_map.get(immunization, 'black'),\n",
    "        alpha=0.1\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    \n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₁₀ enrichment)\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    if immunization in faint_immunizations:\n",
    "        ax.lines[-1].set_alpha(faint_alpha)\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    #highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    #for _, site_data in highlight_sites.iterrows():\n",
    "    #    ax.hlines(\n",
    "    #        y=0.1,  # set near bottom\n",
    "    #        xmin=site_data['Spike_AS_Position'] - 0.5,\n",
    "    #        xmax=site_data['Spike_AS_Position'] + 0.5,\n",
    "    #        color='black',\n",
    "    #        linestyle='-',\n",
    "    #        linewidth=10\n",
    "    #    )\n",
    "\n",
    "# Y-axis limit (adjust if needed for log scale)\n",
    "ax.set_ylim(bottom=-0.05,\n",
    "            top=np.nanmax(df_filtered_im['Smoothed_Enrichment']) + 0.2)\n",
    "\n",
    "plt.title('', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Log10 AB binding (Mean)', fontsize=18)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Create a square patch for the legend entry\n",
    "epitope_patch = Patch(facecolor='orange', edgecolor='orange', label='SARS-CoV-2 Spike antibody epitopes')\n",
    "\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Legend (subset only to certain labels)\n",
    "group_1_labels = ['Polyclonal_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles + [epitope_patch]\n",
    "\n",
    "label_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'wildtype_RBD': 'ASCs from SARS-CoV-2 Wuhan Imm.',\n",
    "    'Mutant_RBD': 'ASCs from SARS-CoV-2 B.1.135 Imm.'\n",
    "}\n",
    "labels = [label_map[label] for label in group_1_labels + group_2_labels] + ['Selected Antibody RBD epitopes']\n",
    "\n",
    "plt.legend(\n",
    "    handles, labels,\n",
    "    title=\"Immunization\",\n",
    "    title_fontproperties=font_manager.FontProperties(weight='bold'),\n",
    "    loc='upper left',\n",
    "    fontsize=11,\n",
    "    frameon=False,\n",
    "    handlelength=2,\n",
    "    handleheight=1,\n",
    "    markerscale=1\n",
    ")\n",
    "\n",
    "# X-axis ticks\n",
    "# Set x-ticks every 10 positions\n",
    "# Major ticks every 10 positions\n",
    "major_locator = MultipleLocator(10)\n",
    "ax.xaxis.set_major_locator(major_locator)\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f\"{int(x)}\"))\n",
    "\n",
    "# Minor ticks every 2 positions (sub-ticks without labels)\n",
    "minor_locator = MultipleLocator(2)\n",
    "ax.xaxis.set_minor_locator(minor_locator)\n",
    "\n",
    "# Enable minor ticks\n",
    "ax.tick_params(axis='x', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='x', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "ax.tick_params(axis='y', which='major', length=7, width=1.2)\n",
    "ax.tick_params(axis='y', which='minor', length=4, width=0.8, direction='out')\n",
    "\n",
    "# Optionally rotate x labels\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=0, ha='center')\n",
    "# Tick marks every 0.1\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "\n",
    "# Only label 0.0, 0.3, 0.6\n",
    "label_positions = [0.0, 0.3, 0.6]\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda y, _: f\"{y:.1f}\" if any(np.isclose(y, lp, atol=1e-3) for lp in label_positions) else \"\"))\n",
    "\n",
    "# Optional minor ticks every 0.05\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "\n",
    "# Save\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot_final_log10.png\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics for Manuscript: Comparing Antibody binding ratios (median of individual droplets) across Spike protein regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"380-400\": (380, 400),\n",
    "    \"400-410\": (400, 410),\n",
    "    \"420-440\": (420, 440),\n",
    "    \"490-510\": (490, 510),\n",
    "    \"510-520\": (510, 520),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "\n",
    "# Update immunizations array to exclude 'Un-enrich. Libr'\n",
    "immunizations = [imm for imm in df_total2['immunization'].unique() if imm != 'Un-enrich. Libr']\n",
    "print(\"Immunizations found in data (excluding 'Un-enrich. Libr'):\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values_log = {}  # for plotting (log10 means)\n",
    "    region_values_raw = {}  # for stats (raw means)\n",
    "    \n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        # Filter to positive means (>=1) to safely log-transform (for plotting)\n",
    "        barcode_stats = barcode_stats[barcode_stats['Mean_Enrichment'] > 0].copy()\n",
    "        \n",
    "        # Store raw means for stats\n",
    "        region_values_raw[imm] = barcode_stats['Mean_Enrichment']\n",
    "        \n",
    "        # Log10 transform means for plotting\n",
    "        barcode_stats['Mean_Enrichment_log10'] = np.log10(barcode_stats['Mean_Enrichment'])\n",
    "        region_values_log[imm] = barcode_stats['Mean_Enrichment_log10']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment_log10'],  # log10 for plotting\n",
    "                'Std': row['Std_Enrichment'],  # Std still original scale\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    # Perform statistical tests on raw enrichment means (not log10)\n",
    "    for imm1, imm2 in combinations(region_values_raw.keys(), 2):\n",
    "        vals1 = region_values_raw[imm1].dropna()\n",
    "        vals2 = region_values_raw[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats_log10.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Sort immunizations for plotting (exclude 'Un-enrich. Libr')\n",
    "immunizations_sorted = ['Neutralizing_Ab', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=7, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('log10 (Barcode Mean Enrichment ER)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 2.25\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, ymax)\n",
    "    y_offset = ymax - 2*ystep\n",
    "    ax.tick_params(axis='y', labelsize=12)  # increase y-axis tick label size\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_log10.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats_log10.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manuscript Statistics plot, comparison of Raw-ER values across immunizations (Color) and across Spike Region (separate box-plots). Significance test: MW-u test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"360-370\": (360, 370),\n",
    "    \"400-410\": (400, 410),\n",
    "    \"410-420\": (410, 420),\n",
    "    #\"420-430\": (420, 430),\n",
    "    #\"430-440\": (430, 440),\n",
    "    #\"440-450\": (440, 450),\n",
    "    #\"450-460\": (450, 460),\n",
    "    #\"460-470\": (460, 470),\n",
    "    #\"470-480\": (470, 480),\n",
    "    #\"480-490\": (480, 490),\n",
    "    \"490-500\": (490, 500),\n",
    "    \"500-510\": (500, 510),\n",
    "    #\"510-520\": (510, 520),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 0)]\n",
    "\n",
    "# Update immunizations array to exclude 'Un-enrich. Libr'\n",
    "immunizations = [imm for imm in df_total2['immunization'].unique() if imm != 'Un-enrich. Libr']\n",
    "print(\"Immunizations found in data (excluding 'Un-enrich. Libr'):\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': (255/255, 140/255, 0/255, 0.4),    # darkorange\n",
    "    'Neutralizing_Ab': (255/255, 0/255, 0/255, 0.4),    # red\n",
    "    'wildtype_RBD': (0/255, 128/255, 0/255, 0.4),       # green\n",
    "    'Mutant_RBD': (30/255, 144/255, 255/255, 0.4)       # dodgerblue\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values_log = {}  # for plotting (log10 means)\n",
    "    region_values_raw = {}  # for stats (raw means)\n",
    "    \n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        # Filter to positive means (>=1) to safely log-transform (for plotting)\n",
    "        barcode_stats = barcode_stats[barcode_stats['Mean_Enrichment'] > 0].copy()\n",
    "        \n",
    "        # Store raw means for stats\n",
    "        region_values_raw[imm] = barcode_stats['Mean_Enrichment']\n",
    "        \n",
    "        # Log10 transform means for plotting\n",
    "        barcode_stats['Mean_Enrichment_log10'] = np.log10(barcode_stats['Mean_Enrichment'])\n",
    "        region_values_log[imm] = barcode_stats['Mean_Enrichment_log10']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment_log10'],  # log10 for plotting\n",
    "                'Std': row['Std_Enrichment'],  # Std still original scale\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    # Perform statistical tests on raw enrichment means (not log10)\n",
    "    for imm1, imm2 in combinations(region_values_raw.keys(), 2):\n",
    "        vals1 = region_values_raw[imm1].dropna()\n",
    "        vals2 = region_values_raw[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats_log10.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Sort immunizations for plotting (exclude 'Un-enrich. Libr')\n",
    "immunizations_sorted = ['Neutralizing_Ab', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "palette = {imm: color_map[imm] for imm in immunizations_sorted}\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False,\n",
    "                order=immunizations_sorted, palette=palette)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=7, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('Log10 AB binding (Mean)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 2.5\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(-0.4, ymax)\n",
    "    y_offset = ymax - 4*ystep\n",
    "    ax.tick_params(axis='y', labelsize=12)  # increase y-axis tick label size\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.01, star, ha='center', va='bottom', fontsize=22, fontweight='bold')\n",
    "\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_log10.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats_log10.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"360-370\": (360, 370),\n",
    "    \"400-410\": (400, 410),\n",
    "    \"410-420\": (410, 420),\n",
    "    #\"420-430\": (420, 430),\n",
    "    #\"430-440\": (430, 440),\n",
    "    #\"440-450\": (440, 450),\n",
    "    #\"450-460\": (450, 460),\n",
    "    #\"460-470\": (460, 470),\n",
    "    #\"470-480\": (470, 480),\n",
    "    #\"480-490\": (480, 490),\n",
    "    \"490-500\": (490, 500),\n",
    "    \"500-510\": (500, 510),\n",
    "    #\"510-520\": (510, 520),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 0)]\n",
    "\n",
    "# Update immunizations array to exclude 'Un-enrich. Libr'\n",
    "#immunizations = [imm for imm in df_total2['immunization'].unique()\n",
    "               #  if imm not in ['Un-enrich. Libr', 'Neutralizing_Ab']]\n",
    "immunizations = [imm for imm in df_total2['immunization'].unique() if imm != 'Un-enrich. Libr']\n",
    "print(\"Immunizations found in data (excluding 'Un-enrich. Libr'):\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': (255/255, 140/255, 0/255, 0.4),    # darkorange\n",
    "    'Neutralizing_Ab': (255/255, 0/255, 0/255, 0.4),    # red\n",
    "    'wildtype_RBD': (0/255, 128/255, 0/255, 0.4),       # green\n",
    "    'Mutant_RBD': (30/255, 144/255, 255/255, 0.4)       # dodgerblue\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values_log = {}  # for plotting (log10 means)\n",
    "    region_values_raw = {}  # for stats (raw means)\n",
    "    \n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        # Filter to positive means (>=1) to safely log-transform (for plotting)\n",
    "        barcode_stats = barcode_stats[barcode_stats['Mean_Enrichment'] > 0].copy()\n",
    "        \n",
    "        # Store raw means for stats\n",
    "        region_values_raw[imm] = barcode_stats['Mean_Enrichment']\n",
    "        \n",
    "        # Log10 transform means for plotting\n",
    "        barcode_stats['Mean_Enrichment_log10'] = np.log10(barcode_stats['Mean_Enrichment'])\n",
    "        region_values_log[imm] = barcode_stats['Mean_Enrichment_log10']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment_log10'],  # log10 for plotting\n",
    "                'Std': row['Std_Enrichment'],  # Std still original scale\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    # Perform statistical tests on raw enrichment means (not log10)\n",
    "    for imm1, imm2 in combinations(region_values_raw.keys(), 2):\n",
    "        vals1 = region_values_raw[imm1].dropna()\n",
    "        vals2 = region_values_raw[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats_log10.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Sort immunizations for plotting (exclude 'Un-enrich. Libr')\n",
    "immunizations_sorted = ['Neutralizing_Ab', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "palette = {imm: color_map[imm] for imm in immunizations_sorted}\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False,\n",
    "                order=immunizations_sorted, palette=palette)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=7, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('Log10 AB binding (Mean)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 2.5\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(-0.4, ymax)\n",
    "    y_offset = ymax - 4*ystep\n",
    "    ax.tick_params(axis='y', labelsize=12)  # increase y-axis tick label size\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.01, star, ha='center', va='bottom', fontsize=22, fontweight='bold')\n",
    "\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_log10_noNeut.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats_log10.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as before but with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    #\"360-370\": (360, 370),\n",
    "    \"370-380\": (370, 380),\n",
    "    #\"380-390\": (380, 390),\n",
    "    \"390-400\": (390, 400),\n",
    "    \"400-410\": (400, 410),\n",
    "    \"410-420\": (410, 420),\n",
    "    #\"420-430\": (420, 430),\n",
    "    \"430-440\": (430, 440),\n",
    "    \"440-450\": (440, 450),\n",
    "    #\"450-460\": (450, 460),\n",
    "    #\"480-490\": (480, 490),\n",
    "    \"490-500\": (490, 500),\n",
    "    #\"500-510\": (500, 510),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 0\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 0)]\n",
    "\n",
    "# Update immunizations array to exclude 'Un-enrich. Libr'\n",
    "immunizations = [imm for imm in df_total2['immunization'].unique() if imm != 'Un-enrich. Libr']\n",
    "print(\"Immunizations found in data (excluding 'Un-enrich. Libr'):\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': (255/255, 140/255, 0/255, 0.4),    # darkorange\n",
    "    'Neutralizing_Ab': (255/255, 0/255, 0/255, 0.4),    # red\n",
    "    'wildtype_RBD': (0/255, 128/255, 0/255, 0.4),       # green\n",
    "    'Mutant_RBD': (30/255, 144/255, 255/255, 0.4)       # dodgerblue\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values_log = {}  # for plotting (log10 means)\n",
    "    region_values_raw = {}  # for stats (raw means)\n",
    "    \n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        # Step 1: Median per position per barcode\n",
    "        median_per_pos = df_region.groupby(['barcode', 'Spike_AS_Position'])['Enrichment_Ratio'].median().reset_index()\n",
    "\n",
    "        # Step 2: Keep only positive values for log transformation\n",
    "        median_per_pos = median_per_pos[median_per_pos['Enrichment_Ratio'] > 0].copy()\n",
    "\n",
    "        # Step 3: Log10 transform\n",
    "        median_per_pos['Enrichment_Ratio_log10'] = np.log10(median_per_pos['Enrichment_Ratio'])\n",
    "\n",
    "        # Step 4: Average log10 medians across the region for each barcode\n",
    "        barcode_stats = median_per_pos.groupby('barcode').agg(\n",
    "            Mean_Enrichment_log10=('Enrichment_Ratio_log10', 'mean'),\n",
    "            Std_Enrichment_log10=('Enrichment_Ratio_log10', 'std'),\n",
    "            n=('Enrichment_Ratio_log10', 'count')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Also store raw scale averages of medians for stats\n",
    "        barcode_stats['Mean_Enrichment'] = median_per_pos.groupby('barcode')['Enrichment_Ratio'].mean().values\n",
    "\n",
    "        # Store for later\n",
    "        region_values_raw[imm] = barcode_stats['Mean_Enrichment']\n",
    "        region_values_log[imm] = barcode_stats['Mean_Enrichment_log10']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment_log10'],  # already log10\n",
    "                'Std': row['Std_Enrichment_log10'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    # Perform statistical tests on raw enrichment means (not log10)\n",
    "    for imm1, imm2 in combinations(region_values_raw.keys(), 2):\n",
    "        vals1 = region_values_raw[imm1].dropna()\n",
    "        vals2 = region_values_raw[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats_log10.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Sort immunizations for plotting (exclude 'Un-enrich. Libr')\n",
    "immunizations_sorted = ['Neutralizing_Ab', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "palette = {imm: color_map[imm] for imm in immunizations_sorted}\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False,\n",
    "                order=immunizations_sorted, palette=palette)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=7, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('Log10 AB binding (Median)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 0.5\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(-0.65, ymax)\n",
    "    y_offset = ymax - 4*ystep-0.04\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        #if row['Group1'] == 'Neutralizing_Ab' or row['Group2'] == 'Neutralizing_Ab':\n",
    "         #   continue\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.15, y_offset+ystep*0.15, y_offset], lw=1, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.01, star, ha='center', va='bottom', fontsize=18, fontweight='bold')\n",
    "\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_log10_noNeut.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats_log10.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KS Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import ks_2samp\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    #\"360-370\": (360, 370),\n",
    "    #\"370-380\": (370, 380),\n",
    "    \"370-400\": (380, 390),\n",
    "    \"400-430\": (390, 400),\n",
    "    \"430-460\": (400, 410),\n",
    "    \"460-490\": (410, 420),\n",
    "    \"490-520\": (420, 430),\n",
    "    \"520-550\": (430, 440),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 0\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 0)]\n",
    "\n",
    "# Update immunizations array to exclude 'Un-enrich. Libr'\n",
    "immunizations = [imm for imm in df_total2['immunization'].unique() if imm != 'Un-enrich. Libr']\n",
    "print(\"Immunizations found in data (excluding 'Un-enrich. Libr'):\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': (255/255, 140/255, 0/255, 0.4),    # darkorange\n",
    "    'Neutralizing_Ab': (255/255, 0/255, 0/255, 0.4),    # red\n",
    "    'wildtype_RBD': (0/255, 128/255, 0/255, 0.4),       # green\n",
    "    'Mutant_RBD': (30/255, 144/255, 255/255, 0.4)       # dodgerblue\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values_log = {}  # for plotting (log10 means)\n",
    "    region_values_raw = {}  # for stats (raw means)\n",
    "    \n",
    "    for imm in immunizations:\n",
    "        print(f\"{imm}: total barcodes = {df_total2[df_total2['immunization'] == imm]['barcode'].nunique()}\")\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        # Step 1: Median per position per barcode\n",
    "        median_per_pos = df_region.groupby(['barcode', 'Spike_AS_Position'])['Enrichment_Ratio'].mean().reset_index()\n",
    "\n",
    "        # Step 2: Keep only positive values for log transformation\n",
    "        median_per_pos = median_per_pos[median_per_pos['Enrichment_Ratio'] > 0].copy()\n",
    "\n",
    "        # Step 3: Log10 transform\n",
    "        median_per_pos['Enrichment_Ratio_log10'] = np.log10(median_per_pos['Enrichment_Ratio'])\n",
    "\n",
    "        # Step 4: Average log10 medians across the region for each barcode\n",
    "        barcode_stats = median_per_pos.groupby('barcode').agg(\n",
    "            Mean_Enrichment_log10=('Enrichment_Ratio_log10', 'mean'),\n",
    "            Std_Enrichment_log10=('Enrichment_Ratio_log10', 'std'),\n",
    "            n=('Enrichment_Ratio_log10', 'count')\n",
    "        ).reset_index()\n",
    "\n",
    "        # Also store raw scale averages of medians for stats\n",
    "        barcode_stats['Mean_Enrichment'] = median_per_pos.groupby('barcode')['Enrichment_Ratio'].mean().values\n",
    "\n",
    "        # Store for later\n",
    "        region_values_raw[imm] = barcode_stats['Mean_Enrichment']\n",
    "        region_values_log[imm] = barcode_stats['Mean_Enrichment_log10']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment_log10'],  # already log10\n",
    "                'Std': row['Std_Enrichment_log10'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    # Perform statistical tests on raw enrichment means (not log10)\n",
    "    for imm1, imm2 in combinations(region_values_raw.keys(), 2):\n",
    "        vals1 = region_values_raw[imm1].dropna()\n",
    "        vals2 = region_values_raw[imm2].dropna()\n",
    "    \n",
    "        print(f\"  KS test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping KS test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = ks_2samp(vals1, vals2)\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'KS_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats_KS.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats_KS.csv'\")\n",
    "\n",
    "# Now that all regions are processed and plot_data is complete:\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "print(f\"\\nPrepared plot DataFrame with {len(plot_df)} rows\")\n",
    "print(\"\\nFinal mean log10 enrichment values per Region and Immunization (per barcode):\\n\")\n",
    "\n",
    "for region_name in sorted(plot_df['Region'].unique()):\n",
    "    print(f\"Region: {region_name}\")\n",
    "    sub_region = plot_df[plot_df['Region'] == region_name]\n",
    "    \n",
    "    for imm in immunizations:\n",
    "        sub_imm = sub_region[sub_region['Immunization'] == imm]\n",
    "        if sub_imm.empty:\n",
    "            print(f\"  {imm}: No data\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"  Immunization: {imm} (n={len(sub_imm)})\")\n",
    "        for idx, row in sub_imm.iterrows():\n",
    "            print(f\"    Barcode: {row['barcode']}, Mean log10 enrichment: {row['Enrichment']:.4f}\")\n",
    "        \n",
    "        median_val = sub_imm['Enrichment'].median()\n",
    "        mean_val = sub_imm['Enrichment'].mean()\n",
    "        print(f\"    Summary: median={median_val:.4f}, mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    else:\n",
    "        return ''   # skip * and nonsignificant\n",
    "\n",
    "\n",
    "#def pval_to_stars(p):\n",
    " #   if p < 0.001:\n",
    "  #      return '***'\n",
    "   # elif p < 0.01:\n",
    "    #    return '**'\n",
    "    #elif p < 0.05:\n",
    "    #    return '*'\n",
    "    #else:\n",
    "    #    return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "#fig, axes = plt.subplots(2, 3, figsize=(24, 10), sharey=True)\n",
    "axes = axes.flatten()  \n",
    "\n",
    "# Sort immunizations for plotting (exclude 'Un-enrich. Libr')\n",
    "immunizations_sorted = ['Neutralizing_Ab', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "palette = {imm: color_map[imm] for imm in immunizations_sorted}\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False,\n",
    "                order=immunizations_sorted, palette=palette)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=7, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "    ax.set_ylabel(\"Log10 AB binding (median)\\n$\\\\mathbf{\\\\Leftarrow}$ Enrichment $\\\\mathbf{\\\\Rightarrow}$\", \n",
    "                  rotation=90, labelpad=30, va='center', fontsize=18)\n",
    "    ax.yaxis.set_label_coords(-0.3, 0.4)\n",
    "    #ax.set_ylabel('Log10 AB binding (Median)', fontsize=14)\n",
    "    #ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = sub_df['Enrichment'].max() \n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(-1, 4)\n",
    "    y_offset = (ymax - 4*ystep-0.02)+ 1.3\n",
    "    \n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2],\n",
    "                [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset],\n",
    "                lw=1.5, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.01, star,\n",
    "                ha='center', va='bottom',\n",
    "                fontsize=22, fontweight='bold')\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_log10_KS_NeutF.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats_log10.csv'\")\n",
    "\n",
    "print(\"\\nPairwise KS Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, KS_stat = {row['KS_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"360-370\": (360, 370),\n",
    "    \"400-410\": (400, 410),\n",
    "    \"410-420\": (410, 420),\n",
    "    #\"420-430\": (420, 430),\n",
    "    #\"430-440\": (430, 440),\n",
    "    #\"440-450\": (440, 450),\n",
    "    #\"450-460\": (450, 460),\n",
    "    #\"460-470\": (460, 470),\n",
    "    #\"470-480\": (470, 480),\n",
    "    #\"480-490\": (480, 490),\n",
    "    \"490-500\": (490, 500),\n",
    "    \"500-510\": (500, 510),\n",
    "    #\"510-520\": (510, 520),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 0)]\n",
    "\n",
    "# Update immunizations array to exclude 'Un-enrich. Libr'\n",
    "#immunizations = [imm for imm in df_total2['immunization'].unique()\n",
    "               #  if imm not in ['Un-enrich. Libr', 'Neutralizing_Ab']]\n",
    "immunizations = [imm for imm in df_total2['immunization'].unique() if imm != 'Un-enrich. Libr']\n",
    "print(\"Immunizations found in data (excluding 'Un-enrich. Libr'):\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': (255/255, 140/255, 0/255, 0.4),    # darkorange\n",
    "    'Neutralizing_Ab': (255/255, 0/255, 0/255, 0.4),    # red\n",
    "    'wildtype_RBD': (0/255, 128/255, 0/255, 0.4),       # green\n",
    "    'Mutant_RBD': (30/255, 144/255, 255/255, 0.4)       # dodgerblue\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values_log = {}  # for plotting (log10 means)\n",
    "    region_values_raw = {}  # for stats (raw means)\n",
    "    \n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['median', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'median': 'Median_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        # Filter to positive means (>=1) to safely log-transform (for plotting)\n",
    "        barcode_stats = barcode_stats[barcode_stats['Median_Enrichment'] > 0].copy()\n",
    "        \n",
    "        # Store raw means for stats\n",
    "        region_values_raw[imm] = barcode_stats['Median_Enrichment']\n",
    "        \n",
    "        # Log10 transform means for plotting\n",
    "        barcode_stats['Median_Enrichment_log10'] = np.log10(barcode_stats['Median_Enrichment'])\n",
    "        region_values_log[imm] = barcode_stats['Median_Enrichment_log10']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Median_Enrichment_log10'],  # log10 for plotting\n",
    "                'Std': row['Std_Enrichment'],  # Std still original scale\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    # Perform statistical tests on raw enrichment means (not log10)\n",
    "    for imm1, imm2 in combinations(region_values_raw.keys(), 2):\n",
    "        vals1 = region_values_raw[imm1].dropna()\n",
    "        vals2 = region_values_raw[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats_log10.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Sort immunizations for plotting (exclude 'Un-enrich. Libr')\n",
    "immunizations_sorted = ['Neutralizing_Ab', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "palette = {imm: color_map[imm] for imm in immunizations_sorted}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False,\n",
    "                order=immunizations_sorted, palette=palette)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=7, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('Log10 AB binding (Median)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 0.4\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(-0.3, ymax)\n",
    "    y_offset = ymax - 4*ystep\n",
    "    ax.tick_params(axis='y', labelsize=12)  # increase y-axis tick label size\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.01, star, ha='center', va='bottom', fontsize=22, fontweight='bold')\n",
    "\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_log10_noNeut.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats_log10.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Above for publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-analysis of statistics of ER values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import os\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "\n",
    "\n",
    "# Define regions of interest\n",
    "regions = {\n",
    "    \"380-390\": (380, 390),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "\n",
    "# Immunization groups\n",
    "immunizations = ['Polyclonal_Ab', 'Neutralizing_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "# Display titles\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135'\n",
    "}\n",
    "\n",
    "# Load datasets\n",
    "data_dict = {}\n",
    "for imm in immunizations:\n",
    "    csv_path = os.path.join(output_dir, f\"{imm}_data.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    data_dict[imm] = df\n",
    "\n",
    "# Collect data for plotting\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "print(data_dict['Polyclonal_Ab'].columns)\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    region_values = {}\n",
    "    \n",
    "    for imm, df in data_dict.items():\n",
    "        df_region = df[(df['Spike_AS_Position'] >= start) & (df['Spike_AS_Position'] <= end)]\n",
    "        vals = df_region['Enrichment_Ratio'].dropna()\n",
    "        region_values[imm] = vals\n",
    "        \n",
    "        for val in vals:\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': val\n",
    "            })\n",
    "    \n",
    "    # Pairwise statistical testing\n",
    "    for (imm1, imm2) in combinations(region_values.keys(), 2):\n",
    "        vals1, vals2 = region_values[imm1], region_values[imm2]\n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval\n",
    "        })\n",
    "\n",
    "# Save stats\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "\n",
    "# Convert plot data to DataFrame\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Helper for p-value to stars\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=3)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Enrichment', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Relabel x-ticks\n",
    "    new_labels = [title_map.get(label.get_text(), label.get_text()) for label in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    # Add significance annotations\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    # Set fixed y-axis max and star annotation range\n",
    "    ymax = 90\n",
    "    star_start = 50  # Start placing stars from here\n",
    "    star_step = 3     # Distance between significance bars\n",
    "    ax.set_ylim(0, ymax)\n",
    "    y_offset = star_start\n",
    "    #ymax = sub_df['Enrichment'].max()\n",
    "    #ymax = 85\n",
    "    #ax.set_ylim(0, ymax)\n",
    "    #ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    #y_offset = ymax - ystep\n",
    "    for i, row in region_results.iterrows():\n",
    "        group1, group2 = row['Group1'], row['Group2']\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            x1 = immunizations.index(group1)\n",
    "            x2 = immunizations.index(group2)\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep  # increment to avoid overlap\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# For safety: set output_dir if not already set\n",
    "output_dir = \"output\"  # <- Update if needed\n",
    "\n",
    "print(\"Current working dir:\", os.getcwd())\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define regions of interest\n",
    "regions = {\n",
    "    \"380-390\": (380, 390),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "\n",
    "# Immunization groups\n",
    "immunizations = ['Polyclonal_Ab', 'Neutralizing_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "# Display titles\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135'\n",
    "}\n",
    "\n",
    "# Load and transform datasets\n",
    "data_dict = {}\n",
    "for imm in immunizations:\n",
    "    csv_path = os.path.join(output_dir, f\"{imm}_data.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Remove non-positive enrichment values before log10 transform\n",
    "    df = df[df['Enrichment_Ratio'] > 0].copy()\n",
    "    df['Log10_Enrichment'] = np.log10(df['Enrichment_Ratio'])\n",
    "    data_dict[imm] = df\n",
    "\n",
    "# Collect data for plotting\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    region_values = {}\n",
    "\n",
    "    for imm, df in data_dict.items():\n",
    "        df_region = df[(df['Spike_AS_Position'] >= start) & (df['Spike_AS_Position'] <= end)]\n",
    "        vals = df_region['Log10_Enrichment'].dropna()\n",
    "        region_values[imm] = vals\n",
    "\n",
    "        for val in vals:\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Log10_Enrichment': val\n",
    "            })\n",
    "\n",
    "    # Pairwise statistical testing on log10 data\n",
    "    for (imm1, imm2) in combinations(region_values.keys(), 2):\n",
    "        vals1, vals2 = region_values[imm1], region_values[imm2]\n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval\n",
    "        })\n",
    "\n",
    "# Save statistics\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_log10_stats.csv\", index=False)\n",
    "\n",
    "# Convert plot data to DataFrame\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "# Helper for p-value to stars\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Plot\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Log10_Enrichment', ax=ax, showfliers=False)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Log10_Enrichment', ax=ax, color=\".25\", size=3)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('log₁₀(Enrichment)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    # Relabel x-ticks\n",
    "    new_labels = [title_map.get(label.get_text(), label.get_text()) for label in ax.get_xticklabels()]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    # Add significance annotations\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = sub_df['Log10_Enrichment'].max() + 0.5\n",
    "    y_offset = ymax - 0.1\n",
    "    y_step = 0.2\n",
    "\n",
    "    ax.set_ylim(bottom=sub_df['Log10_Enrichment'].min() - 0.5, top=ymax + 0.2)\n",
    "\n",
    "    for i, row in region_results.iterrows():\n",
    "        group1, group2 = row['Group1'], row['Group2']\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            x1 = immunizations.index(group1)\n",
    "            x2 = immunizations.index(group2)\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset + 0.05, y_offset + 0.05, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset + 0.07, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += y_step\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_log10_enrichment_comparison.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Filter out NaN immunizations before sorting\n",
    "# Define the plotting order explicitly (excluding 'wildtype_RBD')\n",
    "immunizations_sorted = sorted([imm for imm in immunizations if pd.notna(imm)])\n",
    "immunizations_sorted = ['Library_ctrl', 'Neutralizing_Ab', 'Polyclonal_Ab','wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 40\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, 35)\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "# Save per-barcode enrichment data\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p values mann whitney across regions, all enrichment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "\n",
    "immunizations = df_total['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total[df_total['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Filter out NaN immunizations before sorting\n",
    "# Define the plotting order explicitly (excluding 'wildtype_RBD')\n",
    "immunizations_sorted = sorted([imm for imm in immunizations if pd.notna(imm)])\n",
    "immunizations_sorted = ['Library_ctrl', 'Polyclonal_Ab','wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 15\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, 22)\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_Above1.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "# Save per-barcode enrichment data\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"380-390\": (380, 390),\n",
    "    \"390-400\": (390, 400),\n",
    "    \"400-410\": (400, 410),\n",
    "    \"420-430\": (420, 430),\n",
    "    \"430-440\": (430, 440),\n",
    "    \"440-450\": (440, 450),\n",
    "    \"450-460\": (450, 460),\n",
    "    \"460-470\": (460, 470),\n",
    "    \"470-480\": (470, 480),\n",
    "    \"480-490\": (480, 490),\n",
    "    \"490-500\": (490, 500),\n",
    "    \"500-510\": (500, 510),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "\n",
    "# Update immunizations array to exclude 'Un-enrich. Libr'\n",
    "immunizations = [imm for imm in df_total2['immunization'].unique() if imm != 'Un-enrich. Libr']\n",
    "print(\"Immunizations found in data (excluding 'Un-enrich. Libr'):\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    #'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        # Remove zero or negative means before log transform (should be >=1 anyway)\n",
    "        barcode_stats = barcode_stats[barcode_stats['Mean_Enrichment'] > 0].copy()\n",
    "        barcode_stats['Mean_Enrichment'] = np.log10(barcode_stats['Mean_Enrichment'])\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],  # Note: Std is still on original scale\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats_log10.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Sort immunizations for plotting (exclude 'Un-enrich. Libr')\n",
    "immunizations_sorted = ['Library_ctrl', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('log10 (Mean Enrichment per Barcode)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 5\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, ymax)\n",
    "    y_offset = ymax - ystep\n",
    "    ax.tick_params(axis='y', labelsize=12)  # increase y-axis tick label size\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_log10.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats_log10.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats_log10.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p values mann whitney across regions, >1 enrichment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Filter out NaN immunizations before sorting\n",
    "# Define the plotting order explicitly (excluding 'wildtype_RBD')\n",
    "immunizations_sorted = sorted([imm for imm in immunizations if pd.notna(imm)])\n",
    "immunizations_sorted = ['Library_ctrl', 'Polyclonal_Ab','wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 15\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, 22)\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_Above1.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "# Save per-barcode enrichment data\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean ER per barcode, larger Spike regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "\n",
    "# Update immunizations array to include the new sample\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    #'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "    #'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Make sure to include 'Un-enrich. Libr' in the sorted immunizations order for plotting\n",
    "immunizations_sorted = ['Un-enrich. Libr','Library_ctrl', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 15\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, 22)\n",
    "    y_offset = ymax + ystep\n",
    "    ax.tick_params(axis='y', labelsize=12)  # increase y-axis tick label size\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star or 'Un-enrich. Libr' in [row['Group1'], row['Group2']]:\n",
    "            continue\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=16, fontweight='bold')\n",
    "\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_Above1_Lib.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-490\": (470, 490),\n",
    "    \"490-510\": (490, 510),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "\n",
    "# Update immunizations array to include the new sample\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\n2',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Make sure to include 'Un-enrich. Libr' in the sorted immunizations order for plotting\n",
    "immunizations_sorted = ['Un-enrich. Libr','Library_ctrl', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 15\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, 26)\n",
    "    y_offset = ymax + ystep\n",
    "    ax.tick_params(axis='y', labelsize=12)  # increase y-axis tick label size\n",
    "\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star or 'Un-enrich. Libr' in [row['Group1'], row['Group2']]:\n",
    "            continue\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=18, fontweight='bold')\n",
    "\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_ER_per_barcode_Above1_Lib.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:. 4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Log10 Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-490\": (470, 490),\n",
    "    \"490-510\": (490, 510),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "positions = sorted({pos for start, end in regions.values() for pos in range(start, end + 1)})\n",
    "\n",
    "new_sample_rows = [{\n",
    "    'barcode': f\"UnEnrichLib_{pos}\",\n",
    "    'immunization': 'Un-enrich. Libr',\n",
    "    'Spike_AS_Position': pos,\n",
    "    'Enrichment_Ratio': 1.0\n",
    "} for pos in positions]\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# --- Filter and log-transform ---\n",
    "df_total2 = df_total[df_total['Enrichment_Ratio'] >= 1].copy()\n",
    "df_total2['Log10_Enrichment'] = np.log10(df_total2['Enrichment_Ratio'])\n",
    "\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\n2',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        grouped = df_region.groupby('barcode')\n",
    "\n",
    "        barcode_stats = grouped['Log10_Enrichment'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Log10_Enrichment', 'std': 'Std_Log10_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Log10_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Log10_Enrichment': row['Mean_Log10_Enrichment'],\n",
    "                'Std': row['Std_Log10_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            continue\n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_log10_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_log10_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "immunizations_sorted = ['Un-enrich. Libr','Library_ctrl', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Log10_Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Log10_Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "    ax.set_ylabel('log10 (Mean Enrichment per Barcode)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels([title_map.get(label, label) for label in immunizations_sorted], rotation=0)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.set_ylim(0, 1.2)  # adjust as needed based on data range\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    y_offset = 0.4\n",
    "    ystep = 0.1\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star or 'Un-enrich. Libr' in [row['Group1'], row['Group2']]:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.2, y_offset+ystep*0.2, y_offset], lw=1.5, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.3, star, ha='center', va='bottom', fontsize=18, fontweight='bold')\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_log10_ER_per_barcode.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_log10_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode log10 enrichment stats to 'per_barcode_log10_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:. 4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-490\": (470, 490),\n",
    "    \"490-510\": (490, 510),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "positions = sorted({pos for start, end in regions.values() for pos in range(start, end + 1)})\n",
    "\n",
    "new_sample_rows = [{\n",
    "    'barcode': f\"UnEnrichLib_{pos}\",\n",
    "    'immunization': 'Un-enrich. Libr',\n",
    "    'Spike_AS_Position': pos,\n",
    "    'Enrichment_Ratio': 1.0\n",
    "} for pos in positions]\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# --- Filter and log-transform ---\n",
    "df_total2 = df_total[df_total['Enrichment_Ratio'] >= 0].copy()\n",
    "df_total2['Log10_Enrichment'] = np.log10(df_total2['Enrichment_Ratio'])\n",
    "\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\n2',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        grouped = df_region.groupby('barcode')\n",
    "\n",
    "        barcode_stats = grouped['Log10_Enrichment'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Log10_Enrichment', 'std': 'Std_Log10_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Log10_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Log10_Enrichment': row['Mean_Log10_Enrichment'],\n",
    "                'Std': row['Std_Log10_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            continue\n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_log10_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_log10_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "immunizations_sorted = ['Un-enrich. Libr','Library_ctrl', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Log10_Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Log10_Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name, fontsize=16)\n",
    "    ax.set_ylabel('log10 (Mean Enrichment per Barcode)', fontsize=14)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_xticklabels([title_map.get(label, label) for label in immunizations_sorted], rotation=0)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "    ax.set_ylim(-0.6, 0.8)  # adjust as needed based on data range\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    y_offset = 0.4\n",
    "    ystep = 0.12\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if not star or 'Un-enrich. Libr' in [row['Group1'], row['Group2']]:\n",
    "            continue\n",
    "        if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "            continue\n",
    "        x1 = immunizations_sorted.index(row['Group1'])\n",
    "        x2 = immunizations_sorted.index(row['Group2'])\n",
    "        x_center = (x1 + x2) / 2\n",
    "        ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.2, y_offset+ystep*0.2, y_offset], lw=1.5, c='k')\n",
    "        ax.text(x_center, y_offset+ystep*0.3, star, ha='center', va='bottom', fontsize=18, fontweight='bold')\n",
    "        y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_log10_ALLER_per_barcode.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_log10_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode log10 enrichment stats to 'per_barcode_log10_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:. 4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-490\": (470, 490),\n",
    "    \"490-510\": (490, 510),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "\n",
    "# Update immunizations array to include the new sample\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Make sure to include 'Un-enrich. Libr' in the sorted immunizations order for plotting\n",
    "immunizations_sorted = ['Un-enrich. Libr','Library_ctrl', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 15\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, 26)\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_Above1_Lib.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "import numpy as np\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "# --- Define regions ---\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-490\": (470, 490),\n",
    "    \"490-510\": (490, 510),\n",
    "}\n",
    "\n",
    "# --- Add new sample \"Un-enrich. Libr\" with enrichment=1 at all region positions ---\n",
    "\n",
    "positions = []\n",
    "for start, end in regions.values():\n",
    "    positions.extend(range(start, end + 1))\n",
    "positions = sorted(set(positions))\n",
    "\n",
    "new_sample_rows = []\n",
    "for pos in positions:\n",
    "    new_sample_rows.append({\n",
    "        'barcode': f\"UnEnrichLib_{pos}\",\n",
    "        'immunization': 'Un-enrich. Libr',\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Enrichment_Ratio': 1.0\n",
    "    })\n",
    "\n",
    "new_sample_df = pd.DataFrame(new_sample_rows)\n",
    "\n",
    "# Append new sample rows to df_total\n",
    "df_total = pd.concat([df_total, new_sample_df], ignore_index=True)\n",
    "print(f\"Added {len(new_sample_df)} new rows for 'Un-enrich. Libr' sample with Enrichment_Ratio=1.\")\n",
    "\n",
    "# Filter df_total to keep Enrichment_Ratio >= 1\n",
    "#df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "\n",
    "# Update immunizations array to include the new sample\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total[df_total['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Make sure to include 'Un-enrich. Libr' in the sorted immunizations order for plotting\n",
    "immunizations_sorted = ['Un-enrich. Libr','Library_ctrl', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 12\n",
    "    ystep = (ymax * 0.15) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, 27)\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode_ALL_Lib.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p values mann whitney across regions, <1 enrichment values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] <= 1)]\n",
    "immunizations = df_total2['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Filter out NaN immunizations before sorting\n",
    "# Define the plotting order explicitly (excluding 'wildtype_RBD')\n",
    "immunizations_sorted = sorted([imm for imm in immunizations if pd.notna(imm)])\n",
    "immunizations_sorted = ['Library_ctrl', 'Neutralizing_Ab', 'Polyclonal_Ab','wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = 1.1\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    ax.set_ylim(0, 2)\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcodeAllRatios.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "# Save per-barcode enrichment data\n",
    "plot_df.to_csv(\"per_barcode_enrichment_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n",
    "\n",
    "print(\"\\nPairwise Mann-Whitney U Test Results (sorted by p-value):\")\n",
    "for _, row in results_df.iterrows():\n",
    "    star = pval_to_stars(row['p_value'])\n",
    "    print(f\"Region: {row['Region']}, {row['Group1']} vs {row['Group2']}, \"\n",
    "          f\"p = {row['p_value']:.4g} {star}, U = {row['U_stat']:.2f}, \"\n",
    "          f\"n1 = {row['n1']}, n2 = {row['n2']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p values mann whitney across regions, >1 enrichment values and < 1: AB Escape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "\n",
    "immunizations = df_total['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 0) & (df_total['Enrichment_Ratio'] <= 1)]\n",
    "# Use df_filtered instead of df_total in the rest of the code\n",
    "\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Filter out NaN immunizations before sorting\n",
    "# Define the plotting order explicitly (excluding 'wildtype_RBD')\n",
    "immunizations_sorted = sorted([imm for imm in immunizations if pd.notna(imm)])\n",
    "immunizations_sorted = ['Library_ctrl', 'Neutralizing_Ab', 'Polyclonal_Ab','wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = sub_df['Enrichment'].max()\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "# Save per-barcode enrichment data\n",
    "plot_df.to_csv(\"per_barcode_Escape_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "\n",
    "immunizations = df_total['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 0) & (df_total['Enrichment_Ratio'] <= 1)]\n",
    "# Use df_filtered instead of df_total in the rest of the code\n",
    "\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Filter out NaN immunizations before sorting\n",
    "# Define the plotting order explicitly (excluding 'wildtype_RBD')\n",
    "immunizations_sorted = sorted([imm for imm in immunizations if pd.notna(imm)])\n",
    "immunizations_sorted = ['Library_ctrl', 'Neutralizing_Ab', 'Polyclonal_Ab','wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = sub_df['Enrichment'].max()\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "# Save per-barcode enrichment data\n",
    "plot_df.to_csv(\"per_barcode_Escape_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Assume df_total is your original DataFrame with all data combined\n",
    "print(\"Initial df_total columns:\", df_total.columns.tolist())\n",
    "\n",
    "assert 'barcode' in df_total.columns, \"'barcode' column missing in df_total!\"\n",
    "assert 'immunization' in df_total.columns, \"'immunization' column missing in df_total!\"\n",
    "\n",
    "regions = {\n",
    "    \"390-420\": (390, 420),\n",
    "    \"424-450\": (424, 450),\n",
    "    \"450-470\": (450, 470),\n",
    "    \"470-510\": (470, 510),\n",
    "}\n",
    "\n",
    "immunizations = df_total['immunization'].unique()\n",
    "print(\"Immunizations found in data:\", immunizations)\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\nCtrl'\n",
    "}\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "df_total2 = df_total[(df_total['Enrichment_Ratio'] >= 1)]\n",
    "# Use df_filtered instead of df_total in the rest of the code\n",
    "\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    print(f\"\\nProcessing region {region_name} from {start} to {end}\")\n",
    "    \n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total2[df_total2['immunization'] == imm]\n",
    "        print(f\"  {imm}: {len(df_imm)} rows before region filtering\")\n",
    "        \n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        print(f\"  {imm}: {len(df_region)} rows after region filtering\")\n",
    "\n",
    "        if 'barcode' not in df_region.columns:\n",
    "            raise ValueError(f\"'barcode' column missing after filtering for immunization {imm} in region {region_name}!\")\n",
    "\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        print(f\"  {imm}: {len(grouped)} unique barcodes in region\")\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "    \n",
    "        print(f\"  Mann-Whitney test between {imm1} (n={len(vals1)}) and {imm2} (n={len(vals2)})\")\n",
    "    \n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            print(f\"   Skipping Mann-Whitney test for {imm1} vs {imm2} due to zero data size.\")\n",
    "            continue\n",
    "    \n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "    \n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "results_df.to_csv(\"pairwise_enrichment_stats.csv\", index=False)\n",
    "print(\"\\nSaved statistical test results to 'pairwise_enrichment_stats.csv'\")\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "def pval_to_stars(p):\n",
    "    if p < 0.001:\n",
    "        return '***'\n",
    "    elif p < 0.01:\n",
    "        return '**'\n",
    "    elif p < 0.05:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, axes = plt.subplots(1, len(regions), figsize=(16, 5), sharey=True)\n",
    "\n",
    "# Filter out NaN immunizations before sorting\n",
    "# Define the plotting order explicitly (excluding 'wildtype_RBD')\n",
    "immunizations_sorted = sorted([imm for imm in immunizations if pd.notna(imm)])\n",
    "immunizations_sorted = ['Library_ctrl', 'Neutralizing_Ab', 'Polyclonal_Ab','wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "\n",
    "for ax, (region_name, _) in zip(axes, regions.items()):\n",
    "    sub_df = plot_df[plot_df['Region'] == region_name]\n",
    "\n",
    "    sns.boxplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, showfliers=False, order=immunizations_sorted)\n",
    "    sns.swarmplot(data=sub_df, x='Immunization', y='Enrichment', ax=ax, color=\".25\", size=4, order=immunizations_sorted)\n",
    "\n",
    "    ax.set_title(region_name)\n",
    "    ax.set_ylabel('Mean Enrichment per Barcode')\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "    new_labels = [title_map.get(label, label) for label in immunizations_sorted]\n",
    "    ax.set_xticklabels(new_labels, rotation=0)\n",
    "\n",
    "    region_results = results_df[results_df['Region'] == region_name]\n",
    "    ymax = sub_df['Enrichment'].max()\n",
    "    ystep = (ymax * 0.1) if ymax > 0 else 1\n",
    "    y_offset = ymax + ystep\n",
    "    for _, row in region_results.iterrows():\n",
    "        star = pval_to_stars(row['p_value'])\n",
    "        if star:\n",
    "            if row['Group1'] not in immunizations_sorted or row['Group2'] not in immunizations_sorted:\n",
    "                continue\n",
    "            x1 = immunizations_sorted.index(row['Group1'])\n",
    "            x2 = immunizations_sorted.index(row['Group2'])\n",
    "            x_center = (x1 + x2) / 2\n",
    "            ax.plot([x1, x1, x2, x2], [y_offset, y_offset+ystep*0.1, y_offset+ystep*0.1, y_offset], lw=1.5, c='k')\n",
    "            ax.text(x_center, y_offset+ystep*0.15, star, ha='center', va='bottom', fontsize=12)\n",
    "            y_offset += ystep\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"regionwise_enrichment_comparison_per_barcode.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "print(f\"Prepared plot DataFrame with {len(plot_df)} rows\")\n",
    "\n",
    "# Save per-barcode enrichment data\n",
    "plot_df.to_csv(\"per_barcode_Escape_stats.csv\", index=False)\n",
    "print(\"Saved per-barcode enrichment stats to 'per_barcode_enrichment_stats.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Your enrichment function is NOT used here (no transformation)\n",
    "# We filter values 0 < enrichment <= 1 only\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total[df_total['immunization'] == imm]\n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        grouped = df_region.groupby('barcode')\n",
    "\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        # Filter values between 0 and 1 (excluding 0)\n",
    "        barcode_stats = barcode_stats[(barcode_stats['Mean_Enrichment'] > 0) & (barcode_stats['Mean_Enrichment'] <= 1)]\n",
    "\n",
    "        region_values[imm] = barcode_stats['Mean_Enrichment']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Mean_Enrichment'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    # Mann-Whitney U test between immunization groups\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            continue\n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "# Convert plot data to DataFrame\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "\n",
    "# Save data if you want\n",
    "plot_df.to_csv(\"block1_filtered_no_transform_plot_data.csv\", index=False)\n",
    "results_df.to_csv(\"block1_filtered_no_transform_stats.csv\", index=False)\n",
    "\n",
    "# Plotting violin plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.violinplot(data=plot_df, x='Region', y='Enrichment', hue='Immunization', cut=0, inner='quartile')\n",
    "plt.title('Enrichment Ratios (0 < Enrichment ≤ 1) by Region and Immunization (No Transformation)')\n",
    "plt.ylabel('Mean Enrichment Ratio')\n",
    "plt.xlabel('Region')\n",
    "plt.legend(title='Immunization')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "def enrichment_height(enrichment):\n",
    "    if enrichment >= 1:\n",
    "        return np.log2(enrichment)\n",
    "    else:\n",
    "        return -np.log2(1 / enrichment)\n",
    "\n",
    "plot_data = []\n",
    "results = []\n",
    "\n",
    "for region_name, (start, end) in regions.items():\n",
    "    region_values = {}\n",
    "\n",
    "    for imm in immunizations:\n",
    "        df_imm = df_total[df_total['immunization'] == imm]\n",
    "        df_region = df_imm[(df_imm['Spike_AS_Position'] >= start) & (df_imm['Spike_AS_Position'] <= end)]\n",
    "        grouped = df_region.groupby('barcode')\n",
    "        barcode_stats = grouped['Enrichment_Ratio'].agg(['mean', 'std', 'count']).reset_index()\n",
    "        barcode_stats.rename(columns={'mean': 'Mean_Enrichment', 'std': 'Std_Enrichment', 'count': 'n'}, inplace=True)\n",
    "\n",
    "        barcode_stats['Transformed'] = barcode_stats['Mean_Enrichment'].apply(enrichment_height)\n",
    "\n",
    "        region_values[imm] = barcode_stats['Transformed']\n",
    "\n",
    "        for _, row in barcode_stats.iterrows():\n",
    "            plot_data.append({\n",
    "                'Region': region_name,\n",
    "                'Immunization': imm,\n",
    "                'Enrichment': row['Transformed'],\n",
    "                'Std': row['Std_Enrichment'],\n",
    "                'n_sites': row['n'],\n",
    "                'barcode': row['barcode']\n",
    "            })\n",
    "\n",
    "    for imm1, imm2 in combinations(region_values.keys(), 2):\n",
    "        vals1 = region_values[imm1].dropna()\n",
    "        vals2 = region_values[imm2].dropna()\n",
    "\n",
    "        if len(vals1) == 0 or len(vals2) == 0:\n",
    "            continue\n",
    "\n",
    "        stat, pval = mannwhitneyu(vals1, vals2, alternative='two-sided')\n",
    "        results.append({\n",
    "            'Region': region_name,\n",
    "            'Group1': imm1,\n",
    "            'Group2': imm2,\n",
    "            'Mean1': vals1.mean(),\n",
    "            'Mean2': vals2.mean(),\n",
    "            'Median1': vals1.median(),\n",
    "            'Median2': vals2.median(),\n",
    "            'U_stat': stat,\n",
    "            'p_value': pval,\n",
    "            'n1': len(vals1),\n",
    "            'n2': len(vals2)\n",
    "        })\n",
    "\n",
    "plot_df = pd.DataFrame(plot_data)\n",
    "results_df = pd.DataFrame(results).sort_values(by='p_value')\n",
    "plot_df.to_csv(\"block2_transformed_all.csv\", index=False)\n",
    "results_df.to_csv(\"block2_stats_all.csv\", index=False)\n",
    "\n",
    "immunizations_sorted = ['Library_ctrl', 'Neutralizing_Ab', 'Polyclonal_Ab', 'wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "ax = sns.boxplot(data=plot_df, x='Region', y='Enrichment', hue='Immunization',\n",
    "                 order=sorted(plot_df['Region'].unique()),\n",
    "                 hue_order=immunizations_sorted,\n",
    "                 showfliers=False)\n",
    "sns.swarmplot(data=plot_df, x='Region', y='Enrichment', hue='Immunization',\n",
    "              order=sorted(plot_df['Region'].unique()),\n",
    "              hue_order=immunizations_sorted,\n",
    "              dodge=True, color=\".25\", ax=ax)\n",
    "\n",
    "plt.title('Transformed Enrichment by Region and Immunization')\n",
    "plt.ylabel('Transformed Enrichment (log2 scale)')\n",
    "plt.xlabel('Region')\n",
    "\n",
    "# Fix legend duplicates\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "n = len(immunizations_sorted)\n",
    "plt.legend(handles[:n], labels[:n], title='Immunization', loc='best')\n",
    "\n",
    "# Add p-value annotations above boxplots for each region and pair\n",
    "regions_unique = sorted(plot_df['Region'].unique())\n",
    "n_regions = len(regions_unique)\n",
    "n_hues = len(immunizations_sorted)\n",
    "\n",
    "positions = {}\n",
    "for i, region in enumerate(regions_unique):\n",
    "    for j, imm in enumerate(immunizations_sorted):\n",
    "        positions[(region, imm)] = i - 0.2 + (j * 0.4 / (n_hues - 1)) if n_hues > 1 else i\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    region = row['Region']\n",
    "    imm1 = row['Group1']\n",
    "    imm2 = row['Group2']\n",
    "    pval = row['p_value']\n",
    "\n",
    "    if (region, imm1) not in positions or (region, imm2) not in positions:\n",
    "        continue  # skip if missing\n",
    "\n",
    "    x1 = positions[(region, imm1)]\n",
    "    x2 = positions[(region, imm2)]\n",
    "    y_max = plot_df[(plot_df['Region'] == region) & \n",
    "                    (plot_df['Immunization'].isin([imm1, imm2]))]['Enrichment'].max()\n",
    "\n",
    "    y, h, col = y_max + 0.3, 0.1, 'k'\n",
    "\n",
    "    ax.plot([x1, x1, x2, x2], [y, y+h, y+h, y], lw=1.5, c=col)\n",
    "    if pval < 0.001:\n",
    "        p_text = '***'\n",
    "    elif pval < 0.01:\n",
    "        p_text = '**'\n",
    "    elif pval < 0.05:\n",
    "        p_text = '*'\n",
    "    else:\n",
    "        p_text = f\"ns\\n({pval:.2f})\"\n",
    "\n",
    "    ax.text((x1 + x2) * .5, y + h, p_text, ha='center', va='bottom', color=col, fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 10  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & \n",
    "                       (df_total['Enrichment_Ratio'] > 1)]  # Only include Enrichment_Ratio > 1\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':  # Skip 'Library_ctrl'\n",
    "        continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    # Count number of unique barcodes in this immunization\n",
    "    num_barcodes = df_filtered_agg[df_filtered_agg['immunization'] == immunization]['barcode'].nunique()\n",
    "    \n",
    "    # Aggregate and normalize by barcode count\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "    df_filtered_im['Enrichment_Ratio'] /= num_barcodes  # Normalize\n",
    "    if df_filtered_im['Enrichment_Ratio'].isna().any():\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "    # Avoid log of 0 or negative numbers\n",
    "    df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].replace(0, np.nan)\n",
    "    df_filtered_im['Log_Enrichment'] = np.log10(df_filtered_im['Enrichment_Ratio'])\n",
    "\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Log_Enrichment'].rolling(\n",
    "        window=ROLLING_WINDOW, center=True, min_periods=1\n",
    "    ).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values (linear interpolation)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization (after interpolation to avoid issues)\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    print(f\"Target sites to highlight: {list(sites_to_show)}\")\n",
    "\n",
    "    # Check the data type of Spike_AS_Position and sites_to_show for comparison\n",
    "    print(f\"Data type of 'Spike_AS_Position': {df_filtered_agg['Spike_AS_Position'].dtype}\")\n",
    "    print(f\"Data type of 'sites_to_show': {type(sites_to_show)}\")\n",
    "\n",
    "    # Ensure High_Enrichment is still boolean\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "    # Use dmslogo.line.draw_line but plot on the same axes with specified color\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",  # Remove individual titles for each plot\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"show_site\",  # Highlight high enrichment clusters\n",
    "        ax=ax,  # Pass the same axes object for all plots\n",
    "        linewidth=2,\n",
    "        color=color_map.get(immunization, 'black')  # Get the color for the immunization (default to black)\n",
    "    )\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        # Use ax.hlines to draw horizontal lines only where there are sites to show\n",
    "        ax.hlines(\n",
    "            y=0,  # Set the y-position of the line to 0 (or a small value near the bottom of the plot)\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,  # Start of the line (slightly before the site)\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,  # End of the line (slightly after the site)\n",
    "            color='black',  # Line color\n",
    "            linestyle='-',  # Line style\n",
    "            linewidth=10  # Line width\n",
    "        )\n",
    "\n",
    "# Set the y-axis limit to 200\n",
    "# Set y-axis limit and ticks at 0.1 intervals\n",
    "ax.set_ylim(0.4, 1.35)\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=False, prune='lower', nbins=20))  # allows decimals\n",
    "ax.set_yticks(np.arange(0.4, 1.35, 0.1))\n",
    "\n",
    "# After all lines are drawn, adjust plot settings\n",
    "plt.title('Smoothed Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Antibody Repertoire - Enrichment \\n (Median per-cell Polyreactivity)', fontsize=16)\n",
    "\n",
    "# Add the legend in the top right\n",
    "# Create a grouped legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "group_1_labels = ['Polyclonal_Ab', 'Neutralizing_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles\n",
    "labels = group_1_labels + group_2_labels\n",
    "\n",
    "#handles = group_2_handles\n",
    "#labels = group_2_labels\n",
    "\n",
    "# Add the legend to the top right\n",
    "plt.legend(handles, labels, title=\"Single Droplet Repertoire\", loc='upper right', fontsize=11, frameon=False, handlelength=2, handleheight=1, title_fontsize=11, markerscale=8)\n",
    "\n",
    "# Set the x-axis ticks explicitly to 20 ticks across the range, and label every other one\n",
    "xticks = np.linspace(df_filtered_agg['Spike_AS_Position'].min(), df_filtered_agg['Spike_AS_Position'].max(), 10).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "\n",
    "# Set the labels to only show for every other tick\n",
    "ax.set_xticklabels([str(x) if i % 2 == 0 else '' for i, x in enumerate(xticks)])\n",
    "\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, prune='lower', nbins=8))\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot.png\")\n",
    "fig.tight_layout() \n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "\n",
    "# Display the combined plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 20  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 1  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & \n",
    "                       (df_total['Enrichment_Ratio'] > 1)]  # Only include Enrichment_Ratio > 1\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'darkblue',\n",
    "    'Mutant_RBD': '#004c4c'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':  # Skip 'Library_ctrl'\n",
    "        continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'median',\n",
    "    })\n",
    "    if df_filtered_im['Enrichment_Ratio'].isna().any():\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data by interpolating missing values (linear interpolation)\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization (after interpolation to avoid issues)\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    print(f\"Target sites to highlight: {list(sites_to_show)}\")\n",
    "\n",
    "    # Check the data type of Spike_AS_Position and sites_to_show for comparison\n",
    "    print(f\"Data type of 'Spike_AS_Position': {df_filtered_agg['Spike_AS_Position'].dtype}\")\n",
    "    print(f\"Data type of 'sites_to_show': {type(sites_to_show)}\")\n",
    "\n",
    "    # Ensure High_Enrichment is still boolean\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "    # Use dmslogo.line.draw_line but plot on the same axes with specified color\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Smoothed_Enrichment\",\n",
    "        title=\"\",  # Remove individual titles for each plot\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding\",\n",
    "        show_col=\"show_site\",  # Highlight high enrichment clusters\n",
    "        ax=ax,  # Pass the same axes object for all plots\n",
    "        linewidth=2.5,\n",
    "        color=color_map.get(immunization, 'black')  # Get the color for the immunization (default to black)\n",
    "    )\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        # Use ax.hlines to draw horizontal lines only where there are sites to show\n",
    "        ax.hlines(\n",
    "            y=0,  # Set the y-position of the line to 0 (or a small value near the bottom of the plot)\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,  # Start of the line (slightly before the site)\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,  # End of the line (slightly after the site)\n",
    "            color='black',  # Line color\n",
    "            linestyle='-',  # Line style\n",
    "            linewidth=10  # Line width\n",
    "        )\n",
    "\n",
    "# Set the y-axis limit to 200\n",
    "ax.set_ylim(0, 9)\n",
    "\n",
    "# After all lines are drawn, adjust plot settings\n",
    "plt.title('Smoothed Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Single-cell Polyreactivity)', fontsize=16)\n",
    "\n",
    "# Add the legend in the top right\n",
    "# Create a grouped legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# Group the legend as required\n",
    "group_1_labels = ['Polyclonal_Ab', 'Neutralizing_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels]\n",
    "\n",
    "# Combine handles and labels with a custom order\n",
    "handles = group_1_handles + group_2_handles\n",
    "labels = group_1_labels + group_2_labels\n",
    "\n",
    "# Add the legend to the top right\n",
    "plt.legend(handles, labels, title=\"Single Droplet Repertoire\", loc='upper right', fontsize=11, frameon=False, handlelength=2, handleheight=1, title_fontsize=11, markerscale=8)\n",
    "\n",
    "# Set the x-axis ticks explicitly to 20 ticks across the range, and label every other one\n",
    "xticks = np.linspace(df_filtered_agg['Spike_AS_Position'].min(), df_filtered_agg['Spike_AS_Position'].max(), 20).astype(int)\n",
    "ax.set_xticks(xticks)\n",
    "\n",
    "# Set the labels to only show for every other tick\n",
    "ax.set_xticklabels([str(x) if i % 2 == 0 else '' for i, x in enumerate(xticks)])\n",
    "\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True, prune='lower', nbins=8))\n",
    "plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop\", f\"{immunization}_Line2_plot.png\")\n",
    "fig.tight_layout() \n",
    "fig.savefig(plot_file_path, format='png')\n",
    "\n",
    "\n",
    "# Display the combined plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 20  # Adjust this window size to refine the smoothing\n",
    "ENRICHMENT_THRESHOLD = 0.8  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "\n",
    "sites_to_show = list(sites_to_show)\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create a single figure\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Define color mapping\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'darkblue',\n",
    "    'Mutant_RBD': '#004c4c'\n",
    "}\n",
    "\n",
    "# Loop through each immunization and plot on the same axes, excluding 'Library_ctrl'\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    if immunization == 'Library_ctrl':  # Skip 'Library_ctrl'\n",
    "        continue\n",
    "\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "    if df_filtered_im['Enrichment_Ratio'].isna().any():\n",
    "        df_filtered_im['Enrichment_Ratio'] = df_filtered_im['Enrichment_Ratio'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Interpolate missing values\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Log2 transformation after smoothing\n",
    "    df_filtered_im['Log2_Enrichment'] = np.log2(df_filtered_im['Smoothed_Enrichment'].replace(0, np.nan))\n",
    "    df_filtered_im['Log2_Enrichment'] = df_filtered_im['Log2_Enrichment'].fillna(0)\n",
    "\n",
    "    # Identify high enrichment sites (based on raw smoothed enrichment)\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    if immunization == 'Neutralizing_Ab':\n",
    "        df_filtered_im['Log2_Enrichment'] = df_filtered_im['Log2_Enrichment'].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    df_filtered_im = df_filtered_im.assign(\n",
    "        show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    "    )\n",
    "\n",
    "    print(df_filtered_im[['Spike_AS_Position', 'show_site']].head(10))\n",
    "\n",
    "    # Plot log2 enrichment\n",
    "    dmslogo.line.draw_line(\n",
    "        df_filtered_im,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Log2_Enrichment\",\n",
    "        title=\"\",\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Antibody Repertoire \\n binding (log₂ Enrichment)\",\n",
    "        show_col=\"show_site\",\n",
    "        ax=ax,\n",
    "        linewidth=2.5,\n",
    "        color=color_map.get(immunization, 'black')\n",
    "    )\n",
    "    ax.plot([], [], color=color_map.get(immunization, 'black'), label=immunization)\n",
    "\n",
    "    # Highlight sites\n",
    "    highlight_sites = df_filtered_im[df_filtered_im['show_site']]\n",
    "    for _, site_data in highlight_sites.iterrows():\n",
    "        ax.hlines(\n",
    "            y=0,\n",
    "            xmin=site_data['Spike_AS_Position'] - 0.5,\n",
    "            xmax=site_data['Spike_AS_Position'] + 0.5,\n",
    "            color='black',\n",
    "            linestyle='-',\n",
    "            linewidth=10\n",
    "        )\n",
    "\n",
    "# Set y-axis limit based on log2-transformed data\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.set_ylim(2.5, 11)\n",
    "\n",
    "# Final plot settings\n",
    "plt.title('Smoothed Log₂ Enrichment Ratios for Different Immunizations', fontsize=14)\n",
    "plt.xlabel('Spike AA Position', fontsize=16)\n",
    "plt.ylabel('Antibody Repertoire - log₂ Enrichment', fontsize=16)\n",
    "\n",
    "# Legend\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "group_1_labels = ['Polyclonal_Ab', 'Neutralizing_Ab']\n",
    "group_2_labels = ['wildtype_RBD', 'Mutant_RBD']\n",
    "\n",
    "group_1_handles = [handles[labels.index(label)] for label in group_1_labels if label in labels]\n",
    "group_2_handles = [handles[labels.index(label)] for label in group_2_labels if label in labels]\n",
    "\n",
    "handles = group_1_handles + group_2_handles\n",
    "labels = group_1_labels + group_2_labels\n",
    "\n",
    "plt.legend(handles, labels, title=\"Single Droplet Repertoire\", loc='upper center', fontsize=11, frameon=False, handlelength=2, handleheight=1, title_fontsize=11, markerscale=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 20\n",
    "ENRICHMENT_THRESHOLD = 0.8\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  \n",
    "    list(range(394,414)) +  \n",
    "    list(range(484, 505))  \n",
    ")\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Color mapping based on immunization name\n",
    "color_map = {\n",
    "    'Polyclonal_Ab': '#d2691e',       # dark orange / terracotta\n",
    "    'Neutralizing_Ab': '#ff0000',     # red\n",
    "    'wildtype_RBD': '#0000ff',        # blue\n",
    "    'mutant': '#00ced1',              # dark turquoise\n",
    "}\n",
    "\n",
    "# Prepare figure\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for immunization in df_filtered_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    df_filtered_im = df_filtered_agg.query('immunization == @immunization')\n",
    "\n",
    "    # Aggregate enrichment ratios at each position\n",
    "    df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio': 'sum',\n",
    "    })\n",
    "\n",
    "    # Apply rolling mean for smoothing\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "    # Handle missing data\n",
    "    df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Identify clusters of high enrichment\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['Smoothed_Enrichment'] > ENRICHMENT_THRESHOLD\n",
    "    df_filtered_im['High_Enrichment'] = df_filtered_im['High_Enrichment'].fillna(False).astype(bool)\n",
    "\n",
    "    # Save CSV\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_data.csv\")\n",
    "    df_filtered_im.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Reindex for visualization\n",
    "    df_filtered_im = df_filtered_im.set_index('Spike_AS_Position').reindex(\n",
    "        range(df_filtered_im['Spike_AS_Position'].min(), df_filtered_im['Spike_AS_Position'].max() + 1)\n",
    "    ).reset_index()\n",
    "\n",
    "    # Plot line on same axis\n",
    "    label = immunization.replace(\"_\", \" \")\n",
    "    color = color_map.get(immunization, \"gray\")\n",
    "    ax.plot(df_filtered_im['Spike_AS_Position'], df_filtered_im['Smoothed_Enrichment'], label=label, color=color)\n",
    "\n",
    "# Final formatting\n",
    "ax.set_xlim(420, df_filtered_im['Spike_AS_Position'].max())\n",
    "ax.set_ylim(0, df_filtered_agg['Enrichment_Ratio'].max())\n",
    "ax.set_xlabel(\"Spike AA Position\")\n",
    "ax.set_ylabel(\"Antibody Repertoire \\n binding\")\n",
    "ax.set_title(\"Smoothed Enrichment Across Spike Positions by Immunization\")\n",
    "ax.legend(title=\"Immunization\", fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_filtered_agg.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code block for generating logoplots of enriched positions\n",
    "Color codes are assigned to each barcode, and the colors are shown in a separate plot.\n",
    "This can be used to show how each barcode/single cell is contributing to the grouped enrichments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# Enable inline plotting in Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# Define rolling window size for smoothing\n",
    "ROLLING_WINDOW = 8  # Adjust for more smoothing\n",
    "ENRICHMENT_THRESHOLD = 50  # Adjust based on data distribution\n",
    "\n",
    "# Filter dataset to remove low-quality reads and select only non-synonymous mutations\n",
    "df_filtered = df_total[(df_total['Spike_AS_Position'] > 33+331) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Aggregate enrichment ratio by position and barcode\n",
    "df_filtered_agg = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Define target sites\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394,414)) +  # R21 peptide sequence\n",
    "    list(range(484, 505))  # R13 peptide sequence\n",
    ")\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"barcode_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over each barcode\n",
    "for barcode in df_filtered_agg['barcode'].unique():\n",
    "    print(f\"Processing barcode: {barcode}\")\n",
    "    df_filtered_bc = df_filtered_agg[df_filtered_agg['barcode'] == barcode]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    \n",
    "    for immunization in df_filtered_bc['immunization'].unique():\n",
    "        df_filtered_im = df_filtered_bc[df_filtered_bc['immunization'] == immunization]\n",
    "\n",
    "        # Aggregate enrichment ratios at each position\n",
    "        df_filtered_im = df_filtered_im.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "            'Enrichment_Ratio': 'sum',\n",
    "        })\n",
    "\n",
    "        # Apply rolling mean for smoothing\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Enrichment_Ratio'].rolling(window=ROLLING_WINDOW, center=True, min_periods=1).mean()\n",
    "\n",
    "        # Handle missing data by interpolating missing values\n",
    "        df_filtered_im['Smoothed_Enrichment'] = df_filtered_im['Smoothed_Enrichment'].interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "        # Plot each immunization as a separate line\n",
    "        ax.plot(df_filtered_im['Spike_AS_Position'], df_filtered_im['Smoothed_Enrichment'], label=f'Immunization {immunization}', alpha=0.7)\n",
    "\n",
    "    # Formatting plot\n",
    "    ax.set_title(f\"Barcode {barcode}\")\n",
    "    ax.set_xlabel(\"Spike AA Position\")\n",
    "    ax.set_ylabel(\"Antibody Repertoire \\n Binding\")\n",
    "\n",
    "    ax.xaxis.set_minor_locator(MultipleLocator(5))\n",
    "    ax.set_xlim(350, df_filtered_bc['Spike_AS_Position'].max())\n",
    "\n",
    "    # Adjust legend to be outside the plot\n",
    "    ax.legend(bbox_to_anchor=(1.05, 0.5), loc='center left', borderaxespad=0.)\n",
    "\n",
    "    # Save plot\n",
    "    plot_file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\", f\"Barcode_{barcode}_plot.png\")\n",
    "    fig.savefig(plot_file_path, format='png', bbox_inches='tight')\n",
    "    \n",
    "    # Show the plot inline in Jupyter\n",
    "    plt.show()\n",
    "\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "#Code block for generating logoplots of enriched positions\n",
    "#Change immunization to barcode to do individual droplet analysis\n",
    "\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode','immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [417,484,501]\n",
    "    #[(i+336) for i in range(107, 114) if i not in [33, 72, 81, 151]] +  \n",
    "    #[455, 456, 472, 473, 484, 485, 486, 490, 496, 499] + # RBD-ACE2 interface according to article\n",
    "    #list(range(394,414)) + # R21 peptide sequence with high affinity\n",
    "    #list(range(484, 506)) # R13 peptide sequence with high affinity\n",
    ")\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[~df_logo_agg['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "\n",
    "#The query can be changed to filter for specific barcodes or removed to get all barcodes\n",
    "#.query('immunization == \"wildtype_RBD\"')\n",
    "for barcode in df_logo_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_logo_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\"),\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Enrichment_Ratio\",\n",
    "        title=barcode + ' logoplot',\n",
    "        addbreaks=True\n",
    "    )\n",
    "    \n",
    "    ax.set_ylabel(\"Antigen Binding\")  # Set the y-axis label to Binding Ratio\n",
    "    ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  # Se\n",
    "    # Save the figure\n",
    "    file_path = os.path.join(r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\", f\"{barcode}_logoplots.png\", )\n",
    "    plt.savefig(file_path, dpi = 300, bbox_inches = 'tight')\n",
    "    #plt.close(fig)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Aggregate data\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "# Filter for Enrichment_Ratio > 1\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Define sites to show\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "# Add site labels and determine which sites to show\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Ensure amino acids are uppercase and exclude specific characters\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[~df_logo_agg['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "# Generate logo plots for each unique barcode\n",
    "for barcode in df_logo_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_logo_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\"),\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Enrichment_Ratio\",\n",
    "        title=barcode + ' logoplot',\n",
    "        addbreaks=True\n",
    "    )\n",
    "    \n",
    "    ax.set_ylabel(\"Antigen Binding\")  # Set the y-axis label to Binding Ratio\n",
    "    ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  # Set the x-axis label\n",
    "    # Save the figure\n",
    "    file_path = os.path.join(\n",
    "        r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\",\n",
    "        f\"{barcode}_logoplots.png\"\n",
    "    )\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Aggregate data\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "# Filter for Enrichment_Ratio > 1\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Define sites to show\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "# Add site labels and determine which sites to show\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Ensure amino acids are uppercase and exclude specific characters\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[~df_logo_agg['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "# Generate logo plots for each unique barcode and immunization\n",
    "for barcode in df_logo_agg['barcode'].unique():\n",
    "    print(f\"Processing barcode: {barcode}\")\n",
    "    \n",
    "    # Get the immunization for the current barcode (assuming it's consistent for the barcode)\n",
    "    immunization = df_logo_agg.query(f'barcode == \"{barcode}\"')['immunization'].iloc[0]\n",
    "    \n",
    "    # Create the plot for the specific barcode and immunization\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_logo_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\"),\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Enrichment_Ratio\",\n",
    "        title=f'{barcode} Logoplot - Immunization: {immunization}',  # Add immunization to title\n",
    "        addbreaks=True\n",
    "    )\n",
    "    \n",
    "    # Set axis labels\n",
    "    ax.set_ylabel(\"Antigen Binding\")  # Set the y-axis label to Binding Ratio\n",
    "    ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  # Set the x-axis label\n",
    "    \n",
    "    # Save the figure\n",
    "    file_path = os.path.join(\n",
    "        r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\",\n",
    "        f\"{barcode}_logoplots.png\"\n",
    "    )\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved logoplot for {barcode} to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Filter out rows where Enrichment_Ratio is zero and Enrichment_Ratio < 1\n",
    "df_escape = df_total[(df_total['Enrichment_Ratio'] < 1) & (df_total['Enrichment_Ratio'] != 0)]\n",
    "\n",
    "# Apply the inverse to the Enrichment_Ratio\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "# Apply log2 transformation\n",
    "df_escape['Enrichment_Ratio_log2'] = df_escape['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "# Aggregate the data by position, amino acid, barcode, and immunization\n",
    "df_escape_agg = df_escape.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio_log2': 'mean'})  # Add Enrichment_Ratio_log2 here\n",
    "\n",
    "# Define the sites to show\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])  # RBD-ACE2 interface according to article\n",
    "\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Add the following before the \"barcode.unique\" to select various conditions\n",
    "# .query('immunization == \"Mutant_RBD\"')\n",
    "\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True,\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(\"Antibody Escape\")  # Set the y-axis label\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  \n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/immunization_escape\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Filter out rows where Enrichment_Ratio is zero and Enrichment_Ratio < 1\n",
    "df_escape = df_total[(df_total['Enrichment_Ratio'] < 1) & (df_total['Enrichment_Ratio'] != 0)]\n",
    "\n",
    "# Apply the inverse to the Enrichment_Ratio\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "# Apply log2 transformation\n",
    "df_escape['Enrichment_Ratio_log2'] = df_escape['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "# Aggregate the data by position, amino acid, barcode, and immunization\n",
    "df_escape_agg = df_escape.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio_log2': 'sum'})  # Add Enrichment_Ratio_log2 here\n",
    "\n",
    "# Define the sites to show\n",
    "sites_to_show = map(str, [417, 484,  501])  # RBD-ACE2 interface according to article\n",
    "\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Add the following before the \"barcode.unique\" to select various conditions\n",
    "# .query('immunization == \"Mutant_RBD\"')\n",
    "\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True,\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(\"Antibody Escape\")  # Set the y-axis label\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  \n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/immunization_escape\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight', pad_inches=0.8)   # Save with tight bounding box\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wuhan_strain_aa = {\n",
    "    417: 'K', 439: 'N', 440: 'N', 452: 'L', 476: 'G', 477: 'S', 484: 'E',\n",
    "    493: 'Q', 501: 'N', 502: 'G', 505: 'L'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Define the dictionary for the specific amino acids at certain positions\n",
    "wuhan_strain_aa = {\n",
    "    417: 'K', 439: 'N', 440: 'N', 452: 'L', 476: 'G', 477: 'S', 484: 'E',\n",
    "    493: 'Q', 501: 'N', 502: 'G', 505: 'L'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Filter for Enrichment_Ratio > 1\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "\n",
    "# Aggregate data\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "\n",
    "# Define sites to show (as strings for consistency)\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "# Add site labels and determine which sites to show\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Ensure amino acids are uppercase and exclude specific characters\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[~df_logo_agg['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "# Debugging: Check the filtered positions and amino acids\n",
    "print(\"Filtered data with relevant sites and amino acids:\")\n",
    "print(df_logo_agg[['Spike_AS_Position', 'Amino_Acid']].drop_duplicates())\n",
    "\n",
    "# Generate logo plots for each unique barcode\n",
    "for barcode in df_logo_agg['barcode'].unique():\n",
    "    print(f\"Generating plot for barcode: {barcode}\")\n",
    "    filtered_data = df_logo_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "\n",
    "    # Debugging: Check positions for the current barcode\n",
    "    print(f\"Positions and amino acids for {barcode}:\")\n",
    "    print(filtered_data[['Spike_AS_Position', 'Amino_Acid']])\n",
    "\n",
    "    # Check if there is any data to plot\n",
    "    if not filtered_data.empty:\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            filtered_data,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True\n",
    "        )\n",
    "\n",
    "        ax.set_ylabel(\"Antigen Binding\")  # Set the y-axis label to Binding Ratio\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  # Set the x-axis label\n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files2\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memorya\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        print(f\"No data to plot for barcode: {barcode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ensure all positions are included in every barcode\n",
    "all_positions = pd.DataFrame({'Spike_AS_Position': list(map(str, wuhan_strain_aa.keys()))})\n",
    "\n",
    "for barcode in df_logo_agg['barcode'].unique():\n",
    "    print(f\"Generating plot for barcode: {barcode}\")\n",
    "    filtered_data = df_logo_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "\n",
    "    # Ensure all positions exist in the dataset, even if empty\n",
    "    filtered_data = all_positions.merge(filtered_data, on=\"Spike_AS_Position\", how=\"left\")\n",
    "\n",
    "    # Fill missing values for plotting\n",
    "    filtered_data['Amino_Acid'].fillna(\"\", inplace=True)  # Empty amino acid for missing positions\n",
    "    filtered_data['Enrichment_Ratio'].fillna(0, inplace=True)  # Set enrichment to 0\n",
    "\n",
    "    # Debugging: Check positions for the current barcode\n",
    "    print(f\"Positions and amino acids for {barcode}:\")\n",
    "    print(filtered_data[['Spike_AS_Position', 'Amino_Acid', 'Enrichment_Ratio']])\n",
    "\n",
    "    # Check if there is any data to plot (there should be at least empty positions)\n",
    "    if not filtered_data.empty:\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            filtered_data,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True\n",
    "        )\n",
    "\n",
    "        ax.set_ylabel(\"Antigen Binding\")  # Set the y-axis label to Binding Ratio\n",
    "        ax.set_xlabel(\"SARS-CoV-2 Spike AA Position\")  # Set the x-axis label\n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        print(f\"No data to plot for barcode: {barcode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Define the dictionary for the specific amino acids at certain positions\n",
    "wuhan_strain_aa = {\n",
    "    417: 'K', 439: 'N', 440: 'N', 452: 'L', 476: 'G', 477: 'S', 484: 'E',\n",
    "    493: 'Q', 501: 'N', 502: 'G', 505: 'L'\n",
    "}\n",
    "\n",
    "# Aggregate data\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio': 'mean'})\n",
    "\n",
    "# Filter for Enrichment_Ratio > 1\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Define sites to show (as strings for consistency)\n",
    "sites_to_show = map(str, [417, 484, 501])\n",
    "\n",
    "# Add site labels and determine which sites to show\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Ensure amino acids are uppercase and exclude specific characters\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[~df_logo_agg['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "# Debugging: Check the filtered positions and amino acids\n",
    "print(\"Filtered data with relevant sites and amino acids:\")\n",
    "print(df_logo_agg[['Spike_AS_Position', 'Amino_Acid']].drop_duplicates())\n",
    "\n",
    "# Generate logo plots for each unique barcode\n",
    "for barcode in df_logo_agg['barcode'].unique():\n",
    "    print(f\"Generating plot for barcode: {barcode}\")\n",
    "    filtered_data = df_logo_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "\n",
    "    # Debugging: Check positions for the current barcode\n",
    "    print(f\"Positions and amino acids for {barcode}:\")\n",
    "    print(filtered_data[['Spike_AS_Position', 'Amino_Acid']])\n",
    "\n",
    "    # Check if there is any data to plot\n",
    "    if not filtered_data.empty:\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            filtered_data,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True\n",
    "        )\n",
    "\n",
    "        ax.set_ylabel(\"Antigen Binding\")  # Set the y-axis label to Binding Ratio\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  # Set the x-axis label\n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memorya\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        print(f\"No data to plot for barcode: {barcode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Define the dictionary for the specific amino acids at certain positions\n",
    "wuhan_strain_aa = {\n",
    "    417: 'K', 439: 'N', 440: 'N', 452: 'L', 476: 'G', 477: 'S', 484: 'E',\n",
    "    493: 'Q', 501: 'N', 502: 'G', 505: 'L'\n",
    "}\n",
    "\n",
    "# Filter out rows where Enrichment_Ratio is zero and Enrichment_Ratio < 1\n",
    "df_escape = df_total[(df_total['Enrichment_Ratio'] < 1) & (df_total['Enrichment_Ratio'] != 0)]\n",
    "\n",
    "# Apply the inverse to the Enrichment_Ratio\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "# Aggregate the data by position, amino acid, barcode, and immunization\n",
    "df_escape_agg = df_escape.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio_inverted': 'sum'})\n",
    "\n",
    "# Apply log2 transformation\n",
    "df_escape_agg['Enrichment_Ratio_log2'] = df_escape_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "# Filter out rows where the amino acid is in wuhan_strain_aa at the corresponding positions\n",
    "df_escape_agg = df_escape_agg[~df_escape_agg.apply(\n",
    "    lambda row: row['Spike_AS_Position'] in wuhan_strain_aa and row['Amino_Acid'] == wuhan_strain_aa[row['Spike_AS_Position']],\n",
    "    axis=1\n",
    ")]\n",
    "\n",
    "# Define the sites to show (RBD-ACE2 interface)\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Loop through each barcode to generate the plots\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True,\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(\"Antibody Escape\")  # Set the y-axis label\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  \n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/immunization_escape\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Asess if some are esacped and enrichedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Define the dictionary for the specific amino acids at certain positions\n",
    "wuhan_strain_aa = {\n",
    "    417: 'K', 439: 'N', 440: 'N', 452: 'L', 476: 'G', 477: 'S', 484: 'E',\n",
    "    493: 'Q', 501: 'N', 502: 'G', 505: 'L'\n",
    "}\n",
    "\n",
    "# Filter out rows where Enrichment_Ratio is zero and Enrichment_Ratio < 1\n",
    "df_escape = df_total[(df_total['Enrichment_Ratio'] < 1) & (df_total['Enrichment_Ratio'] != 0)]\n",
    "\n",
    "# Apply the inverse to the Enrichment_Ratio\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "# Aggregate the data by position, amino acid, barcode, and immunization\n",
    "df_escape_agg = df_escape.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio_inverted': 'sum'})\n",
    "\n",
    "# Apply log2 transformation\n",
    "df_escape_agg['Enrichment_Ratio_log2'] = df_escape_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "# Filter out rows where the amino acid is in wuhan_strain_aa at the corresponding positions\n",
    "df_escape_agg = df_escape_agg[~df_escape_agg.apply(\n",
    "    lambda row: row['Spike_AS_Position'] in wuhan_strain_aa and row['Amino_Acid'] == wuhan_strain_aa[row['Spike_AS_Position']],\n",
    "    axis=1\n",
    ")]\n",
    "\n",
    "# Define the sites to show (RBD-ACE2 interface)\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Loop through each barcode to generate the plots\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(f\"Processing barcode: {barcode}\")\n",
    "    \n",
    "    # Get the immunization for the current barcode\n",
    "    immunization = df_escape_agg.query(f'barcode == \"{barcode}\"')['immunization'].iloc[0]\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=f'{barcode} Logoplot - Immunization: {immunization}',  # Add immunization to title\n",
    "            addbreaks=True,\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(\"Antibody Escape\")  # Set the y-axis label\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  \n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/ETH/immunization_escape\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n",
    "        print(f\"Saved logoplot for {barcode} - Immunization: {immunization} to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to identify and print the conflicting cases (where both Enrichment_Ratio > 1 and < 1 for the same barcode, position, and amino acid)\n",
    "def find_conflicting_cases(df):\n",
    "    # Group by barcode, position, and amino acid\n",
    "    grouped = df.groupby(['barcode', 'Spike_AS_Position', 'Amino_Acid'])\n",
    "    \n",
    "    # List to store conflicting cases\n",
    "    conflicting_cases = []\n",
    "    \n",
    "    # Loop through each group to identify conflicts\n",
    "    for (barcode, position, aa), group in grouped:\n",
    "        if (group['Enrichment_Ratio'] > 1).any() and (group['Enrichment_Ratio'] < 1).any():\n",
    "            conflicting_cases.append((barcode, position, aa, group))\n",
    "    \n",
    "    return conflicting_cases\n",
    "\n",
    "# Find and print the conflicting cases\n",
    "conflicting_cases = find_conflicting_cases(df_escape)\n",
    "\n",
    "# Print the conflicting cases for inspection\n",
    "for barcode, position, aa, group in conflicting_cases:\n",
    "    print(f\"Conflicting cases for barcode {barcode}, position {position}, amino acid {aa}:\")\n",
    "    print(group[['barcode', 'Spike_AS_Position', 'Amino_Acid', 'Enrichment_Ratio']])\n",
    "    print(\"\\n---\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Define the dictionary for the specific amino acids at certain positions\n",
    "wuhan_strain_aa = {\n",
    "    417: 'K', 439: 'N', 440: 'N', 452: 'L', 476: 'G', 477: 'S', 484: 'E',\n",
    "    493: 'Q', 501: 'N', 502: 'G', 505: 'L'\n",
    "}\n",
    "\n",
    "# Filter out rows where Enrichment_Ratio is zero and Enrichment_Ratio < 1\n",
    "df_escape = df_total[(df_total['Enrichment_Ratio'] < 1) & (df_total['Enrichment_Ratio'] != 0)]\n",
    "\n",
    "# Step 1: Identify positions with the same amino acid where both Enrichment_Ratio > 1 and < 1 exist per barcode.\n",
    "def filter_positions_per_barcode(df):\n",
    "    # Group by barcode, position, and amino acid\n",
    "    grouped = df.groupby(['barcode', 'Spike_AS_Position', 'Amino_Acid'])\n",
    "    \n",
    "    # Identify positions where there are both Enrichment_Ratio > 1 and < 1 for the same barcode\n",
    "    positions_to_filter = grouped.filter(\n",
    "        lambda x: any(x['Enrichment_Ratio'] < 1) and any(x['Enrichment_Ratio'] > 1)\n",
    "    )['Spike_AS_Position'].unique()\n",
    "    \n",
    "    return positions_to_filter\n",
    "\n",
    "# Step 2: For each barcode, filter out rows with conflicting enrichment ratios at the same position and amino acid\n",
    "positions_to_filter = filter_positions_per_barcode(df_escape)\n",
    "df_filtered = df_escape[~df_escape['Spike_AS_Position'].isin(positions_to_filter)]\n",
    "\n",
    "# Apply the inverse to the Enrichment_Ratio\n",
    "df_filtered['Enrichment_Ratio_inverted'] = df_filtered['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "# Aggregate the data by position, amino acid, barcode, and immunization\n",
    "df_filtered_agg = df_filtered.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio_inverted': 'mean'})\n",
    "\n",
    "# Apply log2 transformation\n",
    "df_filtered_agg['Enrichment_Ratio_log2'] = df_filtered_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "# Filter out rows where the amino acid is in wuhan_strain_aa at the corresponding positions\n",
    "df_filtered_agg = df_filtered_agg[~df_filtered_agg.apply(\n",
    "    lambda row: row['Spike_AS_Position'] in wuhan_strain_aa and row['Amino_Acid'] == wuhan_strain_aa[row['Spike_AS_Position']],\n",
    "    axis=1\n",
    ")]\n",
    "\n",
    "# Define the sites to show (RBD-ACE2 interface)\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "df_filtered_agg = df_filtered_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Loop through each barcode to generate the plots\n",
    "for barcode in df_filtered_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered_barcode = df_filtered_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered_barcode.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered_barcode = df_filtered_barcode[~df_filtered_barcode['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered_barcode,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True,\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(\"Antibody Escape\")  # Set the y-axis label\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  \n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/immunization_escape\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#volcano plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for enriched and escaped data\n",
    "df_enriched = df_total[df_total['Enrichment_Ratio'] > 1]\n",
    "df_escaped = df_total[df_total['Enrichment_Ratio'] < 1]\n",
    "\n",
    "# Group by position and barcode (or any other relevant grouping)\n",
    "df_enriched_grouped = df_enriched.groupby(['Spike_AS_Position', 'barcode'], as_index=False).agg({'Enrichment_Ratio': 'sum'})\n",
    "df_escaped_grouped = df_escaped.groupby(['Spike_AS_Position', 'barcode'], as_index=False).agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "# Identify positions that appear in both enriched and escaped subsets\n",
    "# We can find common positions between the two grouped datasets\n",
    "common_positions = set(df_enriched_grouped['Spike_AS_Position']).intersection(df_escaped_grouped['Spike_AS_Position'])\n",
    "\n",
    "# Filter the data to include only rows where the position is in both enriched and escaped\n",
    "df_enriched_escaped = df_total[df_total['Spike_AS_Position'].isin(common_positions)]\n",
    "\n",
    "# Now, you can inspect the data where positions are both enriched and escaped\n",
    "# You may want to further investigate by grouping by position and barcode\n",
    "df_enriched_escaped_grouped = df_enriched_escaped.groupby(\n",
    "    ['Spike_AS_Position', 'barcode'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "# Show results\n",
    "print(df_enriched_escaped_grouped)\n",
    "\n",
    "# Plot or analyze further, depending on your goal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a dataframe named df_combined with at least these columns:\n",
    "# 'Spike_AS_Position', 'Amino_Acid', 'Sample_Count', 'Max_Enrichment'\n",
    "\n",
    "# Also assuming you have the ancestral (Wuhan strain) amino acid reference:\n",
    "wuhan_strain_aa = {\n",
    "    484: 'E', 417: 'K', 501: 'N', 346: 'R', 452: 'L',\n",
    "    # Add other positions as needed\n",
    "}\n",
    "\n",
    "# Create E484K-style mutation labels\n",
    "df_combined['mutation_label'] = df_combined.apply(\n",
    "    lambda row: f\"{wuhan_strain_aa.get(row['Spike_AS_Position'], '?')}\"\n",
    "                f\"{row['Spike_AS_Position']}\"\n",
    "                f\"{row['Amino_Acid']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Define a threshold for labeling (you can change this!)\n",
    "label_threshold_enrichment = 10\n",
    "label_threshold_count = 5\n",
    "\n",
    "# Mark which rows to label\n",
    "df_combined['label_this'] = (\n",
    "    (df_combined['Max_Enrichment'] > label_threshold_enrichment) &\n",
    "    (df_combined['Sample_Count'] > label_threshold_count)\n",
    ")\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot\n",
    "sc = ax.scatter(\n",
    "    df_combined['Max_Enrichment'],\n",
    "    df_combined['Sample_Count'],\n",
    "    c='grey',\n",
    "    alpha=0.7,\n",
    "    edgecolors='k',\n",
    "    s=40\n",
    ")\n",
    "\n",
    "# Highlight points to be labeled\n",
    "highlighted = df_combined[df_combined['label_this']]\n",
    "ax.scatter(\n",
    "    highlighted['Max_Enrichment'],\n",
    "    highlighted['Sample_Count'],\n",
    "    c='red',\n",
    "    edgecolors='black',\n",
    "    s=60,\n",
    "    label='Labeled mutations'\n",
    ")\n",
    "\n",
    "# Add text labels for selected mutations\n",
    "for _, row in highlighted.iterrows():\n",
    "    ax.text(\n",
    "        row['Max_Enrichment'],\n",
    "        row['Sample_Count'],\n",
    "        row['mutation_label'],\n",
    "        fontsize=9,\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "# Formatting\n",
    "ax.set_xlabel('Enrichment Score', fontsize=12)\n",
    "ax.set_ylabel('Sample Count', fontsize=12)\n",
    "ax.set_title('Volcano Plot of Spike Mutations', fontsize=14)\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Combine enriched and escaped data\n",
    "df_combined_volcano = pd.concat([\n",
    "    df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1],\n",
    "    df_escape.assign(Enrichment_Ratio=df_escape['Enrichment_Ratio'])\n",
    "])\n",
    "\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Enrichment_Ratio'] > 0]\n",
    "df_combined_volcano['log2_Enrichment'] = np.log2(df_combined_volcano['Enrichment_Ratio'])\n",
    "\n",
    "# Count appearances across barcodes\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Get mean log2 enrichment\n",
    "df_max_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .mean()\n",
    "    .reset_index(name='log2_Enrichment')\n",
    ")\n",
    "\n",
    "# Merge\n",
    "df_volcano = pd.merge(df_counts, df_max_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['mutation'] = df_volcano['Spike_AS_Position'].astype(str)\n",
    "df_volcano['mutation_label'] = df_volcano['mutation'].str.zfill(3)\n",
    "df_volcano['site_label'] = df_volcano['Amino_Acid'] + df_volcano['mutation_label']\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "top_enriched = df_filtered[df_filtered['log2_Enrichment'] > 0].nlargest(top_n, ['Sample_Count', 'log2_Enrichment'])\n",
    "top_escape = df_filtered[df_filtered['log2_Enrichment'] < 0].nsmallest(top_n, ['Sample_Count', 'log2_Enrichment'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.scatterplot(\n",
    "    data=df_volcano,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    alpha=0.8,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Annotate top points\n",
    "texts = []\n",
    "for _, row in pd.concat([top_enriched, top_escape]).iterrows():\n",
    "    offset_x = 1 if row['log2_Enrichment'] > 0 else -1\n",
    "    offset_y = 2\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            row['Sample_Count'] + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=10,\n",
    "            weight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "    # Draw line to the actual point\n",
    "    plt.plot(\n",
    "        [row['log2_Enrichment'], row['log2_Enrichment'] + offset_x],\n",
    "        [row['Sample_Count'], row['Sample_Count'] + offset_y],\n",
    "        linestyle='--',\n",
    "        color='gray',\n",
    "        linewidth=0.8\n",
    "    )\n",
    "\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['mutation'] = df_volcano['Spike_AS_Position'].astype(str)\n",
    "df_volcano['mutation_label'] = df_volcano['mutation'].str.zfill(3)\n",
    "df_volcano['site_label'] = df_volcano['Amino_Acid'] + df_volcano['mutation_label']\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "top_enriched = df_filtered[df_filtered['log2_Enrichment'] > 0].nlargest(top_n, ['Sample_Count', 'log2_Enrichment'])\n",
    "top_escape = df_filtered[df_filtered['log2_Enrichment'] < 0].nsmallest(top_n, ['Sample_Count', 'log2_Enrichment'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.scatterplot(\n",
    "    data=df_volcano,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    alpha=0.8,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Annotate top points\n",
    "texts = []\n",
    "for _, row in pd.concat([top_enriched, top_escape]).iterrows():\n",
    "    offset_x = 1 if row['log2_Enrichment'] > 0 else -1\n",
    "    offset_y = 2\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            row['Sample_Count'] + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=10,\n",
    "            weight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "    # Draw line to the actual point\n",
    "    plt.plot(\n",
    "        [row['log2_Enrichment'], row['log2_Enrichment'] + offset_x],\n",
    "        [row['Sample_Count'], row['Sample_Count'] + offset_y],\n",
    "        linestyle='--',\n",
    "        color='gray',\n",
    "        linewidth=0.8\n",
    "    )\n",
    "\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Combine enriched and escaped data\n",
    "df_combined_volcano = pd.concat([\n",
    "    df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1],\n",
    "    df_escape.assign(Enrichment_Ratio=df_escape['Enrichment_Ratio'])\n",
    "])\n",
    "\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Enrichment_Ratio'] > 0]\n",
    "df_combined_volcano['log2_Enrichment'] = np.log2(df_combined_volcano['Enrichment_Ratio'])\n",
    "\n",
    "# Retain all columns from the original data frame\n",
    "original_columns = df_combined_volcano.columns.tolist()\n",
    "\n",
    "# Count appearances across barcodes\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Get mean log2 enrichment\n",
    "df_max_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .mean()\n",
    "    .reset_index(name='log2_Enrichment')\n",
    ")\n",
    "\n",
    "# Merge counts and enrichment data\n",
    "df_volcano = pd.merge(df_counts, df_max_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['mutation'] = df_volcano['Spike_AS_Position'].astype(str)\n",
    "df_volcano['mutation_label'] = df_volcano['mutation'].str.zfill(3)\n",
    "df_volcano['site_label'] = df_volcano['Amino_Acid'] + df_volcano['mutation_label']\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "top_enriched = df_filtered[df_filtered['log2_Enrichment'] > 0].nlargest(top_n, ['Sample_Count', 'log2_Enrichment'])\n",
    "top_escape = df_filtered[df_filtered['log2_Enrichment'] < 0].nsmallest(top_n, ['Sample_Count', 'log2_Enrichment'])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.scatterplot(\n",
    "    data=df_volcano,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    alpha=0.8,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Annotate top points\n",
    "texts = []\n",
    "for _, row in pd.concat([top_enriched, top_escape]).iterrows():\n",
    "    offset_x = 1 if row['log2_Enrichment'] > 0 else -1\n",
    "    offset_y = 2\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            row['Sample_Count'] + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=10,\n",
    "            weight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "    # Draw line to the actual point\n",
    "    plt.plot(\n",
    "        [row['log2_Enrichment'], row['log2_Enrichment'] + offset_x],\n",
    "        [row['Sample_Count'], row['Sample_Count'] + offset_y],\n",
    "        linestyle='--',\n",
    "        color='gray',\n",
    "        linewidth=0.8\n",
    "    )\n",
    "\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['mutation'] = df_volcano['Spike_AS_Position'].astype(str)\n",
    "df_volcano['mutation_label'] = df_volcano['mutation'].str.zfill(3)\n",
    "df_volcano['site_label'] = df_volcano['Amino_Acid'] + df_volcano['mutation_label']\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#1f77b4',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#009688',       # Adjust colors as needed\n",
    "}\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.scatterplot(\n",
    "    data=df_volcano_filtered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# Update the labels to show the correct ones as you prefer\n",
    "new_labels = ['B cells - B.1.135 RBD vaccine',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'mAB (NEUT)']\n",
    "\n",
    "# Apply the updated labels\n",
    "ax.legend(handles, new_labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "\n",
    "# Customize the minor ticks (smaller ticks)\n",
    "ax.tick_params(axis='both', which='minor', length=4, width=1, color='gray')\n",
    "\n",
    "# Annotate top points\n",
    "texts = []\n",
    "for _, row in pd.concat([top_enriched, top_escape]).iterrows():\n",
    "    offset_x = 1 if row['log2_Enrichment'] > 0 else -1\n",
    "    offset_y = 2\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            row['Sample_Count'] + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=10,\n",
    "            weight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "    # Draw line to the actual point\n",
    "    plt.plot(\n",
    "        [row['log2_Enrichment'], row['log2_Enrichment'] + offset_x],\n",
    "        [row['Sample_Count'], row['Sample_Count'] + offset_y],\n",
    "        linestyle='--',\n",
    "        color='gray',\n",
    "        linewidth=0.8\n",
    "    )\n",
    "\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in df_combined_volcano:\")\n",
    "print(df_combined_volcano.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['mutation'] = df_volcano['Spike_AS_Position'].astype(str)\n",
    "df_volcano['mutation_label'] = df_volcano['mutation'].str.zfill(3)\n",
    "df_volcano['site_label'] = df_volcano['Amino_Acid'] + df_volcano['mutation_label']\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#1f77b4',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#009688',       # Adjust colors as needed\n",
    "}\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.scatterplot(\n",
    "    data=df_volcano_filtered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    alpha=0.8,\n",
    ")\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# Update the labels to show the correct ones as you prefer\n",
    "new_labels = ['B cells - B.1.135 RBD vaccine',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'mAB (NEUT)']\n",
    "\n",
    "# Apply the updated labels\n",
    "ax.legend(handles, new_labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "\n",
    "# Customize the minor ticks (smaller ticks)\n",
    "ax.tick_params(axis='both', which='minor', length=4, width=1, color='gray')\n",
    "\n",
    "# Annotate top points\n",
    "# Drop duplicate site labels\n",
    "df_labels = df_sig.drop_duplicates(subset=['site_label'])\n",
    "\n",
    "texts = []\n",
    "for _, row in df_labels.iterrows():\n",
    "    offset_x = 1 if row['log2_Enrichment'] > 0 else -1\n",
    "    offset_y = 2\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            row['Sample_Count'] + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=10,\n",
    "            weight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "    plt.plot(\n",
    "        [row['log2_Enrichment'], row['log2_Enrichment'] + offset_x],\n",
    "        [row['Sample_Count'], row['Sample_Count'] + offset_y],\n",
    "        linestyle='--',\n",
    "        color='gray',\n",
    "        linewidth=0.8\n",
    "    )\n",
    "\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray'))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "hb = plt.hexbin(\n",
    "    df_volcano_filtered['log2_Enrichment'],\n",
    "    df_volcano_filtered['Sample_Count'],\n",
    "    gridsize=50,\n",
    "    cmap='viridis',\n",
    "    bins='log'\n",
    ")\n",
    "plt.colorbar(hb, label='Log10(count)')\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.title(\"Hexbin Density of Enrichment vs Sample Count\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(\n",
    "    data=df_volcano_filtered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    dodge=True,\n",
    "    jitter=0.25,\n",
    "    alpha=0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.swarmplot(\n",
    "    data=df_volcano_filtered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    dodge=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "g = sns.FacetGrid(df_volcano_filtered, col='immunization', col_wrap=2, height=4, aspect=1.5)\n",
    "g.map_dataframe(\n",
    "    lambda data, color: plt.hexbin(\n",
    "        data['log2_Enrichment'],\n",
    "        data['Sample_Count'],\n",
    "        gridsize=40,\n",
    "        cmap='viridis',\n",
    "        bins='log'\n",
    "    )\n",
    ")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.set_axis_labels(\"log2(Enrichment Ratio)\", \"Sample Count\")\n",
    "g.fig.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle(\"Hexbin Plot of Enrichment vs Sample Count by Immunization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Select only relevant numeric features\n",
    "features = df_volcano_filtered[['log2_Enrichment','Sample_Count']].copy()\n",
    "\n",
    "# 2. Normalize the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 3. Run UMAP\n",
    "reducer = umap.UMAP(random_state=42)\n",
    "embedding = reducer.fit_transform(features_scaled)\n",
    "\n",
    "# 4. Add UMAP coordinates to the dataframe\n",
    "df_volcano_filtered['UMAP1'] = embedding[:, 0]\n",
    "df_volcano_filtered['UMAP2'] = embedding[:, 1]\n",
    "\n",
    "# 5. Plot UMAP\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_volcano_filtered,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "plt.title(\"UMAP of Mutation Features\")\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO, Seq\n",
    "\n",
    "# --- Load the reference sequence ---\n",
    "fasta_file = r'/Users/lucaschlotheuber/Desktop/ETH/RBD201_DMS1.fa'\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    wuhan_sequence = str(record.seq)\n",
    "    break  # Assumes only one sequence in FASTA\n",
    "\n",
    "# --- Load and filter the DMS dataset ---\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "\n",
    "df = pd.read_excel(file_path, usecols=[\n",
    "    \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\", \"Amino_Acid\",\n",
    "    \"Type_of_Mutation\", \"Enrichment_Ratio\", \"barcode\", \"immunization\",\n",
    "    \"condition\", \"Total_Reads\", \"Codon_Change\", \"Nucleotide_Ref\"\n",
    "])\n",
    "\n",
    "# Adjust Spike position to match wuhan_sequence indexing\n",
    "df[\"Spike_AS_Position\"] = df[\"Spike_AS_Position\"] - 5\n",
    "\n",
    "# Filter out low read counts and NaNs\n",
    "df = df.dropna(subset=[\"Enrichment_Ratio\", \"Amino_Acid\"])\n",
    "df = df[df[\"Total_Reads\"] > 500]\n",
    "\n",
    "# Filter to non-synonymous mutations and region of interest\n",
    "df = df[(df['Spike_AS_Position'] > 364) & (df['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "# Log2 transform enrichment\n",
    "df['log2_Enrichment'] = np.log2(df['Enrichment_Ratio'])\n",
    "\n",
    "# Function to compute reference amino acid\n",
    "def get_reference_aa(codon_change, nucleotide_ref):\n",
    "    try:\n",
    "        original_codon = ''.join(\n",
    "            [nucleotide_ref if base.isupper() else base for base in codon_change]\n",
    "        )\n",
    "        return str(Seq.Seq(original_codon).translate())\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "# Calculate reference amino acid\n",
    "df['Reference_Amino_Acid'] = df.apply(\n",
    "    lambda row: get_reference_aa(row['Codon_Change'], row['Nucleotide_Ref'])\n",
    "    if pd.notna(row['Codon_Change']) and pd.notna(row['Nucleotide_Ref']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create site label like N501Y\n",
    "df['site_label'] = df.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Final cleaned dataset\n",
    "df_combined_volcano = df.copy()\n",
    "\n",
    "# Add inverted enrichment ratio (1/x)\n",
    "df_combined_volcano['Enrichment_Ratio_inverted'] = df_combined_volcano['Enrichment_Ratio'].apply(\n",
    "    lambda x: 1 / x if x != 0 else x\n",
    ")\n",
    "\n",
    "# Label sites of interest for display\n",
    "sites_to_show = list(map(\n",
    "    str,\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] +  # RBD-ACE2 interface\n",
    "    list(range(394, 414)) +  # R21 peptide\n",
    "    list(range(484, 505))    # R13 peptide\n",
    "))\n",
    "df_combined_volcano['show_site'] = df_combined_volcano['Spike_AS_Position'].astype(str).isin(sites_to_show)\n",
    "\n",
    "# Then define this:\n",
    "original_columns = [\n",
    "    'Spike_AS_Position', 'Amino_Acid', 'immunization', 'site_label',\n",
    "    'Enrichment_Ratio', 'log2_Enrichment', 'barcode', 'condition',\n",
    "    'Total_Reads', 'Codon_Change', 'Reference_Amino_Acid',\n",
    "    'Enrichment_Ratio_inverted', 'show_site'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only the immunizations of interest\n",
    "subset = df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])]\n",
    "\n",
    "# Group by immunization and calculate the desired statistics\n",
    "stats = subset.groupby('immunization')['log2_Enrichment'].agg(['min', 'max', 'median'])\n",
    "\n",
    "print(\"📊 Log2 Enrichment stats by immunization:\")\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed CSVs from your plot code\n",
    "poly_df = pd.read_csv(\"immunization_csv_files/Polyclonal_Ab_data.csv\")\n",
    "neut_df = pd.read_csv(\"immunization_csv_files/Neutralizing_Ab_data.csv\")\n",
    "\n",
    "# Check the medians of smoothed enrichment\n",
    "print(\"Polyclonal (Smoothed Enrichment):\", poly_df[\"Smoothed_Enrichment\"].median())\n",
    "print(\"Neutralizing (Smoothed Enrichment):\", neut_df[\"Smoothed_Enrichment\"].median())\n",
    "# Load the processed CSVs from your plot code\n",
    "poly_df = pd.read_csv(\"immunization_csv_files/Polyclonal_Ab_data.csv\")\n",
    "neut_df = pd.read_csv(\"immunization_csv_files/Neutralizing_Ab_data.csv\")\n",
    "\n",
    "# Check the medians of smoothed enrichment\n",
    "print(\"Polyclonal (Smoothed Enrichment):\", poly_df[\"Smoothed_Enrichment\"].median())\n",
    "print(\"Neutralizing (Smoothed Enrichment):\", neut_df[\"Smoothed_Enrichment\"].median())\n",
    "# Load the processed CSVs from your plot code\n",
    "poly_df = pd.read_csv(\"immunization_csv_files/Polyclonal_Ab_data.csv\")\n",
    "neut_df = pd.read_csv(\"immunization_csv_files/Neutralizing_Ab_data.csv\")\n",
    "\n",
    "# Check the medians of smoothed enrichment\n",
    "print(\"Polyclonal (Smoothed Enrichment):\", poly_df[\"Smoothed_Enrichment\"].median())\n",
    "print(\"Neutralizing (Smoothed Enrichment):\", neut_df[\"Smoothed_Enrichment\"].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "sns.violinplot(\n",
    "    data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    x='barcode', y='Enrichment_Ratio', hue='immunization',\n",
    "    split=True, inner=None, cut=0\n",
    ")\n",
    "sns.stripplot(\n",
    "    data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    x='barcode', y='Enrichment_Ratio', hue='immunization',\n",
    "    dodge=True, color='black', alpha=0.25, jitter=True\n",
    ")\n",
    "plt.title(\"Enrichment Ratio by Barcode and Immunization\")\n",
    "plt.xticks(rotation=30)\n",
    "plt.yscale('log')  # Again, helps with wide enrichment ranges\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Enrichment_Ratio_by_Barcode_and_Immunization.png\", dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Violin plot\n",
    "sns.violinplot(\n",
    "    data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    x='barcode', y='Enrichment_Ratio', hue='immunization',\n",
    "    split=True, inner=None, cut=0\n",
    ")\n",
    "\n",
    "# Strip plot (overlaid points)\n",
    "sns.stripplot(\n",
    "    data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    x='barcode', y='Enrichment_Ratio', hue='immunization',\n",
    "    dodge=False, color='black', alpha=0.3, jitter=True\n",
    ")\n",
    "\n",
    "# Add horizontal line at Enrichment Ratio = 1\n",
    "plt.axhline(y=1, color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title(\"Enrichment Ratio by Barcode and Immunization\")\n",
    "plt.yscale('log')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Clean legend (remove duplicate handles)\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "n = len(set(df_combined_volcano['immunization']))\n",
    "plt.legend(handles[:n], labels[:n], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"enrichment_ratio_by_barcode.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22, 6))\n",
    "\n",
    "# Violin plot (with hue split for immunization)\n",
    "sns.violinplot(\n",
    "    data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    x='barcode', y='Enrichment_Ratio', hue='immunization',\n",
    "    split=True, inner=None, cut=0\n",
    ")\n",
    "\n",
    "# Strip plot (points overlaid, not dodged)\n",
    "sns.stripplot(\n",
    "    data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    x='barcode', y='Enrichment_Ratio', hue='immunization',\n",
    "    dodge=False, color='black', alpha=0.3, jitter=True\n",
    ")\n",
    "\n",
    "plt.title(\"Enrichment Ratio by Barcode and Immunization\")\n",
    "plt.yscale('log')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Remove duplicate legends\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "n = len(set(df_combined_volcano['immunization']))\n",
    "plt.legend(handles[:n], labels[:n], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Violin plot\n",
    "sns.violinplot(\n",
    "    data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    x='barcode', y='Enrichment_Ratio', hue='immunization',\n",
    "    split=True, inner=None, cut=0\n",
    ")\n",
    "\n",
    "# Strip plot (overlaid points)\n",
    "sns.stripplot(\n",
    "    data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "    x='barcode', y='Enrichment_Ratio', hue='immunization',\n",
    "    dodge=False, color='black', alpha=0.3, jitter=True\n",
    ")\n",
    "\n",
    "# Add vertical line at x=1 (2nd barcode group)\n",
    "plt.axvline(x=1, color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title(\"Enrichment Ratio by Barcode and Immunization\")\n",
    "plt.yscale('log')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Fix duplicate legend from stripplot\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "n = len(set(df_combined_volcano['immunization']))\n",
    "plt.legend(handles[:n], labels[:n], bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"enrichment_ratio_by_barcode.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.violinplot(data=df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])],\n",
    "               x='immunization', y='log2_Enrichment')\n",
    "plt.title(\"Log2 Enrichment Distribution by Immunization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available columns\n",
    "print(\"Available columns:\", poly_df.columns)\n",
    "\n",
    "# Print summary for Smoothed_Enrichment (raw scale)\n",
    "print(\"\\n--- Smoothed_Enrichment ---\")\n",
    "print(\"Polyclonal median:\", poly_df[\"Smoothed_Enrichment\"].median())\n",
    "print(\"Neutralizing median:\", neut_df[\"Smoothed_Enrichment\"].median())\n",
    "\n",
    "# Add log2 version for comparison\n",
    "import numpy as np\n",
    "poly_df['log2_Enrichment'] = np.log2(poly_df[\"Smoothed_Enrichment\"] + 1e-6)\n",
    "neut_df['log2_Enrichment'] = np.log2(neut_df[\"Smoothed_Enrichment\"] + 1e-6)\n",
    "\n",
    "print(\"\\n--- log2_Enrichment ---\")\n",
    "print(\"Polyclonal median (log2):\", poly_df['log2_Enrichment'].median())\n",
    "print(\"Neutralizing median (log2):\", neut_df['log2_Enrichment'].median())\n",
    "\n",
    "# Print quantiles to visualize distribution skew\n",
    "print(\"\\nQuantiles (Polyclonal - log2):\\n\", poly_df['log2_Enrichment'].quantile([0.1, 0.25, 0.5, 0.75, 0.9]))\n",
    "print(\"\\nQuantiles (Neutralizing - log2):\\n\", neut_df['log2_Enrichment'].quantile([0.1, 0.25, 0.5, 0.75, 0.9]))\n",
    "\n",
    "# Plot violin again with same data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df_combined = pd.concat([\n",
    "    poly_df.assign(immunization='Polyclonal_Ab'),\n",
    "    neut_df.assign(immunization='Neutralizing_Ab')\n",
    "])\n",
    "\n",
    "sns.violinplot(data=df_combined, x='immunization', y='log2_Enrichment')\n",
    "plt.title(\"Log2 Enrichment Distribution by Immunization\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for Polyclonal and Neutralizing Ab groups\n",
    "df_filtered = df_combined_volcano[df_combined_volcano['immunization'].isin(['Polyclonal_Ab', 'Neutralizing_Ab'])]\n",
    "\n",
    "# Calculate median log2 enrichment for each group\n",
    "polyclonal_median = df_filtered[df_filtered['immunization'] == 'Polyclonal_Ab']['log2_Enrichment'].median()\n",
    "neutralizing_median = df_filtered[df_filtered['immunization'] == 'Neutralizing_Ab']['log2_Enrichment'].median()\n",
    "\n",
    "# Print out the medians\n",
    "print(f\"--- log2_Enrichment ---\")\n",
    "print(f\"Polyclonal median (log2): {polyclonal_median}\")\n",
    "print(f\"Neutralizing median (log2): {neutralizing_median}\")\n",
    "\n",
    "# Calculate quantiles for both groups\n",
    "polyclonal_quantiles = df_filtered[df_filtered['immunization'] == 'Polyclonal_Ab']['log2_Enrichment'].quantile([0.10, 0.25, 0.50, 0.75, 0.90])\n",
    "neutralizing_quantiles = df_filtered[df_filtered['immunization'] == 'Neutralizing_Ab']['log2_Enrichment'].quantile([0.10, 0.25, 0.50, 0.75, 0.90])\n",
    "\n",
    "# Print quantiles \n",
    "print(\"\\nQuantiles (Polyclonal - log2):\")\n",
    "print(polyclonal_quantiles)\n",
    "\n",
    "print(\"\\nQuantiles (Neutralizing - log2):\")\n",
    "print(neutralizing_quantiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Final columns in df_combined_volcano:\")\n",
    "print(df_combined_volcano.columns.tolist())\n",
    "\n",
    "print(\"\\n🔍 Preview of df_combined_volcano:\")\n",
    "print(df_combined_volcano.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if each row has the correct site_label\n",
    "df_combined_volcano['generated_label'] = df_combined_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Compare the generated label to the existing site_label column\n",
    "df_combined_volcano['label_correct'] = df_combined_volcano['generated_label'] == df_combined_volcano['site_label']\n",
    "\n",
    "# Print rows where the label does not match\n",
    "incorrect_labels = df_combined_volcano[df_combined_volcano['label_correct'] == False]\n",
    "print(incorrect_labels[['Spike_AS_Position', 'Reference_Amino_Acid', 'Amino_Acid', 'site_label', 'generated_label']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "#FINALCODE\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['mutation'] = df_volcano['Spike_AS_Position'].astype(str)\n",
    "df_volcano['mutation_label'] = df_volcano['mutation'].str.zfill(3)\n",
    "df_volcano['site_label'] = df_volcano['Amino_Acid'] + df_volcano['mutation_label']\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#1f77b4',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#009688',       # Adjust colors as needed\n",
    "}\n",
    "\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# --------------------------\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)  # Example threshold for significance (log2(0.5))\n",
    "high_thresh = np.log2(2)   # Example threshold for significance (log2(2))\n",
    "\n",
    "# --------------------------\n",
    "# Create two separate DataFrames for significant and non-significant data\n",
    "df_non_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] >= low_thresh) & \n",
    "                                 (df_volcano_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "\n",
    "df_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] < low_thresh) | \n",
    "                             (df_volcano_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "\n",
    "# Plot non-significant points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',  # Light gray for non-significant points\n",
    "    s=18,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Plot significant points\n",
    "sns.scatterplot(\n",
    "    data=df_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    s=20,\n",
    "    alpha=0.9,\n",
    "    zorder=2,\n",
    "    linewidth=0.4\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(0, linestyle='--', color='gray', lw=1)\n",
    "\n",
    "# Add text labels for thresholds\n",
    "plt.text(low_thresh, 0.2, 'log2(0.5)', ha='center', va='bottom', fontsize=9)\n",
    "plt.text(high_thresh, 0.2, 'log2(2)', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"← Escape   |   Binding →\")\n",
    "plt.ylabel(\"Single-Antibody Repertoire\")\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = ['B cells - B.1.135 RBD vaccine',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'mAB (NEUT)']\n",
    "plt.legend(handles, new_labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "ax.tick_params(axis='both', which='minor', length=4, width=1, color='gray')\n",
    "\n",
    "# Annotate top points\n",
    "texts = []\n",
    "for _, row in pd.concat([top_enriched, top_escape]).iterrows():\n",
    "    offset_x = 1 if row['log2_Enrichment'] > 0 else -1\n",
    "    offset_y = 2\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            row['Sample_Count'] + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=10,\n",
    "            weight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "    # Draw line to the actual point\n",
    "    plt.plot(\n",
    "        [row['log2_Enrichment'], row['log2_Enrichment'] + offset_x],\n",
    "        [row['Sample_Count'], row['Sample_Count'] + offset_y],\n",
    "        linestyle='--',\n",
    "        color='gray',\n",
    "        linewidth=0.8\n",
    "    )\n",
    "\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "#FINALCODE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['mutation'] = df_volcano['Spike_AS_Position'].astype(str)\n",
    "df_volcano['mutation_label'] = df_volcano['mutation'].str.zfill(3)\n",
    "df_volcano['site_label'] = df_volcano['Amino_Acid'] + df_volcano['mutation_label']\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#1f77b4',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#009688',       # Adjust colors as needed\n",
    "}\n",
    "\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# --------------------------\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)  # Example threshold for significance (log2(0.5))\n",
    "high_thresh = np.log2(2)   # Example threshold for significance (log2(2))\n",
    "\n",
    "# --------------------------\n",
    "# Create two separate DataFrames for significant and non-significant data\n",
    "df_non_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] >= low_thresh) & \n",
    "                                 (df_volcano_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "\n",
    "df_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] < low_thresh) | \n",
    "                             (df_volcano_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "\n",
    "# Plot non-significant points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',  # Light gray for non-significant points\n",
    "    s=18,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Plot significant points\n",
    "sns.scatterplot(\n",
    "    data=df_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    s=20,\n",
    "    alpha=0.9,\n",
    "    zorder=2,\n",
    "    linewidth=0.4\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(0, linestyle='--', color='gray', lw=1)\n",
    "\n",
    "# Add text labels for thresholds\n",
    "plt.text(low_thresh, 0.2, 'log2(0.5)', ha='center', va='bottom', fontsize=9)\n",
    "plt.text(high_thresh, 0.2, 'log2(2)', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"← Escape   |   Binding →\")\n",
    "plt.ylabel(\"Single-Antibody Repertoire\")\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = ['Anti-RBD mAB (NEUT)',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'B cells - B.1.135 RBD vaccine',]\n",
    "plt.legend(handles, new_labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "ax.tick_params(axis='both', which='minor', length=4, width=1, color='gray')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493,494,495,496,497,498,499,500, 501, 502, 505]\n",
    "\n",
    "# Step 1: Filter for log enrichment and sample count\n",
    "df_labels = df_sig[\n",
    "    ((df_sig['log2_Enrichment'] > 2) | (df_sig['log2_Enrichment'] < -2)) &\n",
    "    (df_sig['Sample_Count'] == 3) &\n",
    "    (df_sig['Spike_AS_Position'].isin(residues_to_label))\n",
    "].copy()\n",
    "\n",
    "# Step 2: Deduplicate by site_label within each immunization group\n",
    "seen = defaultdict(set)\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 3: Annotate plot\n",
    "texts = []\n",
    "for row in filtered_rows:\n",
    "    offset_x = 1 if row['log2_Enrichment'] > 0 else -1\n",
    "    offset_y = 2\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            row['Sample_Count'] + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=10,\n",
    "            weight='bold',\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "    plt.plot(\n",
    "        [row['log2_Enrichment'], row['log2_Enrichment'] + offset_x],\n",
    "        [row['Sample_Count'], row['Sample_Count'] + offset_y],\n",
    "        linestyle='--',\n",
    "        color='gray',\n",
    "        linewidth=0.8\n",
    "    )\n",
    "\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray'))\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove duplicates before aggregation and filtering\n",
    "df_combined_volcano = df_combined_volcano.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "#FINALCODE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend for saving to a file\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "\n",
    "\n",
    "\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#1f77b4',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#009688',       # Adjust colors as needed\n",
    "}\n",
    "\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# --------------------------\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)  # Example threshold for significance (log2(0.5))\n",
    "high_thresh = np.log2(2)   # Example threshold for significance (log2(2))\n",
    "\n",
    "# --------------------------\n",
    "# Create two separate DataFrames for significant and non-significant data\n",
    "df_non_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] >= low_thresh) & \n",
    "                                 (df_volcano_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "\n",
    "df_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] < low_thresh) | \n",
    "                             (df_volcano_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "\n",
    "# Set jitter magnitude\n",
    "y_jitter_std = 0.05  # Adjust as needed\n",
    "\n",
    "# Add jittered Y values for plotting\n",
    "df_non_sig['Sample_Count_jitter'] = df_non_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_non_sig))\n",
    "df_sig['Sample_Count_jitter'] = df_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_sig))\n",
    "\n",
    "# Plot non-significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    color='lightgray',\n",
    "    s=15,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Plot significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    s=15,\n",
    "    alpha=0.9,\n",
    "    zorder=2,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(0, linestyle='--', color='gray', lw=1)\n",
    "\n",
    "# Add text labels for thresholds\n",
    "plt.text(low_thresh, 0.2, 'log2(0.5)', ha='center', va='bottom', fontsize=11)\n",
    "plt.text(high_thresh, 0.2, 'log2(2)', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)  # Adjust fontsize as needed\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=18)  # Adjust fontsize as needed\n",
    "plt.ylabel(\"Single-Antibody (Droplet Barcode)\", fontsize=18)  # Adjust fontsize as needed\n",
    "\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = ['Anti-RBD mAB (NEUT)',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'B cells - B.1.135 RBD vaccine',]\n",
    "plt.legend(handles, new_labels, title=\"Immunization\", bbox_to_anchor=(0.75, 1), loc='upper left')\n",
    "\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "ax.tick_params(axis='both', which='minor', length=4, width=1, color='gray')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "residues_to_label = [417, 439, 440, 452, 477, 484, 495, 501, 502, 505]\n",
    "\n",
    "# Step 1: Filter for log enrichment and sample count\n",
    "df_labels = df_sig[\n",
    "    ((df_sig['log2_Enrichment'] > 3) | (df_sig['log2_Enrichment'] < -3)) &\n",
    "    (df_sig['Sample_Count'] > 2) &\n",
    "    (df_sig['Spike_AS_Position'].isin(residues_to_label))\n",
    "].copy()\n",
    "\n",
    "# Step 2: Deduplicate by site_label within each immunization group\n",
    "seen = defaultdict(set)\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 3: Add top 5, bottom 5, and highest Sample_Count to label\n",
    "top_5 = df_volcano_filtered.nlargest(15, 'log2_Enrichment')\n",
    "bottom_5 = df_volcano_filtered.nsmallest(15, 'log2_Enrichment')\n",
    "\n",
    "# Get the top sample count (highest value)\n",
    "max_sample_count_row = df_volcano_filtered.loc[df_volcano_filtered['Sample_Count'].idxmax()]\n",
    "\n",
    "# Combine top 5, bottom 5, and the highest sample count\n",
    "df_combined_labels = pd.concat([top_5, bottom_5, pd.DataFrame([max_sample_count_row])])\n",
    "\n",
    "# Step 4: Deduplicate the combined labels by site_label within each immunization group\n",
    "for _, row in df_combined_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 5: Add additional label for data above Sample_Count of 12 and log enrichment of 3\n",
    "new_label_condition = (df_sig['Sample_Count'] > 12) & (df_sig['log2_Enrichment'] > 3)\n",
    "new_labels = df_sig[new_label_condition].copy()\n",
    "\n",
    "# Deduplicate by site_label for new labels\n",
    "for _, row in new_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "\n",
    "# Step 6: Annotate plot with unique labels per immunization group\n",
    "texts = []\n",
    "for row in filtered_rows:\n",
    "    offset_x = 0 if row['log2_Enrichment'] > 0 else -1  # Adjust offset based on log2 enrichment\n",
    "    offset_y = 0.2\n",
    "\n",
    "    # Add jitter only to the scatter points, not to the labels\n",
    "    jittered_sample_count = row['Sample_Count'] + np.random.normal(0, y_jitter_std)\n",
    "\n",
    "    # Add the text annotations for each unique label\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            jittered_sample_count + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=13,\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "    # Draw line connecting point to the label (only for jittered points)\n",
    "\n",
    "\n",
    "# Adjust text labels to prevent overlap\n",
    "adjust_text(\n",
    "    texts,\n",
    "    arrowprops=None,  # No arrows, since you have custom lines\n",
    "    expand_text=(2, 2),  # Increase repulsion in both x and y direction\n",
    "    expand_points=(2, 2),  # Increase repulsion for points as well\n",
    "    force_text=1.0,  # Stronger push away for text to prevent overlap\n",
    "    force_points=0.3,  # Push points further away for better distribution\n",
    "    only_move={'points': 'y', 'texts': 'xy'},  # Allow movement in both x and y for texts\n",
    "    lim=100  # Limit the number of text label adjustments to prevent infinite loops\n",
    ")\n",
    "\n",
    "plt.xlim(-7, 9)\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()\n",
    "plt.draw()  # Ensure the plot is drawn before saving\n",
    "plt.savefig('/Users/lucaschlotheuber/Desktop/Volcano2.jpeg', format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "#FINALCODE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend for saving to a file\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "# Normalize Sample_Count between 0 and 1\n",
    "# Step 1: Count total unique barcodes per immunization group\n",
    "barcode_totals = df_combined_volcano.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Step 2: Normalize Sample_Count by total barcodes per immunization\n",
    "df_counts['Sample_Count'] = df_counts.apply(\n",
    "    lambda row: row['Sample_Count'] / barcode_totals.get(row['immunization'], 1), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "\n",
    "\n",
    "\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#1f77b4',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#009688',       # Adjust colors as needed\n",
    "}\n",
    "\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# --------------------------\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)  # Example threshold for significance (log2(0.5))\n",
    "high_thresh = np.log2(2)   # Example threshold for significance (log2(2))\n",
    "\n",
    "# --------------------------\n",
    "# Create two separate DataFrames for significant and non-significant data\n",
    "df_non_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] >= low_thresh) & \n",
    "                                 (df_volcano_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "\n",
    "df_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] < low_thresh) | \n",
    "                             (df_volcano_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "\n",
    "# Set jitter magnitude\n",
    "y_jitter_std = 0.02 # Adjust as needed\n",
    "\n",
    "# Add jittered Y values for plotting\n",
    "df_non_sig['Sample_Count_jitter'] = df_non_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_non_sig))\n",
    "df_sig['Sample_Count_jitter'] = df_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_sig))\n",
    "\n",
    "# Plot non-significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    color='lightgray',\n",
    "    s=15,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Plot significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    s=25,\n",
    "    alpha=0.9,\n",
    "    zorder=2,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(0, linestyle='--', color='gray', lw=1)\n",
    "\n",
    "# Add text labels for thresholds\n",
    "plt.text(low_thresh, -0.05, 'log2(0.5)', ha='center', va='bottom', fontsize=11)\n",
    "plt.text(high_thresh, -0.05, 'log2(2)', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)  # Adjust fontsize as needed\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=18)  # Adjust fontsize as needed\n",
    "plt.ylabel(\"Frequency of Mutation in Single-Antibody Repertoire\", fontsize=18)  # Adjust fontsize as needed\n",
    "\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = ['Anti-RBD mAB (NEUT)',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'B cells - B.1.135 RBD vaccine',]\n",
    "plt.legend(\n",
    "    handles, \n",
    "    new_labels, \n",
    "    title=\"Immunization\", \n",
    "    bbox_to_anchor=(0.8, 1), \n",
    "    loc='upper left', \n",
    "    fontsize=12,  # Adjust the size of the legend text\n",
    "    title_fontsize=14  # Adjust the size of the title\n",
    ")\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "ax.tick_params(axis='both', which='minor', length=4, width=1, color='gray')\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "residues_to_label = [417, 439, 440, 452, 477, 484, 495, 501, 502, 505]\n",
    "\n",
    "df_labels = df_sig[\n",
    "    ((df_sig['log2_Enrichment'] > high_thresh) | (df_sig['log2_Enrichment'] < low_thresh)) &  # Significant data\n",
    "    (df_sig['Sample_Count'] > 2) &  # Filter based on Sample_Count\n",
    "    (df_sig['Spike_AS_Position'].isin(residues_to_label))  # Only specific residues\n",
    "].copy()\n",
    "\n",
    "# Step 2: Deduplicate by site_label within each immunization group\n",
    "seen = defaultdict(set)\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 3: Add top 5, bottom 5, and highest Sample_Count to label\n",
    "top_5 = df_volcano_filtered.nlargest(5, 'log2_Enrichment')\n",
    "bottom_5 = df_volcano_filtered.nsmallest(25, 'log2_Enrichment')\n",
    "\n",
    "# Get the top sample count (highest value)\n",
    "top_y = df_volcano_filtered.nlargest(50, 'Sample_Count')\n",
    "\n",
    "max_sample_count_row = df_volcano_filtered.loc[df_volcano_filtered['Sample_Count'].idxmax()]\n",
    "\n",
    "\n",
    "# Combine top 5, bottom 5, and the highest sample count\n",
    "df_combined_labels = pd.concat([\n",
    "    top_5,\n",
    "    bottom_5,\n",
    "    top_y,  # <-- ADDED\n",
    "    pd.DataFrame([max_sample_count_row])\n",
    "])\n",
    "\n",
    "# --- Debugging block for inspecting label rows ---\n",
    "# Debugging block to inspect contents of filtered_rows\n",
    "# --- End of debug block ---\n",
    "\n",
    "\n",
    "# Step 4: Deduplicate the combined labels by site_label within each immunization group\n",
    "for _, row in df_combined_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 5: Add additional label for data above Sample_Count of 12 and log enrichment of 3\n",
    "new_label_condition = (df_sig['Sample_Count'] > 10) & (df_sig['log2_Enrichment'] > 3)\n",
    "new_labels = df_sig[new_label_condition].copy()\n",
    "\n",
    "# Deduplicate by site_label for new labels\n",
    "for _, row in new_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "        \n",
    "\n",
    "\n",
    "# Step 6: Annotate plot with unique labels per immunization group\n",
    "texts = []\n",
    "for row in filtered_rows:\n",
    "    # Calculate dynamic offsets based on log2_Enrichment value\n",
    "    offset_x = 0.01  # Default offset\n",
    "    offset_y = 0.01  # Default vertical offset\n",
    "\n",
    "    # Adjust offset based on log2_Enrichment values\n",
    "    if row['log2_Enrichment'] < 0:\n",
    "        offset_x = -0.6  # Offset to the left for negative log2_Enrichment\n",
    "    else:\n",
    "        offset_x = 0.6  # Offset to the right for positive log2_Enrichment\n",
    "\n",
    "    # Add jitter only to the scatter points, not to the labels\n",
    "    jittered_sample_count = row['Sample_Count'] + np.random.normal(0, y_jitter_std)\n",
    "\n",
    "    # Add the text annotations for each unique label\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'] + offset_x,\n",
    "            jittered_sample_count + offset_y,\n",
    "            row['site_label'],\n",
    "            fontsize=12,\n",
    "            color='black'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Draw line connecting point to the label (only for jittered points)\n",
    "    plt.plot(\n",
    "        [row['log2_Enrichment'], row['log2_Enrichment'] + offset_x],\n",
    "        [row['Sample_Count'], jittered_sample_count + offset_y],\n",
    "        linestyle='--',\n",
    "        color='black',\n",
    "        linewidth=0.8\n",
    "    )\n",
    "\n",
    "\n",
    "# Adjust text labels to prevent overlap\n",
    "adjust_text(\n",
    "    texts,\n",
    "    arrowprops=None,  # No arrows, since you have custom lines\n",
    "    expand_text=(2, 2),  # Increase repulsion in both x and y direction\n",
    "    expand_points=(2, 2),  # Increase repulsion for points as well\n",
    "    force_text=1.0,  # Stronger push away for text to prevent overlap\n",
    "    force_points=0.3,  # Push points further away for better distribution\n",
    "    only_move={'points': 'y', 'texts': 'xy'},  # Allow movement in both x and y for texts\n",
    "    lim=100  # Limit the number of text label adjustments to prevent infinite loops\n",
    ")\n",
    "\n",
    "plt.xlim(-9, 9)\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.show()\n",
    "plt.draw()  # Ensure the plot is drawn before saving\n",
    "plt.savefig('/Users/lucaschlotheuber/Desktop/Volcano3.jpeg', format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "#FINALCODE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend for saving to a file\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "# Normalize Sample_Count between 0 and 1\n",
    "# Step 1: Count total unique barcodes per immunization group\n",
    "barcode_totals = df_combined_volcano.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Step 2: Normalize Sample_Count by total barcodes per immunization\n",
    "df_counts['Sample_Count'] = df_counts.apply(\n",
    "    lambda row: row['Sample_Count'] / barcode_totals.get(row['immunization'], 1), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "\n",
    "\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "print(\"Remaining rows after all filters:\", len(df_filtered))\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#009688',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#1f77b4',       # Adjust colors as needed  \n",
    "}\n",
    "print(df_volcano[['Reference_Amino_Acid', 'Spike_AS_Position', 'Amino_Acid', 'site_label']].drop_duplicates().head())\n",
    "\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# --------------------------\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)  # Example threshold for significance (log2(0.5))\n",
    "high_thresh = np.log2(2)   # Example threshold for significance (log2(2))\n",
    "\n",
    "# --------------------------\n",
    "# Create two separate DataFrames for significant and non-significant data\n",
    "df_non_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] >= low_thresh) & \n",
    "                                 (df_volcano_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "\n",
    "df_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] < low_thresh) | \n",
    "                             (df_volcano_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "\n",
    "\n",
    "# Set jitter magnitude\n",
    "y_jitter_std = 0 # Adjust as needed\n",
    "\n",
    "# Add jittered Y values for plotting\n",
    "df_non_sig['Sample_Count_jitter'] = df_non_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_non_sig))\n",
    "df_sig['Sample_Count_jitter'] = df_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_sig))\n",
    "\n",
    "# Plot non-significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    color='lightgray',\n",
    "    s=15,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Plot significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    s=25,\n",
    "    alpha=0.9,\n",
    "    zorder=2,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(0, linestyle='--', color='gray', lw=1)\n",
    "\n",
    "# Add text labels for thresholds\n",
    "plt.text(low_thresh, -0.05, 'log2(0.5)', ha='center', va='bottom', fontsize=13)\n",
    "plt.text(high_thresh, -0.05, 'log2(2)', ha='center', va='bottom', fontsize=13)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)  # Adjust fontsize as needed\n",
    "# Remove default xlabel\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "# Add centered xlabel at x=0\n",
    "ax.text(0, -0.05, \"← Escape   |   Binding →\", fontsize=21,\n",
    "        ha='center', va='top', transform=ax.get_xaxis_transform())\n",
    "\n",
    "plt.ylabel(\"Frequency of Mutation in Single-Antibody Repertoire\", fontsize=21)  # Adjust fontsize as needed\n",
    "\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = ['Anti-RBD mAB (NEUT)',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'B cells - B.1.135 RBD vaccine',]\n",
    "plt.legend(\n",
    "    handles, \n",
    "    new_labels, \n",
    "    title=\"Immunization\", \n",
    "    bbox_to_anchor=(0.8, 0.9), \n",
    "    loc='upper left', \n",
    "    fontsize=12,  # Adjust the size of the legend text\n",
    "    title_fontsize=14,  # Adjust the size of the title\n",
    "    markerscale=1.8  \n",
    ")\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)  # Increase font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Residues to label\n",
    "residues_to_label = [417, 439, 440, 452, 477, 484, 495, 501, 502, 505]\n",
    "\n",
    "# Step 1: Filter the significant data\n",
    "df_labels = df_sig[\n",
    "    ((df_sig['log2_Enrichment'] > high_thresh) | (df_sig['log2_Enrichment'] < low_thresh)) &  # Significant data\n",
    "    (df_sig['Sample_Count'] > 2) &  # Filter based on Sample_Count\n",
    "    (df_sig['Spike_AS_Position'].isin(residues_to_label))  # Only specific residues\n",
    "].copy()\n",
    "\n",
    "# Step 2: Deduplicate by site_label within each immunization group\n",
    "seen = defaultdict(set)\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 3: Add top 5, bottom 5, and highest Sample_Count to label\n",
    "top_5 = df_volcano_filtered.nlargest(5, 'log2_Enrichment')\n",
    "bottom_5 = df_volcano_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "\n",
    "# Get the top sample count (highest value)\n",
    "top_y = df_volcano_filtered.nlargest(20, 'Sample_Count')\n",
    "\n",
    "max_sample_count_row = df_volcano_filtered.loc[df_volcano_filtered['Sample_Count'].idxmax()]\n",
    "\n",
    "# Combine top 5, bottom 5, and the highest sample count\n",
    "df_combined_labels = pd.concat([\n",
    "    top_5,\n",
    "    bottom_5,\n",
    "    top_y,  # <-- ADDED\n",
    "    pd.DataFrame([max_sample_count_row])\n",
    "])\n",
    "\n",
    "# Step 4: Deduplicate the combined labels by site_label within each immunization group\n",
    "for _, row in df_combined_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 5: Add additional label for data above Sample_Count of 12 and log enrichment of 3\n",
    "\n",
    "is_484 = df_sig['site_label'].str.contains('484', na=False)\n",
    "\n",
    "\n",
    "new_labels = (\n",
    "    ((df_sig['Sample_Count'] > 0.6) & (df_sig['log2_Enrichment'] > 2.5)) | \n",
    "    ((df_sig['Sample_Count'] > 0.2) & (df_sig['log2_Enrichment'] > 5.5)) | \n",
    "    ((df_sig['Sample_Count'] > 0.2) & (df_sig['log2_Enrichment'] < -4.7)) |\n",
    "    ((df_sig['Sample_Count'] < 0.16) & (df_sig['log2_Enrichment'] > 2))  # 👈 Add this to include all 484-related entries\n",
    ")\n",
    "\n",
    "for _, row in df_sig[new_labels].iterrows():  # ✅ use the mask to filter df_sig\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Now we are only dealing with significant data, so we will proceed to add labels ---\n",
    "# Step 6: Annotate plot with unique labels per immunization group\n",
    "# Step 1: Calculate and add text annotations with initial jitter and offsets\n",
    "texts = []\n",
    "offsets = []  # To store the final offsets after jitter and initial offsets\n",
    "jittered_positions = []  # To store jittered positions for lines\n",
    "\n",
    "for _, row in df_sig.iterrows():\n",
    "    if row['Spike_AS_Position'] in residues_to_label:\n",
    "        texts.append(\n",
    "            ax.text(\n",
    "                row['log2_Enrichment'],\n",
    "                row['Sample_Count_jitter'],\n",
    "                row['site_label'],\n",
    "                fontsize=9,\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                zorder=5,\n",
    "                clip_on=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "for row in filtered_rows:\n",
    "    if -1 <= row['log2_Enrichment'] <= 1:\n",
    "        continue  # Skip this label if within the range\n",
    "    # Default offsets for label positioning\n",
    "    offset_x = 0.01  # Default horizontal offset\n",
    "    offset_y = 0.01  # Default vertical offset\n",
    "\n",
    "    # Adjust horizontal offset based on log2_Enrichment values\n",
    "    if row['log2_Enrichment'] < 0:\n",
    "        offset_x = -1  # Leftward offset for negative log2_Enrichment\n",
    "    else:\n",
    "        offset_x = 1   # Rightward offset for positive log2_Enrichment\n",
    "\n",
    "    # Add jitter only to the scatter points (not the labels)\n",
    "    jittered_sample_count = row['Sample_Count'] + np.random.normal(0, y_jitter_std)\n",
    "\n",
    "    # Store jittered positions for later\n",
    "    jittered_positions.append((row['log2_Enrichment'], row['Sample_Count']))\n",
    "\n",
    "    # Add text annotations with the initial position\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'] + offset_x,\n",
    "        jittered_sample_count + offset_y,\n",
    "        row['site_label'],\n",
    "        fontsize=12,\n",
    "        color='black'\n",
    "    )\n",
    "    texts.append(text)\n",
    "    offsets.append((row['log2_Enrichment'] + offset_x, jittered_sample_count + offset_y))\n",
    "\n",
    "# Step 2: Adjust the text labels to avoid overlap\n",
    "adjust_text(\n",
    "    texts,\n",
    "    arrowprops=None,  # No arrows, we will manually handle lines\n",
    "    expand_text=(2, 2),  # Increase repulsion in both x and y direction\n",
    "    expand_points=(2, 2),  # Increase repulsion for points as well\n",
    "    force_text=1.0,  # Stronger push for text to avoid overlap\n",
    "    force_points=0.3,  # Push points further for better distribution\n",
    "    only_move={'points': 'y', 'texts': 'xy'},  # Allow movement in both x and y for texts\n",
    "    lim=100  # Limit the number of text label adjustments to prevent infinite loops\n",
    ")\n",
    "\n",
    "# Step 3: Redraw the lines connecting points to adjusted label positions\n",
    "for i in range(len(texts)):\n",
    "    adjusted_text_x, adjusted_text_y = texts[i].get_position()\n",
    "    original_jittered_x, original_jittered_y = jittered_positions[i]\n",
    "\n",
    "    ax.plot(\n",
    "        [original_jittered_x, adjusted_text_x],\n",
    "        [original_jittered_y, adjusted_text_y],\n",
    "        color='gray',\n",
    "        linestyle='--',\n",
    "        linewidth=0.5,\n",
    "        zorder=1\n",
    "    )\n",
    "\n",
    "# Adjust plot\n",
    "plt.xlim(-7, 9)\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "print(df_labels[['Spike_AS_Position', 'Amino_Acid', 'site_label', 'log2_Enrichment', 'Sample_Count_jitter']])\n",
    "\n",
    "plt.draw()  # Ensure the plot is drawn before saving\n",
    "plt.savefig('/Users/lucaschlotheuber/Desktop/Volcano9.jpeg', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "#FINALCODE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend for saving to a file\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "# Normalize Sample_Count between 0 and 1\n",
    "# Step 1: Count total unique barcodes per immunization group\n",
    "barcode_totals = df_combined_volcano.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Step 2: Normalize Sample_Count by total barcodes per immunization\n",
    "df_counts['Sample_Count'] = df_counts.apply(\n",
    "    lambda row: row['Sample_Count'] / barcode_totals.get(row['immunization'], 1), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "\n",
    "\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "print(\"Remaining rows after all filters:\", len(df_filtered))\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#009688',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#1f77b4',       # Adjust colors as needed  \n",
    "}\n",
    "print(df_volcano[['Reference_Amino_Acid', 'Spike_AS_Position', 'Amino_Acid', 'site_label']].drop_duplicates().head())\n",
    "\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# --------------------------\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)  # Example threshold for significance (log2(0.5))\n",
    "high_thresh = np.log2(2)   # Example threshold for significance (log2(2))\n",
    "\n",
    "# --------------------------\n",
    "# Create two separate DataFrames for significant and non-significant data\n",
    "df_non_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] >= low_thresh) & \n",
    "                                 (df_volcano_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "\n",
    "df_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] < low_thresh) | \n",
    "                             (df_volcano_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "\n",
    "\n",
    "# Set jitter magnitude\n",
    "y_jitter_std = 0 # Adjust as needed\n",
    "\n",
    "# Add jittered Y values for plotting\n",
    "df_non_sig['Sample_Count_jitter'] = df_non_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_non_sig))\n",
    "df_sig['Sample_Count_jitter'] = df_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_sig))\n",
    "\n",
    "# Plot non-significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    color='lightgray',\n",
    "    s=15,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Plot significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    s=25,\n",
    "    alpha=0.9,\n",
    "    zorder=2,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(0, linestyle='--', color='gray', lw=1)\n",
    "\n",
    "# Add text labels for thresholds\n",
    "plt.text(low_thresh, -0.05, 'log2(0.5)', ha='center', va='bottom', fontsize=13)\n",
    "plt.text(high_thresh, -0.05, 'log2(2)', ha='center', va='bottom', fontsize=13)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)  # Adjust fontsize as needed\n",
    "# Remove default xlabel\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "# Add centered xlabel at x=0\n",
    "ax.text(0, -0.05, \"← Escape   |   Binding →\", fontsize=21,\n",
    "        ha='center', va='top', transform=ax.get_xaxis_transform())\n",
    "\n",
    "plt.ylabel(\"Frequency of Mutation in Single-Antibody Repertoire\", fontsize=21)  # Adjust fontsize as needed\n",
    "\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = ['Anti-RBD mAB (NEUT)',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'B cells - B.1.135 RBD vaccine',]\n",
    "plt.legend(\n",
    "    handles, \n",
    "    new_labels, \n",
    "    title=\"Immunization\", \n",
    "    bbox_to_anchor=(0.8, 0.9), \n",
    "    loc='upper left', \n",
    "    fontsize=12,  # Adjust the size of the legend text\n",
    "    title_fontsize=14,  # Adjust the size of the title\n",
    "    markerscale=1.8  \n",
    ")\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)  # Increase font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Residues to label\n",
    "residues_to_label = [417, 439, 440, 452, 477, 484, 495, 501, 502, 505]\n",
    "\n",
    "# Step 1: Filter the significant data\n",
    "df_labels = df_sig[\n",
    "    ((df_sig['log2_Enrichment'] > high_thresh) | (df_sig['log2_Enrichment'] < low_thresh)) &  # Significant data\n",
    "    (df_sig['Sample_Count'] > 2) &  # Filter based on Sample_Count\n",
    "    (df_sig['Spike_AS_Position'].isin(residues_to_label))  # Only specific residues\n",
    "].copy()\n",
    "\n",
    "# Step 2: Deduplicate by site_label within each immunization group\n",
    "seen = defaultdict(set)\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 3: Add top 5, bottom 5, and highest Sample_Count to label\n",
    "top_5 = df_volcano_filtered.nlargest(5, 'log2_Enrichment')\n",
    "bottom_5 = df_volcano_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "\n",
    "# Get the top sample count (highest value)\n",
    "top_y = df_volcano_filtered.nlargest(20, 'Sample_Count')\n",
    "\n",
    "max_sample_count_row = df_volcano_filtered.loc[df_volcano_filtered['Sample_Count'].idxmax()]\n",
    "\n",
    "# Combine top 5, bottom 5, and the highest sample count\n",
    "df_combined_labels = pd.concat([\n",
    "    top_5,\n",
    "    bottom_5,\n",
    "    top_y,  # <-- ADDED\n",
    "    pd.DataFrame([max_sample_count_row])\n",
    "])\n",
    "\n",
    "# Step 4: Deduplicate the combined labels by site_label within each immunization group\n",
    "for _, row in df_combined_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 5: Add additional label for data above Sample_Count of 12 and log enrichment of 3\n",
    "\n",
    "is_484 = df_sig['site_label'].str.contains('484', na=False)\n",
    "\n",
    "\n",
    "new_labels = (\n",
    "    ((df_sig['Sample_Count'] > 0.6) & (df_sig['log2_Enrichment'] > 2.5)) | \n",
    "    ((df_sig['Sample_Count'] > 0.2) & (df_sig['log2_Enrichment'] > 5.5)) | \n",
    "    ((df_sig['Sample_Count'] > 0.2) & (df_sig['log2_Enrichment'] < -4.7)) |\n",
    "    ((df_sig['Sample_Count'] < 0.16) & (df_sig['log2_Enrichment'] > 2)) |\n",
    "    ((df_sig['Sample_Count'] < 0.16) & (df_sig['log2_Enrichment'] < 2)) |\n",
    "    is_484  # 👈 Add this to include all 484-related entries\n",
    ")\n",
    "for _, row in df_sig[new_labels].iterrows():  # ✅ use the mask to filter df_sig\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "\n",
    "highlight_df = df_sig[\n",
    "    (df_sig['Sample_Count'] > 0) &\n",
    "    (df_sig['log2_Enrichment'] > -10) &\n",
    "    (df_sig['Spike_AS_Position'] == 484)\n",
    "]\n",
    "\n",
    "\n",
    "# --- Now we are only dealing with significant data, so we will proceed to add labels ---\n",
    "# Step 6: Annotate plot with unique labels per immunization group\n",
    "# Step 1: Calculate and add text annotations with initial jitter and offsets\n",
    "texts = []\n",
    "offsets = []  # To store the final offsets after jitter and initial offsets\n",
    "jittered_positions = []  # To store jittered positions for lines\n",
    "\n",
    "for _, row in df_sig.iterrows():\n",
    "    if row['Spike_AS_Position'] in residues_to_label:\n",
    "        texts.append(\n",
    "            ax.text(\n",
    "                row['log2_Enrichment'],\n",
    "                row['Sample_Count_jitter'],\n",
    "                row['site_label'],\n",
    "                fontsize=9,\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                zorder=5,\n",
    "                clip_on=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "for _, row in highlight_df.iterrows():\n",
    "    texts.append(\n",
    "        plt.text(\n",
    "            row['log2_Enrichment'],\n",
    "            row['Sample_Count_jitter'],\n",
    "            row['site_label'],\n",
    "            fontsize=10,\n",
    "            color='black',\n",
    "            weight='bold',\n",
    "            ha='center',\n",
    "            va='center'\n",
    "        )\n",
    "    )\n",
    "\n",
    "        \n",
    "for row in filtered_rows:\n",
    "    if -1 <= row['log2_Enrichment'] <= 1:\n",
    "        continue  # Skip this label if within the range\n",
    "    # Default offsets for label positioning\n",
    "    offset_x = 0.01  # Default horizontal offset\n",
    "    offset_y = 0.01  # Default vertical offset\n",
    "\n",
    "    # Adjust horizontal offset based on log2_Enrichment values\n",
    "    if row['log2_Enrichment'] < 0:\n",
    "        offset_x = -1  # Leftward offset for negative log2_Enrichment\n",
    "    else:\n",
    "        offset_x = 1   # Rightward offset for positive log2_Enrichment\n",
    "\n",
    "    # Add jitter only to the scatter points (not the labels)\n",
    "    jittered_sample_count = row['Sample_Count'] + np.random.normal(0, y_jitter_std)\n",
    "\n",
    "    # Store jittered positions for later\n",
    "    jittered_positions.append((row['log2_Enrichment'], row['Sample_Count']))\n",
    "\n",
    "    # Add text annotations with the initial position\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'] + offset_x,\n",
    "        jittered_sample_count + offset_y,\n",
    "        row['site_label'],\n",
    "        fontsize=12,\n",
    "        color='black'\n",
    "    )\n",
    "    texts.append(text)\n",
    "    offsets.append((row['log2_Enrichment'] + offset_x, jittered_sample_count + offset_y))\n",
    "\n",
    "# Step 2: Adjust the text labels to avoid overlap\n",
    "adjust_text(\n",
    "    texts,\n",
    "    arrowprops=None,  # No arrows, we will manually handle lines\n",
    "    expand_text=(2, 2),  # Increase repulsion in both x and y direction\n",
    "    expand_points=(2, 2),  # Increase repulsion for points as well\n",
    "    force_text=1.0,  # Stronger push for text to avoid overlap\n",
    "    force_points=0.3,  # Push points further for better distribution\n",
    "    only_move={'points': 'y', 'texts': 'xy'},  # Allow movement in both x and y for texts\n",
    "    lim=100  # Limit the number of text label adjustments to prevent infinite loops\n",
    ")\n",
    "\n",
    "# Step 3: Redraw the lines connecting points to adjusted label positions\n",
    "for i in range(len(texts)):\n",
    "    adjusted_text_x, adjusted_text_y = texts[i].get_position()\n",
    "    original_jittered_x, original_jittered_y = jittered_positions[i]\n",
    "\n",
    "    ax.plot(\n",
    "        [original_jittered_x, adjusted_text_x],\n",
    "        [original_jittered_y, adjusted_text_y],\n",
    "        color='gray',\n",
    "        linestyle='--',\n",
    "        linewidth=0.5,\n",
    "        zorder=1\n",
    "    )\n",
    "\n",
    "# Adjust plot\n",
    "plt.xlim(-7, 9)\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "print(df_labels[['Spike_AS_Position', 'Amino_Acid', 'site_label', 'log2_Enrichment', 'Sample_Count_jitter']])\n",
    "\n",
    "plt.draw()  # Ensure the plot is drawn before saving\n",
    "plt.savefig('/Users/lucaschlotheuber/Desktop/Volcano8.jpeg', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "#FINALCODE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend for saving to a file\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def stack_points(df, x_col, y_col, spacing=0.002):\n",
    "    \"\"\"\n",
    "    Spreads points in y-axis if they have identical x and y values\n",
    "    to avoid overlap without jitter.\n",
    "    \"\"\"\n",
    "    coords_counter = defaultdict(int)\n",
    "    for idx, row in df.iterrows():\n",
    "        key = (row[x_col], row[y_col])\n",
    "        count = coords_counter[key]\n",
    "        df.at[idx, y_col] += count * spacing\n",
    "        coords_counter[key] += 1\n",
    "    return df\n",
    "\n",
    "\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "# Normalize Sample_Count between 0 and 1\n",
    "# Step 1: Count total unique barcodes per immunization group\n",
    "barcode_totals = df_combined_volcano.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Step 2: Normalize Sample_Count by total barcodes per immunization\n",
    "df_counts['Sample_Count'] = df_counts.apply(\n",
    "    lambda row: row['Sample_Count'] / barcode_totals.get(row['immunization'], 1), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "\n",
    "\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "print(\"Remaining rows after all filters:\", len(df_filtered))\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#009688',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#1f77b4',       # Adjust colors as needed  \n",
    "}\n",
    "print(df_volcano[['Reference_Amino_Acid', 'Spike_AS_Position', 'Amino_Acid', 'site_label']].drop_duplicates().head())\n",
    "\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# --------------------------\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)  # Example threshold for significance (log2(0.5))\n",
    "high_thresh = np.log2(2)   # Example threshold for significance (log2(2))\n",
    "\n",
    "# --------------------------\n",
    "# Create two separate DataFrames for significant and non-significant data\n",
    "df_non_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] >= low_thresh) & \n",
    "                                 (df_volcano_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "\n",
    "df_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] < low_thresh) | \n",
    "                             (df_volcano_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "df_non_sig = stack_points(df_non_sig, 'log2_Enrichment', 'Sample_Count')\n",
    "df_sig = stack_points(df_sig, 'log2_Enrichment', 'Sample_Count')\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "\n",
    "\n",
    "\n",
    "# Plot non-significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    s=15,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Plot significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    s=25,\n",
    "    alpha=0.9,\n",
    "    zorder=2,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(0, linestyle='--', color='gray', lw=1)\n",
    "\n",
    "# Add text labels for thresholds\n",
    "plt.text(low_thresh, -0.05, 'log2(0.5)', ha='center', va='bottom', fontsize=13)\n",
    "plt.text(high_thresh, -0.05, 'log2(2)', ha='center', va='bottom', fontsize=13)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)  # Adjust fontsize as needed\n",
    "# Remove default xlabel\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "# Add centered xlabel at x=0\n",
    "ax.text(0, -0.05, \"← Escape   |   Binding →\", fontsize=21,\n",
    "        ha='center', va='top', transform=ax.get_xaxis_transform())\n",
    "\n",
    "plt.ylabel(\"Frequency of Mutation in Single-Antibody Repertoire\", fontsize=21)  # Adjust fontsize as needed\n",
    "\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = ['Anti-RBD mAB (NEUT)',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'B cells - B.1.135 RBD vaccine',]\n",
    "plt.legend(\n",
    "    handles, \n",
    "    new_labels, \n",
    "    title=\"Immunization\", \n",
    "    bbox_to_anchor=(0.8, 0.9), \n",
    "    loc='upper left', \n",
    "    fontsize=12,  # Adjust the size of the legend text\n",
    "    title_fontsize=14,  # Adjust the size of the title\n",
    "    markerscale=1.8  \n",
    ")\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)  # Increase font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Residues to label\n",
    "residues_to_label = [417, 439, 440, 452, 477, 484, 495, 501, 502, 505]\n",
    "\n",
    "# Step 1: Filter the significant data\n",
    "df_labels = df_sig[\n",
    "    ((df_sig['log2_Enrichment'] > high_thresh) | (df_sig['log2_Enrichment'] < low_thresh)) &  # Significant data\n",
    "    (df_sig['Sample_Count'] > 2) &  # Filter based on Sample_Count\n",
    "    (df_sig['Spike_AS_Position'].isin(residues_to_label))  # Only specific residues\n",
    "].copy()\n",
    "\n",
    "# Step 2: Deduplicate by site_label within each immunization group\n",
    "seen = defaultdict(set)\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 3: Add top 5, bottom 5, and highest Sample_Count to label\n",
    "top_5 = df_volcano_filtered.nlargest(5, 'log2_Enrichment')\n",
    "bottom_5 = df_volcano_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "\n",
    "# Get the top sample count (highest value)\n",
    "top_y = df_volcano_filtered.nlargest(20, 'Sample_Count')\n",
    "\n",
    "max_sample_count_row = df_volcano_filtered.loc[df_volcano_filtered['Sample_Count'].idxmax()]\n",
    "\n",
    "# Combine top 5, bottom 5, and the highest sample count\n",
    "df_combined_labels = pd.concat([\n",
    "    top_5,\n",
    "    bottom_5,\n",
    "    top_y,  # <-- ADDED\n",
    "    pd.DataFrame([max_sample_count_row])\n",
    "])\n",
    "\n",
    "# Step 4: Deduplicate the combined labels by site_label within each immunization group\n",
    "for _, row in df_combined_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 5: Add additional label for data above Sample_Count of 12 and log enrichment of 3\n",
    "\n",
    "new_labels = (\n",
    "    ((df_sig['Sample_Count'] > 0.6) & (df_sig['log2_Enrichment'] > 2.5)) | \n",
    "    ((df_sig['Sample_Count'] > 0.2) & (df_sig['log2_Enrichment'] > 5.5)) | \n",
    "    ((df_sig['Sample_Count'] > 0.2) & (df_sig['log2_Enrichment'] < -4.7)) |\n",
    "    ((df_sig['Sample_Count'] < 0.16) & (df_sig['log2_Enrichment'] > 2 )) |\n",
    "    ((df_sig['Sample_Count'] < 0.16) & (df_sig['log2_Enrichment'] < 2 ))\n",
    ")\n",
    "\n",
    "for _, row in df_sig[new_labels].iterrows():  # ✅ use the mask to filter df_sig\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "\n",
    "# --- Now we are only dealing with significant data, so we will proceed to add labels ---\n",
    "# Step 6: Annotate plot with unique labels per immunization group\n",
    "# Step 1: Calculate and add text annotations with initial jitter and offsets\n",
    "texts = []\n",
    "offsets = []  # To store the final offsets after fixed offsets\n",
    "positions = []  # To store positions for lines\n",
    "\n",
    "for _, row in df_sig.iterrows():\n",
    "    if row['Spike_AS_Position'] in residues_to_label:\n",
    "        texts.append(\n",
    "            ax.text(\n",
    "                row['log2_Enrichment'],\n",
    "                row['Sample_Count'],\n",
    "                row['site_label'],\n",
    "                fontsize=9,\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                zorder=5,\n",
    "                clip_on=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "for row in filtered_rows:\n",
    "    if -1 <= row['log2_Enrichment'] <= 1:\n",
    "        continue  # Skip this label if within the range\n",
    "    # Default offsets for label positioning\n",
    "    offset_x = 0.01  # Default horizontal offset\n",
    "    offset_y = 0.01  # Default vertical offset\n",
    "\n",
    "    # Adjust horizontal offset based on log2_Enrichment values\n",
    "    if row['log2_Enrichment'] < 0:\n",
    "        offset_x = -1  # Leftward offset for negative log2_Enrichment\n",
    "    else:\n",
    "        offset_x = 1   # Rightward offset for positive log2_Enrichment\n",
    "\n",
    "    # No jitter here — just use original Sample_Count\n",
    "    sample_count = row['Sample_Count']\n",
    "\n",
    "    # Store positions for later\n",
    "    positions.append((row['log2_Enrichment'], sample_count))\n",
    "\n",
    "    # Add text annotations with the initial position\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'] + offset_x,\n",
    "        sample_count + offset_y,\n",
    "        row['site_label'],\n",
    "        fontsize=12,\n",
    "        color='black'\n",
    "    )\n",
    "    texts.append(text)\n",
    "    offsets.append((row['log2_Enrichment'] + offset_x, sample_count + offset_y))\n",
    "\n",
    "# Step 2: Adjust the text labels to avoid overlap\n",
    "adjust_text(\n",
    "    texts,\n",
    "    arrowprops=None,\n",
    "    expand_text=(2, 2),\n",
    "    expand_points=(2, 2),\n",
    "    force_text=1.0,\n",
    "    force_points=0.3,\n",
    "    only_move={'points': 'y', 'texts': 'xy'},\n",
    "    lim=100\n",
    ")\n",
    "\n",
    "# Step 3: Redraw the lines connecting points to adjusted label positions\n",
    "for i in range(len(texts)):\n",
    "    adjusted_text_x, adjusted_text_y = texts[i].get_position()\n",
    "    original_x, original_y = positions[i]\n",
    "\n",
    "    ax.plot(\n",
    "        [original_x, adjusted_text_x],\n",
    "        [original_y, adjusted_text_y],\n",
    "        color='gray',\n",
    "        linestyle='--',\n",
    "        linewidth=0.5,\n",
    "        zorder=1\n",
    "        \n",
    "    )\n",
    "# Adjust plot\n",
    "plt.xlim(-7, 9)\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "print(df_labels[['Spike_AS_Position', 'Amino_Acid', 'site_label', 'log2_Enrichment', 'Sample_Count']])\n",
    "\n",
    "\n",
    "plt.draw()  # Ensure the plot is drawn before saving\n",
    "plt.savefig('/Users/lucaschlotheuber/Desktop/Volcano9.jpeg', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_combined_volcano.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def stack_points(df, x_col, y_col, stack_direction='vertical', min_distance=0.005):\n",
    "    \"\"\"\n",
    "    Spread overlapping points along y-axis (vertical) or x-axis (horizontal) \n",
    "    for better visualization.\n",
    "    \"\"\"\n",
    "    grouped = defaultdict(list)\n",
    "    adjusted_y = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        key = (round(row[x_col], 4), round(row[y_col], 4))\n",
    "        stack_pos = len(grouped[key])\n",
    "        grouped[key].append(idx)\n",
    "\n",
    "        if stack_direction == 'vertical':\n",
    "            new_y = row[y_col] + (stack_pos * min_distance)\n",
    "            adjusted_y.append(new_y)\n",
    "        else:\n",
    "            new_x = row[x_col] + (stack_pos * min_distance)\n",
    "            df.at[idx, x_col] = new_x\n",
    "            adjusted_y.append(row[y_col])  # Keep y unchanged\n",
    "\n",
    "    df['Sample_Count_adjusted'] = adjusted_y\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of unique barcodes per unique combination of 'Spike_AS_Position' and 'Amino_Acid'\n",
    "#FINALCODE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # Use a non-interactive backend for saving to a file\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .agg(Sample_Count=('barcode', 'nunique'))  # Count unique barcodes\n",
    "    .reset_index()\n",
    ")\n",
    "# Normalize Sample_Count between 0 and 1\n",
    "# Step 1: Count total unique barcodes per immunization group\n",
    "barcode_totals = df_combined_volcano.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Step 2: Normalize Sample_Count by total barcodes per immunization\n",
    "df_counts['Sample_Count'] = df_counts.apply(\n",
    "    lambda row: row['Sample_Count'] / barcode_totals.get(row['immunization'], 1), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Calculate the median log2 Enrichment Ratio for each unique combination\n",
    "df_median_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .median()\n",
    "    .reset_index(name='log2_Enrichment')  # Use median instead of mean\n",
    ")\n",
    "\n",
    "# Merge the counts and median enrichment ratio\n",
    "df_volcano = pd.merge(df_counts, df_median_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Print out the columns to verify\n",
    "print(\"Columns in df_volcano after merging and cleaning:\")\n",
    "print(df_volcano.columns.tolist())\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "\n",
    "\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "print(\"Remaining rows after all filters:\", len(df_filtered))\n",
    "# Get top N enriched and escape\n",
    "top_n = 5\n",
    "\n",
    "palette = {\n",
    "    'Polyclonal_Ab': '#ff7f0e',     # Adjust colors as needed\n",
    "    'Neutralizing_Ab': '#d62728',    # Adjust colors as needed\n",
    "    'Mutant_RBD': '#009688',         # Adjust colors as needed\n",
    "    'wildtype_RBD': '#1f77b4',       # Adjust colors as needed  \n",
    "}\n",
    "print(df_volcano[['Reference_Amino_Acid', 'Spike_AS_Position', 'Amino_Acid', 'site_label']].drop_duplicates().head())\n",
    "\n",
    "# Ensure you're filtering based on the actual immunization values including the new ones\n",
    "df_volcano_filtered = df_volcano[df_volcano['immunization'].isin(palette.keys())]\n",
    "\n",
    "# --------------------------\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)  # Example threshold for significance (log2(0.5))\n",
    "high_thresh = np.log2(2)   # Example threshold for significance (log2(2))\n",
    "\n",
    "# --------------------------\n",
    "# Create two separate DataFrames for significant and non-significant data\n",
    "df_non_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] >= low_thresh) & \n",
    "                                 (df_volcano_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "\n",
    "df_sig = df_volcano_filtered[(df_volcano_filtered['log2_Enrichment'] < low_thresh) | \n",
    "                             (df_volcano_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "df_non_sig = stack_points(df_non_sig, 'log2_Enrichment', 'Sample_Count')\n",
    "df_sig = stack_points(df_sig, 'log2_Enrichment', 'Sample_Count')\n",
    "\n",
    "# --------------------------\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "\n",
    "\n",
    "# Set jitter magnitude\n",
    "y_jitter_std = 0 # Adjust as needed\n",
    "\n",
    "def ensure_no_overlap(df, x_col, y_col, min_distance=0.01):\n",
    "    seen_y = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        y_val = row[y_col]\n",
    "        x_val = row[x_col]\n",
    "        # If this y value has been seen before, adjust it\n",
    "        if y_val in seen_y:\n",
    "            new_y_val = y_val + seen_y[y_val] * min_distance\n",
    "            seen_y[y_val] += 1  # Increase the count for this y value\n",
    "            df.at[idx, y_col] = new_y_val\n",
    "        else:\n",
    "            seen_y[y_val] = 1\n",
    "    return df\n",
    "\n",
    "# Ensure no overlap for both non-significant and significant data\n",
    "df_non_sig = ensure_no_overlap(df_non_sig, 'log2_Enrichment', 'Sample_Count')\n",
    "df_sig = ensure_no_overlap(df_sig, 'log2_Enrichment', 'Sample_Count')\n",
    "\n",
    "# Add jittered Y values for plotting\n",
    "df_non_sig['Sample_Count_jitter'] = df_non_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_non_sig))\n",
    "df_sig['Sample_Count_jitter'] = df_sig['Sample_Count'] + np.random.normal(0, y_jitter_std, size=len(df_sig))\n",
    "\n",
    "# Plot non-significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    color='lightgray',\n",
    "    s=15,\n",
    "    alpha=0.4\n",
    ")\n",
    "\n",
    "# Plot significant points with jitter\n",
    "sns.scatterplot(\n",
    "    data=df_sig,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count_jitter',\n",
    "    hue='immunization',\n",
    "    palette=palette,\n",
    "    s=25,\n",
    "    alpha=0.9,\n",
    "    zorder=2,\n",
    "    linewidth=0\n",
    ")\n",
    "\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1)\n",
    "plt.axvline(0, linestyle='--', color='gray', lw=1)\n",
    "\n",
    "# Add text labels for thresholds\n",
    "plt.text(low_thresh, -0.05, 'log2(0.5)', ha='center', va='bottom', fontsize=13)\n",
    "plt.text(high_thresh, -0.05, 'log2(2)', ha='center', va='bottom', fontsize=13)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)  # Adjust fontsize as needed\n",
    "# Remove default xlabel\n",
    "plt.xlabel(\"\")\n",
    "\n",
    "# Add centered xlabel at x=0\n",
    "ax.text(0, -0.05, \"← Escape   |   Binding →\", fontsize=21,\n",
    "        ha='center', va='top', transform=ax.get_xaxis_transform())\n",
    "\n",
    "plt.ylabel(\"Frequency of Mutation in Single-Antibody Repertoire\", fontsize=21)  # Adjust fontsize as needed\n",
    "\n",
    "\n",
    "# Customizing the legend to use the desired labels\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "new_labels = ['Anti-RBD mAB (NEUT)',\n",
    "              'Polyreactive pAB',\n",
    "              'B cells - Ancestral Wuhan RBD vaccine',\n",
    "              'B cells - B.1.135 RBD vaccine',]\n",
    "plt.legend(\n",
    "    handles, \n",
    "    new_labels, \n",
    "    title=\"Immunization\", \n",
    "    bbox_to_anchor=(0.8, 0.9), \n",
    "    loc='upper left', \n",
    "    fontsize=12,  # Adjust the size of the legend text\n",
    "    title_fontsize=14,  # Adjust the size of the title\n",
    "    markerscale=1.8  \n",
    ")\n",
    "\n",
    "# Enable minor ticks\n",
    "plt.minorticks_on()\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)  # Increase font size for major ticks\n",
    "ax.tick_params(axis='both', which='minor', labelsize=15)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# Residues to label\n",
    "residues_to_label = [417, 439, 440, 452, 477, 484, 495, 501, 502, 505]\n",
    "\n",
    "# Step 1: Filter the significant data\n",
    "df_labels = df_sig[\n",
    "    ((df_sig['log2_Enrichment'] > high_thresh) | (df_sig['log2_Enrichment'] < low_thresh)) &  # Significant data\n",
    "    (df_sig['Sample_Count'] > 2) &  # Filter based on Sample_Count\n",
    "    (df_sig['Spike_AS_Position'].isin(residues_to_label))  # Only specific residues\n",
    "].copy()\n",
    "\n",
    "# Step 2: Deduplicate by site_label within each immunization group\n",
    "seen = defaultdict(set)\n",
    "filtered_rows = []\n",
    "\n",
    "for _, row in df_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 3: Add top 5, bottom 5, and highest Sample_Count to label\n",
    "top_5 = df_volcano_filtered.nlargest(5, 'log2_Enrichment')\n",
    "bottom_5 = df_volcano_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "\n",
    "# Get the top sample count (highest value)\n",
    "top_y = df_volcano_filtered.nlargest(20, 'Sample_Count')\n",
    "\n",
    "max_sample_count_row = df_volcano_filtered.loc[df_volcano_filtered['Sample_Count'].idxmax()]\n",
    "\n",
    "# Combine top 5, bottom 5, and the highest sample count\n",
    "df_combined_labels = pd.concat([\n",
    "    top_5,\n",
    "    bottom_5,\n",
    "    top_y,  # <-- ADDED\n",
    "    pd.DataFrame([max_sample_count_row])\n",
    "])\n",
    "\n",
    "# Step 4: Deduplicate the combined labels by site_label within each immunization group\n",
    "for _, row in df_combined_labels.iterrows():\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "# Step 5: Add additional label for data above Sample_Count of 12 and log enrichment of 3\n",
    "\n",
    "new_labels = (\n",
    "    ((df_sig['Sample_Count'] > 0.6) & (df_sig['log2_Enrichment'] > 2.5)) | \n",
    "    ((df_sig['Sample_Count'] > 0.2) & (df_sig['log2_Enrichment'] > 5.5)) | \n",
    "    ((df_sig['Sample_Count'] > 0.2) & (df_sig['log2_Enrichment'] < -4.7)) |\n",
    "    ((df_sig['Sample_Count'] < 0.16) & (df_sig['log2_Enrichment'] > 2 )) |\n",
    "    ((df_sig['Sample_Count'] < 0.16) & (df_sig['log2_Enrichment'] < 2 ))\n",
    ")\n",
    "\n",
    "for _, row in df_sig[new_labels].iterrows():  # ✅ use the mask to filter df_sig\n",
    "    label = row['site_label']\n",
    "    group = row['immunization']\n",
    "    if \"*\" in label:\n",
    "        continue\n",
    "    if label not in seen[group]:\n",
    "        seen[group].add(label)\n",
    "        filtered_rows.append(row)\n",
    "\n",
    "\n",
    "# --- Now we are only dealing with significant data, so we will proceed to add labels ---\n",
    "# Step 6: Annotate plot with unique labels per immunization group\n",
    "# Step 1: Calculate and add text annotations with initial jitter and offsets\n",
    "texts = []\n",
    "offsets = []  # To store the final offsets after jitter and initial offsets\n",
    "jittered_positions = []  # To store jittered positions for lines\n",
    "\n",
    "for _, row in df_sig.iterrows():\n",
    "    if row['Spike_AS_Position'] in residues_to_label:\n",
    "        texts.append(\n",
    "            ax.text(\n",
    "                row['log2_Enrichment'],\n",
    "                row['Sample_Count_jitter'],\n",
    "                row['site_label'],\n",
    "                fontsize=9,\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                zorder=5,\n",
    "                clip_on=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "for row in filtered_rows:\n",
    "    if -1 <= row['log2_Enrichment'] <= 1:\n",
    "        continue  # Skip this label if within the range\n",
    "    # Default offsets for label positioning\n",
    "    offset_x = 0.01  # Default horizontal offset\n",
    "    offset_y = 0.01  # Default vertical offset\n",
    "\n",
    "    # Adjust horizontal offset based on log2_Enrichment values\n",
    "    if row['log2_Enrichment'] < 0:\n",
    "        offset_x = -1  # Leftward offset for negative log2_Enrichment\n",
    "    else:\n",
    "        offset_x = 1   # Rightward offset for positive log2_Enrichment\n",
    "\n",
    "    # Add jitter only to the scatter points (not the labels)\n",
    "    jittered_sample_count = row['Sample_Count'] + np.random.normal(0, y_jitter_std)\n",
    "\n",
    "    # Store jittered positions for later\n",
    "    jittered_positions.append((row['log2_Enrichment'], row['Sample_Count']))\n",
    "\n",
    "    # Add text annotations with the initial position\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'] + offset_x,\n",
    "        jittered_sample_count + offset_y,\n",
    "        row['site_label'],\n",
    "        fontsize=12,\n",
    "        color='black'\n",
    "    )\n",
    "    texts.append(text)\n",
    "    offsets.append((row['log2_Enrichment'] + offset_x, jittered_sample_count + offset_y))\n",
    "\n",
    "# Step 2: Adjust the text labels to avoid overlap\n",
    "adjust_text(\n",
    "    texts,\n",
    "    arrowprops=None,  # No arrows, we will manually handle lines\n",
    "    expand_text=(2, 2),  # Increase repulsion in both x and y direction\n",
    "    expand_points=(2, 2),  # Increase repulsion for points as well\n",
    "    force_text=1.0,  # Stronger push for text to avoid overlap\n",
    "    force_points=0.3,  # Push points further for better distribution\n",
    "    only_move={'points': 'y', 'texts': 'xy'},  # Allow movement in both x and y for texts\n",
    "    lim=100  # Limit the number of text label adjustments to prevent infinite loops\n",
    ")\n",
    "\n",
    "# Step 3: Redraw the lines connecting points to adjusted label positions\n",
    "for i in range(len(texts)):\n",
    "    adjusted_text_x, adjusted_text_y = texts[i].get_position()\n",
    "    original_jittered_x, original_jittered_y = jittered_positions[i]\n",
    "\n",
    "    ax.plot(\n",
    "        [original_jittered_x, adjusted_text_x],\n",
    "        [original_jittered_y, adjusted_text_y],\n",
    "        color='gray',\n",
    "        linestyle='--',\n",
    "        linewidth=0.5,\n",
    "        zorder=1\n",
    "    )\n",
    "\n",
    "# Adjust plot\n",
    "plt.xlim(-7, 9)\n",
    "plt.tight_layout()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(2)\n",
    "print(df_labels[['Spike_AS_Position', 'Amino_Acid', 'site_label', 'log2_Enrichment', 'Sample_Count_jitter']])\n",
    "\n",
    "\n",
    "plt.draw()  # Ensure the plot is drawn before saving\n",
    "plt.savefig('/Users/lucaschlotheuber/Desktop/Volcano9.jpeg', format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "# Define a function to calculate the reference amino acid\n",
    "def get_reference_aa(codon_change, nucleotide_ref):\n",
    "    # Replace the capitalized nucleotide in the codon change with the nucleotide_ref\n",
    "    original_codon = ''.join(\n",
    "        [nucleotide_ref if base.isupper() else base for base in codon_change]\n",
    "    )\n",
    "    # Use Bio.Seq to translate the codon to an amino acid\n",
    "    return Seq(original_codon).translate()\n",
    "\n",
    "# Combine enriched and escaped data\n",
    "df_combined_volcano = pd.concat([\n",
    "    df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1],\n",
    "    df_escape.assign(Enrichment_Ratio=df_escape['Enrichment_Ratio'])\n",
    "])\n",
    "\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Enrichment_Ratio'] > 0]\n",
    "df_combined_volcano['log2_Enrichment'] = np.log2(df_combined_volcano['Enrichment_Ratio'])\n",
    "\n",
    "# Retain all columns from the original data frame\n",
    "original_columns = df_combined_volcano.columns.tolist()\n",
    "\n",
    "# Count appearances across barcodes\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Get mean log2 enrichment\n",
    "df_max_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .mean()\n",
    "    .reset_index(name='log2_Enrichment')\n",
    ")\n",
    "\n",
    "# Merge counts and enrichment data\n",
    "df_volcano = pd.merge(df_counts, df_max_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['Reference_Amino_Acid'] = df_volcano.apply(\n",
    "    lambda row: get_reference_aa(row['Codon_Change'], row['Nucleotide_Ref'])\n",
    "    if pd.notna(row['Codon_Change']) and pd.notna(row['Nucleotide_Ref']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create labels like N501Y\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Calculate Reference Amino Acid\n",
    "df_filtered['Reference_Amino_Acid'] = df_filtered.apply(\n",
    "    lambda row: get_reference_aa(row['Codon_Change'], row['Nucleotide_Ref']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Get top N enriched, escaped, and top sample count\n",
    "top_n = 10\n",
    "\n",
    "top_enriched = df_filtered[df_filtered['log2_Enrichment'] > 0].nlargest(top_n, ['Sample_Count', 'log2_Enrichment'])\n",
    "top_escape = df_filtered[df_filtered['log2_Enrichment'] < 0].nsmallest(top_n, ['Sample_Count', 'log2_Enrichment'])\n",
    "top_sample_count = df_filtered.nlargest(top_n, 'Sample_Count')\n",
    "\n",
    "# Combine and drop duplicates\n",
    "top_combined = pd.concat([top_enriched, top_escape, top_sample_count]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Shade non-significant region (0.5–2 enrichment ratio in log2 space)\n",
    "plt.axvspan(np.log2(0.5), np.log2(2), color='lightgray', alpha=0.3, zorder=0)\n",
    "\n",
    "# Create masks for significant and non-significant mutations\n",
    "mask_significant = (df_volcano['Enrichment_Ratio'] <= 0.5) | (df_volcano['Enrichment_Ratio'] >= 2)\n",
    "mask_nonsig = ~mask_significant\n",
    "\n",
    "# Plot non-significant mutations in gray (without hue)\n",
    "sns.scatterplot(\n",
    "    data=df_volcano[mask_nonsig],\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='gray',  # Explicitly set color to gray\n",
    "    alpha=0.4,\n",
    "    edgecolor='black',\n",
    "    s=10,\n",
    "    label='Not significant',\n",
    "    zorder=1\n",
    ")\n",
    "\n",
    "# Plot significant mutations with original coloring (keep hue)\n",
    "ax = sns.scatterplot(\n",
    "    data=df_volcano[mask_significant],\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',  # Keep hue for significant mutations\n",
    "    alpha=0.8,\n",
    "    edgecolor='black',\n",
    "    s=10,\n",
    "    zorder=2\n",
    ")\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Annotate only the top points with labels\n",
    "texts = []\n",
    "for _, row in top_combined.iterrows():\n",
    "    offset_x = 0.2 if row['log2_Enrichment'] > 0 else -0.2\n",
    "    offset_y = 0.2\n",
    "    custom_label = f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'] + offset_x,\n",
    "        row['Sample_Count'] + offset_y,\n",
    "        custom_label,\n",
    "        fontsize=8,\n",
    "        color='black',\n",
    "        ha='left' if row['log2_Enrichment'] > 0 else 'right',\n",
    "        va='bottom'\n",
    "    )\n",
    "    texts.append(text)\n",
    "\n",
    "# Adjust label positions to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'xy', 'text': 'xy'}, expand_text=(1.1, 1.1), ax=ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "# Define a function to calculate the reference amino acid\n",
    "def get_reference_aa(codon_change, nucleotide_ref):\n",
    "    # Replace the capitalized nucleotide in the codon change with the nucleotide_ref\n",
    "    original_codon = ''.join(\n",
    "        [nucleotide_ref if base.isupper() else base for base in codon_change]\n",
    "    )\n",
    "    # Use Bio.Seq to translate the codon to an amino acid\n",
    "    return Seq(original_codon).translate()\n",
    "\n",
    "# Combine enriched and escaped data\n",
    "df_combined_volcano = pd.concat([\n",
    "    df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1],\n",
    "    df_escape.assign(Enrichment_Ratio=df_escape['Enrichment_Ratio'])\n",
    "])\n",
    "\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Enrichment_Ratio'] > 0]\n",
    "df_combined_volcano['log2_Enrichment'] = np.log2(df_combined_volcano['Enrichment_Ratio'])\n",
    "\n",
    "# Retain all columns from the original data frame\n",
    "original_columns = df_combined_volcano.columns.tolist()\n",
    "\n",
    "# Count appearances across barcodes\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Get mean log2 enrichment\n",
    "df_max_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .mean()\n",
    "    .reset_index(name='log2_Enrichment')\n",
    ")\n",
    "\n",
    "# Merge counts and enrichment data\n",
    "df_volcano = pd.merge(df_counts, df_max_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['Reference_Amino_Acid'] = df_volcano.apply(\n",
    "    lambda row: get_reference_aa(row['Codon_Change'], row['Nucleotide_Ref'])\n",
    "    if pd.notna(row['Codon_Change']) and pd.notna(row['Nucleotide_Ref']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create labels like N501Y\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Assign categories to 'Category' column\n",
    "df_filtered = df_filtered.copy()  # Make sure we are not working on a view\n",
    "df_filtered['Category'] = pd.NA\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Neutralizing_Ab', 'Category'] = 'mAB (NEUT)'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Polyclonal_Ab', 'Category'] = 'Polyreactive pAB'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Mutant_RBD', 'Category'] = 'B cells - B.1.135 RBD vaccine'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'wildtype_RBD', 'Category'] = 'B cells - Ancestral Wuhan RBD vaccine'\n",
    "\n",
    "# Create a color palette based on the 'Category' column\n",
    "palette = {\n",
    "    'mAB (NEUT)': 'red',\n",
    "    'Polyreactive pAB': 'orange',\n",
    "    'B cells - B.1.135 RBD vaccine': 'blue',\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': 'turquoise'\n",
    "}\n",
    "\n",
    "# Create the volcano plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Shade non-significant region (0.5–2 enrichment ratio in log2 space)\n",
    "plt.axvspan(np.log2(0.5), np.log2(2), color='lightgray', alpha=0.3, zorder=0)\n",
    "\n",
    "# Plot the data with custom colors for each category\n",
    "sns.scatterplot(\n",
    "    data=df_filtered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,  # Use custom palette\n",
    "    alpha=0.8,\n",
    "    edgecolor='black',\n",
    "    s=30,\n",
    "    zorder=2\n",
    ")\n",
    "\n",
    "# Get top 10 dots for escape (log2 enrichment)\n",
    "top_escape = df_filtered.nlargest(10, 'log2_Enrichment')\n",
    "\n",
    "# Get top 10 dots for binding (sample count)\n",
    "top_binding = df_filtered.nlargest(10, 'Sample_Count')\n",
    "\n",
    "# Get top 10 dots for sample count\n",
    "top_sample_count = df_filtered.nlargest(10, 'Sample_Count')\n",
    "\n",
    "# Add labels to the plot (escape)\n",
    "texts = []\n",
    "for i, row in top_escape.iterrows():\n",
    "    texts.append(plt.text(row['log2_Enrichment'], row['Sample_Count'], row['site_label'], fontsize=10, ha='center', va='center'))\n",
    "\n",
    "# Add labels to the plot (binding)\n",
    "for i, row in top_binding.iterrows():\n",
    "    texts.append(plt.text(row['log2_Enrichment'], row['Sample_Count'], row['site_label'], fontsize=10, ha='center', va='center'))\n",
    "\n",
    "# Adjust text positions to avoid overlap\n",
    "adjust_text(texts, arrowprops=dict(arrowstyle='->', color='gray', lw=0.5))\n",
    "\n",
    "# Plot the line at x=0 for separation\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)  # Increase title font size\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14)  # Increase x-axis label font size\n",
    "plt.ylabel(\"Sample Count\", fontsize=14)  # Increase y-axis label font size\n",
    "\n",
    "# Custom legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust label positions to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Slight y-jitter function\n",
    "def add_y_jitter(arr, jitter_strength=10):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply y-jitter\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['Sample_Count'] = add_y_jitter(df_non_sig_jittered['Sample_Count'], jitter_strength=0.2)\n",
    "df_sig_jittered['Sample_Count'] = add_y_jitter(df_sig_jittered['Sample_Count'], jitter_strength=0.2)\n",
    "\n",
    "# Darker color palette\n",
    "palette = {\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': '#1f77b4',\n",
    "    'B cells - B.1.135 RBD vaccine': '#ff7f0e',\n",
    "    'mAB (NEUT)': '#2ca02c',\n",
    "    'Polyreactive pAB': '#d62728'\n",
    "}\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=14,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=10,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=2, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=2, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=12, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "# Label top 10 by escape, binding, and count\n",
    "top_10_escape = df_filtered.nlargest(10, 'log2_Enrichment')\n",
    "top_10_binding = df_filtered.nsmallest(10, 'log2_Enrichment')\n",
    "top_10_sample = df_filtered.nlargest(10, 'Sample_Count')\n",
    "top_10_labels = pd.concat([top_10_escape, top_10_binding, top_10_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Thresholds for labeling: top 5% by count and extreme enrichment\n",
    "count_thresh = df_filtered['Sample_Count'].quantile(0.95)\n",
    "escape_thresh = df_filtered['log2_Enrichment'].quantile(0.05)  # very low log2 enrichment (escape)\n",
    "binding_thresh = df_filtered['log2_Enrichment'].quantile(0.95)  # very high log2 enrichment (binding)\n",
    "\n",
    "df_high_escape_and_count = df_filtered[(df_filtered['Sample_Count'] > count_thresh) & (df_filtered['log2_Enrichment'] < escape_thresh)]\n",
    "df_high_binding_and_count = df_filtered[(df_filtered['Sample_Count'] > count_thresh) & (df_filtered['log2_Enrichment'] > binding_thresh)]\n",
    "\n",
    "additional_labels = pd.concat([df_high_escape_and_count, df_high_binding_and_count])\n",
    "\n",
    "texts = []\n",
    "for _, row in top_10_labels.iterrows():\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'], row['Sample_Count'], row['site_label'],\n",
    "        ha='center', va='center', fontsize=10\n",
    "    )\n",
    "    texts.append(text)\n",
    "\n",
    "# Add custom residue labels\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "for pos in residues_to_label:\n",
    "    residue_data = df_filtered[df_filtered['Spike_AS_Position'] == pos]\n",
    "    if not residue_data.empty:\n",
    "        text = plt.text(\n",
    "            residue_data['log2_Enrichment'].values[0],\n",
    "            residue_data['Sample_Count'].values[0],\n",
    "            f\"{residue_data['site_label'].values[0]}\",\n",
    "            fontsize=12, ha='center', va='center', color='black'\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "for _, row in additional_labels.iterrows():\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'], row['Sample_Count'], row['site_label'],\n",
    "        ha='center', va='center', fontsize=10, color='black'\n",
    "    )\n",
    "    texts.append(text)\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.2, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "plt.ylabel(\"Sample Count\", fontsize=14)\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Symmetric x-axis\n",
    "xlim = max(abs(df_filtered['log2_Enrichment'].min()), abs(df_filtered['log2_Enrichment'].max()))\n",
    "plt.xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "\n",
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Slight y-jitter function\n",
    "def add_y_jitter(arr, jitter_strength=10):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply y-jitter\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['Sample_Count'] = add_y_jitter(df_non_sig_jittered['Sample_Count'], jitter_strength=0)\n",
    "df_sig_jittered['Sample_Count'] = add_y_jitter(df_sig_jittered['Sample_Count'], jitter_strength=0)\n",
    "\n",
    "# Corrected color palette (darker turquoise)\n",
    "palette = {\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': '#1f77b4',  # Blue for Wuhan\n",
    "    'B cells - B.1.135 RBD vaccine': '#009688',  # Darker turquoise for B.1.135\n",
    "    'mAB (NEUT)': '#d62728',  # Red for NEUT\n",
    "    'Polyreactive pAB': '#ff7f0e'  # Orange for Polyreactive pAB\n",
    "}\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=14,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=14,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=10, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Label top 5 by escape, binding, and count\n",
    "top_5_escape = df_filtered.nlargest(5, 'log2_Enrichment')\n",
    "top_5_binding = df_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "top_5_sample = df_filtered.nlargest(5, 'Sample_Count')\n",
    "\n",
    "# Concatenate and drop duplicates based on 'site_label' to avoid overlap\n",
    "top_5_labels = pd.concat([top_5_escape, top_5_binding, top_5_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Thresholds for labeling: sample count > 10 and extreme enrichment\n",
    "count_thresh = df_filtered['Sample_Count'] > 10\n",
    "enrichment_thresh = df_filtered['log2_Enrichment'] > 2\n",
    "escape_thresh = df_filtered['log2_Enrichment'] < -5\n",
    "\n",
    "df_labels = df_filtered[(count_thresh & (enrichment_thresh | escape_thresh))]\n",
    "\n",
    "# Combine all labels for plotting\n",
    "labels_to_plot = pd.concat([top_5_labels, df_labels]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Define the specific residues to label\n",
    "# Define the specific residues to label\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "\n",
    "# Label the specified residues\n",
    "texts = []\n",
    "for _, row in labels_to_plot.iterrows():\n",
    "    # Ensure site_label is not NaN and check if residue is in the list\n",
    "    if pd.notna(row['site_label']) and row['Spike_AS_Position'] in residues_to_label:  # Check residue position\n",
    "        # Determine whether the label should be placed on the left or right\n",
    "        if row['log2_Enrichment'] < 0:\n",
    "            x_offset = -1.1  # Move labels to the left\n",
    "        else:\n",
    "            x_offset = 1.1  # Move labels to the right\n",
    "\n",
    "        # Adjust the y position to avoid overlap\n",
    "        y_offset = 1.1 if row['Sample_Count'] < 50 else 1.1\n",
    "\n",
    "        # Plot the label with the adjusted position\n",
    "        text = plt.text(\n",
    "            row['log2_Enrichment'] + x_offset, row['Sample_Count'] + y_offset, row['site_label'],\n",
    "            ha='center', va='center', fontsize=10, color='black'\n",
    "        )\n",
    "        texts.append(text)\n",
    "        plt.plot([row['log2_Enrichment'], row['log2_Enrichment'] + x_offset], \n",
    "                 [row['Sample_Count'], row['Sample_Count'] + y_offset], color='gray', linestyle='-', linewidth=1)\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.2, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "# Titles and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=10)  # Adjusted labelpad for the x-axis title\n",
    "plt.ylabel(\"Droplet Monoclonal Antibody repertoire\", fontsize=14)\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.ylim(bottom=0.5)\n",
    "# Symmetric x-axis\n",
    "xlim = max(abs(df_filtered['log2_Enrichment'].min()), abs(df_filtered['log2_Enrichment'].max()))\n",
    "plt.xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Slight y-jitter function\n",
    "def add_y_jitter(arr, jitter_strength=10):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply y-jitter\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['Sample_Count'] = add_y_jitter(df_non_sig_jittered['Sample_Count'], jitter_strength=0.1)\n",
    "df_sig_jittered['Sample_Count'] = add_y_jitter(df_sig_jittered['Sample_Count'], jitter_strength=0.1)\n",
    "\n",
    "# Darker color palette\n",
    "palette = {\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': '#1f77b4',\n",
    "    'B cells - B.1.135 RBD vaccine': '#ff7f0e',\n",
    "    'mAB (NEUT)': '#2ca02c',\n",
    "    'Polyreactive pAB': '#d62728'\n",
    "}\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=12,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=12,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=10, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Label top 5 by escape, binding, and count\n",
    "top_5_escape = df_filtered.nlargest(5, 'log2_Enrichment')\n",
    "top_5_binding = df_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "top_5_sample = df_filtered.nlargest(5, 'Sample_Count')\n",
    "\n",
    "# Concatenate and drop duplicates based on 'site_label' to avoid overlap\n",
    "top_5_labels = pd.concat([top_5_escape, top_5_binding, top_5_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Thresholds for labeling: sample count > 10 and extreme enrichment\n",
    "count_thresh = df_filtered['Sample_Count'] > 10\n",
    "enrichment_thresh = df_filtered['log2_Enrichment'] > 2\n",
    "escape_thresh = df_filtered['log2_Enrichment'] < -4\n",
    "\n",
    "df_labels = df_filtered[(count_thresh & (enrichment_thresh | escape_thresh))]\n",
    "\n",
    "# Combine all labels for plotting\n",
    "labels_to_plot = pd.concat([top_5_labels, df_labels]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "texts = []\n",
    "for _, row in labels_to_plot.iterrows():\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'], row['Sample_Count'], row['site_label'],\n",
    "        ha='center', va='center', fontsize=10\n",
    "    )\n",
    "    texts.append(text)\n",
    "    plt.plot([row['log2_Enrichment'], row['log2_Enrichment']], [row['Sample_Count'], row['Sample_Count'] + 0.5], color='gray', linestyle='-', linewidth=1)\n",
    "\n",
    "# Add custom residue labels\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "for pos in residues_to_label:\n",
    "    residue_data = df_filtered[df_filtered['Spike_AS_Position'] == pos]\n",
    "    if not residue_data.empty:\n",
    "        text = plt.text(\n",
    "            residue_data['log2_Enrichment'].values[0],\n",
    "            residue_data['Sample_Count'].values[0],\n",
    "            f\"{residue_data['site_label'].values[0]}\",\n",
    "            fontsize=10, ha='center', va='center', color='black'\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.2, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "plt.ylabel(\"Sample Count\", fontsize=14)\n",
    "plt.xlim(-xlim, xlim)\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Symmetric x-axis\n",
    "xlim = max(abs(df_filtered['log2_Enrichment'].min()), abs(df_filtered['log2_Enrichment'].max()))\n",
    "plt.xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "\n",
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Slight y-jitter function\n",
    "def add_y_jitter(arr, jitter_strength=10):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply y-jitter\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['Sample_Count'] = add_y_jitter(df_non_sig_jittered['Sample_Count'], jitter_strength=0.1)\n",
    "df_sig_jittered['Sample_Count'] = add_y_jitter(df_sig_jittered['Sample_Count'], jitter_strength=0.1)\n",
    "\n",
    "# Darker color palette\n",
    "palette = {\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': '#1f77b4',  # Blue\n",
    "    'B cells - B.1.135 RBD vaccine': '#40E0D0',  # Turquoise\n",
    "    'mAB (NEUT)': '#FF0000',  # Red (Neutralizing antibody)\n",
    "    'Polyreactive pAB': '#FFA500'  # Orange (Polyclonal)\n",
    "}\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=14,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=10,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=10, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Label top 5 by escape, binding, and count\n",
    "top_5_escape = df_filtered.nlargest(5, 'log2_Enrichment')\n",
    "top_5_binding = df_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "top_5_sample = df_filtered.nlargest(5, 'Sample_Count')\n",
    "\n",
    "# Concatenate and drop duplicates based on 'site_label' to avoid overlap\n",
    "top_5_labels = pd.concat([top_5_escape, top_5_binding, top_5_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Thresholds for labeling: sample count > 4 and extreme enrichment (> 2 or < -2)\n",
    "count_thresh = df_filtered['Sample_Count'] > 4\n",
    "enrichment_thresh = (df_filtered['log2_Enrichment'] > 2) | (df_filtered['log2_Enrichment'] < -2)\n",
    "\n",
    "df_labels = df_filtered[count_thresh & enrichment_thresh]\n",
    "\n",
    "# Combine all labels for plotting\n",
    "labels_to_plot = pd.concat([top_5_labels, df_labels]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "texts = []\n",
    "for _, row in labels_to_plot.iterrows():\n",
    "    if row['log2_Enrichment'] < 0:  # Escape labels to the left\n",
    "        text = plt.text(\n",
    "            row['log2_Enrichment'] - 0.5,  # Shift to the left\n",
    "            row['Sample_Count'] + 0.5,  # Shift up\n",
    "            row['site_label'],\n",
    "            ha='center', va='center', fontsize=10\n",
    "        )\n",
    "        plt.plot([row['log2_Enrichment'], row['log2_Enrichment'] - 0.5],\n",
    "                 [row['Sample_Count'], row['Sample_Count'] + 0.5], color='gray', linestyle='-', linewidth=1)\n",
    "    else:  # Binding labels to the right\n",
    "        text = plt.text(\n",
    "            row['log2_Enrichment'] + 0.5,  # Shift to the right\n",
    "            row['Sample_Count'] + 0.5,  # Shift up\n",
    "            row['site_label'],\n",
    "            ha='center', va='center', fontsize=10\n",
    "        )\n",
    "        plt.plot([row['log2_Enrichment'], row['log2_Enrichment'] + 0.5],\n",
    "                 [row['Sample_Count'], row['Sample_Count'] + 0.5], color='gray', linestyle='-', linewidth=1)\n",
    "\n",
    "    texts.append(text)\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.2, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "plt.ylabel(\"Single-Antibody Repertoire n=1x droplet\", fontsize=14)\n",
    "plt.ylim(bottom=0.5)\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Symmetric x-axis\n",
    "xlim = 6\n",
    "plt.xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "\n",
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Slight y-jitter function\n",
    "def add_y_jitter(arr, jitter_strength=10):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply y-jitter\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['Sample_Count'] = add_y_jitter(df_non_sig_jittered['Sample_Count'], jitter_strength=0.2)\n",
    "df_sig_jittered['Sample_Count'] = add_y_jitter(df_sig_jittered['Sample_Count'], jitter_strength=0.2)\n",
    "\n",
    "# Darker color palette\n",
    "palette = {\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': '#1f77b4',\n",
    "    'B cells - B.1.135 RBD vaccine': '#ff7f0e',\n",
    "    'mAB (NEUT)': '#2ca02c',\n",
    "    'Polyreactive pAB': '#d62728'\n",
    "}\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=14,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=10,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=10, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Label top 5 by escape, binding, and count\n",
    "top_5_escape = df_filtered.nlargest(5, 'log2_Enrichment')\n",
    "top_5_binding = df_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "top_5_sample = df_filtered.nlargest(5, 'Sample_Count')\n",
    "\n",
    "# Concatenate and drop duplicates based on 'site_label' to avoid overlap\n",
    "top_5_labels = pd.concat([top_5_escape, top_5_binding, top_5_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Thresholds for labeling: sample count > 10 and extreme enrichment\n",
    "count_thresh = df_filtered['Sample_Count'] > 10\n",
    "enrichment_thresh = df_filtered['log2_Enrichment'] > 2\n",
    "escape_thresh = df_filtered['log2_Enrichment'] < -5\n",
    "\n",
    "df_labels = df_filtered[(count_thresh & (enrichment_thresh | escape_thresh))]\n",
    "\n",
    "# Combine all labels for plotting\n",
    "labels_to_plot = pd.concat([top_5_labels, df_labels]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "texts = []\n",
    "for _, row in labels_to_plot.iterrows():\n",
    "    # Determine whether the label should be placed on the left or right\n",
    "    if row['log2_Enrichment'] < 0:\n",
    "        x_offset = -1.2  # Move labels to the left\n",
    "    else:\n",
    "        x_offset = 1.2  # Move labels to the right\n",
    "\n",
    "    # Adjust the y position to avoid overlap\n",
    "    y_offset = 1.9 if row['Sample_Count'] < 50 else 3\n",
    "\n",
    "    # Plot the label with the adjusted position\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'] + x_offset, row['Sample_Count'] + y_offset, row['site_label'],\n",
    "        ha='center', va='center', fontsize=10, color='black'\n",
    "    )\n",
    "    texts.append(text)\n",
    "    plt.plot([row['log2_Enrichment'], row['log2_Enrichment'] + x_offset], \n",
    "             [row['Sample_Count'], row['Sample_Count'] + y_offset], color='gray', linestyle='-', linewidth=1)\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.2, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "plt.ylabel(\"Monoclonal Antibody repertoire [n = 1x droplet]\", fontsize=14)\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.ylim(bottom=0.5)\n",
    "# Symmetric x-axis\n",
    "xlim = max(abs(df_filtered['log2_Enrichment'].min()), abs(df_filtered['log2_Enrichment'].max()))\n",
    "plt.xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "\n",
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Slight y-jitter function\n",
    "def add_y_jitter(arr, jitter_strength=10):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply y-jitter\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['Sample_Count'] = add_y_jitter(df_non_sig_jittered['Sample_Count'], jitter_strength=0.15)\n",
    "df_sig_jittered['Sample_Count'] = add_y_jitter(df_sig_jittered['Sample_Count'], jitter_strength=0.15)\n",
    "\n",
    "# Corrected color palette\n",
    "palette = {\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': '#1f77b4',  # Blue for Wuhan\n",
    "    'B cells - B.1.135 RBD vaccine': '#00bfae',  # Turquoise for B.1.135\n",
    "    'mAB (NEUT)': '#d62728',  # Red for NEUT\n",
    "    'Polyreactive pAB': '#ff7f0e'  # Orange for Polyreactive pAB\n",
    "}\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=10,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=10,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=10, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Label top 5 by escape, binding, and count\n",
    "top_5_escape = df_filtered.nlargest(5, 'log2_Enrichment')\n",
    "top_5_binding = df_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "top_5_sample = df_filtered.nlargest(5, 'Sample_Count')\n",
    "\n",
    "# Concatenate and drop duplicates based on 'site_label' to avoid overlap\n",
    "top_5_labels = pd.concat([top_5_escape, top_5_binding, top_5_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Thresholds for labeling: sample count > 10 and extreme enrichment\n",
    "count_thresh = df_filtered['Sample_Count'] > 10\n",
    "enrichment_thresh = df_filtered['log2_Enrichment'] > 2\n",
    "escape_thresh = df_filtered['log2_Enrichment'] < -5\n",
    "\n",
    "df_labels = df_filtered[(count_thresh & (enrichment_thresh | escape_thresh))]\n",
    "\n",
    "# Combine all labels for plotting\n",
    "labels_to_plot = pd.concat([top_5_labels, df_labels]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "texts = []\n",
    "for _, row in labels_to_plot.iterrows():\n",
    "    # Determine whether the label should be placed on the left or right\n",
    "    if row['log2_Enrichment'] < 0:\n",
    "        x_offset = -1.1  # Move labels to the left\n",
    "    else:\n",
    "        x_offset = 1.1  # Move labels to the right\n",
    "\n",
    "    # Adjust the y position to avoid overlap\n",
    "    y_offset = 1.1 if row['Sample_Count'] < 50 else 1.1\n",
    "\n",
    "    # Plot the label with the adjusted position\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'] + x_offset, row['Sample_Count'] + y_offset, row['site_label'],\n",
    "        ha='center', va='center', fontsize=10, color='black'\n",
    "    )\n",
    "    texts.append(text)\n",
    "    plt.plot([row['log2_Enrichment'], row['log2_Enrichment'] + x_offset], \n",
    "             [row['Sample_Count'], row['Sample_Count'] + y_offset], color='gray', linestyle='-', linewidth=1)\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.2, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "plt.ylabel(\"Droplet Monoclonal Antibody repertoire\", fontsize=14)\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.ylim(bottom=0.5)\n",
    "plt.xlim(-6, 6)\n",
    "# Symmetric x-axis\n",
    "xlim = max(abs(df_filtered['log2_Enrichment'].min()), abs(df_filtered['log2_Enrichment'].max()))\n",
    "plt.xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# ------------------ Data Preparation ------------------\n",
    "\n",
    "# Assuming `df_volcano` is already prepared and contains the necessary columns\n",
    "# Filter out synonymous mutations or stop codons\n",
    "df_volcano = df_volcano[~df_volcano['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "# Top 10 enriched, escaped, and sample count mutations\n",
    "df_volcano['label_this'] = False\n",
    "\n",
    "# Top 10 enriched\n",
    "top_enriched = df_volcano.nlargest(10, 'log2_Enrichment')\n",
    "\n",
    "# Top 10 escaped (most negative enrichment)\n",
    "top_escaped = df_volcano.nsmallest(10, 'log2_Enrichment')\n",
    "\n",
    "# Top 10 by sample count\n",
    "top_sample = df_volcano.nlargest(10, 'Sample_Count')\n",
    "\n",
    "# Combine top 10 from each\n",
    "label_indices = pd.concat([top_enriched, top_escaped, top_sample]).index.unique()\n",
    "df_volcano.loc[label_indices, 'label_this'] = True\n",
    "\n",
    "# ------------------ Plot ------------------\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_volcano,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    alpha=0.8,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Add directional labels with arrows\n",
    "for _, row in df_volcano[df_volcano['label_this']].iterrows():\n",
    "    if row['log2_Enrichment'] >= 0:\n",
    "        offset = (10, 5)  # closer to point to keep within plot\n",
    "        ha = 'left'\n",
    "    else:\n",
    "        offset = (-10, 5)\n",
    "        ha = 'right'\n",
    "    \n",
    "    plt.annotate(\n",
    "        row['site_label'],\n",
    "        xy=(row['log2_Enrichment'], row['Sample_Count']),\n",
    "        xytext=offset,\n",
    "        textcoords='offset points',\n",
    "        ha=ha,\n",
    "        va='bottom',\n",
    "        fontsize=8,\n",
    "        arrowprops=dict(arrowstyle='-', lw=0.6, color='gray'),\n",
    "        bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "        clip_on=True  # Keep inside axes limits\n",
    "    )\n",
    "\n",
    "# Vertical line for the center (log2(1) = 0)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Title and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout and display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "fasta_file = r'/Users/lucaschlotheuber/Desktop/ETH/RBD201_DMS1.fa'\n",
    "\n",
    "# Read the FASTA file\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    wuhan_sequence = str(record.seq)\n",
    "    break  # Assuming there's only one sequence in the FASTA file\n",
    "\n",
    "\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "\n",
    "df_total = pd.read_excel(\n",
    "    file_path,\n",
    "    usecols=[\n",
    "        \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\", \"Amino_Acid\",\n",
    "        \"Type_of_Mutation\", \"Enrichment_Ratio\", \"barcode\", \"immunization\",\n",
    "        \"condition\", \"Total_Reads\", \"Nucleotide_Ref\", \"Codon_Change\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Subtract 5 to every position of Spike_AS_Position. (In excel sheets this starts at 336, instead of 331) I could also just have fixed the excel sheets. \n",
    "df_total[\"Spike_AS_Position\"] = df_total[\"Spike_AS_Position\"] - 5\n",
    "\n",
    "#Removing ~5000 datapoints with \"inf\" values in the Enrichment_Ratio column and discarding reads with less than 10.000 total reads\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio','Amino_Acid'])\n",
    "\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 1000]\n",
    "\n",
    "immunization = \"Wuhan_Sequence\"\n",
    "barcode = \"Wuhan_Barcode\"\n",
    "\n",
    "data_wuhan = []\n",
    "for position, amino_acid in enumerate(wuhan_sequence, start=1):\n",
    "    data_wuhan.append({\n",
    "        'DMS_RBD_AS_position': position,\n",
    "        'Spike_AS_Position': position + 330,\n",
    "        'Amino_Acid': amino_acid,\n",
    "        'immunization': immunization,\n",
    "        'barcode': barcode,\n",
    "        'Enrichment_Ratio': 1,# Assuming an enrichment ratio of 1 for simplicity\n",
    "    })\n",
    "\n",
    "# Filter escape mutations (Enrichment_Ratio < 1 and not zero)\n",
    "print(\"Columns in total:\")\n",
    "print(df_total.columns)\n",
    "df_escape = df_total[(df_total['Enrichment_Ratio'] < 1) & (df_total['Enrichment_Ratio'] != 0)].copy()\n",
    "\n",
    "# Invert and log-transform Enrichment_Ratio\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x)\n",
    "df_escape['Enrichment_Ratio_log2'] = np.log2(df_escape['Enrichment_Ratio_inverted'])\n",
    "\n",
    "# Extract relevant info (avoid duplication of Nucleotide_Ref, Codon_Change per group)\n",
    "df_info = df_escape[['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization', 'Nucleotide_Ref', 'Codon_Change']].drop_duplicates()\n",
    "\n",
    "# Aggregate\n",
    "df_escape_agg = df_escape.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio_log2': 'mean'})\n",
    "\n",
    "# Merge the info back in\n",
    "df_escape_agg = pd.merge(df_escape_agg, df_info, on=['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], how='left')\n",
    "\n",
    "# Merge necessary columns from df_total into df_logo_agg before aggregation\n",
    "df_logo_agg = df_total[['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization', 'Enrichment_Ratio', 'Nucleotide_Ref', 'Codon_Change']]\n",
    "\n",
    "# Perform the aggregation\n",
    "df_logo_agg = df_logo_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean',\n",
    "    'Nucleotide_Ref': 'first',  # Assuming 'Nucleotide_Ref' is the same for all rows in each group\n",
    "    'Codon_Change': 'first'  # Assuming 'Codon_Change' is the same for all rows in each group\n",
    "})\n",
    "\n",
    "print(\"Columns in df_combined_volcano before processing:\")\n",
    "print(df_combined_volcano.columns)\n",
    "\n",
    "\n",
    "# Combine enriched and escaped data\n",
    "df_combined_volcano = pd.concat([\n",
    "    df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1],\n",
    "    df_escape.assign(Enrichment_Ratio=df_escape['Enrichment_Ratio'])  # keep column naming consistent\n",
    "])\n",
    "\n",
    "\n",
    "print(\"Columns in df_combined_volcano after combining:\")\n",
    "print(df_combined_volcano.columns)\n",
    "\n",
    "# Check the column names of df_logo_agg and df_escape\n",
    "print(\"Columns in df_logo_agg:\")\n",
    "print(df_logo_agg.columns)\n",
    "\n",
    "print(\"\\nColumns in df_escape:\")\n",
    "print(df_escape.columns)\n",
    "\n",
    "# Check if the necessary columns exist\n",
    "necessary_columns = ['Nucleotide_Ref', 'Codon_Change']\n",
    "\n",
    "for column in necessary_columns:\n",
    "    print(f\"\\nChecking if '{column}' is present in df_logo_agg:\")\n",
    "    print(column in df_logo_agg.columns)\n",
    "\n",
    "    print(f\"Checking if '{column}' is present in df_escape:\")\n",
    "    print(column in df_escape.columns)\n",
    "\n",
    "# After combining the datasets, ensure you're working with df_combined_volcano\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Enrichment_Ratio'] > 0]\n",
    "\n",
    "print(df_combined_volcano.columns)\n",
    "\n",
    "# Add log2 enrichment to df_combined_volcano\n",
    "df_combined_volcano['log2_Enrichment'] = np.log2(df_combined_volcano['Enrichment_Ratio'])\n",
    "\n",
    "\n",
    "print(\"Columns after adding log2_Enrichment:\", df_combined_volcano.columns)\n",
    "\n",
    "# Count how often each mutation appears across barcodes (like in df_combined)\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "print(\"Columns after counting mutations:\", df_combined_volcano.columns)\n",
    "\n",
    "# Get max log2 enrichment ratio for coloring (optional aesthetic)\n",
    "df_max_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .mean()\n",
    "    .reset_index(name='log2_Enrichment')\n",
    ")\n",
    "\n",
    "# Rename the 'log2_Enrichment' column in df_max_enrichment to avoid conflicts during the merge\n",
    "df_max_enrichment = df_max_enrichment.rename(columns={'log2_Enrichment': 'log2_Enrichment_max'})\n",
    "\n",
    "# Merge count and enrichment\n",
    "df_combined_volcano = pd.merge(\n",
    "    df_combined_volcano,  # Keep all columns from original df_combined_volcano\n",
    "    df_counts[['Spike_AS_Position', 'Amino_Acid', 'immunization', 'Sample_Count']],  # Keep only relevant columns\n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Merge log2 enrichment (ensuring no conflict)\n",
    "df_combined_volcano = pd.merge(\n",
    "    df_combined_volcano,  # Keep all columns from previous merge\n",
    "    df_max_enrichment, \n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename the new column if necessary to match the naming convention\n",
    "df_combined_volcano = df_combined_volcano.rename(columns={'log2_Enrichment_max': 'log2_Enrichment'})\n",
    "\n",
    "\n",
    "print(\"Columns after both merges:\", df_combined_volcano.columns)\n",
    "\n",
    "# Assign label for volcano plot\n",
    "df_combined_volcano['site_label'] = df_combined_volcano['Amino_Acid'] + \"_\" + df_combined_volcano['Spike_AS_Position'].astype(str)\n",
    "\n",
    "print(df_combined_volcano.columns)\n",
    "\n",
    "# Filter to positions of interest (optional)\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Spike_AS_Position'] > 365]\n",
    "\n",
    "print(df_combined_volcano.columns)\n",
    "\n",
    "print(df_combined_volcano.dtypes)\n",
    "\n",
    "\n",
    "# Function to get amino acid from codon\n",
    "def get_amino_acid(codon):\n",
    "    \"\"\" Translate a codon to the corresponding amino acid \"\"\"\n",
    "    try:\n",
    "        return str(Seq(codon).translate())\n",
    "    except:\n",
    "        return '?'  # Return '?' if translation fails (e.g., invalid codon)\n",
    "\n",
    "# ------------------ Data Preparation ------------------\n",
    "\n",
    "# Assuming df_combined_volcano is already prepared and contains the necessary columns\n",
    "# Filter out synonymous mutations or stop codons\n",
    "df_combined_volcano = df_combined_volcano[~df_combined_volcano['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "# Compute reference codon and amino acid\n",
    "df_combined_volcano['Reference_Codon'] = df_combined_volcano['Nucleotide_Ref'] + df_combined_volcano['Codon_Change']\n",
    "df_combined_volcano['Reference_Amino_Acid'] = df_combined_volcano['Reference_Codon'].apply(get_amino_acid)\n",
    "\n",
    "# Generate mutation label in the format \"ReferenceAminoAcidPositionMutatedAminoAcid\"\n",
    "df_combined_volcano['mutation_label'] = df_combined_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if row['Amino_Acid'] != row['Reference_Amino_Acid'] else \"\", \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Top 10 enriched, escaped, and sample count mutations\n",
    "df_combined_volcano['label_this'] = False\n",
    "\n",
    "# Top 10 enriched\n",
    "top_enriched = df_combined_volcano.nlargest(10, 'log2_Enrichment')\n",
    "\n",
    "# Top 10 escaped (most negative enrichment)\n",
    "top_escaped = df_combined_volcano.nsmallest(10, 'log2_Enrichment')\n",
    "\n",
    "# Top 10 by sample count\n",
    "top_sample = df_combined_volcano.nlargest(10, 'Sample_Count')\n",
    "\n",
    "# Combine top 10 from each\n",
    "label_indices = pd.concat([top_enriched, top_escaped, top_sample]).index.unique()\n",
    "df_combined_volcano.loc[label_indices, 'label_this'] = True\n",
    "\n",
    "# ------------------ Plot ------------------\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_combined_volcano,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    alpha=0.8,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Add directional labels with arrows\n",
    "for _, row in df_combined_volcano[df_combined_volcano['label_this']].iterrows():\n",
    "    if row['log2_Enrichment'] >= 0:\n",
    "        offset = (10, 5)  # closer to point to keep within plot\n",
    "        ha = 'left'\n",
    "    else:\n",
    "        offset = (-10, 5)\n",
    "        ha = 'right'\n",
    "    \n",
    "    # Use the mutation label for annotation\n",
    "    plt.annotate(\n",
    "        row['mutation_label'],  # Use the mutation label for annotation\n",
    "        xy=(row['log2_Enrichment'], row['Sample_Count']),\n",
    "        xytext=offset,\n",
    "        textcoords='offset points',\n",
    "        ha=ha,\n",
    "        va='bottom',\n",
    "        fontsize=8,\n",
    "        arrowprops=dict(arrowstyle='-', lw=0.6, color='gray'),\n",
    "        bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "        clip_on=True  # Keep inside axes limits\n",
    "    )\n",
    "\n",
    "# Vertical line for the center (log2(1) = 0)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Title and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout and display plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volcanoplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Combine enriched and escaped data\n",
    "df_combined_volcano = pd.concat([\n",
    "    df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1],\n",
    "    df_escape.assign(Enrichment_Ratio=df_escape['Enrichment_Ratio'])  # keep column naming consistent\n",
    "])\n",
    "\n",
    "# Drop zero or invalid enrichment ratios\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Enrichment_Ratio'] > 0]\n",
    "\n",
    "# Add log2 enrichment\n",
    "df_combined_volcano['log2_Enrichment'] = np.log2(df_combined_volcano['Enrichment_Ratio'])\n",
    "\n",
    "# Count how often each mutation appears across barcodes (like in df_combined)\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Get max log2 enrichment ratio for coloring (optional aesthetic)\n",
    "df_max_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .mean()\n",
    "    .reset_index(name='log2_Enrichment')\n",
    ")\n",
    "\n",
    "# Merge count and enrichment\n",
    "df_volcano = pd.merge(df_counts, df_max_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Filter to positions of interest (optional)\n",
    "df_volcano = df_volcano[df_volcano['Spike_AS_Position'] > 365]\n",
    "\n",
    "# ------- Add E484K-style mutation labels -------\n",
    "# ------- Add E484K-style mutation labels for specific positions -------\n",
    "\n",
    "# Define ancestral (Wuhan) residues at key positions\n",
    "wuhan_strain_aa = {\n",
    "    417: 'K',\n",
    "    452: 'L',\n",
    "    484: 'E',\n",
    "    501: 'N',\n",
    "    346: 'R',\n",
    "    # Add more if needed\n",
    "}\n",
    "\n",
    "# Generate mutation label like E484K\n",
    "df_volcano['mutation_label'] = df_volcano.apply(\n",
    "    lambda row: (\n",
    "        f\"{wuhan_strain_aa.get(row['Spike_AS_Position'], '?')}\"\n",
    "        f\"{row['Spike_AS_Position']}\"\n",
    "        f\"{row['Amino_Acid']}\"\n",
    "    ) if row['Spike_AS_Position'] in wuhan_strain_aa else \"\",\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Label only mutations at selected positions\n",
    "positions_to_label = set(wuhan_strain_aa.keys())\n",
    "df_volcano['label_this'] = df_volcano['Spike_AS_Position'].isin(positions_to_label)\n",
    "\n",
    "\n",
    "# ------------------ PLOT ------------------\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_volcano,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    alpha=0.8,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Add text labels for selected mutations\n",
    "for _, row in df_volcano[df_volcano['label_this']].iterrows():\n",
    "    plt.text(\n",
    "        row['log2_Enrichment'],\n",
    "        row['Sample_Count'] + 0.5,  # offset to avoid overlap\n",
    "        row['mutation_label'],\n",
    "        fontsize=12,\n",
    "        ha='center',\n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')  # Center at log2(1) = 0\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "# Define a function to calculate the reference amino acid\n",
    "def get_reference_aa(codon_change, nucleotide_ref):\n",
    "    original_codon = ''.join(\n",
    "        [nucleotide_ref if base.isupper() else base for base in codon_change]\n",
    "    )\n",
    "    return Seq(original_codon).translate()\n",
    "\n",
    "# Combine enriched and escaped data\n",
    "df_combined_volcano = pd.concat([\n",
    "    df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1],\n",
    "    df_escape.assign(Enrichment_Ratio=df_escape['Enrichment_Ratio'])\n",
    "])\n",
    "\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Enrichment_Ratio'] > 0]\n",
    "df_combined_volcano['log2_Enrichment'] = np.log2(df_combined_volcano['Enrichment_Ratio'])\n",
    "\n",
    "# Retain all columns from the original data frame\n",
    "original_columns = df_combined_volcano.columns.tolist()\n",
    "\n",
    "# Count appearances across barcodes\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Get mean log2 enrichment\n",
    "df_max_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .mean()\n",
    "    .reset_index(name='log2_Enrichment')\n",
    ")\n",
    "\n",
    "# Merge counts and enrichment data\n",
    "df_volcano = pd.merge(df_counts, df_max_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['Reference_Amino_Acid'] = df_volcano.apply(\n",
    "    lambda row: get_reference_aa(row['Codon_Change'], row['Nucleotide_Ref'])\n",
    "    if pd.notna(row['Codon_Change']) and pd.notna(row['Nucleotide_Ref']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create labels like N501Y\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Assign categories to 'Category' column\n",
    "df_filtered = df_filtered.copy()\n",
    "df_filtered['Category'] = pd.NA\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Neutralizing_Ab', 'Category'] = 'mAB (NEUT)'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Polyclonal_Ab', 'Category'] = 'Polyreactive pAB'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Mutant_RBD', 'Category'] = 'B cells - B.1.135 RBD vaccine'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'wildtype_RBD', 'Category'] = 'B cells - Ancestral Wuhan RBD vaccine'\n",
    "\n",
    "# Create a color palette based on the 'Category' column\n",
    "palette = {\n",
    "    'mAB (NEUT)': 'red',\n",
    "    'Polyreactive pAB': 'orange',\n",
    "    'B cells - B.1.135 RBD vaccine': 'blue',\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': 'turquoise'\n",
    "}\n",
    "\n",
    "# Create the volcano plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Shade non-significant region (0.5–2 enrichment ratio in log2 space) with 50% transparency\n",
    "plt.axvspan(np.log2(0.5), np.log2(2), color='gray', alpha=0.5, zorder=2)\n",
    "\n",
    "# Add black dotted lines for the non-significant region borders\n",
    "plt.plot([np.log2(0.5), np.log2(0.5)], [0, df_filtered['Sample_Count'].max()], 'k--', lw=2, zorder=3)\n",
    "plt.plot([np.log2(2), np.log2(2)], [0, df_filtered['Sample_Count'].max()], 'k--', lw=2, zorder=3)\n",
    "\n",
    "# Label the intersection of the non-significant area with the x-axis\n",
    "plt.text(np.log2(0.5), -5, 'log2(0.5)', ha='center', va='center', fontsize=12, color='black')\n",
    "plt.text(np.log2(2), -5, 'log2(2)', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "# Plot the data with custom colors for each category\n",
    "sns.scatterplot(\n",
    "    data=df_filtered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.8,\n",
    "    edgecolor='black',\n",
    "    s=30,\n",
    "    zorder=4,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Ensure we label each dot only once\n",
    "top_10_escape = df_filtered.nlargest(10, 'log2_Enrichment')\n",
    "top_10_binding = df_filtered.nsmallest(10, 'log2_Enrichment')\n",
    "top_10_sample = df_filtered.nlargest(10, 'Sample_Count')\n",
    "\n",
    "# Concatenate the dataframes and drop duplicates to ensure unique labels\n",
    "top_10_labels = pd.concat([top_10_escape, top_10_binding, top_10_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Add labels\n",
    "texts = []\n",
    "for _, row in top_10_labels.iterrows():\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'], row['Sample_Count'], row['site_label'],\n",
    "        ha='center', va='center', fontsize=10\n",
    "    )\n",
    "    texts.append(text)\n",
    "\n",
    "# Add labels for specific residues\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "for pos in residues_to_label:\n",
    "    residue_data = df_filtered[df_filtered['Spike_AS_Position'] == pos]\n",
    "    if not residue_data.empty:\n",
    "        plt.text(\n",
    "            residue_data['log2_Enrichment'].values[0],\n",
    "            residue_data['Sample_Count'].values[0],\n",
    "            f\"{residue_data['site_label'].values[0]}\",\n",
    "            fontsize=12, ha='center', va='center', color='black'\n",
    "        )\n",
    "\n",
    "# Use adjustText to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.1, army_strength=2.0)\n",
    "\n",
    "# Adjust x-axis title to avoid overlap with shaded area\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)  # Adjusted x-axis label position\n",
    "plt.ylabel(\"Sample Count\", fontsize=14)\n",
    "\n",
    "# Custom legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from adjustText import adjust_text\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "# Define a function to calculate the reference amino acid\n",
    "def get_reference_aa(codon_change, nucleotide_ref):\n",
    "    original_codon = ''.join(\n",
    "        [nucleotide_ref if base.isupper() else base for base in codon_change]\n",
    "    )\n",
    "    return Seq(original_codon).translate()\n",
    "\n",
    "# Combine enriched and escaped data\n",
    "df_combined_volcano = pd.concat([\n",
    "    df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1],\n",
    "    df_escape.assign(Enrichment_Ratio=df_escape['Enrichment_Ratio'])\n",
    "])\n",
    "\n",
    "df_combined_volcano = df_combined_volcano[df_combined_volcano['Enrichment_Ratio'] > 0]\n",
    "df_combined_volcano['log2_Enrichment'] = np.log2(df_combined_volcano['Enrichment_Ratio'])\n",
    "\n",
    "# Retain all columns from the original data frame\n",
    "original_columns = df_combined_volcano.columns.tolist()\n",
    "\n",
    "# Count appearances across barcodes\n",
    "df_counts = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Get mean log2 enrichment\n",
    "df_max_enrichment = (\n",
    "    df_combined_volcano\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['log2_Enrichment']\n",
    "    .mean()\n",
    "    .reset_index(name='log2_Enrichment')\n",
    ")\n",
    "\n",
    "# Merge counts and enrichment data\n",
    "df_volcano = pd.merge(df_counts, df_max_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Merge with the original data to retain all columns\n",
    "df_volcano = pd.merge(df_volcano, df_combined_volcano[original_columns], on=['Spike_AS_Position', 'Amino_Acid', 'immunization'], how='left')\n",
    "\n",
    "# Rename the 'log2_Enrichment' columns to keep only one\n",
    "df_volcano['log2_Enrichment'] = df_volcano['log2_Enrichment_x']\n",
    "df_volcano.drop(columns=['log2_Enrichment_x', 'log2_Enrichment_y'], inplace=True)\n",
    "\n",
    "# Assign mutation label like E484K\n",
    "df_volcano['Reference_Amino_Acid'] = df_volcano.apply(\n",
    "    lambda row: get_reference_aa(row['Codon_Change'], row['Nucleotide_Ref'])\n",
    "    if pd.notna(row['Codon_Change']) and pd.notna(row['Nucleotide_Ref']) else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Create labels like N501Y\n",
    "df_volcano['site_label'] = df_volcano.apply(\n",
    "    lambda row: f\"{row['Reference_Amino_Acid']}{row['Spike_AS_Position']}{row['Amino_Acid']}\"\n",
    "    if pd.notna(row['Reference_Amino_Acid']) and pd.notna(row['Amino_Acid']) else '',\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Exclude synonymous mutations and stop codons\n",
    "df_volcano = df_volcano[df_volcano['Amino_Acid'].notna()]\n",
    "df_volcano['is_synonymous'] = df_volcano['site_label'].str[0] == df_volcano['site_label'].str[-1]\n",
    "stop_codons = ['*', 'Stop', 'X']\n",
    "df_filtered = df_volcano[\n",
    "    (~df_volcano['Amino_Acid'].isin(stop_codons)) &\n",
    "    (~df_volcano['is_synonymous'])\n",
    "]\n",
    "\n",
    "# Assign categories to 'Category' column\n",
    "df_filtered = df_filtered.copy()\n",
    "df_filtered['Category'] = pd.NA\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Neutralizing_Ab', 'Category'] = 'mAB (NEUT)'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Polyclonal_Ab', 'Category'] = 'Polyreactive pAB'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'Mutant_RBD', 'Category'] = 'B cells - B.1.135 RBD vaccine'\n",
    "df_filtered.loc[df_filtered['immunization'] == 'wildtype_RBD', 'Category'] = 'B cells - Ancestral Wuhan RBD vaccine'\n",
    "\n",
    "# Create a color palette based on the 'Category' column\n",
    "palette = {\n",
    "    'mAB (NEUT)': 'red',\n",
    "    'Polyreactive pAB': 'orange',\n",
    "    'B cells - B.1.135 RBD vaccine': 'blue',\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': 'turquoise'\n",
    "}\n",
    "\n",
    "# Create the volcano plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Shade non-significant region (0.5–2 enrichment ratio in log2 space) with 50% transparency\n",
    "plt.axvspan(np.log2(0.5), np.log2(2), color='gray', alpha=0.5, zorder=2)\n",
    "\n",
    "# Add black dotted lines for the non-significant region borders\n",
    "plt.plot([np.log2(0.5), np.log2(0.5)], [0, df_filtered['Sample_Count'].max()], 'k--', lw=2, zorder=3)\n",
    "plt.plot([np.log2(2), np.log2(2)], [0, df_filtered['Sample_Count'].max()], 'k--', lw=2, zorder=3)\n",
    "\n",
    "# Label the intersection of the non-significant area with the x-axis\n",
    "plt.text(np.log2(0.5), -5, 'log2(0.5)', ha='center', va='center', fontsize=12, color='black')\n",
    "plt.text(np.log2(2), -5, 'log2(2)', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "# Plot the data with custom colors for each category\n",
    "sns.scatterplot(\n",
    "    data=df_filtered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.8,\n",
    "    edgecolor='black',\n",
    "    s=15,\n",
    "    zorder=4,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Ensure we label each dot only once\n",
    "top_10_escape = df_filtered.nlargest(10, 'log2_Enrichment')\n",
    "top_10_binding = df_filtered.nsmallest(10, 'log2_Enrichment')\n",
    "top_10_sample = df_filtered.nlargest(10, 'Sample_Count')\n",
    "\n",
    "# Concatenate the dataframes and drop duplicates to ensure unique labels\n",
    "top_10_labels = pd.concat([top_10_escape, top_10_binding, top_10_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Add labels\n",
    "texts = []\n",
    "for _, row in top_10_labels.iterrows():\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'], row['Sample_Count'], row['site_label'],\n",
    "        ha='center', va='center', fontsize=10\n",
    "    )\n",
    "    texts.append(text)\n",
    "\n",
    "# Add labels for specific residues\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "for pos in residues_to_label:\n",
    "    residue_data = df_filtered[df_filtered['Spike_AS_Position'] == pos]\n",
    "    if not residue_data.empty:\n",
    "        plt.text(\n",
    "            residue_data['log2_Enrichment'].values[0],\n",
    "            residue_data['Sample_Count'].values[0],\n",
    "            f\"{residue_data['site_label'].values[0]}\",\n",
    "            fontsize=12, ha='center', va='center', color='black'\n",
    "        )\n",
    "\n",
    "# Use adjustText to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.1, army_strength=2.0)\n",
    "\n",
    "# Adjust x-axis title to avoid overlap with shaded area\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)  # Adjusted x-axis label position\n",
    "plt.ylabel(\"Sample Count\", fontsize=14)\n",
    "\n",
    "# Custom legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Slight y-jitter function\n",
    "def add_y_jitter(arr, jitter_strength=0.1):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply y-jitter\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['Sample_Count'] = add_y_jitter(df_non_sig_jittered['Sample_Count'], jitter_strength=10)\n",
    "df_sig_jittered['Sample_Count'] = add_y_jitter(df_sig_jittered['Sample_Count'], jitter_strength=10)\n",
    "\n",
    "# Darker color palette\n",
    "palette = {\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': '#1f77b4',\n",
    "    'B cells - B.1.135 RBD vaccine': '#ff7f0e',\n",
    "    'mAB (NEUT)': '#2ca02c',\n",
    "    'Polyreactive pAB': '#d62728'\n",
    "}\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=14,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=14,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=2, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=2, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=12, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "# Label top 10 by escape, binding, and count\n",
    "top_10_escape = df_filtered.nlargest(10, 'log2_Enrichment')\n",
    "top_10_binding = df_filtered.nsmallest(10, 'log2_Enrichment')\n",
    "top_10_sample = df_filtered.nlargest(10, 'Sample_Count')\n",
    "top_10_labels = pd.concat([top_10_escape, top_10_binding, top_10_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "texts = []\n",
    "for _, row in top_10_labels.iterrows():\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'], row['Sample_Count'], row['site_label'],\n",
    "        ha='center', va='center', fontsize=10\n",
    "    )\n",
    "    texts.append(text)\n",
    "\n",
    "# Add custom residue labels\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "for pos in residues_to_label:\n",
    "    residue_data = df_filtered[df_filtered['Spike_AS_Position'] == pos]\n",
    "    if not residue_data.empty:\n",
    "        text = plt.text(\n",
    "            residue_data['log2_Enrichment'].values[0],\n",
    "            residue_data['Sample_Count'].values[0],\n",
    "            f\"{residue_data['site_label'].values[0]}\",\n",
    "            fontsize=12, ha='center', va='center', color='black'\n",
    "        )\n",
    "        texts.append(text)\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.2, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "plt.ylabel(\"Sample Count\", fontsize=14)\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Symmetric x-axis\n",
    "xlim = max(abs(df_filtered['log2_Enrichment'].min()), abs(df_filtered['log2_Enrichment'].max()))\n",
    "plt.xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Create the volcano plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot the data with custom colors for each category\n",
    "sns.scatterplot(\n",
    "    data=df_filtered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.8,\n",
    "    edgecolor='black',\n",
    "    s=12,\n",
    "    zorder=4,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot shaded non-significant region\n",
    "plt.axvspan(np.log2(0.5), np.log2(2), color='gray', alpha=0.5, zorder=5)\n",
    "\n",
    "# Plot non-significant region border lines\n",
    "plt.plot([np.log2(0.5), np.log2(0.5)], [0, df_filtered['Sample_Count'].max()], 'k--', lw=2, zorder=3)\n",
    "plt.plot([np.log2(2), np.log2(2)], [0, df_filtered['Sample_Count'].max()], 'k--', lw=2, zorder=3)\n",
    "\n",
    "# Label axis thresholds\n",
    "plt.text(np.log2(0.5), -5, 'log2(0.5)', ha='center', va='center', fontsize=12, color='black')\n",
    "plt.text(np.log2(2), -5, 'log2(2)', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "# Label top escape, binding, and sample mutations\n",
    "top_10_escape = df_filtered.nlargest(10, 'log2_Enrichment')\n",
    "top_10_binding = df_filtered.nsmallest(10, 'log2_Enrichment')\n",
    "top_10_sample = df_filtered.nlargest(10, 'Sample_Count')\n",
    "top_10_labels = pd.concat([top_10_escape, top_10_binding, top_10_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "texts = []\n",
    "for _, row in top_10_labels.iterrows():\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'], row['Sample_Count'], row['site_label'],\n",
    "        ha='center', va='center', fontsize=10\n",
    "    )\n",
    "    texts.append(text)\n",
    "\n",
    "# Label specific residues of interest\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "for pos in residues_to_label:\n",
    "    residue_data = df_filtered[df_filtered['Spike_AS_Position'] == pos]\n",
    "    if not residue_data.empty:\n",
    "        plt.text(\n",
    "            residue_data['log2_Enrichment'].values[0],\n",
    "            residue_data['Sample_Count'].values[0],\n",
    "            f\"{residue_data['site_label'].values[0]}\",\n",
    "            fontsize=12, ha='center', va='center', color='black'\n",
    "        )\n",
    "\n",
    "# Beautify plot\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.1, army_strength=2.0)\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "\n",
    "# Set x-axis label with extra padding\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "\n",
    "plt.ylabel(\"Sample Count\", fontsize=14)\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from adjustText import adjust_text\n",
    "import pandas as pd\n",
    "\n",
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance thresholds\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Slight y-jitter function\n",
    "def add_y_jitter(arr, jitter_strength=10):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply y-jitter\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['Sample_Count'] = add_y_jitter(df_non_sig_jittered['Sample_Count'], jitter_strength=0.15)\n",
    "df_sig_jittered['Sample_Count'] = add_y_jitter(df_sig_jittered['Sample_Count'], jitter_strength=0.15)\n",
    "\n",
    "# Corrected color palette (darker turquoise)\n",
    "palette = {\n",
    "    'B cells - Ancestral Wuhan RBD vaccine': '#1f77b4',  # Blue for Wuhan\n",
    "    'B cells - B.1.135 RBD vaccine': '#009688',  # Darker turquoise for B.1.135\n",
    "    'mAB (NEUT)': '#d62728',  # Red for NEUT\n",
    "    'Polyreactive pAB': '#ff7f0e'  # Orange for Polyreactive pAB\n",
    "}\n",
    "\n",
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=10,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=10,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=10, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Label top 5 by escape, binding, and count\n",
    "top_5_escape = df_filtered.nlargest(5, 'log2_Enrichment')\n",
    "top_5_binding = df_filtered.nsmallest(5, 'log2_Enrichment')\n",
    "top_5_sample = df_filtered.nlargest(5, 'Sample_Count')\n",
    "\n",
    "# Concatenate and drop duplicates based on 'site_label' to avoid overlap\n",
    "top_5_labels = pd.concat([top_5_escape, top_5_binding, top_5_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Thresholds for labeling: sample count > 10 and extreme enrichment\n",
    "count_thresh = df_filtered['Sample_Count'] > 10\n",
    "enrichment_thresh = df_filtered['log2_Enrichment'] > 2\n",
    "escape_thresh = df_filtered['log2_Enrichment'] < -5\n",
    "\n",
    "df_labels = df_filtered[(count_thresh & (enrichment_thresh | escape_thresh))]\n",
    "\n",
    "# Combine all labels for plotting\n",
    "labels_to_plot = pd.concat([top_5_labels, df_labels]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "# Define the specific residues to label\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "\n",
    "# Label the specified residues\n",
    "texts = []\n",
    "for _, row in labels_to_plot.iterrows():\n",
    "    if row['site_label'] in residues_to_label:  # Check if residue is in the list\n",
    "        # Determine whether the label should be placed on the left or right\n",
    "        if row['log2_Enrichment'] < 0:\n",
    "            x_offset = -1.1  # Move labels to the left\n",
    "        else:\n",
    "            x_offset = 1.1  # Move labels to the right\n",
    "\n",
    "        # Adjust the y position to avoid overlap\n",
    "        y_offset = 1.1 if row['Sample_Count'] < 50 else 1.1\n",
    "\n",
    "        # Plot the label with the adjusted position\n",
    "        text = plt.text(\n",
    "            row['log2_Enrichment'] + x_offset, row['Sample_Count'] + y_offset, row['site_label'],\n",
    "            ha='center', va='center', fontsize=10, color='black'\n",
    "        )\n",
    "        texts.append(text)\n",
    "        plt.plot([row['log2_Enrichment'], row['log2_Enrichment'] + x_offset], \n",
    "                 [row['Sample_Count'], row['Sample_Count'] + y_offset], color='gray', linestyle='-', linewidth=1)\n",
    "\n",
    "# Adjust text to avoid overlap\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.2, arrowprops=dict(arrowstyle='-', color='gray'))\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=10)  # Adjusted labelpad for the x-axis title\n",
    "plt.ylabel(\"Droplet Monoclonal Antibody repertoire\", fontsize=14)\n",
    "\n",
    "# Adding ticks in between\n",
    "# Set x and y axis ticks manually\n",
    "x_ticks = np.arange(-6, 6.1, 0.5)  # Adding ticks between -6 and 6 with a step of 0.5\n",
    "y_ticks = np.arange(0, df_filtered['Sample_Count'].max(), 5)  # You can adjust the range as needed\n",
    "\n",
    "# Apply the ticks to both axes\n",
    "plt.xticks(x_ticks)\n",
    "plt.yticks(y_ticks)\n",
    "\n",
    "# Adding labels for ticks at intersections\n",
    "for tick in x_ticks:\n",
    "    plt.text(tick, 0.5, f'{tick:.1f}', ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.ylim(bottom=0.5)\n",
    "plt.xlim(-6, 6)\n",
    "# Symmetric x-axis\n",
    "xlim = max(abs(df_filtered['log2_Enrichment'].min()), abs(df_filtered['log2_Enrichment'].max()))\n",
    "plt.xlim(-xlim, xlim)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volcano plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Non-significant gray points\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=14,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Significant colored points\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=10,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=1, zorder=1)\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "\n",
    "# Threshold labels\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=10, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "# Symmetric x-axis limit from -6 to 6\n",
    "plt.xlim(-6, 6)\n",
    "\n",
    "# Titles and labels\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "plt.ylabel(\"Monoclonal Antibody repertoire [n = 1x droplet]\", fontsize=14)\n",
    "\n",
    "# Legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for total reads > 500\n",
    "df_filtered = df_filtered[df_filtered['Total_Reads'] > 500]\n",
    "\n",
    "# Define significance threshold\n",
    "low_thresh = np.log2(0.5)\n",
    "high_thresh = np.log2(2)\n",
    "\n",
    "# Split into significant and non-significant\n",
    "df_non_sig = df_filtered[(df_filtered['log2_Enrichment'] >= low_thresh) & (df_filtered['log2_Enrichment'] <= high_thresh)]\n",
    "df_sig = df_filtered[(df_filtered['log2_Enrichment'] < low_thresh) | (df_filtered['log2_Enrichment'] > high_thresh)]\n",
    "\n",
    "# Create the volcano plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Slight jitter function\n",
    "def add_jitter(arr, jitter_strength=0):\n",
    "    return arr + np.random.normal(0, jitter_strength, size=len(arr))\n",
    "\n",
    "# Apply jitter to copies of the data\n",
    "df_non_sig_jittered = df_non_sig.copy()\n",
    "df_sig_jittered = df_sig.copy()\n",
    "\n",
    "df_non_sig_jittered['log2_Enrichment'] = add_jitter(df_non_sig_jittered['log2_Enrichment'], 0.1)\n",
    "df_sig_jittered['log2_Enrichment'] = add_jitter(df_sig_jittered['log2_Enrichment'], 0.1)\n",
    "\n",
    "# Plot non-significant points in light gray\n",
    "sns.scatterplot(\n",
    "    data=df_non_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    color='lightgray',\n",
    "    alpha=0.6,\n",
    "    s=14,\n",
    "    zorder=2,\n",
    "    edgecolor=None\n",
    ")\n",
    "\n",
    "# Plot significant points with category colors\n",
    "sns.scatterplot(\n",
    "    data=df_sig_jittered,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='Category',\n",
    "    palette=palette,\n",
    "    alpha=0.9,\n",
    "    s=14,\n",
    "    zorder=3,\n",
    "    edgecolor=None,\n",
    "    hue_order=[\n",
    "        'B cells - Ancestral Wuhan RBD vaccine',\n",
    "        'B cells - B.1.135 RBD vaccine',\n",
    "        'mAB (NEUT)',\n",
    "        'Polyreactive pAB'\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot threshold lines\n",
    "plt.axvline(low_thresh, linestyle='--', color='gray', lw=2, zorder=1)\n",
    "plt.axvline(high_thresh, linestyle='--', color='gray', lw=2, zorder=1)\n",
    "\n",
    "# Label thresholds\n",
    "plt.text(low_thresh, -5, 'log2(0.5)', ha='center', va='center', fontsize=12, color='black')\n",
    "plt.text(high_thresh, -5, 'log2(2)', ha='center', va='center', fontsize=12, color='black')\n",
    "\n",
    "# Label top escape, binding, and sample mutations\n",
    "top_10_escape = df_filtered.nlargest(10, 'log2_Enrichment')\n",
    "top_10_binding = df_filtered.nsmallest(10, 'log2_Enrichment')\n",
    "top_10_sample = df_filtered.nlargest(10, 'Sample_Count')\n",
    "top_10_labels = pd.concat([top_10_escape, top_10_binding, top_10_sample]).drop_duplicates(subset=['site_label'])\n",
    "\n",
    "texts = []\n",
    "for _, row in top_10_labels.iterrows():\n",
    "    text = plt.text(\n",
    "        row['log2_Enrichment'], row['Sample_Count'], row['site_label'],\n",
    "        ha='center', va='center', fontsize=10\n",
    "    )\n",
    "    texts.append(text)\n",
    "\n",
    "# Label specific residues of interest\n",
    "residues_to_label = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "for pos in residues_to_label:\n",
    "    residue_data = df_filtered[df_filtered['Spike_AS_Position'] == pos]\n",
    "    if not residue_data.empty:\n",
    "        plt.text(\n",
    "            residue_data['log2_Enrichment'].values[0],\n",
    "            residue_data['Sample_Count'].values[0],\n",
    "            f\"{residue_data['site_label'].values[0]}\",\n",
    "            fontsize=12, ha='center', va='center', color='black'\n",
    "        )\n",
    "\n",
    "# Beautify\n",
    "adjust_text(texts, only_move={'points': 'y', 'texts': 'xy'}, force_text=0.1, army_strength=2.0)\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\", fontsize=16)\n",
    "\n",
    "# Set x-axis label with extra padding\n",
    "plt.xlabel(\"← Escape   |   Binding →\", fontsize=14, labelpad=20)\n",
    "plt.ylabel(\"Sample Count\", fontsize=14)\n",
    "\n",
    "# Legend for significant categories only\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(handles, labels, title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "# Make x-axis symmetric around 0\n",
    "xlim = max(abs(df_filtered['log2_Enrichment'].min()), abs(df_filtered['log2_Enrichment'].max()))\n",
    "plt.xlim(-xlim, xlim)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.scatterplot(\n",
    "    data=df_volcano,\n",
    "    x='log2_Enrichment',\n",
    "    y='Sample_Count',\n",
    "    hue='immunization',\n",
    "    alpha=0.8,\n",
    "    edgecolor='black'\n",
    ")\n",
    "\n",
    "# Add text labels with arrows pointing to the dots\n",
    "for _, row in df_volcano[df_volcano['label_this']].iterrows():\n",
    "    plt.annotate(\n",
    "        row['mutation_label'],\n",
    "        xy=(row['log2_Enrichment'], row['Sample_Count']),           # Point to the data point\n",
    "        xytext=(-40, 20),                                           # Offset label (x,y) in points\n",
    "        textcoords='offset points',\n",
    "        ha='right',\n",
    "        va='bottom',\n",
    "        fontsize=9,\n",
    "        arrowprops=dict(arrowstyle='-', lw=0.8, color='gray'),     # Line pointing to the dot\n",
    "        bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7)  # Optional: background\n",
    "    )\n",
    "\n",
    "plt.axvline(0, linestyle='--', color='gray')  # log2(1)\n",
    "plt.title(\"Volcano Plot: Escape vs Binding Mutations\")\n",
    "plt.xlabel(\"log2(Enrichment Ratio) (← Escape   |   Binding →)\")\n",
    "plt.ylabel(\"Sample Count\")\n",
    "plt.legend(title=\"Immunization\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Define the dictionary for the specific amino acids at certain positions\n",
    "wuhan_strain_aa = {\n",
    "    417: 'K', 439: 'N', 440: 'N', 452: 'L', 476: 'G', 477: 'S', 484: 'E',\n",
    "    493: 'Q', 501: 'N', 502: 'G', 505: 'Y'\n",
    "}\n",
    "\n",
    "# Aggregate data\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "# Filter for Enrichment_Ratio > 1\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Define sites to show (as strings for consistency)\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "# Add site labels and determine which sites to show\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Ensure amino acids are uppercase and exclude specific characters\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[~df_logo_agg['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "# Debugging: Check the filtered positions and amino acids\n",
    "print(\"Filtered data with relevant sites and amino acids:\")\n",
    "print(df_logo_agg[['Spike_AS_Position', 'Amino_Acid']].drop_duplicates())\n",
    "\n",
    "# Generate logo plots for each unique barcode\n",
    "for barcode in df_logo_agg['barcode'].unique():\n",
    "    print(f\"Generating plot for barcode: {barcode}\")\n",
    "    filtered_data = df_logo_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "\n",
    "    # Debugging: Check positions for the current barcode\n",
    "    print(f\"Positions and amino acids for {barcode}:\")\n",
    "    print(filtered_data[['Spike_AS_Position', 'Amino_Acid']])\n",
    "\n",
    "    # Specifically print out rows for position 505 in the original dataframe (df_total)\n",
    "    print(\"\\nRows for position 505 in the original dataframe:\")\n",
    "    rows_505 = df_total[df_total['Spike_AS_Position'] == 505][['Spike_AS_Position', 'Amino_Acid', 'Enrichment_Ratio', 'DMS_RBD_AS_position']]\n",
    "    print(rows_505)\n",
    "\n",
    "    # Check if there is any data to plot\n",
    "    if not filtered_data.empty:\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            filtered_data,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True\n",
    "        )\n",
    "\n",
    "        ax.set_ylabel(\"Antigen Binding\")  # Set the y-axis label to Binding Ratio\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  # Set the x-axis label\n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/ETH/immunization_csv_files\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        print(f\"No data to plot for barcode: {barcode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Enable interactive plotting\n",
    "plt.ion()\n",
    "\n",
    "# Define the dictionary for the specific amino acids at certain positions\n",
    "wuhan_strain_aa = {\n",
    "    417: 'K', 439: 'N', 440: 'N', 452: 'L', 476: 'G', 477: 'S', 484: 'E',\n",
    "    493: 'Q', 501: 'N', 502: 'G', 505: 'L'\n",
    "}\n",
    "\n",
    "# Aggregate data\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio': 'mean'})\n",
    "\n",
    "# Filter for Enrichment_Ratio > 1\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Define sites to show (as strings for consistency)\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "# Add site labels and determine which sites to show\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Ensure amino acids are uppercase and exclude specific characters\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[~df_logo_agg['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "\n",
    "# Generate logo plots for each unique barcode\n",
    "for barcode in df_logo_agg['barcode'].unique():\n",
    "    print(f\"Generating plot for barcode: {barcode}\")\n",
    "    filtered_data = df_logo_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "\n",
    "    # Debugging: Check positions for the current barcode\n",
    "    print(f\"Positions and amino acids for {barcode}:\")\n",
    "    print(filtered_data[['Spike_AS_Position', 'Amino_Acid']])\n",
    "\n",
    "    # Specifically print out rows for position 505 in the original dataframe (df_total)\n",
    "    print(\"\\nRows for position 505 in the original dataframe:\")\n",
    "    rows_505 = df_total[df_total['Spike_AS_Position'] == 505][['Spike_AS_Position', 'Amino_Acid', 'Enrichment_Ratio', 'DMS_RBD_AS_position']]\n",
    "    print(rows_505)\n",
    "\n",
    "    # Check if there is any data to plot\n",
    "    if not filtered_data.empty:\n",
    "        # Plot logo using your drawing function\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            filtered_data,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True\n",
    "        )\n",
    "\n",
    "        ax.set_ylabel(\"Antigen Binding\")  # Set the y-axis label to Binding Ratio\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  # Set the x-axis label\n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"/Users/lucaschlotheuber/Desktop/ETH/immunization_csv_files\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        print(f\"No data to plot for barcode: {barcode}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# Filter out rows where Enrichment_Ratio is zero and Enrichment_Ratio < 1 for escape\n",
    "df_escape = df_total[(df_total['Enrichment_Ratio'] < 1) & (df_total['Enrichment_Ratio'] != 0)]\n",
    "\n",
    "# Apply the inverse to the Enrichment_Ratio\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "# Aggregate the escape data by position, amino acid, barcode, and immunization\n",
    "df_escape_agg = df_escape.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'],\n",
    "    as_index=False\n",
    ").agg({'Enrichment_Ratio_inverted': 'sum'})\n",
    "\n",
    "# Apply log2 transformation\n",
    "df_escape_agg['Enrichment_Ratio_log2'] = df_escape_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "# Now filter out any amino acids that are both enriched and escaped in different samples\n",
    "# Here, we create a set of amino acids that appear in both categories (Enriched and Escaped) for the same position\n",
    "enriched_aa = df_total[df_total['Enrichment_Ratio'] > 1]\n",
    "escaped_aa = df_escape\n",
    "\n",
    "# Extract amino acids that appear in both\n",
    "common_aa = set(enriched_aa['Amino_Acid']).intersection(set(escaped_aa['Amino_Acid']))\n",
    "\n",
    "# Filter both enriched and escaped data to exclude common amino acids\n",
    "df_escape_agg = df_escape_agg[~df_escape_agg['Amino_Acid'].isin(common_aa)]\n",
    "\n",
    "# Define the sites to show\n",
    "sites_to_show = map(str, [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505])\n",
    "\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Loop through each barcode to generate the plots\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=barcode + ' logoplot',\n",
    "            addbreaks=True,\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(\"Antibody Escape\")  # Set the y-axis label\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  \n",
    "\n",
    "        # Save the figure\n",
    "        file_path = os.path.join(\n",
    "            r\"C:\\Users\\lschlotheube\\Desktop\\ETH/Thesis\\LogoEscape3\",\n",
    "            f\"{barcode}_logoplots.png\"\n",
    "        )\n",
    "        plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with tight bounding box\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Code block for generating logoplots of enriched positions grouped by immunization (sum of all barcodes)\n",
    "# Aggregating by immunization, Spike_AS_Position, and Amino_Acid, and summing Enrichment_Ratio\n",
    "\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [417, 439, 440, 452, 476, 477, 484, 493, 501, 505]\n",
    ")\n",
    "\n",
    "# Adding site labels and filtering for sites to show\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "# Now iterate over unique immunization groups instead of barcodes\n",
    "for immunization in df_logo_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_logo_agg.query(f'immunization == \"{immunization}\"').query(\"show_site\"),\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Enrichment_Ratio\",\n",
    "        title=immunization + ' logoplot',\n",
    "        addbreaks=True\n",
    "    )\n",
    "    # Save the figure (uncomment to save the plot)\n",
    "    #file_path = os.path.join(r\"C:\\Users\\au649453\\OneDrive - Aarhus universitet\\PhD\\Luca\\DMS_plots\\Enriched_and_targeted_positions\", f\"{immunization}_logoplots.png\")\n",
    "    #plt.savefig(file_path, dpi = 300, bbox_inches = 'tight')\n",
    "    #plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code block for generating logoplots of enriched positions grouped by immunization (sum of all barcodes)\n",
    "# Aggregating by immunization, Spike_AS_Position, and Amino_Acid, and summing Enrichment_Ratio\n",
    "\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [417, 439, 440, 452, 476, 477, 484, 493, 501, 505]\n",
    ")\n",
    "\n",
    "# Adding site labels and filtering for sites to show\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "# Now iterate over unique immunization groups instead of barcodes\n",
    "for immunization in df_logo_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_logo_agg.query(f'immunization == \"{immunization}\"').query(\"show_site\"),\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Enrichment_Ratio\",\n",
    "        title=immunization + ' logoplot',\n",
    "        addbreaks=True\n",
    "    )\n",
    "    # Save the figure (uncomment to save the plot)\n",
    "    #file_path = os.path.join(r\"C:\\Users\\au649453\\OneDrive - Aarhus universitet\\PhD\\Luca\\DMS_plots\\Enriched_and_targeted_positions\", f\"{immunization}_logoplots.png\")\n",
    "    #plt.savefig(file_path, dpi = 300, bbox_inches = 'tight')\n",
    "    #plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high)\n",
    "def enrichment_color(enrichment):\n",
    "    norm_value = (enrichment - 3) / (df_logo_agg['Enrichment_Ratio'].max() - 3)  # Normalize to range [0,1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "# Select sites to display\n",
    "sites_to_show = [str(x) for x in [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]]\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each site\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 3]  # Filter enrichment > 3\n",
    "\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes\n",
    "    .reset_index(name='Sample_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on enrichment ratio\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Generate logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(immunization)\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_combined.query(f'immunization == \"{immunization}\"').query(\"show_site\"),\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Occurrence-based)\",\n",
    "        addbreaks=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high)\n",
    "def enrichment_color(enrichment):\n",
    "    norm_value = (enrichment - 3) / (df_logo_agg['Enrichment_Ratio'].max() - 3)  # Normalize to range [0,1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 3\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 3]\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes\n",
    "    .reset_index(name='Sample_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on max enrichment ratio per amino acid at each site\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Filter the sites to only include positions larger than 365\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'] > 365]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "    \n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_combined.query(f'immunization == \"{immunization}\"'),  # No site filtering (already done above)\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Occurrence-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    \n",
    "    # Save the plot as a PNG file\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    plt.close(fig)  # Close the figure to prevent displaying\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high)\n",
    "def enrichment_color(enrichment):\n",
    "    # Normalize to range [0, 1], ensuring max enrichment gets the brightest red\n",
    "    max_enrichment = df_logo_agg['Enrichment_Ratio'].max()  # Max value for normalization\n",
    "    norm_value = (enrichment - 3) / (max_enrichment - 3)  # Normalize to range [0, 1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 3\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 3]\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes\n",
    "    .reset_index(name='Sample_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on max enrichment ratio per amino acid at each site\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Filter the sites to only include positions larger than 365\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'] > 365]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "    \n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_combined.query(f'immunization == \"{immunization}\"'),  # No site filtering (already done above)\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Occurrence-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    \n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high) using log scale\n",
    "def enrichment_color(enrichment):\n",
    "    # Set the max enrichment value for normalization\n",
    "    max_enrichment = 3000  # Adjust to the maximum value you want for color scaling\n",
    "    # Apply a logarithmic scale to the enrichment values\n",
    "    log_enrichment = np.log10(enrichment + 1)  # log(x+1) to avoid issues with zero or small values\n",
    "    max_log_enrichment = np.log10(max_enrichment + 1)\n",
    "    norm_value = log_enrichment / max_log_enrichment  # Normalize to range [0, 1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 3\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 3]\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes\n",
    "    .reset_index(name='Sample_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on max enrichment ratio per amino acid at each site\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Filter the sites to only include positions larger than 365\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'] > 365]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Generate and save logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "    \n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_combined.query(f'immunization == \"{immunization}\"'),  # No site filtering (already done above)\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Occurrence-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add colorbar to the plot, now using the axes 'ax' for colorbar placement\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3 + 1), vmax=np.log10(3000 + 1)))  # Log scale for max\n",
    "    sm.set_array([])  # Required for the colorbar to work\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')  # Attach colorbar to the same axes as the plot\n",
    "    cbar.set_label('Log(Enrichment Ratio)', rotation=270, labelpad=15)  # Label the colorbar\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high) using log scale\n",
    "def enrichment_color(enrichment):\n",
    "    max_enrichment = 3000\n",
    "    log_enrichment = np.log10(enrichment + 1)\n",
    "    max_log_enrichment = np.log10(max_enrichment + 1)\n",
    "    norm_value = np.clip(log_enrichment / max_log_enrichment, 0, 1)\n",
    "    return plt.cm.Reds(norm_value)\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 3]\n",
    "\n",
    "# Create a directory to save the PNG files\n",
    "output_dir = \"logo_plots_by_barcode\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each barcode\n",
    "for barcode in df_filtered['barcode'].unique():\n",
    "    df_barcode = df_filtered[df_filtered['barcode'] == barcode].copy()\n",
    "\n",
    "    # Extract the associated immunization for the barcode\n",
    "    immunization = df_barcode['immunization'].iloc[0]\n",
    "\n",
    "    # Count occurrences\n",
    "    df_combined = (\n",
    "        df_barcode.groupby(['Spike_AS_Position', 'Amino_Acid'])\n",
    "        .size()\n",
    "        .reset_index(name='Sample_Count')\n",
    "    )\n",
    "\n",
    "    # Get max enrichment per position/amino acid for coloring\n",
    "    df_combined['Max_Enrichment'] = df_barcode.groupby(['Spike_AS_Position', 'Amino_Acid'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "    df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "    df_combined = df_combined.assign(\n",
    "        site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    "    )\n",
    "\n",
    "    # Filter for sites > 365\n",
    "    df_combined = df_combined[df_combined['Spike_AS_Position'] > 365]\n",
    "\n",
    "    if df_combined.empty:\n",
    "        continue  # Skip barcodes with no data after filtering\n",
    "\n",
    "    print(f\"Generating plot for barcode {barcode} (immunization: {immunization})\")\n",
    "\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_combined,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",\n",
    "        color_col=\"color\",\n",
    "        title=f\"Barcode: {barcode}\\nImmunization: {immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3 + 1), vmax=np.log10(3000 + 1)))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Log(Enrichment Ratio)', rotation=270, labelpad=15)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Save the figure\n",
    "    plot_filename = os.path.join(output_dir, f\"{barcode}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "    print(f\"Plot saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionary to store all position-wise matrices\n",
    "immunization_position_matrices = defaultdict(dict)\n",
    "\n",
    "# Filter for Enrichment_Ratio > 3 and Spike_AS_Position > 365\n",
    "df_filtered = df_total[(df_total['Enrichment_Ratio'] > 3) & (df_total['Spike_AS_Position'] > 365)].copy()\n",
    "df_filtered['Amino_Acid'] = df_filtered['Amino_Acid'].str.upper()\n",
    "\n",
    "# Loop through immunization and position\n",
    "for immunization in df_filtered['immunization'].unique():\n",
    "    df_imm = df_filtered[df_filtered['immunization'] == immunization]\n",
    "    \n",
    "    for position in df_imm['Spike_AS_Position'].unique():\n",
    "        df_pos = df_imm[df_imm['Spike_AS_Position'] == position]\n",
    "\n",
    "        # Pivot table: rows = barcode, columns = Amino_Acid, values = enrichment\n",
    "        pivot = df_pos.pivot_table(index='barcode', columns='Amino_Acid', values='Enrichment_Ratio', fill_value=0)\n",
    "        \n",
    "        # Store\n",
    "        immunization_position_matrices[immunization][position] = pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "reproducibility_stats = []\n",
    "\n",
    "for immunization, positions in immunization_position_matrices.items():\n",
    "    for position, matrix in positions.items():\n",
    "        if matrix.shape[0] < 2:\n",
    "            continue  # Need at least two barcodes to compute reproducibility\n",
    "\n",
    "        # Compute pairwise Pearson correlation\n",
    "        correlation_matrix = matrix.T.corr()  # Transpose so barcodes are compared across amino acids\n",
    "        \n",
    "        # Take the average pairwise correlation (excluding diagonal)\n",
    "        tril_values = correlation_matrix.where(~np.eye(correlation_matrix.shape[0], dtype=bool)).values\n",
    "        tril_values = tril_values[~np.isnan(tril_values)]\n",
    "        mean_corr = tril_values.mean()\n",
    "\n",
    "        reproducibility_stats.append({\n",
    "            'immunization': immunization,\n",
    "            'Spike_AS_Position': position,\n",
    "            'mean_pairwise_correlation': mean_corr,\n",
    "            'n_barcodes': matrix.shape[0]\n",
    "        })\n",
    "\n",
    "df_reproducibility = pd.DataFrame(reproducibility_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high) using log scale\n",
    "def enrichment_color(enrichment):\n",
    "    # Set the max enrichment value for normalization\n",
    "    max_enrichment = 3000  # Adjust to the maximum value you want for color scaling\n",
    "    # Apply a logarithmic scale to the enrichment values\n",
    "    log_enrichment = np.log10(enrichment + 1)  # log(x+1) to avoid issues with zero or small values\n",
    "    max_log_enrichment = np.log10(max_enrichment + 1)\n",
    "    norm_value = log_enrichment / max_log_enrichment  # Normalize to range [0, 1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 3\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes\n",
    "    .reset_index(name='Sample_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on max enrichment ratio per amino acid at each site\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Filter the sites to only include positions larger than 365\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'] > 365]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "# Generate and save logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    \n",
    "    \n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_combined.query(f'immunization == \"{immunization}\"'),  # No site filtering (already done above)\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Occurrence-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    fig.set_size_inches(45, 4)\n",
    "\n",
    "    # Add colorbar to the plot, now using the axes 'ax' for colorbar placement\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3 + 1), vmax=np.log10(3000 + 1)))  # Log scale for max\n",
    "    sm.set_array([])  # Required for the colorbar to work\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')  # Attach colorbar to the same axes as the plot\n",
    "    cbar.set_label('Log(Enrichment Ratio)', rotation=270, labelpad=15)  # Label the colorbar\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity heatmap test with ER >1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Use only data where Enrichment_Ratio > 1, excluding stop codons (*) for analysis\n",
    "df_logo_filtered = df_logo_agg[\n",
    "    (df_logo_agg['Amino_Acid'] != \"*\") & \n",
    "    (df_logo_agg['Enrichment_Ratio'] > 1)\n",
    "]\n",
    "\n",
    "# --- Quick check: confirm all values have ER > 1 ---\n",
    "num_total = len(df_logo_filtered)\n",
    "num_below_or_equal_1 = (df_logo_filtered['Enrichment_Ratio'] <= 1).sum()\n",
    "print(f\"\\nQuick Check: {num_total} entries total; {num_below_or_equal_1} have ER ≤ 1 (should be 0)\")\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# Step 1: Create a pivot table per barcode\n",
    "pivot = df_logo_filtered.pivot_table(\n",
    "    index=['immunization', 'barcode'],\n",
    "    columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "    values='Enrichment_Ratio',\n",
    "    fill_value=0\n",
    ")\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-CoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-CoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS-CoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS-CoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Library-2',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "# Step 2: Analyze within each immunization\n",
    "similarity_stats = []\n",
    "\n",
    "for immunization, sub_df in pivot.groupby(level=0):\n",
    "    data = sub_df.values  # shape (num_barcodes, num_sites)\n",
    "    barcodes = sub_df.index.get_level_values('barcode')\n",
    "\n",
    "    # Pairwise cosine similarities\n",
    "    sim_matrix = cosine_similarity(data)\n",
    "\n",
    "    # Extract upper triangle values (excluding self-comparisons)\n",
    "    pairwise_sims = sim_matrix[np.triu_indices_from(sim_matrix, k=1)]\n",
    "\n",
    "    # Store results\n",
    "    similarity_stats.append({\n",
    "        'immunization': immunization,\n",
    "        'mean_similarity': np.mean(pairwise_sims),\n",
    "        'std_similarity': np.std(pairwise_sims),\n",
    "        'num_barcodes': len(barcodes)\n",
    "    })\n",
    "\n",
    "    # Optional: visualize similarity matrix as heatmap with mapped title\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(sim_matrix, xticklabels=barcodes, yticklabels=barcodes, cmap='viridis', vmin=0, vmax=1)\n",
    "    # Map immunization to pretty name for title, fallback to original if not found\n",
    "    pretty_name = title_map.get(immunization, immunization)\n",
    "    plt.title(f'Cosine Similarity Between Barcodes\\n{pretty_name}')\n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(output_dir, f\"similarity_heatmap_{immunization.replace(' ', '_')}.png\")\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_sim_stats = pd.DataFrame(similarity_stats)\n",
    "\n",
    "# Step 3: Plot overall similarity per immunization using mapped names on x-axis\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(data=df_sim_stats, x='immunization', y='mean_similarity')\n",
    "plt.ylabel('Mean Cosine Similarity Between Barcodes')\n",
    "plt.title('Within-Immunization Barcode Similarity')\n",
    "\n",
    "# Replace x-axis tick labels with mapped names (keep order from df_sim_stats)\n",
    "xticks = ax.get_xticks()\n",
    "xticklabels = [title_map.get(name, name) for name in df_sim_stats['immunization']]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "barplot_file = os.path.join(output_dir, \"summary_barplot_similarity.png\")\n",
    "plt.savefig(barplot_file, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similarity heatmap test with all ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import seaborn as sns\n",
    "\n",
    "# Use all data, but exclude stop codons (*) for analysis\n",
    "df_logo_cleaned = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "# Step 1: Create a pivot table per barcode\n",
    "pivot = df_logo_cleaned.pivot_table(\n",
    "    index=['immunization', 'barcode'],\n",
    "    columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "    values='Enrichment_Ratio',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# --- Quick check: confirm that ER < 1 values are still included ---\n",
    "num_total = len(df_logo_cleaned)\n",
    "num_below_1 = (df_logo_cleaned['Enrichment_Ratio'] < 1).sum()\n",
    "print(f\"\\nQuick Check: {num_below_1} out of {num_total} entries have Enrichment_Ratio < 1\")\n",
    "# ------------------\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\n2',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "# Step 2: Analyze within each immunization\n",
    "similarity_stats = []\n",
    "\n",
    "for immunization, sub_df in pivot.groupby(level=0):\n",
    "    data = sub_df.values  # shape (num_barcodes, num_sites)\n",
    "    barcodes = sub_df.index.get_level_values('barcode')\n",
    "\n",
    "    # Pairwise cosine similarities\n",
    "    sim_matrix = cosine_similarity(data)\n",
    "\n",
    "    # Extract upper triangle values (excluding self-comparisons)\n",
    "    pairwise_sims = sim_matrix[np.triu_indices_from(sim_matrix, k=1)]\n",
    "\n",
    "    # Store results\n",
    "    similarity_stats.append({\n",
    "        'immunization': immunization,\n",
    "        'mean_similarity': np.mean(pairwise_sims),\n",
    "        'std_similarity': np.std(pairwise_sims),\n",
    "        'num_barcodes': len(barcodes)\n",
    "    })\n",
    "\n",
    "    # Optional: visualize similarity matrix as heatmap with mapped title\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(sim_matrix, xticklabels=barcodes, yticklabels=barcodes, cmap='viridis', vmin=0, vmax=1)\n",
    "    # Map immunization to pretty name for title, fallback to original if not found\n",
    "    pretty_name = title_map.get(immunization, immunization)\n",
    "    plt.title(f'Cosine Similarity Between Barcodes\\n{pretty_name}')\n",
    "    plt.tight_layout()\n",
    "    filename = os.path.join(output_dir, f\"similarity_heatmap_{immunization.replace(' ', '_')}.png\")\n",
    "    plt.savefig(filename, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_sim_stats = pd.DataFrame(similarity_stats)\n",
    "\n",
    "# Step 3: Plot overall similarity per immunization using mapped names on x-axis\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(data=df_sim_stats, x='immunization', y='mean_similarity')\n",
    "plt.ylabel('Mean Cosine Similarity Between Barcodes')\n",
    "plt.title('Within-Immunization Barcode Similarity')\n",
    "\n",
    "# Replace x-axis tick labels with mapped names (keep order from df_sim_stats)\n",
    "xticks = ax.get_xticks()\n",
    "xticklabels = [title_map.get(name, name) for name in df_sim_stats['immunization']]\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "barplot_file = os.path.join(output_dir, \"summary_barplot_similarity.png\")\n",
    "plt.savefig(barplot_file, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cosine Similarity ER ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "df_logo_cleaned = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "# Step 1: Create pivot table per barcode\n",
    "pivot = df_logo_cleaned.pivot_table(\n",
    "    index=['immunization', 'barcode'],\n",
    "    columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "    values='Enrichment_Ratio',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\n2',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "print(\"\\n=== Enrichment Ratio Summary Per Immunization ===\")\n",
    "for name, group in df_filtered.groupby('immunization'):\n",
    "    values = group['Enrichment_Ratio'].dropna()\n",
    "    print(f\"\\nImmunization: {name}\")\n",
    "    print(f\"  Count: {len(values)}\")\n",
    "    print(f\"  Min:   {values.min():.4f}\")\n",
    "    print(f\"  Max:   {values.max():.4f}\")\n",
    "    print(f\"  Mean:  {values.mean():.4f}\")\n",
    "    print(f\"  Std:   {values.std():.4f}\")\n",
    "    print(f\"  Median:{values.median():.4f}\")\n",
    "\n",
    "# Step 2: Analyze within each immunization\n",
    "similarity_stats = []\n",
    "all_pairwise = {}  # to store individual similarity values for stats\n",
    "\n",
    "for immunization, sub_df in pivot.groupby(level=0):\n",
    "    data = sub_df.values\n",
    "    barcodes = sub_df.index.get_level_values('barcode')\n",
    "    \n",
    "    sim_matrix = cosine_similarity(data)\n",
    "    pairwise_sims = sim_matrix[np.triu_indices_from(sim_matrix, k=1)]\n",
    "\n",
    "    # Save stats\n",
    "    similarity_stats.append({\n",
    "        'immunization': immunization,\n",
    "        'mean_similarity': np.mean(pairwise_sims),\n",
    "        'std_similarity': np.std(pairwise_sims),\n",
    "        'num_barcodes': len(barcodes)\n",
    "    })\n",
    "\n",
    "    all_pairwise[immunization] = pairwise_sims  # save for comparison\n",
    "    \n",
    "    # Optional: show heatmap\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(sim_matrix, xticklabels=barcodes, yticklabels=barcodes, cmap='viridis', vmin=0, vmax=1)\n",
    "    plt.title(f'Cosine Similarity Between Barcodes\\n{immunization}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "\n",
    "# Step 3: Create summary DataFrame\n",
    "df_sim_stats = pd.DataFrame(similarity_stats)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df_sim_stats)\n",
    "\n",
    "# Step 4: Perform ANOVA and pairwise t-tests\n",
    "print(\"\\nStatistical Tests:\")\n",
    "immunizations = list(all_pairwise.keys())\n",
    "groups = [all_pairwise[imm] for imm in immunizations]\n",
    "\n",
    "# Always run ANOVA for multiple groups\n",
    "if len(immunizations) > 2:\n",
    "    f_stat, p_val = f_oneway(*groups)\n",
    "    print(f\"ANOVA: F = {f_stat:.4f}, p = {p_val:.4e}\")\n",
    "\n",
    "# Pairwise t-tests\n",
    "pairwise_pvals = []\n",
    "for a, b in combinations(immunizations, 2):\n",
    "    stat, p_val = ttest_ind(all_pairwise[a], all_pairwise[b])\n",
    "    print(f\"{a} vs {b}: t = {stat:.4f}, p = {p_val:.4e}\")\n",
    "    pairwise_pvals.append((a, b, p_val))\n",
    "\n",
    "# Step 5: Plot with error bars and significance lines\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(data=df_sim_stats, x='immunization', y='mean_similarity', ci=None, palette='Set2')\n",
    "plt.errorbar(x=np.arange(len(df_sim_stats)),\n",
    "             y=df_sim_stats['mean_similarity'],\n",
    "             yerr=df_sim_stats['std_similarity'],\n",
    "             fmt='none', c='black', capsize=5)\n",
    "plt.ylabel('Mean Cosine Similarity')\n",
    "\n",
    "# Update x-axis labels using title_map\n",
    "xticks = ax.get_xticks()\n",
    "xticklabels = df_sim_stats['immunization'].map(title_map)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels, rotation=0)\n",
    "\n",
    "# Add significance brackets\n",
    "def add_sig_bracket(ax, x1, x2, y, h, p_val, fontsize=12):\n",
    "    barx = [x1, x1, x2, x2]\n",
    "    bary = [y, y+h, y+h, y]\n",
    "    ax.plot(barx, bary, c='black')\n",
    "    if p_val < 0.001:\n",
    "        stars = '***'\n",
    "    elif p_val < 0.01:\n",
    "        stars = '**'\n",
    "    elif p_val < 0.05:\n",
    "        stars = '*'\n",
    "    else:\n",
    "        stars = 'ns'\n",
    "    ax.text((x1 + x2) / 2, y + h + 0.01, stars, ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "# Add brackets above bars\n",
    "y_max = df_sim_stats['mean_similarity'].max() + df_sim_stats['std_similarity'].max()\n",
    "h = 0.1  # height of brackets\n",
    "offset = 0\n",
    "for a, b, p in pairwise_pvals:\n",
    "    if p >= 0.05 or np.isnan(p):\n",
    "        continue \n",
    "    x1 = df_sim_stats[df_sim_stats['immunization'] == a].index[0]\n",
    "    x2 = df_sim_stats[df_sim_stats['immunization'] == b].index[0]\n",
    "    y = y_max + h * offset\n",
    "    add_sig_bracket(ax, x1, x2, y, h, p)\n",
    "    offset += 3\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = os.path.join(output_dir, f\"cosine_heatmap_{immunization}.png\")\n",
    "plt.savefig(filename, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine plotting with ER>1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import ttest_ind, f_oneway\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "df_logo_cleaned = df_logo_agg[(df_logo_agg['Amino_Acid'] != \"*\") & (df_logo_agg['Enrichment_Ratio'] > 1)]\n",
    "\n",
    "# Step 1: Create pivot table per barcode\n",
    "pivot = df_logo_cleaned.pivot_table(\n",
    "    index=['immunization', 'barcode'],\n",
    "    columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "    values='Enrichment_Ratio',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-\\nSARS-\\nCoV-2\\npAB',\n",
    "    'Neutralizing_Ab': 'Anti-\\nSARS-\\nCoV-2\\nnAb',\n",
    "    'wildtype_RBD': 'ASCs\\nSARS\\nCoV-2\\nWuhan',\n",
    "    'Mutant_RBD': 'ASCs\\nSARS\\nCoV-2\\nB.1.135',\n",
    "    'Library_ctrl': 'Lib\\n2',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "print(\"\\n=== Enrichment Ratio Summary Per Immunization ===\")\n",
    "for name, group in df_filtered.groupby('immunization'):\n",
    "    values = group['Enrichment_Ratio'].dropna()\n",
    "    print(f\"\\nImmunization: {name}\")\n",
    "    print(f\"  Count: {len(values)}\")\n",
    "    print(f\"  Min:   {values.min():.4f}\")\n",
    "    print(f\"  Max:   {values.max():.4f}\")\n",
    "    print(f\"  Mean:  {values.mean():.4f}\")\n",
    "    print(f\"  Std:   {values.std():.4f}\")\n",
    "    print(f\"  Median:{values.median():.4f}\")\n",
    "\n",
    "# Step 2: Analyze within each immunization\n",
    "similarity_stats = []\n",
    "all_pairwise = {}  # to store individual similarity values for stats\n",
    "\n",
    "for immunization, sub_df in pivot.groupby(level=0):\n",
    "    data = sub_df.values\n",
    "    barcodes = sub_df.index.get_level_values('barcode')\n",
    "    \n",
    "    sim_matrix = cosine_similarity(data)\n",
    "    pairwise_sims = sim_matrix[np.triu_indices_from(sim_matrix, k=1)]\n",
    "\n",
    "    # Save stats\n",
    "    similarity_stats.append({\n",
    "        'immunization': immunization,\n",
    "        'mean_similarity': np.mean(pairwise_sims),\n",
    "        'std_similarity': np.std(pairwise_sims),\n",
    "        'num_barcodes': len(barcodes)\n",
    "    })\n",
    "\n",
    "    all_pairwise[immunization] = pairwise_sims  # save for comparison\n",
    "    \n",
    "    # Optional: show heatmap\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(sim_matrix, xticklabels=barcodes, yticklabels=barcodes, cmap='viridis', vmin=0, vmax=1)\n",
    "    plt.title(f'Cosine Similarity Between Barcodes\\n{immunization}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.close()\n",
    "    plt.show()\n",
    "\n",
    "# Step 3: Create summary DataFrame\n",
    "df_sim_stats = pd.DataFrame(similarity_stats)\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df_sim_stats)\n",
    "\n",
    "# Step 4: Perform ANOVA and pairwise t-tests\n",
    "print(\"\\nStatistical Tests:\")\n",
    "immunizations = list(all_pairwise.keys())\n",
    "groups = [all_pairwise[imm] for imm in immunizations]\n",
    "\n",
    "# Always run ANOVA for multiple groups\n",
    "if len(immunizations) > 2:\n",
    "    f_stat, p_val = f_oneway(*groups)\n",
    "    print(f\"ANOVA: F = {f_stat:.4f}, p = {p_val:.4e}\")\n",
    "\n",
    "# Pairwise t-tests\n",
    "pairwise_pvals = []\n",
    "for a, b in combinations(immunizations, 2):\n",
    "    stat, p_val = ttest_ind(all_pairwise[a], all_pairwise[b])\n",
    "    print(f\"{a} vs {b}: t = {stat:.4f}, p = {p_val:.4e}\")\n",
    "    pairwise_pvals.append((a, b, p_val))\n",
    "\n",
    "# Step 5: Plot with error bars and significance lines\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(data=df_sim_stats, x='immunization', y='mean_similarity', ci=None, palette='Set2')\n",
    "plt.errorbar(x=np.arange(len(df_sim_stats)),\n",
    "             y=df_sim_stats['mean_similarity'],\n",
    "             yerr=df_sim_stats['std_similarity'],\n",
    "             fmt='none', c='black', capsize=5)\n",
    "plt.ylabel('Mean Cosine Similarity')\n",
    "\n",
    "# Update x-axis labels using title_map\n",
    "xticks = ax.get_xticks()\n",
    "xticklabels = df_sim_stats['immunization'].map(title_map)\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticklabels, rotation=0)\n",
    "\n",
    "# Add significance brackets\n",
    "def add_sig_bracket(ax, x1, x2, y, h, p_val, fontsize=12):\n",
    "    barx = [x1, x1, x2, x2]\n",
    "    bary = [y, y+h, y+h, y]\n",
    "    ax.plot(barx, bary, c='black')\n",
    "    if p_val < 0.001:\n",
    "        stars = '***'\n",
    "    elif p_val < 0.01:\n",
    "        stars = '**'\n",
    "    elif p_val < 0.05:\n",
    "        stars = '*'\n",
    "    else:\n",
    "        stars = 'ns'\n",
    "    ax.text((x1 + x2) / 2, y + h + 0.01, stars, ha='center', va='bottom', fontsize=fontsize)\n",
    "\n",
    "# Add brackets above bars\n",
    "y_max = df_sim_stats['mean_similarity'].max() + df_sim_stats['std_similarity'].max()\n",
    "h = 0.05 # height of brackets\n",
    "offset = 0\n",
    "for a, b, p in pairwise_pvals:\n",
    "    if p >= 0.05 or np.isnan(p):\n",
    "        continue \n",
    "    x1 = df_sim_stats[df_sim_stats['immunization'] == a].index[0]\n",
    "    x2 = df_sim_stats[df_sim_stats['immunization'] == b].index[0]\n",
    "    y = y_max + h * offset\n",
    "    add_sig_bracket(ax, x1, x2, y, h, p)\n",
    "    offset += 3\n",
    "\n",
    "plt.tight_layout()\n",
    "filename = os.path.join(output_dir, f\"cosine_heatmap_{immunization}.png\")\n",
    "plt.savefig(filename, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pingouin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "# For each immunization group:\n",
    "for imm, sub_df in pivot.groupby(level=0):\n",
    "    df_icc = sub_df.reset_index(level='barcode')\n",
    "    df_icc['immunization'] = imm\n",
    "    \n",
    "    # Flatten columns from MultiIndex to simple strings\n",
    "    df_icc.columns = ['_'.join(map(str, col)).strip('_') for col in df_icc.columns.values]\n",
    "    \n",
    "    print(df_icc.columns)  # check column names\n",
    "    \n",
    "    # Now melt with simple column names\n",
    "    df_long = df_icc.melt(id_vars=['immunization', 'barcode'], var_name='feature', value_name='value')\n",
    "    \n",
    "    import pingouin as pg\n",
    "    icc_res = pg.intraclass_corr(data=df_long, targets='barcode', raters='feature', ratings='value')\n",
    "    icc_21 = icc_res.loc[icc_res['Type'] == 'ICC2', :]\n",
    "    print(f\"ICC results for {imm}:\\n\", icc_21[['ICC', 'F', 'df1', 'df2', 'pval']])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Pivot the data\n",
    "pivot = df_filtered.pivot_table(\n",
    "    index=['immunization', 'barcode'],\n",
    "    columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "    values='Enrichment_Ratio',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "print(\"\\nPivot Table Columns (multi-index columns collapsed after reset):\")\n",
    "print(pivot.columns)\n",
    "\n",
    "# Reset index for metadata extraction\n",
    "pivot_data = pivot.reset_index()\n",
    "print(\"\\nPivot Data (after reset_index):\")\n",
    "print(pivot_data.head())\n",
    "\n",
    "# Extract feature matrix and metadata\n",
    "X = pivot_data.drop(columns=['immunization', 'barcode']).values\n",
    "meta = pivot_data[['immunization', 'barcode']]\n",
    "print(\"\\nMetadata Columns:\")\n",
    "print(meta.columns)\n",
    "\n",
    "# --- PCA ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df = pd.concat([pca_df.reset_index(drop=True), meta.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"\\nPCA DataFrame Columns:\")\n",
    "print(pca_df.columns)\n",
    "print(pca_df.head())\n",
    "\n",
    "# Flatten multi-index column names\n",
    "pca_df.columns = [col if isinstance(col, str) else col[0] for col in pca_df.columns]\n",
    "\n",
    "\n",
    "# Plot PCA\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='immunization', style='immunization', s=100)\n",
    "plt.title('PCA of Enrichment Profiles Across Barcodes')\n",
    "plt.xlim(-75, 50)\n",
    "plt.ylim(-65, 0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print explained variance\n",
    "print(\"\\nPCA Explained Variance Ratio:\")\n",
    "print(f\"PC1: {pca.explained_variance_ratio_[0]:.2%}, PC2: {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "\n",
    "# --- UMAP ---\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X)\n",
    "\n",
    "umap_df = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df = pd.concat([umap_df.reset_index(drop=True), meta.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"\\nUMAP DataFrame Columns:\")\n",
    "print(umap_df.columns)\n",
    "print(umap_df.head())\n",
    "\n",
    "umap_df = umap_df.rename(columns={('immunization', ''): 'immunization', ('barcode', ''): 'barcode'})\n",
    "\n",
    "\n",
    "# Plot UMAP\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='immunization', style='immunization', s=100)\n",
    "plt.title('UMAP of Enrichment Profiles Across Barcodes')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# Pivot data: each row is a barcode, columns are (position, AA), values are enrichment\n",
    "pivot = df_filtered.pivot_table(\n",
    "    index=['immunization', 'barcode'],\n",
    "    columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "    values='Enrichment_Ratio',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Reset index to keep immunization/barcode as columns\n",
    "pivot_reset = pivot.reset_index()\n",
    "\n",
    "# Separate features (X) and metadata\n",
    "X = pivot_reset.drop(columns=['immunization', 'barcode']).values\n",
    "meta = pivot_reset[['immunization', 'barcode']]\n",
    "\n",
    "# --- PCA ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['immunization'] = meta['immunization'].values\n",
    "pca_df['barcode'] = meta['barcode'].values\n",
    "\n",
    "# Plot PCA\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(data=pca_df, x='PC1', y='PC2', hue='immunization', style='immunization', s=100)\n",
    "plt.title('PCA of Enrichment Profiles (Each Point = 1 Barcode)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCA explained variance: PC1 = {pca.explained_variance_ratio_[0]:.2%}, PC2 = {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "\n",
    "# --- UMAP ---\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X)\n",
    "\n",
    "umap_df = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['immunization'] = meta['immunization'].values\n",
    "umap_df['barcode'] = meta['barcode'].values\n",
    "\n",
    "# Plot UMAP\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(data=umap_df, x='UMAP1', y='UMAP2', hue='immunization', style='immunization', s=100)\n",
    "plt.title('UMAP of Enrichment Profiles (Each Point = 1 Barcode)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# Filter out 'library_ctrl'\n",
    "df_filtered_no_ctrl = df_filtered[df_filtered['immunization'] != 'Library_ctrl']\n",
    "\n",
    "# Pivot data: each row is a barcode, columns are (position, AA), values are enrichment\n",
    "pivot = df_filtered_no_ctrl.pivot_table(\n",
    "    index=['immunization', 'barcode'],\n",
    "    columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "    values='Enrichment_Ratio',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Reset index to keep immunization/barcode as columns\n",
    "pivot_reset = pivot.reset_index()\n",
    "\n",
    "# Separate features (X) and metadata\n",
    "X = pivot_reset.drop(columns=['immunization', 'barcode']).values\n",
    "meta = pivot_reset[['immunization', 'barcode']]\n",
    "\n",
    "# --- PCA ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['immunization'] = meta['immunization'].values\n",
    "pca_df['barcode'] = meta['barcode'].values\n",
    "\n",
    "# Plot PCA with strong colors and circle markers (no style)\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1', y='PC2',\n",
    "    hue='immunization',\n",
    "    palette=\"bright\",\n",
    "    s=100,\n",
    "    marker='o',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8\n",
    ")\n",
    "plt.title('PCA of Enrichment Profiles (Each Point = 1 Barcode)')\n",
    "plt.legend(title='Immunization', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCA explained variance: PC1 = {pca.explained_variance_ratio_[0]:.2%}, PC2 = {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "\n",
    "# --- UMAP ---\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X)\n",
    "\n",
    "umap_df = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['immunization'] = meta['immunization'].values\n",
    "umap_df['barcode'] = meta['barcode'].values\n",
    "\n",
    "# Plot UMAP with strong colors and circle markers (no style)\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x='UMAP1', y='UMAP2',\n",
    "    hue='immunization',\n",
    "    palette=\"bright\",\n",
    "    s=100,\n",
    "    marker='o',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8\n",
    ")\n",
    "plt.title('UMAP of Enrichment Profiles (Each Point = 1 Barcode)')\n",
    "plt.legend(title='Immunization', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('PCA_UMAP_Clusters.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Optional log transform if data skewed:\n",
    "X_log = np.log10(X + 1e-3)\n",
    "\n",
    "# Standard scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_log)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['immunization'] = meta['immunization'].values\n",
    "pca_df['barcode'] = meta['barcode'].values\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1', y='PC2',\n",
    "    hue='immunization',\n",
    "    palette=\"bright\",\n",
    "    s=40,\n",
    "    marker='o',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8\n",
    ")\n",
    "plt.title('PCA of Enrichment Profiles (Each Point = 1 Barcode)')\n",
    "plt.legend(title='Immunization', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCA explained variance: PC1 = {pca.explained_variance_ratio_[0]:.2%}, PC2 = {pca.explained_variance_ratio_[1]:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    'Polyclonal_Ab': 'darkorange',\n",
    "    'Neutralizing_Ab': 'red',\n",
    "    'wildtype_RBD': 'green',\n",
    "    'Mutant_RBD': 'darkblue'\n",
    "}\n",
    "\n",
    "title_map = {\n",
    "    'Polyclonal_Ab': 'Anti-SARS-CoV-2 pAB',\n",
    "    'Neutralizing_Ab': 'Anti-SARS-CoV-2 nAb',\n",
    "    'wildtype_RBD': 'IgG secreting cells\\n SARS-CoV-2 Wuhan',\n",
    "    'Mutant_RBD': 'IgG secreting cells \\n SARS-CoV-2 B.1.135',\n",
    "    'Library_ctrl': 'Lib\\n2',\n",
    "    'Un-enrich. Libr': 'Un-enrich.\\nLibrary'\n",
    "}\n",
    "\n",
    "# Map the immunization short names to pretty labels\n",
    "pca_df['immunization_pretty'] = pca_df['immunization'].map(title_map).fillna(pca_df['immunization'])\n",
    "\n",
    "# Build palette dict for seaborn keyed by pretty labels\n",
    "color_map_pretty = {\n",
    "    title_map[k]: color_map[k] for k in title_map if k in color_map\n",
    "}\n",
    "# Add jitter to PC1 and PC2 (adjust magnitude as needed)\n",
    "jitter_strength = 0.1\n",
    "pca_df['PC1_jitter'] = pca_df['PC1'] + np.random.normal(0, jitter_strength, size=len(pca_df))\n",
    "pca_df['PC2_jitter'] = pca_df['PC2'] + np.random.normal(0, jitter_strength, size=len(pca_df))\n",
    "\n",
    "plt.figure(figsize=(8 , 6))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1', y='PC2',\n",
    "    hue='immunization_pretty',\n",
    "    palette=color_map_pretty,\n",
    "    s=60,\n",
    "    alpha=0.7,\n",
    "    marker='o',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8\n",
    ")\n",
    "plt.title('')\n",
    "plt.legend(title='Immunization', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "filename = os.path.join(output_dir, f\"PCA_Immuni.png\")\n",
    "plt.savefig(filename, dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "# Run DBSCAN on PCA components\n",
    "dbscan = DBSCAN(eps=2, min_samples=5)  # Tune eps and min_samples as needed\n",
    "pca_df['cluster'] = dbscan.fit_predict(X_pca)\n",
    "\n",
    "# Map cluster -1 (noise) to a label\n",
    "pca_df['cluster_label'] = pca_df['cluster'].apply(lambda x: 'noise' if x == -1 else f'cluster {x}')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1', y='PC2',\n",
    "    hue='immunization_pretty',\n",
    "    style='cluster_label',      # Different markers for clusters\n",
    "    palette=color_map_pretty,\n",
    "    s=60,\n",
    "    alpha=0.8,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8\n",
    ")\n",
    "plt.title('PCA of Enrichment Profiles with DBSCAN Clusters')\n",
    "plt.legend(title='Immunization / Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import ConvexHull\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clustering using DBSCAN ---\n",
    "clustering = DBSCAN(eps=0.5, min_samples=5).fit(X_umap)\n",
    "cluster_labels = clustering.labels_\n",
    "\n",
    "# Add to UMAP DataFrame\n",
    "umap_df['Cluster'] = cluster_labels\n",
    "\n",
    "# Plot UMAP with clusters instead of immunization\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x='UMAP1', y='UMAP2',\n",
    "    hue='Cluster',\n",
    "    palette='tab10',\n",
    "    s=100,\n",
    "    marker='o',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8,\n",
    "    legend='full'\n",
    ")\n",
    "plt.title('UMAP with DBSCAN Clusters')\n",
    "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 7))\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x='UMAP1', y='UMAP2',\n",
    "    hue='Cluster',\n",
    "    palette='tab10',\n",
    "    s=100,\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8,\n",
    "    legend='full'\n",
    ")\n",
    "\n",
    "# Draw convex hulls around each cluster\n",
    "for cluster_id in sorted(umap_df['Cluster'].unique()):\n",
    "    if cluster_id == -1:  # Skip noise if using DBSCAN\n",
    "        continue\n",
    "    cluster_points = umap_df[umap_df['Cluster'] == cluster_id][['UMAP1', 'UMAP2']].values\n",
    "    if len(cluster_points) >= 3:\n",
    "        hull = ConvexHull(cluster_points)\n",
    "        hull_points = cluster_points[hull.vertices]\n",
    "        plt.fill(hull_points[:, 0], hull_points[:, 1], alpha=0.2, label=f'Cluster {cluster_id} boundary')\n",
    "\n",
    "plt.title('UMAP with Cluster Boundaries (DBSCAN)')\n",
    "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap_with_clusters(df_subset, title_suffix):\n",
    "    print(f\"\\n--- Processing subset: {title_suffix} ---\")\n",
    "    print(f\"Original subset size: {df_subset.shape}\")\n",
    "\n",
    "    if df_subset.empty:\n",
    "        print(f\"Subset '{title_suffix}' is empty. Skipping plot.\")\n",
    "        return\n",
    "\n",
    "    pivot = df_subset.pivot_table(\n",
    "        index=['immunization', 'barcode'],\n",
    "        columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "        values='Enrichment_Ratio',\n",
    "        fill_value=0\n",
    "    )\n",
    "    print(\"Enrichment_Ratio values in this subset:\")\n",
    "    print(df_subset['Enrichment_Ratio'].values)\n",
    "    print(f\"Pivot table shape: {pivot.shape}\")\n",
    "\n",
    "    pivot_reset = pivot.reset_index()\n",
    "    print(f\"Pivot reset shape: {pivot_reset.shape}\")\n",
    "    print(f\"Columns: {pivot_reset.columns}\")\n",
    "\n",
    "    X = pivot_reset.drop(columns=['immunization', 'barcode']).values\n",
    "    print(f\"Feature matrix shape (X): {X.shape}\")\n",
    "\n",
    "    if X.shape[0] == 0:\n",
    "        print(f\"No samples in feature matrix after dropping metadata. Skipping.\")\n",
    "        return\n",
    "    if X.shape[1] == 0:\n",
    "        print(f\"No features after dropping metadata. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Run UMAP\n",
    "    reducer = umap.UMAP(random_state=42)\n",
    "    embedding = reducer.fit_transform(X)\n",
    "    print(f\"UMAP embedding shape: {embedding.shape}\")\n",
    "\n",
    "    clustering = DBSCAN(eps=0.5, min_samples=5)\n",
    "    cluster_labels = clustering.fit_predict(embedding)\n",
    "    print(f\"Cluster labels assigned: {set(cluster_labels)}\")\n",
    "\n",
    "    umap_df = pd.DataFrame({\n",
    "        'UMAP1': embedding[:, 0],\n",
    "        'UMAP2': embedding[:, 1],\n",
    "        'Cluster': cluster_labels,\n",
    "        'immunization': pivot_reset['immunization'],\n",
    "        'barcode': pivot_reset['barcode']\n",
    "    })\n",
    "\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    sns.scatterplot(\n",
    "        data=umap_df,\n",
    "        x='UMAP1', y='UMAP2',\n",
    "        hue='Cluster',\n",
    "        palette='tab10',\n",
    "        s=100,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.8,\n",
    "        legend='full'\n",
    "    )\n",
    "\n",
    "    for cluster_id in sorted(umap_df['Cluster'].unique()):\n",
    "        if cluster_id == -1:\n",
    "            continue\n",
    "        cluster_points = umap_df[umap_df['Cluster'] == cluster_id][['UMAP1', 'UMAP2']].values\n",
    "        if len(cluster_points) >= 3:\n",
    "            hull = ConvexHull(cluster_points)\n",
    "            hull_points = cluster_points[hull.vertices]\n",
    "            plt.fill(hull_points[:, 0], hull_points[:, 1], alpha=0.2, label=f'Cluster {cluster_id} boundary')\n",
    "\n",
    "    plt.title(f'UMAP with Cluster Boundaries (DBSCAN) — {title_suffix}')\n",
    "    plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Filter data (check sizes!)\n",
    "df_filtered_no_ctrl = df_filtered[df_filtered['immunization'] != 'Library_ctrl']\n",
    "print(f\"Data after removing 'Library_ctrl': {df_filtered_no_ctrl.shape}\")\n",
    "\n",
    "df_er_gt1 = df_filtered_no_ctrl[df_filtered_no_ctrl['Enrichment_Ratio'] > 1]\n",
    "print(f\"Subset ER > 1 size: {df_er_gt1.shape}\")\n",
    "\n",
    "df_er_0to1 = df_filtered_no_ctrl[\n",
    "    (df_filtered_no_ctrl['Enrichment_Ratio'] > 0) &\n",
    "    (df_filtered_no_ctrl['Enrichment_Ratio'] < 1)\n",
    "]\n",
    "print(f\"Subset 0 < ER < 1 size: {df_er_0to1.shape}\")\n",
    "\n",
    "plot_umap_with_clusters(df_er_gt1, 'ER > 1')\n",
    "plot_umap_with_clusters(df_er_0to1, '0 < ER < 1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.spatial import ConvexHull\n",
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "# Filter out 'library_ctrl'\n",
    "df_filtered_no_ctrl = df_filtered[df_filtered['immunization'] != 'Library_ctrl']\n",
    "\n",
    "# Pivot data: each row is a barcode, columns are (position, AA), values are enrichment\n",
    "pivot = df_filtered_no_ctrl.pivot_table(\n",
    "    index=['immunization', 'barcode'],\n",
    "    columns=['Spike_AS_Position', 'Amino_Acid'],\n",
    "    values='Enrichment_Ratio',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Reset index to keep immunization/barcode as columns\n",
    "pivot_reset = pivot.reset_index()\n",
    "\n",
    "# Separate features (X) and metadata\n",
    "X = pivot_reset.drop(columns=['immunization', 'barcode']).values\n",
    "meta = pivot_reset[['immunization', 'barcode']]\n",
    "\n",
    "# --- PCA ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['immunization'] = meta['immunization'].values\n",
    "pca_df['barcode'] = meta['barcode'].values\n",
    "\n",
    "# Plot and save PCA\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.scatterplot(\n",
    "    data=pca_df,\n",
    "    x='PC1', y='PC2',\n",
    "    hue='immunization',\n",
    "    palette=\"bright\",\n",
    "    s=100,\n",
    "    marker='o',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8\n",
    ")\n",
    "plt.title('PCA of Enrichment Profiles (Each Point = 1 Barcode)')\n",
    "plt.legend(title='Immunization', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('PCA_Enrichment_Profiles.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"PCA explained variance: PC1 = {pca.explained_variance_ratio_[0]:.2%}, PC2 = {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "\n",
    "# --- UMAP ---\n",
    "reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = reducer.fit_transform(X)\n",
    "\n",
    "umap_df = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n",
    "umap_df['immunization'] = meta['immunization'].values\n",
    "umap_df['barcode'] = meta['barcode'].values\n",
    "\n",
    "# --- Clustering using DBSCAN ---\n",
    "clustering = DBSCAN(eps=0.5, min_samples=5).fit(X_umap)\n",
    "cluster_labels = clustering.labels_\n",
    "umap_df['Cluster'] = cluster_labels\n",
    "\n",
    "# Save cluster table\n",
    "umap_df[['barcode', 'immunization', 'Cluster']].to_csv('UMAP_Clusters.csv', index=False)\n",
    "\n",
    "# Plot UMAP with clusters\n",
    "plt.figure(figsize=(8, 7))\n",
    "sns.scatterplot(\n",
    "    data=umap_df,\n",
    "    x='UMAP1', y='UMAP2',\n",
    "    hue='Cluster',\n",
    "    palette='tab10',\n",
    "    s=100,\n",
    "    marker='o',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.8,\n",
    "    legend='full'\n",
    ")\n",
    "\n",
    "# Draw convex hulls around clusters\n",
    "for cluster_id in sorted(umap_df['Cluster'].unique()):\n",
    "    if cluster_id == -1:\n",
    "        continue\n",
    "    cluster_points = umap_df[umap_df['Cluster'] == cluster_id][['UMAP1', 'UMAP2']].values\n",
    "    if len(cluster_points) >= 3:\n",
    "        hull = ConvexHull(cluster_points)\n",
    "        hull_points = cluster_points[hull.vertices]\n",
    "        plt.fill(hull_points[:, 0], hull_points[:, 1], alpha=0.2, label=f'Cluster {cluster_id} boundary')\n",
    "\n",
    "plt.title('UMAP with Cluster Boundaries (DBSCAN)')\n",
    "plt.legend(title='Cluster', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.savefig('UMAP_DBSCAN_Clusters.png', dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high) using log scale\n",
    "def enrichment_color(enrichment):\n",
    "    max_enrichment = 3000\n",
    "    log_enrichment = np.log10(enrichment + 1)\n",
    "    max_log_enrichment = np.log10(max_enrichment + 1)\n",
    "    norm_value = log_enrichment / max_log_enrichment\n",
    "    norm_value = np.clip(norm_value, 0, 1)\n",
    "    return plt.cm.Reds(norm_value)\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Compute Sample_Count and Max_Enrichment for coloring\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'])\n",
    "    .agg(Sample_Count=('Enrichment_Ratio', 'count'),\n",
    "         Max_Enrichment=('Enrichment_Ratio', 'max'))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Assign colors\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Filter for positions > 365\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'] > 365]\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"barcode_logoplots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop by barcode (each plot includes immunization label)\n",
    "for barcode in df_combined['barcode'].unique():\n",
    "    df_barcode = df_combined[df_combined['barcode'] == barcode]\n",
    "    if df_barcode.empty:\n",
    "        continue\n",
    "    \n",
    "    immunization = df_barcode['immunization'].iloc[0]\n",
    "\n",
    "    print(f\"Generating plot for barcode {barcode} ({immunization})...\")\n",
    "\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_barcode,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",\n",
    "        color_col=\"color\",\n",
    "        title=f\"{immunization} - {barcode} logoplot (Occurrence-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    fig.set_size_inches(45, 4)\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3 + 1), vmax=np.log10(3000 + 1)))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Log(Enrichment Ratio)', rotation=270, labelpad=15)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Save plot\n",
    "    safe_barcode = barcode.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")  # Sanitize filename\n",
    "    plot_filename = os.path.join(output_dir, f\"{safe_barcode}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "    print(f\"Plot saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occurance based logo plotting calculates the frequency a certain variant appears across the single droplet/ single antibody repertoire where letter height represents the number of antibodies binding this variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high) using log scale\n",
    "def enrichment_color(enrichment):\n",
    "    # Set the max enrichment value for normalization\n",
    "    max_enrichment = 3000  # Adjust to the maximum value you want for color scaling\n",
    "    # Apply a logarithmic scale to the enrichment values\n",
    "    log_enrichment = np.log10(enrichment + 1)  # log(x+1) to avoid issues with zero or small values\n",
    "    max_log_enrichment = np.log10(max_enrichment + 1)\n",
    "    norm_value = log_enrichment / max_log_enrichment  # Normalize to range [0, 1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 3\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes\n",
    "    .reset_index(name='Sample_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on max enrichment ratio per amino acid at each site\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "\n",
    "df_agg = df_total.copy()\n",
    "df_agg['Amino_Acid'] = df_agg['Amino_Acid'].str.upper()\n",
    "df_agg = df_agg[df_agg['Amino_Acid'] != \"*\"]  # remove stop codons\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Occurrence-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add colorbar to the plot\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3 + 1), vmax=np.log10(3000 + 1)))  # Log scale for max\n",
    "    sm.set_array([])  # Required for the colorbar to work\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')  # Attach colorbar to the same axes as the plot\n",
    "    cbar.set_label('Log(Enrichment Ratio)', rotation=270, labelpad=15)  # Label the colorbar\n",
    "\n",
    "    # Set the y-axis label to 'Single Droplet'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel('IgG Secreting cell [n]')\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logop.png\")\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    \n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    \n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "\n",
    "def enrichment_height(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    \"\"\"\n",
    "    Safe symmetric log10 transformation of enrichment values.\n",
    "    \n",
    "    Args:\n",
    "        enrichment (float or array-like): Enrichment value(s).\n",
    "        epsilon (float): Minimum enrichment value to avoid log10(0).\n",
    "        max_cap (float): Maximum value to cap extremely high enrichments.\n",
    "    \n",
    "    Returns:\n",
    "        float or np.array: Transformed enrichment.\n",
    "    \"\"\"\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "\n",
    "# Count barcodes:\n",
    "# Total number of unique barcodes per immunization\n",
    "barcode_counts = (\n",
    "    df_logo_agg.groupby('immunization')['barcode']\n",
    "    .nunique()\n",
    "    .reset_index(name='Total_Barcodes')\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to numeric in case of strings; coerce errors to NaN\n",
    "df_total['Enrichment_Ratio'] = pd.to_numeric(df_total['Enrichment_Ratio'], errors='coerce')\n",
    "\n",
    "# Filter out rows with Enrichment_Ratio that are NaN, 0, negative, or infinite\n",
    "df_total = df_total[\n",
    "    df_total['Enrichment_Ratio'].notna() &  # not NaN\n",
    "    np.isfinite(df_total['Enrichment_Ratio']) &  # not inf or -inf\n",
    "    (df_total['Enrichment_Ratio'] > 0)  # positive only\n",
    "]\n",
    "\n",
    "df_agg = df_total.copy()\n",
    "# Aggregate enrichment ratio per barcode\n",
    "print(df_logo_agg.columns.tolist())\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "print(df_logo_agg.columns.tolist())\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "# Compute sample count separately\n",
    "sample_counts = (\n",
    "    df_logo_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Merge with df_combined (which contains enrichment and letter height)\n",
    "df_combined = df_agg.copy()\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Merge in sample count\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    sample_counts,\n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'],\n",
    "    how='left'  # Use 'left' to preserve all rows, or 'inner' if you only want those with sample counts\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "# Drop duplicates if needed\n",
    "df_combined = df_combined.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "df_combined = df_combined[df_combined['Enrichment_Ratio'] > 0]\n",
    "\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    barcode_counts,\n",
    "    on='immunization',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_combined['Sample_Fraction'] = (\n",
    "    100 * df_combined['Sample_Count'] / df_combined['Total_Barcodes']\n",
    ")\n",
    "\n",
    "\n",
    "df_combined['letter_height'] = df_combined['Enrichment_Ratio'].apply(enrichment_height)\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Reds(x / 100))\n",
    "df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: orange_cmap(x / 100))\n",
    "\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Add site label\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height', 'Sample_Count', 'Sample_Fraction']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter_heights\")\n",
    "    \n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Set the y-axis label to 'Single Droplet'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel('Log10 AB Escape - Binding', fontsize=13)\n",
    "\n",
    "  \n",
    "\n",
    "    # Set major ticks (e.g., every 1 unit)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "    \n",
    "    # Set minor ticks (e.g., every 0.25 unit)\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logop.png\")\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"orange_cmap\", norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    #sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    ax.set_xlabel('')\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    \n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "orange_cmap = plt.cm.get_cmap('YlOrBr') \n",
    "\n",
    "def enrichment_height(enrichment):\n",
    "    # If enrichment >= 1, use log2 transformation\n",
    "    if enrichment >= 1:\n",
    "        return np.log2(enrichment)\n",
    "    # If enrichment < 1, use -log2(1/enrichment)\n",
    "    else:\n",
    "        return -np.log2(1 / enrichment)\n",
    "\n",
    "\n",
    "# Count barcodes:\n",
    "# Total number of unique barcodes per immunization\n",
    "barcode_counts = (\n",
    "    df_logo_agg.groupby('immunization')['barcode']\n",
    "    .nunique()\n",
    "    .reset_index(name='Total_Barcodes')\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to numeric in case of strings; coerce errors to NaN\n",
    "df_total['Enrichment_Ratio'] = pd.to_numeric(df_total['Enrichment_Ratio'], errors='coerce')\n",
    "\n",
    "# Filter out rows with Enrichment_Ratio that are NaN, 0, negative, or infinite\n",
    "df_total = df_total[\n",
    "    df_total['Enrichment_Ratio'].notna() &  # not NaN\n",
    "    np.isfinite(df_total['Enrichment_Ratio']) &  # not inf or -inf\n",
    "    (df_total['Enrichment_Ratio'] > 0)  # positive only\n",
    "]\n",
    "df_total = df_total[df_total['Amino_Acid'] != \"*\"]\n",
    "df_agg = df_total.copy()\n",
    "# Aggregate enrichment ratio per barcode\n",
    "print(df_logo_agg.columns.tolist())\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "print(df_logo_agg.columns.tolist())\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "# Compute sample count separately\n",
    "sample_counts = (\n",
    "    df_logo_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Merge with df_combined (which contains enrichment and letter height)\n",
    "df_combined = df_agg.copy()\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Merge in sample count\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    sample_counts,\n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'],\n",
    "    how='left'  # Use 'left' to preserve all rows, or 'inner' if you only want those with sample counts\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "# Drop duplicates if needed\n",
    "df_combined = df_combined.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "df_combined = df_combined[df_combined['Enrichment_Ratio'] > 0]\n",
    "\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    barcode_counts,\n",
    "    on='immunization',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_combined['Sample_Fraction'] = (\n",
    "    100 * df_combined['Sample_Count'] / df_combined['Total_Barcodes']\n",
    ")\n",
    "\n",
    "\n",
    "df_combined['letter_height'] = df_combined['Enrichment_Ratio'].apply(enrichment_height)\n",
    "df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: orange_cmap(x / 100))\n",
    "\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Greens(x / 100))\n",
    "\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Add site label\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height', 'Sample_Count', 'Sample_Fraction']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter_heights\")\n",
    "    \n",
    "    positions = df_immunization['Spike_AS_Position']   # pandas Series\n",
    "    amino_acids = df_immunization['Amino_Acid']       # pandas Series\n",
    "    heights = df_immunization['letter_height']        # pandas Series\n",
    "    print(f\"Positions range from {positions.min()} to {positions.max()}\")\n",
    "    print(f\"Unique amino acids: {sorted(amino_acids.unique())}\")\n",
    "    print(\"Counts per position:\")\n",
    "    print(df_immunization.groupby('Spike_AS_Position')['Amino_Acid'].count())\n",
    "    print(f\"Letter height range: min {heights.min():.3f}, max {heights.max():.3f}\")\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter heights\")\n",
    "    \n",
    "        # Separate positive and negative letter heights for correct stacking\n",
    "    def separate_stacked_heights(df):\n",
    "        df_sorted = df.sort_values(\n",
    "            by=['Spike_AS_Position', 'letter_height'], ascending=[True, False]\n",
    "        )\n",
    "    \n",
    "        # Separate positive and negative heights\n",
    "        df_positive = df_sorted[df_sorted['letter_height'] >= 0].copy()\n",
    "        df_negative = df_sorted[df_sorted['letter_height'] < 0].copy()\n",
    "    \n",
    "        # Cumulative heights per position\n",
    "        df_positive['stack_bottom'] = df_positive.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_positive['letter_height']\n",
    "        df_negative['stack_bottom'] = df_negative.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_negative['letter_height']\n",
    "    \n",
    "        # Recombine\n",
    "        return pd.concat([df_positive, df_negative], axis=0).sort_values(\n",
    "            by=['Spike_AS_Position', 'stack_bottom']\n",
    "        )\n",
    "    \n",
    "    # Apply stacking fix per immunization before plotting\n",
    "    df_immunization = separate_stacked_heights(df_immunization)\n",
    "    \n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    ax.set_title('')\n",
    "    # Set the y-axis label to 'Single Droplet'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('AB Escape - Binding')\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logop1.png\")\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=orange_cmap, norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    #sm = plt.cm.ScalarMappable(cmap=\"Greens\", norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    \n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    # Calculate and print total (stacked) height per position\n",
    "    stacked_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTotal stacked heights per position for immunization:\", immunization)\n",
    "    print(stacked_heights.to_string(index=False))\n",
    "    # Compute stacked heights per position with individual contributions\n",
    "    position_summary = (\n",
    "        df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']]\n",
    "        .sort_values(by=['Spike_AS_Position', 'letter_height'], ascending=[True, False])\n",
    "    )\n",
    "    \n",
    "    # Add cumulative stacked height for plotting order visualization (optional)\n",
    "    position_summary['Cumulative_Height'] = position_summary.groupby('Spike_AS_Position')['letter_height'].cumsum()\n",
    "    \n",
    "    # Total stacked height per position\n",
    "    total_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n====== Immunization: {immunization} ======\")\n",
    "    print(\"Breakdown of letter heights at each position:\")\n",
    "    print(position_summary.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nTotal stacked height per position:\")\n",
    "    print(total_heights.to_string(index=False))\n",
    "\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "\n",
    "def enrichment_height(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    \"\"\"\n",
    "    Safe symmetric log10 transformation of enrichment values.\n",
    "    \n",
    "    Args:\n",
    "        enrichment (float or array-like): Enrichment value(s).\n",
    "        epsilon (float): Minimum enrichment value to avoid log10(0).\n",
    "        max_cap (float): Maximum value to cap extremely high enrichments.\n",
    "    \n",
    "    Returns:\n",
    "        float or np.array: Transformed enrichment.\n",
    "    \"\"\"\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "\n",
    "# Count barcodes:\n",
    "# Total number of unique barcodes per immunization\n",
    "barcode_counts = (\n",
    "    df_logo_agg.groupby('immunization')['barcode']\n",
    "    .nunique()\n",
    "    .reset_index(name='Total_Barcodes')\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to numeric in case of strings; coerce errors to NaN\n",
    "df_total['Enrichment_Ratio'] = pd.to_numeric(df_total['Enrichment_Ratio'], errors='coerce')\n",
    "\n",
    "# Filter out rows with Enrichment_Ratio that are NaN, 0, negative, or infinite\n",
    "df_total = df_total[\n",
    "    df_total['Enrichment_Ratio'].notna() &  # not NaN\n",
    "    np.isfinite(df_total['Enrichment_Ratio']) &  # not inf or -inf\n",
    "    (df_total['Enrichment_Ratio'] > 0)  # positive only\n",
    "]\n",
    "df_total = df_total[df_total['Amino_Acid'] != \"*\"]\n",
    "df_agg = df_total.copy()\n",
    "# Aggregate enrichment ratio per barcode\n",
    "print(df_logo_agg.columns.tolist())\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "print(df_logo_agg.columns.tolist())\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "# Compute sample count separately\n",
    "sample_counts = (\n",
    "    df_logo_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Merge with df_combined (which contains enrichment and letter height)\n",
    "df_combined = df_agg.copy()\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Merge in sample count\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    sample_counts,\n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'],\n",
    "    how='left'  # Use 'left' to preserve all rows, or 'inner' if you only want those with sample counts\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "# Drop duplicates if needed\n",
    "df_combined = df_combined.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "df_combined = df_combined[df_combined['Enrichment_Ratio'] > 0]\n",
    "\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    barcode_counts,\n",
    "    on='immunization',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_combined['Sample_Fraction'] = (\n",
    "    100 * df_combined['Sample_Count'] / df_combined['Total_Barcodes']\n",
    ")\n",
    "\n",
    "\n",
    "df_combined['letter_height'] = df_combined['Enrichment_Ratio'].apply(enrichment_height)\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: orange_cmap(x / 100))\n",
    "\n",
    "df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Greens(x / 100))\n",
    "\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Add site label\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height', 'Sample_Count', 'Sample_Fraction']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter_heights\")\n",
    "    \n",
    "    positions = df_immunization['Spike_AS_Position']   # pandas Series\n",
    "    amino_acids = df_immunization['Amino_Acid']       # pandas Series\n",
    "    heights = df_immunization['letter_height']        # pandas Series\n",
    "    print(f\"Positions range from {positions.min()} to {positions.max()}\")\n",
    "    print(f\"Unique amino acids: {sorted(amino_acids.unique())}\")\n",
    "    print(\"Counts per position:\")\n",
    "    print(df_immunization.groupby('Spike_AS_Position')['Amino_Acid'].count())\n",
    "    print(f\"Letter height range: min {heights.min():.3f}, max {heights.max():.3f}\")\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter heights\")\n",
    "    \n",
    "        # Separate positive and negative letter heights for correct stacking\n",
    "    def separate_stacked_heights(df):\n",
    "        df_sorted = df.sort_values(\n",
    "            by=['Spike_AS_Position', 'letter_height'], ascending=[True, False]\n",
    "        )\n",
    "    \n",
    "        # Separate positive and negative heights\n",
    "        df_positive = df_sorted[df_sorted['letter_height'] >= 0].copy()\n",
    "        df_negative = df_sorted[df_sorted['letter_height'] < 0].copy()\n",
    "    \n",
    "        # Cumulative heights per position\n",
    "        df_positive['stack_bottom'] = df_positive.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_positive['letter_height']\n",
    "        df_negative['stack_bottom'] = df_negative.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_negative['letter_height']\n",
    "    \n",
    "        # Recombine\n",
    "        return pd.concat([df_positive, df_negative], axis=0).sort_values(\n",
    "            by=['Spike_AS_Position', 'stack_bottom']\n",
    "        )\n",
    "    \n",
    "    # Apply stacking fix per immunization before plotting\n",
    "    df_immunization = separate_stacked_heights(df_immunization)\n",
    "    \n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    ax.set_title('')\n",
    "    # Set the y-axis label to 'Single Droplet'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Log10 AB Escape - Binding', fontsize=13)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.25))\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logop1.png\")\n",
    "\n",
    "    # Add colorbar\n",
    "    #sm = plt.cm.ScalarMappable(cmap=orange_cmap, norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Greens\", norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    \n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    # Calculate and print total (stacked) height per position\n",
    "    stacked_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTotal stacked heights per position for immunization:\", immunization)\n",
    "    print(stacked_heights.to_string(index=False))\n",
    "    # Compute stacked heights per position with individual contributions\n",
    "    position_summary = (\n",
    "        df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']]\n",
    "        .sort_values(by=['Spike_AS_Position', 'letter_height'], ascending=[True, False])\n",
    "    )\n",
    "    \n",
    "    # Add cumulative stacked height for plotting order visualization (optional)\n",
    "    position_summary['Cumulative_Height'] = position_summary.groupby('Spike_AS_Position')['letter_height'].cumsum()\n",
    "    \n",
    "    # Total stacked height per position\n",
    "    total_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n====== Immunization: {immunization} ======\")\n",
    "    print(\"Breakdown of letter heights at each position:\")\n",
    "    print(position_summary.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nTotal stacked height per position:\")\n",
    "    print(total_heights.to_string(index=False))\n",
    "\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL PLOT with Inversed coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plots For single barcodes in SI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import altair as alt\n",
    "\n",
    "# Load and clean the Excel data\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "df_total = pd.read_excel(file_path, usecols=[\n",
    "    \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\",\n",
    "    \"Amino_Acid\", \"Type_of_Mutation\", \"Enrichment_Ratio\",\n",
    "    \"barcode\", \"immunization\", \"condition\", \"Total_Reads\"\n",
    "])\n",
    "df_total[\"Spike_AS_Position\"] -= 5  # Adjust for 336 -> 331\n",
    "\n",
    "# Clean up: remove NaNs, low reads, and stop codons\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio','Amino_Acid'])\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 100]\n",
    "df_total = df_total[df_total[\"Type_of_Mutation\"] != 'SYNOM']\n",
    "df_total = df_total[df_total[\"Enrichment_Ratio\"] > 0]\n",
    "df_total = df_total[df_total[\"Amino_Acid\"] != '*']  # Exclude stop codons\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "def enrichment_height(enrichment, epsilon=1e-6, max_cap=1e6):\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "df_logo_agg = df_total.copy()\n",
    "df_logo_agg = df_logo_agg.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'])\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Spike_AS_Position'] > 364]\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "df_combined = df_logo_agg.copy()\n",
    "df_combined['letter_height'] = df_combined['Enrichment_Ratio'].apply(enrichment_height)\n",
    "\n",
    "# -----------------------------\n",
    "# Color amino acids by identity\n",
    "# Color amino acids by identity\n",
    "aa_colors = {\n",
    "    'A':'#1f77b4','R':'#ff7f0e','N':'#2ca02c','D':'#d62728',\n",
    "    'C':'#9467bd','Q':'#8c564b','E':'#e377c2','G':'#7f7f7f',\n",
    "    'H':'#bcbd22','I':'#17becf','L':'#aec7e8','K':'#ffbb78',\n",
    "    'M':'#98df8a','F':'#ff9896','P':'#c5b0d5','S':'#c49c94',\n",
    "    'T':'#f7b6d2','W':'#dbdb8d','Y':'#9edae5','V':'#393b79'\n",
    "}\n",
    "df_combined['color'] = df_combined['Amino_Acid'].map(aa_colors).fillna('#000000')\n",
    "\n",
    "\n",
    "\n",
    "# Add site label\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Stacking function\n",
    "def separate_stacked_heights(df):\n",
    "    # Sort once by position and height descending\n",
    "    df_sorted = df.sort_values(by=['Spike_AS_Position', 'letter_height'], ascending=[True, False])\n",
    "    df_positive = df_sorted[df_sorted['letter_height'] >= 0].copy()\n",
    "    df_negative = df_sorted[df_sorted['letter_height'] < 0].copy()\n",
    "\n",
    "    df_positive['stack_bottom'] = df_positive.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_positive['letter_height']\n",
    "    df_negative['stack_bottom'] = df_negative.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_negative['letter_height']\n",
    "\n",
    "    return pd.concat([df_positive, df_negative], axis=0).sort_values(by=['Spike_AS_Position', 'stack_bottom'])\n",
    "\n",
    "# -----------------------------\n",
    "# Plot per barcode\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    eligible_barcodes = [\n",
    "        bc for bc, sub_df in df_immunization.groupby('barcode')\n",
    "        if sub_df['Spike_AS_Position'].nunique() > 10\n",
    "    ]\n",
    "\n",
    "    if not eligible_barcodes:\n",
    "        continue\n",
    "\n",
    "    sampled_barcodes = random.sample(eligible_barcodes, min(12, len(eligible_barcodes)))\n",
    "\n",
    "    for barcode in sampled_barcodes:\n",
    "        df_barcode = df_immunization.query(f'barcode == \"{barcode}\"').copy()\n",
    "\n",
    "        df_barcode = df_barcode[(df_barcode['Spike_AS_Position'] >= 420) &\n",
    "                                (df_barcode['Spike_AS_Position'] <= 520)]\n",
    "\n",
    "        if df_barcode.empty:\n",
    "            continue  # skip if nothing in this range\n",
    "\n",
    "        aa_list = sorted(df_barcode['Amino_Acid'].unique())\n",
    "        gray_values = np.linspace(0.0, 0.9, len(aa_list))  # from black (0.0) to almost white (0.9)\n",
    "        aa_gray_colors = {aa: str(gray_values[i]) for i, aa in enumerate(aa_list)}\n",
    "        df_barcode['color'] = df_barcode['Amino_Acid'].map(aa_gray_colors)\n",
    "\n",
    "        \n",
    "        # Assign colors per barcode (optional: adjust colormap if needed)\n",
    "        #norm = colors.Normalize(vmin=df_barcode['letter_height'].min(), vmax=df_barcode['letter_height'].max())\n",
    "        #df_barcode['color'] = df_barcode['letter_height'].apply(lambda x: plt.cm.Blues_r(norm(x)))\n",
    "        # Apply stacking\n",
    "        df_barcode = separate_stacked_heights(df_barcode)\n",
    "        plot_title = f\"{immunization} - {barcode}\"\n",
    "        print(f\"Generating plot: {plot_title}\")\n",
    "        # Plot logo\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_barcode,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"letter_height\",\n",
    "            color_col=\"color\",\n",
    "            title=f\"\",\n",
    "            addbreaks=True\n",
    "        )\n",
    "        fig.set_size_inches(fig.get_size_inches()[0], fig.get_size_inches()[1] + 1)\n",
    "        ax.set_ylabel(\n",
    "            \"Log10 AB binding (median)\\n$\\\\mathbf{\\\\Leftarrow}$ Enrichment $\\\\mathbf{\\\\Rightarrow}$\",\n",
    "            rotation=90, labelpad=15, ha='right', fontsize=14\n",
    "        )\n",
    "        ax.yaxis.set_label_coords(-0.025, 1)\n",
    "        # Y-axis ticks: fewer and larger\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(2))   # every 2 units\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(1))   # minor every 1 unit\n",
    "        ax.tick_params(axis='y', which='major', length=8, labelsize=14)  # major ticks longer & labels bigger\n",
    "        ax.tick_params(axis='y', which='minor', length=4, labelsize=10)  # minor ticks smaller\n",
    "        \n",
    "\n",
    "        fig_path = os.path.join(output_dir, f\"logo_{immunization}_{barcode}_RandomAll.png\")\n",
    "        fig.savefig(fig_path, bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "# Load and clean the Excel data\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "df_total = pd.read_excel(file_path, usecols=[\n",
    "    \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\",\n",
    "    \"Amino_Acid\", \"Type_of_Mutation\", \"Enrichment_Ratio\",\n",
    "    \"barcode\", \"immunization\", \"condition\", \"Total_Reads\"\n",
    "])\n",
    "df_total[\"Spike_AS_Position\"] -= 5  # Adjust for 336 -> 331\n",
    "\n",
    "# Clean up: remove NaNs, low reads, stop codons, and synom mutations\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio','Amino_Acid'])\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 100]\n",
    "df_total = df_total[df_total[\"Type_of_Mutation\"] != 'SYNOM']\n",
    "df_total = df_total[df_total[\"Enrichment_Ratio\"] > 0]\n",
    "df_total = df_total[df_total[\"Amino_Acid\"] != '*']\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "def enrichment_height(enrichment, epsilon=1e-6, max_cap=1e6):\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "df_logo_agg = df_total.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'])\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Spike_AS_Position'] > 364]\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg['letter_height'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_height)\n",
    "\n",
    "# -----------------------------\n",
    "# Color amino acids by identity\n",
    "aa_colors = {\n",
    "    'A':'#1f77b4','R':'#ff7f0e','N':'#2ca02c','D':'#d62728',\n",
    "    'C':'#9467bd','Q':'#8c564b','E':'#e377c2','G':'#7f7f7f',\n",
    "    'H':'#bcbd22','I':'#17becf','L':'#aec7e8','K':'#ffbb78',\n",
    "    'M':'#98df8a','F':'#ff9896','P':'#c5b0d5','S':'#c49c94',\n",
    "    'T':'#f7b6d2','W':'#dbdb8d','Y':'#9edae5','V':'#393b79'\n",
    "}\n",
    "df_logo_agg['color'] = df_logo_agg['Amino_Acid'].map(aa_colors).fillna('#000000')\n",
    "\n",
    "# Add site label\n",
    "df_logo_agg = df_logo_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Stacking function (DMS-style)\n",
    "def separate_stacked_heights(df):\n",
    "    df_sorted = df.sort_values(by=['Spike_AS_Position', 'letter_height'], ascending=[True, False])\n",
    "    df_positive = df_sorted[df_sorted['letter_height'] >= 0].copy()\n",
    "    df_negative = df_sorted[df_sorted['letter_height'] < 0].copy()\n",
    "\n",
    "    df_positive['stack_bottom'] = df_positive.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_positive['letter_height']\n",
    "    df_negative['stack_bottom'] = df_negative.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_negative['letter_height']\n",
    "\n",
    "    return pd.concat([df_positive, df_negative], axis=0).sort_values(by=['Spike_AS_Position', 'stack_bottom'])\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Plot per barcode\n",
    "for immunization in df_logo_agg['immunization'].unique():\n",
    "    df_immunization = df_logo_agg.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    eligible_barcodes = [\n",
    "        bc for bc, sub_df in df_immunization.groupby('barcode')\n",
    "        if sub_df['Spike_AS_Position'].nunique() > 10\n",
    "    ]\n",
    "\n",
    "    if not eligible_barcodes:\n",
    "        continue\n",
    "\n",
    "    sampled_barcodes = random.sample(eligible_barcodes, min(12, len(eligible_barcodes)))\n",
    "\n",
    "    for barcode in sampled_barcodes:\n",
    "        df_barcode = df_immunization.query(f'barcode == \"{barcode}\"').copy()\n",
    "        df_barcode = df_barcode[(df_barcode['Spike_AS_Position'] >= 420) &\n",
    "                                (df_barcode['Spike_AS_Position'] <= 520)]\n",
    "        if df_barcode.empty:\n",
    "            continue\n",
    "\n",
    "        # Apply stacking\n",
    "        df_barcode = separate_stacked_heights(df_barcode)\n",
    "\n",
    "        # Plot\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_barcode,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"letter_height\",\n",
    "            color_col=\"color\",\n",
    "            title=f\"\",\n",
    "            addbreaks=True\n",
    "        )\n",
    "        #fig.set_size_inches(fig.get_size_inches()[0], fig.get_size_inches()[1] + 1)\n",
    "        ax.set_ylabel(\n",
    "            \"Log10 AB binding (median)\\n$\\\\mathbf{\\\\Leftarrow}$ Enrichment $\\\\mathbf{\\\\Rightarrow}$\",\n",
    "            rotation=90, labelpad=15, ha='right', fontsize=14\n",
    "        )\n",
    "        ax.yaxis.set_label_coords(-0.025, 1)\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "        ax.yaxis.set_minor_locator(ticker.MultipleLocator(1))\n",
    "        ax.tick_params(axis='y', which='major', length=8, labelsize=15)\n",
    "        ax.tick_params(axis='y', which='minor', length=4, labelsize=15)\n",
    "\n",
    "        fig_path = os.path.join(output_dir, f\"logo_{immunization}_{barcode}New.png\")\n",
    "        fig.savefig(fig_path, bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single droplet letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logoplots for Figure 1. Log10 median ER (Logoplots are separated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "\n",
    "def enrichment_height(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    \"\"\"\n",
    "    Safe symmetric log10 transformation of enrichment values.\n",
    "    \n",
    "    Args:\n",
    "        enrichment (float or array-like): Enrichment value(s).\n",
    "        epsilon (float): Minimum enrichment value to avoid log10(0).\n",
    "        max_cap (float): Maximum value to cap extremely high enrichments.\n",
    "    \n",
    "    Returns:\n",
    "        float or np.array: Transformed enrichment.\n",
    "    \"\"\"\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "\n",
    "# Count barcodes:\n",
    "# Total number of unique barcodes per immunization\n",
    "barcode_counts = (\n",
    "    df_logo_agg.groupby('immunization')['barcode']\n",
    "    .nunique()\n",
    "    .reset_index(name='Total_Barcodes')\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to numeric in case of strings; coerce errors to NaN\n",
    "df_total['Enrichment_Ratio'] = pd.to_numeric(df_total['Enrichment_Ratio'], errors='coerce')\n",
    "df_total = df_total[df_total[\"Count_of_Base\"] > 3]\n",
    "\n",
    "# Filter out rows with Enrichment_Ratio that are NaN, 0, negative, or infinite\n",
    "df_total = df_total[\n",
    "    df_total['Enrichment_Ratio'].notna() &  # not NaN\n",
    "    np.isfinite(df_total['Enrichment_Ratio']) &  # not inf or -inf\n",
    "    (df_total['Enrichment_Ratio'] > 0)  # positive only\n",
    "]\n",
    "df_total = df_total[df_total['Amino_Acid'] != \"*\"]\n",
    "df_agg = df_total.copy()\n",
    "# Aggregate enrichment ratio per barcode\n",
    "print(df_logo_agg.columns.tolist())\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "print(df_logo_agg.columns.tolist())\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "# Compute sample count separately\n",
    "sample_counts = (\n",
    "    df_logo_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Merge with df_combined (which contains enrichment and letter height)\n",
    "df_combined = df_agg.copy()\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Merge in sample count\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    sample_counts,\n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'],\n",
    "    how='left'  # Use 'left' to preserve all rows, or 'inner' if you only want those with sample counts\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "# Drop duplicates if needed\n",
    "df_combined = df_combined.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "df_combined = df_combined[df_combined['Enrichment_Ratio'] > 0]\n",
    "\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    barcode_counts,\n",
    "    on='immunization',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_combined['Sample_Fraction'] = (\n",
    "    100 * df_combined['Sample_Count'] / df_combined['Total_Barcodes']\n",
    ")\n",
    "\n",
    "\n",
    "df_combined['letter_height'] = df_combined['Enrichment_Ratio'].apply(enrichment_height)\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: orange_cmap(x / 100))\n",
    "norm = colors.Normalize(vmin=0, vmax=100)\n",
    "df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Blues(1 - norm(x)))\n",
    "\n",
    "\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Blues(x / 100))\n",
    "\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Add site label\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417,418, 439,400, 440,441,442, 452,453,454, 476, 477, 483,484,485, 493, 499,500,501, 502, 505,506]\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "    print(f\"Sample_Fraction range: min={df_combined['Sample_Fraction'].min()}, max={df_combined['Sample_Fraction'].max()}\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height', 'Sample_Count', 'Sample_Fraction']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter_heights\")\n",
    "    \n",
    "    positions = df_immunization['Spike_AS_Position']   # pandas Series\n",
    "    amino_acids = df_immunization['Amino_Acid']       # pandas Series\n",
    "    heights = df_immunization['letter_height']        # pandas Series\n",
    "    print(f\"Positions range from {positions.min()} to {positions.max()}\")\n",
    "    print(f\"Unique amino acids: {sorted(amino_acids.unique())}\")\n",
    "    print(\"Counts per position:\")\n",
    "    print(df_immunization.groupby('Spike_AS_Position')['Amino_Acid'].count())\n",
    "    print(f\"Letter height range: min {heights.min():.3f}, max {heights.max():.3f}\")\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter heights\")\n",
    "    \n",
    "        # Separate positive and negative letter heights for correct stacking\n",
    "    def separate_stacked_heights(df):\n",
    "        df_sorted = df.sort_values(\n",
    "            by=['Spike_AS_Position', 'letter_height'], ascending=[True, False]\n",
    "        )\n",
    "    \n",
    "        # Separate positive and negative heights\n",
    "        df_positive = df_sorted[df_sorted['letter_height'] >= 0].copy()\n",
    "        df_negative = df_sorted[df_sorted['letter_height'] < 0].copy()\n",
    "    \n",
    "        # Cumulative heights per position\n",
    "        df_positive['stack_bottom'] = df_positive.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_positive['letter_height']\n",
    "        df_negative['stack_bottom'] = df_negative.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_negative['letter_height']\n",
    "    \n",
    "        # Recombine\n",
    "        return pd.concat([df_positive, df_negative], axis=0).sort_values(\n",
    "            by=['Spike_AS_Position', 'stack_bottom']\n",
    "        )\n",
    "    \n",
    "    # Apply stacking fix per immunization before plotting\n",
    "    df_immunization = separate_stacked_heights(df_immunization)\n",
    "    \n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    ax.set_title('')\n",
    "    # Set the y-axis label to 'Single Droplet'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Log10 AB Escape - Binding', fontsize=13)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logop1.png\")\n",
    "\n",
    "    # Add colorbar\n",
    "    #sm = plt.cm.ScalarMappable(cmap=orange_cmap, norm=plt.Normalize(vmin=0, vmax=100))\n",
    "\n",
    "    cmap = plt.cm.Blues_r  # reversed Blues colormap\n",
    "    norm = colors.Normalize(vmin=0, vmax=100)\n",
    "    \n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "        \n",
    "    #sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    #sm.set_array([])\n",
    "    #cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    #cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    \n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    # Calculate and print total (stacked) height per position\n",
    "    stacked_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTotal stacked heights per position for immunization:\", immunization)\n",
    "    print(stacked_heights.to_string(index=False))\n",
    "    # Compute stacked heights per position with individual contributions\n",
    "    position_summary = (\n",
    "        df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']]\n",
    "        .sort_values(by=['Spike_AS_Position', 'letter_height'], ascending=[True, False])\n",
    "    )\n",
    "    \n",
    "    # Add cumulative stacked height for plotting order visualization (optional)\n",
    "    position_summary['Cumulative_Height'] = position_summary.groupby('Spike_AS_Position')['letter_height'].cumsum()\n",
    "    \n",
    "    # Total stacked height per position\n",
    "    total_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n====== Immunization: {immunization} ======\")\n",
    "    print(\"Breakdown of letter heights at each position:\")\n",
    "    print(position_summary.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nTotal stacked height per position:\")\n",
    "    print(total_heights.to_string(index=False))\n",
    "\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# --------#luca3\n",
    "def enrichment_height(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    \"\"\"\n",
    "    Safe symmetric log10 transformation of enrichment values.\n",
    "    \n",
    "    Args:\n",
    "        enrichment (float or array-like): Enrichment value(s).\n",
    "        epsilon (float): Minimum enrichment value to avoid log10(0).\n",
    "        max_cap (float): Maximum value to cap extremely high enrichments.\n",
    "    \n",
    "    Returns:\n",
    "        float or np.array: Transformed enrichment.\n",
    "    \"\"\"\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "\n",
    "# Count barcodes:\n",
    "# Total number of unique barcodes per immunization\n",
    "barcode_counts = (\n",
    "    df_logo_agg.groupby('immunization')['barcode']\n",
    "    .nunique()\n",
    "    .reset_index(name='Total_Barcodes')\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to numeric in case of strings; coerce errors to NaN\n",
    "df_total['Enrichment_Ratio'] = pd.to_numeric(df_total['Enrichment_Ratio'], errors='coerce')\n",
    "\n",
    "# Filter out rows with Enrichment_Ratio that are NaN, 0, negative, or infinite\n",
    "df_total = df_total[\n",
    "    df_total['Enrichment_Ratio'].notna() &  # not NaN\n",
    "    np.isfinite(df_total['Enrichment_Ratio']) &  # not inf or -inf\n",
    "    (df_total['Enrichment_Ratio'] > 0)  # positive only\n",
    "]\n",
    "df_total = df_total[df_total['Amino_Acid'] != \"*\"]\n",
    "df_agg = df_total.copy()\n",
    "# Aggregate enrichment ratio per barcode\n",
    "print(df_logo_agg.columns.tolist())\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "print(df_logo_agg.columns.tolist())\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "# Compute sample count separately\n",
    "sample_counts = (\n",
    "    df_logo_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Merge with df_combined (which contains enrichment and letter height)\n",
    "df_combined = df_agg.copy()\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Merge in sample count\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    sample_counts,\n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'],\n",
    "    how='left'  # Use 'left' to preserve all rows, or 'inner' if you only want those with sample counts\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "# Drop duplicates if needed\n",
    "df_combined = df_combined.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "df_combined = df_combined[df_combined['Enrichment_Ratio'] > 0]\n",
    "\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    barcode_counts,\n",
    "    on='immunization',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_combined['Sample_Fraction'] = (\n",
    "    100 * df_combined['Sample_Count'] / df_combined['Total_Barcodes']\n",
    ")\n",
    "\n",
    "\n",
    "df_combined['letter_height'] = df_combined['Enrichment_Ratio'].apply(enrichment_height)\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: orange_cmap(x / 100))\n",
    "norm = colors.Normalize(vmin=0, vmax=100)\n",
    "df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Blues(1 - norm(x)))\n",
    "\n",
    "\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Blues(x / 100))\n",
    "\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Add site label\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "    print(f\"Sample_Fraction range: min={df_combined['Sample_Fraction'].min()}, max={df_combined['Sample_Fraction'].max()}\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height', 'Sample_Count', 'Sample_Fraction']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter_heights\")\n",
    "    \n",
    "    positions = df_immunization['Spike_AS_Position']   # pandas Series\n",
    "    amino_acids = df_immunization['Amino_Acid']       # pandas Series\n",
    "    heights = df_immunization['letter_height']        # pandas Series\n",
    "    print(f\"Positions range from {positions.min()} to {positions.max()}\")\n",
    "    print(f\"Unique amino acids: {sorted(amino_acids.unique())}\")\n",
    "    print(\"Counts per position:\")\n",
    "    print(df_immunization.groupby('Spike_AS_Position')['Amino_Acid'].count())\n",
    "    print(f\"Letter height range: min {heights.min():.3f}, max {heights.max():.3f}\")\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter heights\")\n",
    "    \n",
    "        # Separate positive and negative letter heights for correct stacking\n",
    "    def separate_stacked_heights(df):\n",
    "        df_sorted = df.sort_values(\n",
    "            by=['Spike_AS_Position', 'letter_height'], ascending=[True, False]\n",
    "        )\n",
    "    \n",
    "        # Separate positive and negative heights\n",
    "        df_positive = df_sorted[df_sorted['letter_height'] >= 0].copy()\n",
    "        df_negative = df_sorted[df_sorted['letter_height'] < 0].copy()\n",
    "    \n",
    "        # Cumulative heights per position\n",
    "        df_positive['stack_bottom'] = df_positive.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_positive['letter_height']\n",
    "        df_negative['stack_bottom'] = df_negative.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_negative['letter_height']\n",
    "    \n",
    "        # Recombine\n",
    "        return pd.concat([df_positive, df_negative], axis=0).sort_values(\n",
    "            by=['Spike_AS_Position', 'stack_bottom']\n",
    "        )\n",
    "    \n",
    "    # Apply stacking fix per immunization before plotting\n",
    "    df_immunization = separate_stacked_heights(df_immunization)\n",
    "    \n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    ax.set_title('')\n",
    "    # Set the y-axis label to 'Single Droplet'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(\"Log10 AB binding (median)\\n$\\\\mathbf{\\\\Leftarrow}$ Enrichment $\\\\mathbf{\\\\Rightarrow}$\", \n",
    "                  rotation=90, labelpad=20, ha='right', fontsize=14)\n",
    "    ax.yaxis.set_label_coords(-0.08, 0.97)\n",
    "    #ax.set_ylabel('Log10 AB Escape - Binding', fontsize=13)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logop1.png\")\n",
    "\n",
    "    # Add colorbar\n",
    "    #sm = plt.cm.ScalarMappable(cmap=orange_cmap, norm=plt.Normalize(vmin=0, vmax=100))\n",
    "\n",
    "    norm = colors.Normalize(vmin=0, vmax=100)\n",
    "\n",
    "    # 2) Grab the reversed colormap and truncate it so we skip the very top (white) 10%\n",
    "    orig_cmap = plt.cm.Blues_r\n",
    "    #    here we take only the values from 0.0→0.9 of the original colormap\n",
    "    trunc_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'truncBlues_r',\n",
    "        orig_cmap(np.linspace(0.0, 0.75, 256))\n",
    "    )\n",
    "\n",
    "    df_combined['color'] = df_combined['Sample_Fraction'].apply(\n",
    "        lambda x: trunc_cmap(norm(x))\n",
    "    )\n",
    "    \n",
    "    # 3) When you assign colors, still invert the norm so 0%→dark, 100%→light:\n",
    "    #df_combined['color'] = df_combined['Sample_Fraction'].apply(\n",
    "       # lambda x: trunc_cmap(1 - norm(x))\n",
    "    #)\n",
    "    \n",
    "    # …later, when you draw your logo, the letters will get these colors…\n",
    "    \n",
    "    # 4) And for the colorbar:\n",
    "    sm = plt.cm.ScalarMappable(cmap=trunc_cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    #sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    #sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "        \n",
    "    #sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    #sm.set_array([])\n",
    "    #cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    #cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    \n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    # Calculate and print total (stacked) height per position\n",
    "    stacked_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTotal stacked heights per position for immunization:\", immunization)\n",
    "    print(stacked_heights.to_string(index=False))\n",
    "    # Compute stacked heights per position with individual contributions\n",
    "    position_summary = (\n",
    "        df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']]\n",
    "        .sort_values(by=['Spike_AS_Position', 'letter_height'], ascending=[True, False])\n",
    "    )\n",
    "    \n",
    "    # Add cumulative stacked height for plotting order visualization (optional)\n",
    "    position_summary['Cumulative_Height'] = position_summary.groupby('Spike_AS_Position')['letter_height'].cumsum()\n",
    "    \n",
    "    # Total stacked height per position\n",
    "    total_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n====== Immunization: {immunization} ======\")\n",
    "    print(\"Breakdown of letter heights at each position:\")\n",
    "    print(position_summary.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nTotal stacked height per position:\")\n",
    "    print(total_heights.to_string(index=False))\n",
    "\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def create_truncated_cmap(base_cmap_name, vmin=0, vmax=100, max_fraction=0.75):\n",
    "    base_cmap = plt.cm.get_cmap(base_cmap_name)\n",
    "    trunc_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        f'{base_cmap_name}_trunc',\n",
    "        base_cmap(np.linspace(0.0, max_fraction, 256))\n",
    "    )\n",
    "    norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    return trunc_cmap, norm\n",
    "\n",
    "fig = plt.figure(figsize=(1, 3))\n",
    "\n",
    "# All reversed\n",
    "orange_cmap, norm_orange = create_truncated_cmap('YlOrBr_r', max_fraction=0.75)\n",
    "green_cmap,  norm_green  = create_truncated_cmap('Greens_r', max_fraction=0.75)\n",
    "blue_cmap,   norm_blue   = create_truncated_cmap('Blues_r',  max_fraction=0.75)\n",
    "\n",
    "gs = GridSpec(1, 3, figure=fig, wspace=0)\n",
    "\n",
    "axs = [fig.add_subplot(gs[0, i]) for i in range(3)]\n",
    "\n",
    "colorbars = [\n",
    "    (axs[0], orange_cmap, norm_orange, 'Fraction %\\nSingle-droplet repertoire'),\n",
    "    (axs[1], green_cmap, norm_green, ''),\n",
    "    (axs[2], blue_cmap, norm_blue, '')\n",
    "]\n",
    "\n",
    "# Custom ticks and labels for blue bar:\n",
    "custom_ticks = [0, 25, 50, 75, 100]\n",
    "custom_labels = ['Present in \\n 1x droplet', '25%', '50%', '75%', 'Present \\n in all \\n droplets']\n",
    "\n",
    "for i, (ax, cmap, norm, label) in enumerate(colorbars):\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, cax=ax, orientation='vertical')\n",
    "    cbar.set_label(label, rotation=270, labelpad=35, fontsize=14)\n",
    "\n",
    "    if i == 2:  # Blue bar gets custom text ticks\n",
    "        cbar.set_ticks(custom_ticks)\n",
    "        cbar.set_ticklabels(custom_labels)\n",
    "        cbar.ax.tick_params(labelsize=9)\n",
    "    else:\n",
    "        cbar.set_ticks([])\n",
    "        cbar.ax.tick_params(labelsize=0)\n",
    "\n",
    "fig.suptitle('Color Legends for Enrichment Ratio Plot', fontsize=14, y=1.02)\n",
    "plt.savefig('ColorBarDMS.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "def create_truncated_cmap(base_cmap_name, vmin=0, vmax=100, min_fraction=0.0, max_fraction=1.0):\n",
    "    base_cmap = plt.cm.get_cmap(base_cmap_name)\n",
    "    trunc_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        f'{base_cmap_name}_trunc',\n",
    "        base_cmap(np.linspace(min_fraction, max_fraction, 256))\n",
    "    )\n",
    "    norm = colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "    return trunc_cmap, norm\n",
    "\n",
    "fig = plt.figure(figsize=(2, 5))\n",
    "gs = GridSpec(1, 3, figure=fig, wspace=0)\n",
    "\n",
    "axs = [fig.add_subplot(gs[0, i]) for i in range(3)]\n",
    "\n",
    "# Use non-reversed colormaps: dark at 0, bright (white) at 100\n",
    "orange_cmap, norm_orange = create_truncated_cmap('YlOrBr', 0, 100, 0.0, 1.0)\n",
    "green_cmap, norm_green = create_truncated_cmap('Greens', 0, 100, 0.0, 1.0)\n",
    "blue_cmap, norm_blue = create_truncated_cmap('Blues', 0, 100, 0.0, 1.0)\n",
    "\n",
    "colorbars = [\n",
    "    (axs[0], orange_cmap, norm_orange, 'Fraction %\\nSingle-droplet repertoire'),\n",
    "    (axs[1], green_cmap, norm_green, ''),\n",
    "    (axs[2], blue_cmap, norm_blue, '')\n",
    "]\n",
    "\n",
    "for i, (ax, cmap, norm, label) in enumerate(colorbars):\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, cax=ax, orientation='vertical')\n",
    "    cbar.set_label(label, rotation=270, labelpad=35, fontsize=12)\n",
    "    ax.yaxis.set_label_coords(5, 0.5)\n",
    "    \n",
    "    if i == 2:\n",
    "        cbar.set_ticks(np.linspace(0, 100, 6))\n",
    "        cbar.ax.tick_params(labelsize=9)\n",
    "    else:\n",
    "        cbar.set_ticks([])\n",
    "        cbar.ax.tick_params(labelsize=0)\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "fig.suptitle('Color Legends for Enrichment Ratio Plot', fontsize=14, y=1.02)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "import altair as alt\n",
    "\n",
    "# Load FASTA sequence (Wuhan reference)\n",
    "fasta_file = r'/Users/lucaschlotheuber/Desktop/ETH/RBD201_DMS1.fa'\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    wuhan_sequence = str(record.seq)\n",
    "    break\n",
    "\n",
    "# Load and clean the Excel data\n",
    "file_path = r'/Users/lucaschlotheuber/Desktop/ETH/summary_DMS_cleaned.xlsx'\n",
    "df_total = pd.read_excel(file_path, usecols=[\n",
    "    \"DMS_RBD_AS_position\", \"Spike_AS_Position\", \"Count_of_Base\",\n",
    "    \"Amino_Acid\", \"Type_of_Mutation\", \"Enrichment_Ratio\",\n",
    "    \"barcode\", \"immunization\", \"condition\", \"Total_Reads\"\n",
    "])\n",
    "df_total[\"Spike_AS_Position\"] -= 5  # Adjust 336 -> 331\n",
    "\n",
    "# Clean up\n",
    "df_total = df_total.dropna(subset=['Enrichment_Ratio', 'Amino_Acid'])\n",
    "df_total = df_total[df_total[\"Total_Reads\"] > 1000]\n",
    "df_total = df_total[df_total[\"Amino_Acid\"] != '*']  # Exclude stop codons\n",
    "\n",
    "# Add Wuhan reference\n",
    "immunization = \"Wuhan_Sequence\"\n",
    "barcode = \"Wuhan_Barcode\"\n",
    "data_wuhan = [{\n",
    "    'DMS_RBD_AS_position': pos,\n",
    "    'Spike_AS_Position': pos + 330,\n",
    "    'Amino_Acid': aa,\n",
    "    'immunization': immunization,\n",
    "    'barcode': barcode,\n",
    "    'Enrichment_Ratio': 1,\n",
    "} for pos, aa in enumerate(wuhan_sequence, start=1) if aa != '*']\n",
    "df_wuhan = pd.DataFrame(data_wuhan)\n",
    "df_total = pd.concat([df_total, df_wuhan], ignore_index=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "\n",
    "def enrichment_height(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    \"\"\"\n",
    "    Safe symmetric log10 transformation of enrichment values.\n",
    "    \n",
    "    Args:\n",
    "        enrichment (float or array-like): Enrichment value(s).\n",
    "        epsilon (float): Minimum enrichment value to avoid log10(0).\n",
    "        max_cap (float): Maximum value to cap extremely high enrichments.\n",
    "    \n",
    "    Returns:\n",
    "        float or np.array: Transformed enrichment.\n",
    "    \"\"\"\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "\n",
    "# Count barcodes:\n",
    "# Total number of unique barcodes per immunization\n",
    "barcode_counts = (\n",
    "    df_logo_agg.groupby('immunization')['barcode']\n",
    "    .nunique()\n",
    "    .reset_index(name='Total_Barcodes')\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to numeric in case of strings; coerce errors to NaN\n",
    "df_total['Enrichment_Ratio'] = pd.to_numeric(df_total['Enrichment_Ratio'], errors='coerce')\n",
    "\n",
    "# Filter out rows with Enrichment_Ratio that are NaN, 0, negative, or infinite\n",
    "df_total = df_total[\n",
    "    df_total['Enrichment_Ratio'].notna() &  # not NaN\n",
    "    np.isfinite(df_total['Enrichment_Ratio']) &  # not inf or -inf\n",
    "    (df_total['Enrichment_Ratio'] > 0)  # positive only\n",
    "]\n",
    "df_total = df_total[df_total['Amino_Acid'] != \"*\"]\n",
    "df_agg = df_total.copy()\n",
    "# Aggregate enrichment ratio per barcode\n",
    "print(df_logo_agg.columns.tolist())\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "print(df_logo_agg.columns.tolist())\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "# Compute sample count separately\n",
    "sample_counts = (\n",
    "    df_logo_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Merge with df_combined (which contains enrichment and letter height)\n",
    "df_combined = df_agg.copy()\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Merge in sample count\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    sample_counts,\n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'],\n",
    "    how='left'  # Use 'left' to preserve all rows, or 'inner' if you only want those with sample counts\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "# Drop duplicates if needed\n",
    "df_combined = df_combined.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "df_combined = df_combined[df_combined['Enrichment_Ratio'] > 0]\n",
    "\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    barcode_counts,\n",
    "    on='immunization',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_combined['Sample_Fraction'] = (\n",
    "    100 * df_combined['Sample_Count'] / df_combined['Total_Barcodes']\n",
    ")\n",
    "\n",
    "\n",
    "df_combined['letter_height'] = df_combined['Enrichment_Ratio'].apply(enrichment_height)\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: orange_cmap(x / 100))\n",
    "norm = colors.Normalize(vmin=0, vmax=100)\n",
    "df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.YlOrBr_r(1 - norm(x)))\n",
    "\n",
    "\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Blues(x / 100))\n",
    "\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Add site label\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "\n",
    "# ✅ DEBUG: Check if any M is present at position 452\n",
    "print(\"=== DEBUG: Amino acids at position 452 ===\")\n",
    "print(df_combined[df_combined['Spike_AS_Position'] == 452][['Amino_Acid', 'immunization', 'barcode', 'Enrichment_Ratio']])\n",
    "\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417, 439, 440, 451,452,453,454,455,456, 476,483,484485,499,500,501,502,503,504,505]\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "    print(f\"Sample_Fraction range: min={df_combined['Sample_Fraction'].min()}, max={df_combined['Sample_Fraction'].max()}\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height', 'Sample_Count', 'Sample_Fraction']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter_heights\")\n",
    "    \n",
    "    positions = df_immunization['Spike_AS_Position']   # pandas Series\n",
    "    amino_acids = df_immunization['Amino_Acid']       # pandas Series\n",
    "    heights = df_immunization['letter_height']        # pandas Series\n",
    "    print(f\"Positions range from {positions.min()} to {positions.max()}\")\n",
    "    print(f\"Unique amino acids: {sorted(amino_acids.unique())}\")\n",
    "    print(\"Counts per position:\")\n",
    "    print(df_immunization.groupby('Spike_AS_Position')['Amino_Acid'].count())\n",
    "    print(f\"Letter height range: min {heights.min():.3f}, max {heights.max():.3f}\")\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter heights\")\n",
    "    \n",
    "        # Separate positive and negative letter heights for correct stacking\n",
    "    def separate_stacked_heights(df):\n",
    "        df_sorted = df.sort_values(\n",
    "            by=['Spike_AS_Position', 'letter_height'], ascending=[True, False]\n",
    "        )\n",
    "    \n",
    "        # Separate positive and negative heights\n",
    "        df_positive = df_sorted[df_sorted['letter_height'] >= 0].copy()\n",
    "        df_negative = df_sorted[df_sorted['letter_height'] < 0].copy()\n",
    "    \n",
    "        # Cumulative heights per position\n",
    "        df_positive['stack_bottom'] = df_positive.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_positive['letter_height']\n",
    "        df_negative['stack_bottom'] = df_negative.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_negative['letter_height']\n",
    "    \n",
    "        # Recombine\n",
    "        return pd.concat([df_positive, df_negative], axis=0).sort_values(\n",
    "            by=['Spike_AS_Position', 'stack_bottom']\n",
    "        )\n",
    "    \n",
    "    # Apply stacking fix per immunization before plotting\n",
    "    df_immunization = separate_stacked_heights(df_immunization)\n",
    "\n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    ax.set_title('')\n",
    "    # Set the y-axis label to 'Single Droplet'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Log10 AB Escape - Binding', fontsize=13)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logop1.png\")\n",
    "\n",
    "    # Add colorbar\n",
    "    #sm = plt.cm.ScalarMappable(cmap=orange_cmap, norm=plt.Normalize(vmin=0, vmax=100))\n",
    "\n",
    "    norm = colors.Normalize(vmin=0, vmax=100)\n",
    "\n",
    "    # 2) Grab the reversed colormap and truncate it so we skip the very top (white) 10%\n",
    "    #orig_cmap = plt.cm.orange_cmap_r\n",
    "    orig_cmap   = plt.cm.YlOrBr_r\n",
    "    #    here we take only the values from 0.0→0.9 of the original colormap\n",
    "    trunc_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'YlOrBr_r',\n",
    "        orig_cmap(np.linspace(0.0, 0.75, 256))\n",
    "    )\n",
    "\n",
    "    df_combined['color'] = df_combined['Sample_Fraction'].apply(\n",
    "        lambda x: trunc_cmap(norm(x))\n",
    "    )\n",
    "    \n",
    "    # 3) When you assign colors, still invert the norm so 0%→dark, 100%→light:\n",
    "    #df_combined['color'] = df_combined['Sample_Fraction'].apply(\n",
    "       # lambda x: trunc_cmap(1 - norm(x))\n",
    "    #)\n",
    "    \n",
    "    # …later, when you draw your logo, the letters will get these colors…\n",
    "    \n",
    "    # 4) And for the colorbar:\n",
    "    sm = plt.cm.ScalarMappable(cmap=trunc_cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    #sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    #sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "        \n",
    "    #sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    #sm.set_array([])\n",
    "    #cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    #cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    \n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    # Calculate and print total (stacked) height per position\n",
    "    stacked_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTotal stacked heights per position for immunization:\", immunization)\n",
    "    print(stacked_heights.to_string(index=False))\n",
    "    # Compute stacked heights per position with individual contributions\n",
    "    position_summary = (\n",
    "        df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']]\n",
    "        .sort_values(by=['Spike_AS_Position', 'letter_height'], ascending=[True, False])\n",
    "    )\n",
    "    \n",
    "    # Add cumulative stacked height for plotting order visualization (optional)\n",
    "    position_summary['Cumulative_Height'] = position_summary.groupby('Spike_AS_Position')['letter_height'].cumsum()\n",
    "    \n",
    "    # Total stacked height per position\n",
    "    total_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n====== Immunization: {immunization} ======\")\n",
    "    print(\"Breakdown of letter heights at each position:\")\n",
    "    print(position_summary.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nTotal stacked height per position:\")\n",
    "    print(total_heights.to_string(index=False))\n",
    "\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "\n",
    "def enrichment_height(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    \"\"\"\n",
    "    Safe symmetric log10 transformation of enrichment values.\n",
    "    \n",
    "    Args:\n",
    "        enrichment (float or array-like): Enrichment value(s).\n",
    "        epsilon (float): Minimum enrichment value to avoid log10(0).\n",
    "        max_cap (float): Maximum value to cap extremely high enrichments.\n",
    "    \n",
    "    Returns:\n",
    "        float or np.array: Transformed enrichment.\n",
    "    \"\"\"\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "\n",
    "# Count barcodes:\n",
    "# Total number of unique barcodes per immunization\n",
    "barcode_counts = (\n",
    "    df_logo_agg.groupby('immunization')['barcode']\n",
    "    .nunique()\n",
    "    .reset_index(name='Total_Barcodes')\n",
    ")\n",
    "\n",
    "\n",
    "# Convert to numeric in case of strings; coerce errors to NaN\n",
    "df_total['Enrichment_Ratio'] = pd.to_numeric(df_total['Enrichment_Ratio'], errors='coerce')\n",
    "\n",
    "# Filter out rows with Enrichment_Ratio that are NaN, 0, negative, or infinite\n",
    "df_total = df_total[\n",
    "    df_total['Enrichment_Ratio'].notna() &  # not NaN\n",
    "    np.isfinite(df_total['Enrichment_Ratio']) &  # not inf or -inf\n",
    "    (df_total['Enrichment_Ratio'] > 0)  # positive only\n",
    "]\n",
    "df_total = df_total[df_total['Amino_Acid'] != \"*\"]\n",
    "df_agg = df_total.copy()\n",
    "# Aggregate enrichment ratio per barcode\n",
    "print(df_logo_agg.columns.tolist())\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'mean'\n",
    "})\n",
    "print(df_logo_agg.columns.tolist())\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "# Compute sample count separately\n",
    "sample_counts = (\n",
    "    df_logo_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "print(df_logo_agg.columns.tolist())\n",
    "# Merge with df_combined (which contains enrichment and letter height)\n",
    "df_combined = df_agg.copy()\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Merge in sample count\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    sample_counts,\n",
    "    on=['Spike_AS_Position', 'Amino_Acid', 'immunization'],\n",
    "    how='left'  # Use 'left' to preserve all rows, or 'inner' if you only want those with sample counts\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "# Drop duplicates if needed\n",
    "df_combined = df_combined.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "df_combined = df_combined[df_combined['Enrichment_Ratio'] > 0]\n",
    "\n",
    "df_combined = pd.merge(\n",
    "    df_combined,\n",
    "    barcode_counts,\n",
    "    on='immunization',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "df_combined['Sample_Fraction'] = (\n",
    "    100 * df_combined['Sample_Count'] / df_combined['Total_Barcodes']\n",
    ")\n",
    "\n",
    "\n",
    "df_combined['letter_height'] = df_combined['Enrichment_Ratio'].apply(enrichment_height)\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: orange_cmap(x / 100))\n",
    "norm = colors.Normalize(vmin=0, vmax=100)\n",
    "df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.YlOrBr_r(1 - norm(x)))\n",
    "\n",
    "\n",
    "#df_combined['color'] = df_combined['Sample_Fraction'].apply(lambda x: plt.cm.Blues(x / 100))\n",
    "\n",
    "\n",
    "print(df_combined.columns.tolist())\n",
    "# Add site label\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "print(df_combined.columns.tolist())\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [415, 422, 440, 452, 466, 447]\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "    print(f\"Sample_Fraction range: min={df_combined['Sample_Fraction'].min()}, max={df_combined['Sample_Fraction'].max()}\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height', 'Sample_Count', 'Sample_Fraction']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter_heights\")\n",
    "    \n",
    "    positions = df_immunization['Spike_AS_Position']   # pandas Series\n",
    "    amino_acids = df_immunization['Amino_Acid']       # pandas Series\n",
    "    heights = df_immunization['letter_height']        # pandas Series\n",
    "    print(f\"Positions range from {positions.min()} to {positions.max()}\")\n",
    "    print(f\"Unique amino acids: {sorted(amino_acids.unique())}\")\n",
    "    print(\"Counts per position:\")\n",
    "    print(df_immunization.groupby('Spike_AS_Position')['Amino_Acid'].count())\n",
    "    print(f\"Letter height range: min {heights.min():.3f}, max {heights.max():.3f}\")\n",
    "    print(df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']])\n",
    "    print(df_immunization['letter_height'].isna().sum(), \"NaN letter heights\")\n",
    "    \n",
    "        # Separate positive and negative letter heights for correct stacking\n",
    "    def separate_stacked_heights(df):\n",
    "        df_sorted = df.sort_values(\n",
    "            by=['Spike_AS_Position', 'letter_height'], ascending=[True, False]\n",
    "        )\n",
    "    \n",
    "        # Separate positive and negative heights\n",
    "        df_positive = df_sorted[df_sorted['letter_height'] >= 0].copy()\n",
    "        df_negative = df_sorted[df_sorted['letter_height'] < 0].copy()\n",
    "    \n",
    "        # Cumulative heights per position\n",
    "        df_positive['stack_bottom'] = df_positive.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_positive['letter_height']\n",
    "        df_negative['stack_bottom'] = df_negative.groupby('Spike_AS_Position')['letter_height'].cumsum() - df_negative['letter_height']\n",
    "    \n",
    "        # Recombine\n",
    "        return pd.concat([df_positive, df_negative], axis=0).sort_values(\n",
    "            by=['Spike_AS_Position', 'stack_bottom']\n",
    "        )\n",
    "    \n",
    "    # Apply stacking fix per immunization before plotting\n",
    "    df_immunization = separate_stacked_heights(df_immunization)\n",
    "    \n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    ax.set_title('')\n",
    "    # Set the y-axis label to 'Single Droplet'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Log10 AB Escape - Binding', fontsize=13)\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_minor_locator(ticker.MultipleLocator(0.5))\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logop1.png\")\n",
    "\n",
    "    # Add colorbar\n",
    "    #sm = plt.cm.ScalarMappable(cmap=orange_cmap, norm=plt.Normalize(vmin=0, vmax=100))\n",
    "\n",
    "    norm = colors.Normalize(vmin=0, vmax=100)\n",
    "\n",
    "    # 2) Grab the reversed colormap and truncate it so we skip the very top (white) 10%\n",
    "    #orig_cmap = plt.cm.orange_cmap_r\n",
    "    orig_cmap   = plt.cm.YlOrBr_r\n",
    "    #    here we take only the values from 0.0→0.9 of the original colormap\n",
    "    trunc_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'YlOrBr_r',\n",
    "        orig_cmap(np.linspace(0.0, 0.75, 256))\n",
    "    )\n",
    "\n",
    "    df_combined['color'] = df_combined['Sample_Fraction'].apply(\n",
    "        lambda x: trunc_cmap(norm(x))\n",
    "    )\n",
    "    \n",
    "    # 3) When you assign colors, still invert the norm so 0%→dark, 100%→light:\n",
    "    #df_combined['color'] = df_combined['Sample_Fraction'].apply(\n",
    "       # lambda x: trunc_cmap(1 - norm(x))\n",
    "    #)\n",
    "    \n",
    "    # …later, when you draw your logo, the letters will get these colors…\n",
    "    \n",
    "    # 4) And for the colorbar:\n",
    "    sm = plt.cm.ScalarMappable(cmap=trunc_cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    \n",
    "    #sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    #sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "        \n",
    "    #sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    #sm.set_array([])\n",
    "    #cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    #cbar.set_label('Fraction % of \\n Single-droplet repertoire', rotation=270, labelpad=35)\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    \n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    # Calculate and print total (stacked) height per position\n",
    "    stacked_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTotal stacked heights per position for immunization:\", immunization)\n",
    "    print(stacked_heights.to_string(index=False))\n",
    "    # Compute stacked heights per position with individual contributions\n",
    "    position_summary = (\n",
    "        df_immunization[['Spike_AS_Position', 'Amino_Acid', 'letter_height']]\n",
    "        .sort_values(by=['Spike_AS_Position', 'letter_height'], ascending=[True, False])\n",
    "    )\n",
    "    \n",
    "    # Add cumulative stacked height for plotting order visualization (optional)\n",
    "    position_summary['Cumulative_Height'] = position_summary.groupby('Spike_AS_Position')['letter_height'].cumsum()\n",
    "    \n",
    "    # Total stacked height per position\n",
    "    total_heights = (\n",
    "        df_immunization.groupby('Spike_AS_Position')['letter_height']\n",
    "        .sum()\n",
    "        .reset_index(name='Total_Stacked_Height')\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n====== Immunization: {immunization} ======\")\n",
    "    print(\"Breakdown of letter heights at each position:\")\n",
    "    print(position_summary.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nTotal stacked height per position:\")\n",
    "    print(total_heights.to_string(index=False))\n",
    "\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fractions = np.linspace(0, 100, 11)\n",
    "colors = [plt.cm.Blues(1 - x/100) for x in fractions]\n",
    "\n",
    "plt.figure(figsize=(8,1))\n",
    "for i, color in enumerate(colors):\n",
    "    plt.bar(i, 1, color=color)\n",
    "plt.xticks(range(11), [f\"{int(x)}%\" for x in fractions])\n",
    "plt.yticks([])\n",
    "plt.title(\"Color mapping test: low % → strong blue, high % → faint blue\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#End of publication logo plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 1 (adjust threshold as needed)\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences (number of barcodes supporting AA at site)\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Compute average enrichment ratio per amino acid at each site and immunization\n",
    "avg_enrichment = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].mean().reset_index(name='Avg_Enrichment')\n",
    "\n",
    "# Merge average enrichment into df_combined\n",
    "df_combined = df_combined.merge(avg_enrichment, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Function to assign occurrence-based colors (low count = light blue, high count = dark blue)\n",
    "def occurrence_color(count):\n",
    "    max_count = df_combined['Sample_Count'].max()\n",
    "    norm_value = count / max_count\n",
    "    norm_value = np.clip(norm_value, 0, 1)\n",
    "    return plt.cm.Blues(norm_value)\n",
    "\n",
    "df_combined['color'] = df_combined['Sample_Count'].apply(occurrence_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Sites to show (adjust as needed)\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create output directory for saving plots\n",
    "output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots per immunization\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    # Filter data for this immunization\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Draw logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Avg_Enrichment\",  # height = average enrichment\n",
    "        color_col=\"color\",                    # color = occurrence\n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add colorbar for occurrence count\n",
    "    sm = plt.cm.ScalarMappable(cmap=orange_cmap, norm=plt.Normalize(vmin=0, vmax=100))\n",
    "    #sm = plt.cm.ScalarMappable(cmap=\"Blues\", norm=plt.Normalize(vmin=0, vmax=df_combined['Sample_Count'].max()))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('Occurrence (Number of Supporting Samples)', rotation=270, labelpad=15)\n",
    "\n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel('Antibody-Binding (Mean)')\n",
    "\n",
    "    # Save plots (you may want to define a barcode or rename accordingly)\n",
    "    # Here I use immunization name for file name\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dmslogo  # make sure this is installed: pip install dmslogo\n",
    "\n",
    "# -----------------------------\n",
    "# PREP: Aggregation and Setup\n",
    "# -----------------------------\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'sum'})\n",
    "\n",
    "# Remove stop codons\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "# -----------------------------\n",
    "# COLOR FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_color(enrichment):\n",
    "    # Apply log2 scale symmetrically, centered at 1\n",
    "    log_enrichment = np.log2(enrichment + 1e-3)  # Add small value to avoid log(0)\n",
    "    norm = plt.Normalize(vmin=-5, vmax=5)\n",
    "    return plt.cm.coolwarm(norm(log_enrichment))\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_height(enrichment):\n",
    "    if enrichment >= 1:\n",
    "        return np.log2(enrichment)\n",
    "    else:\n",
    "        return -np.log2(1 / enrichment)  # Or: -(1 - enrichment)\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "df_logo_agg['letter_height'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_height)\n",
    "df_logo_agg['color'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_color)\n",
    "\n",
    "# -----------------------------\n",
    "# Filter specific Spike positions\n",
    "# -----------------------------\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# -----------------------------\n",
    "# Identify and print duplicates\n",
    "# -----------------------------\n",
    "dup_cols = ['Spike_AS_Position', 'Amino_Acid', 'immunization']\n",
    "duplicates = df_logo_agg[df_logo_agg.duplicated(subset=dup_cols, keep=False)]\n",
    "\n",
    "if not duplicates.empty:\n",
    "    print(\"\\n⚠️ Duplicate entries found (before filtering):\")\n",
    "    print(duplicates.sort_values(dup_cols).to_string(index=False))\n",
    "\n",
    "# -----------------------------\n",
    "# Keep only the entry with the highest Enrichment_Ratio per group\n",
    "# -----------------------------\n",
    "df_logo_agg = df_logo_agg.sort_values('Enrichment_Ratio', ascending=False)\n",
    "df_logo_agg = df_logo_agg.drop_duplicates(subset=dup_cols, keep='first')\n",
    "\n",
    "# Filter specific Spike positions\n",
    "# -----------------------------\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# -----------------------------\n",
    "# Output directory\n",
    "# -----------------------------\n",
    "output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# PREP: Aggregation and Setup\n",
    "# -----------------------------\n",
    "# Use median Enrichment_Ratio per (Spike_AS_Position, Amino_Acid, immunization)\n",
    "df_agg = df_total.copy()\n",
    "df_agg['Amino_Acid'] = df_agg['Amino_Acid'].str.upper()\n",
    "df_agg = df_agg[df_agg['Amino_Acid'] != \"*\"]  # remove stop codons\n",
    "\n",
    "# Aggregate by median across barcodes\n",
    "df_logo_agg = df_agg.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'median'})\n",
    "\n",
    "# -----------------------------\n",
    "# COLOR FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_color(enrichment):\n",
    "    log_enrichment = np.log2(enrichment + 1e-3)  # avoid log(0)\n",
    "    norm = plt.Normalize(vmin=-5, vmax=5)\n",
    "    return plt.cm.coolwarm(norm(log_enrichment))\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_height(enrichment):\n",
    "    return np.log2(enrichment) if enrichment >= 1 else -np.log2(1 / enrichment)\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "df_logo_agg['letter_height'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_height)\n",
    "df_logo_agg['color'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_color)\n",
    "\n",
    "# -----------------------------\n",
    "# Filter specific Spike positions\n",
    "# -----------------------------\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# -----------------------------\n",
    "# Output directory\n",
    "# -----------------------------\n",
    "output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Generate plots\n",
    "# -----------------------------\n",
    "for immunization in df_logo_agg['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    df_immunization = df_logo_agg[df_logo_agg['immunization'] == immunization]\n",
    "\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",\n",
    "        color_col=\"color\",\n",
    "        title=f\"{immunization} Dual Binding Escape Logo Plot\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add zero line and labels\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_ylabel('log₂(Enrichment Ratio)\\n(Positive = binding, Negative = escape)')\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=plt.Normalize(vmin=-5, vmax=5))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('log₂(Enrichment)', rotation=270, labelpad=15)\n",
    "\n",
    "    # Save figure\n",
    "    filename = os.path.join(output_dir, f\"{immunization}_dual_escape_logo.png\")\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved as {filename}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dmslogo  # make sure this is installed: pip install dmslogo\n",
    "\n",
    "# -----------------------------\n",
    "# PREP: Aggregation and Setup\n",
    "# -----------------------------\n",
    "# Use median Enrichment_Ratio per (Spike_AS_Position, Amino_Acid, immunization)\n",
    "df_agg = df_total.copy()\n",
    "df_agg['Amino_Acid'] = df_agg['Amino_Acid'].str.upper()\n",
    "df_agg = df_agg[df_agg['Amino_Acid'] != \"*\"]  # remove stop codons\n",
    "\n",
    "# Aggregate by median across barcodes\n",
    "df_logo_agg = df_agg.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'median'})\n",
    "\n",
    "# -----------------------------\n",
    "# COLOR FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_color(enrichment):\n",
    "    log_enrichment = np.log2(enrichment + 1e-3)  # avoid log(0)\n",
    "    norm = plt.Normalize(vmin=-5, vmax=5)\n",
    "    return plt.cm.coolwarm(norm(log_enrichment))\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_height(enrichment):\n",
    "    return np.log2(enrichment) if enrichment >= 1 else -np.log2(1 / enrichment)\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "df_logo_agg['letter_height'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_height)\n",
    "df_logo_agg['color'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_color)\n",
    "\n",
    "# -----------------------------\n",
    "# Filter specific Spike positions\n",
    "# -----------------------------\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# -----------------------------\n",
    "# Output directory\n",
    "# -----------------------------\n",
    "output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Generate plots\n",
    "# -----------------------------\n",
    "for immunization in df_logo_agg['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    df_immunization = df_logo_agg[df_logo_agg['immunization'] == immunization]\n",
    "\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",\n",
    "        color_col=\"color\",\n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add zero line and labels\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_ylabel('Antibody-binding (Log2) \\n AA frequency')\n",
    "\n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=plt.Normalize(vmin=-5, vmax=5))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('log₂(Enrichment)', rotation=270, labelpad=15)\n",
    "\n",
    "    # Save figure\n",
    "    filename = os.path.join(output_dir, f\"{immunization}_dual_escape_logo.png\")\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved as {filename}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dmslogo\n",
    "\n",
    "# -----------------------------\n",
    "# PREP: Filter and uppercase, remove stop codons\n",
    "# -----------------------------\n",
    "df_logo_agg = df_total.copy()\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# -----------------------------\n",
    "# For each (Position, Amino Acid, immunization), keep row with max Total_Reads\n",
    "# -----------------------------\n",
    "df_filtered = (\n",
    "    df_logo_agg.sort_values('Total_Reads', ascending=False)\n",
    "    .drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization'], keep='first')\n",
    ").copy()\n",
    "\n",
    "# -----------------------------\n",
    "# Separate positive (>1) and negative (<=1 but >0) enrichment groups\n",
    "# -----------------------------\n",
    "df_pos = df_filtered[df_filtered['Enrichment_Ratio'] > 1].copy()\n",
    "df_neg = df_filtered[(df_filtered['Enrichment_Ratio'] <= 1) & (df_filtered['Enrichment_Ratio'] > 0)].copy()\n",
    "\n",
    "# -----------------------------\n",
    "# For positive: letter_height = 1 (or counts?), direction 'up'\n",
    "# Color: Reds scaled by log10 enrichment (clipped)\n",
    "# -----------------------------\n",
    "df_pos['letter_height'] = 1  # or use counts if you want, here 1 means presence\n",
    "df_pos['direction'] = 'up'\n",
    "df_pos['color'] = df_pos['Enrichment_Ratio'].apply(\n",
    "    lambda x: plt.cm.Reds(np.clip(np.log10(x + 1) / np.log10(3000 + 1), 0, 1))\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# For negative: letter_height = -1 (inverted for plotting), direction 'down'\n",
    "# Color: Blues_r scaled by enrichment ratio 0-1\n",
    "# -----------------------------\n",
    "def reversed_blue_color(enrichment):\n",
    "    norm = plt.Normalize(vmin=0, vmax=1)\n",
    "    return plt.cm.Blues_r(norm(enrichment))\n",
    "\n",
    "df_neg['letter_height'] = -1\n",
    "df_neg['direction'] = 'down'\n",
    "df_neg['color'] = df_neg['Enrichment_Ratio'].apply(reversed_blue_color)\n",
    "\n",
    "# -----------------------------\n",
    "# Combine both\n",
    "# -----------------------------\n",
    "df_plot = pd.concat([df_pos, df_neg], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Plotting loop by immunization\n",
    "# -----------------------------\n",
    "output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for immunization in df_plot['immunization'].unique():\n",
    "    print(f\"Plotting {immunization}...\")\n",
    "\n",
    "    df_immunization = df_plot[df_plot['immunization'] == immunization]\n",
    "\n",
    "    # IMPORTANT: For each position and amino acid, only one row must remain\n",
    "    # Check duplicates just in case:\n",
    "    duplicates = df_immunization.duplicated(subset=['Spike_AS_Position', 'Amino_Acid'])\n",
    "    if duplicates.any():\n",
    "        print(f\"Warning: duplicates found for {immunization} at these rows:\")\n",
    "        print(df_immunization[duplicates])\n",
    "\n",
    "    # Aggregate letter_height per group, color take first (all same anyway)\n",
    "    df_agg = df_immunization.groupby(['Spike_AS_Position', 'Amino_Acid', 'direction']).agg({\n",
    "        'letter_height': 'mean',\n",
    "        'color': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_agg,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",\n",
    "        color_col=\"color\",\n",
    "        title=f\"{immunization} Escape vs. Binding Logo\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_ylabel('IgG Secreting Cell [n]')\n",
    "\n",
    "    # Colorbars\n",
    "    sm_red = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3), vmax=np.log10(3000)))\n",
    "    sm_blue = plt.cm.ScalarMappable(cmap=\"Blues_r\", norm=plt.Normalize(vmin=0, vmax=1))\n",
    "    sm_red.set_array([])\n",
    "    sm_blue.set_array([])\n",
    "\n",
    "    cbar_red = fig.colorbar(sm_red, ax=ax, orientation='vertical', fraction=0.05, pad=0.04)\n",
    "    cbar_red.set_label('log₁₀(Enrichment > 1)', rotation=270, labelpad=15)\n",
    "\n",
    "    cbar_blue = fig.colorbar(sm_blue, ax=ax, orientation='vertical', fraction=0.05, pad=0.10)\n",
    "    cbar_blue.set_label('Enrichment ≤ 1 (Escape)', rotation=270, labelpad=15)\n",
    "\n",
    "    filename = os.path.join(output_dir, f\"{immunization}_escape_binding_logo.png\")\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Saved plot to {filename}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dmslogo  # make sure this is installed: pip install dmslogo\n",
    "\n",
    "# -----------------------------\n",
    "# PREP: Aggregation and Setup\n",
    "# -----------------------------\n",
    "# Use median Enrichment_Ratio per (Spike_AS_Position, Amino_Acid, immunization)\n",
    "df_agg = df_total.copy()\n",
    "df_agg['Amino_Acid'] = df_agg['Amino_Acid'].str.upper()\n",
    "df_agg = df_agg[df_agg['Amino_Acid'] != \"*\"]  # remove stop codons\n",
    "\n",
    "# Replace or clip zeros to a small positive value to avoid issues in log scale\n",
    "df_agg['Enrichment_Ratio'] = df_agg['Enrichment_Ratio'].clip(lower=1e-5)\n",
    "\n",
    "# Aggregate by median across barcodes\n",
    "df_logo_agg = df_agg.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'median'})\n",
    "\n",
    "# -----------------------------\n",
    "# COLOR FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_color(enrichment):\n",
    "    enrichment = max(enrichment, 1e-5)\n",
    "    log_enrichment = np.log2(enrichment)\n",
    "    # Symmetric color scale between -10 and +10\n",
    "    norm = plt.Normalize(vmin=-10, vmax=10)\n",
    "    return plt.cm.coolwarm(norm(log_enrichment))\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_height(enrichment):\n",
    "    enrichment = max(enrichment, 1e-5)\n",
    "    return np.log2(enrichment)\n",
    "\n",
    "# -----------------------------\n",
    "# Add color and letter height\n",
    "# -----------------------------\n",
    "df_logo_agg['letter_height'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_height)\n",
    "df_logo_agg['color'] = df_logo_agg['Enrichment_Ratio'].apply(enrichment_color)\n",
    "\n",
    "# -----------------------------\n",
    "# Filter specific Spike positions\n",
    "# -----------------------------\n",
    "sites_to_show = [453,484,501]\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# -----------------------------\n",
    "# Output directory\n",
    "# -----------------------------\n",
    "output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Generate plots\n",
    "# -----------------------------\n",
    "for immunization in df_logo_agg['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    df_immunization = df_logo_agg[df_logo_agg['immunization'] == immunization]\n",
    "\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",\n",
    "        color_col=\"color\",\n",
    "        title=f\"{immunization}\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add zero line and labels\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_ylabel('Antibody-binding (Log2)')\n",
    "    ax.set_title(ax.get_title(), pad=20) \n",
    "    # Add colorbar\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=plt.Normalize(vmin=-10, vmax=10))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('log2 (Enrichment)', rotation=270, labelpad=15)\n",
    "\n",
    "    # Save figure\n",
    "    filename = os.path.join(output_dir, f\"{immunization}_dual_escape_logo.png\")\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved as {filename}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Preprocess Data ---\n",
    "df = df_total.copy()\n",
    "df['Amino_Acid'] = df['Amino_Acid'].str.upper()\n",
    "df = df[df['Amino_Acid'] != \"*\"]\n",
    "df['Enrichment_Ratio'] = df['Enrichment_Ratio'].clip(lower=1e-5)\n",
    "\n",
    "# Count barcodes and get max enrichment per (position, AA, immunization)\n",
    "\n",
    "# Grouping\n",
    "df_grouped = df.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Barcode count and median enrichment\n",
    "df_counts = df_grouped.size().reset_index(name='Sample_Count')\n",
    "df_median_enrich = df_grouped['Enrichment_Ratio'].median().reset_index(name='Median_Enrichment')\n",
    "\n",
    "# Merge\n",
    "df_logo = pd.merge(df_counts, df_median_enrich, on=['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "\n",
    "# Assign color using median enrichment\n",
    "df_logo['color'] = df_logo['Median_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "# Use barcode count for height (as in your new version)\n",
    "df_logo['letter_height'] = df_logo.apply(\n",
    "    lambda row: row['Sample_Count'] if row['Median_Enrichment'] > 1 else -row['Sample_Count'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "# Assign color by enrichment\n",
    "def enrichment_color(enrichment):\n",
    "    enrichment = max(enrichment, 1e-5)\n",
    "    log_enrichment = np.log2(enrichment)\n",
    "    norm = plt.Normalize(vmin=-10, vmax=10)\n",
    "    return plt.cm.coolwarm(norm(log_enrichment))\n",
    "\n",
    "\n",
    "# Filter specific Spike positions\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "df_logo = df_logo[df_logo['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# --- Step 2: Plot ---\n",
    "output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for immunization in df_logo['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    df_immunization = df_logo[df_logo['immunization'] == immunization]\n",
    "\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"letter_height\",\n",
    "        color_col=\"color\",\n",
    "        title=f\"{immunization} Occurrence-based Enrichment Logo\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    ax.axhline(0, color='black', linewidth=0.8)\n",
    "    ax.set_ylabel('IgG Secreting Cells [n]')\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"coolwarm\", norm=plt.Normalize(vmin=-10, vmax=10))\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')\n",
    "    cbar.set_label('log2(Enrichment Ratio)', rotation=270, labelpad=15)\n",
    "\n",
    "    filename = os.path.join(output_dir, f\"{immunization}_combined_logoplot.png\")\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Plot saved as {filename}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the next block we want to test weather A) occurances and B) Enrichment ratios FOR the selected SPIKE protein positions \n",
    "# are different between the immunization conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_to_show = [416,417, 439, 440,441, 451, 452,453, 475,476, 477,478, 484, 492,493,494,495,500,501, 502, 503,505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Step 1: Filter for NON-SYNOM, selected sites, and Enrichment_Ratio > 3\n",
    "non_syn_df = df_total[\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM') &\n",
    "    (df_total['Spike_AS_Position'].isin(sites_to_show)) &\n",
    "    (df_total['Enrichment_Ratio'] > 3)\n",
    "]\n",
    "\n",
    "# Step 2: Count AA occurrences across barcodes\n",
    "df_non_syn_agg = (\n",
    "    non_syn_df\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'])\n",
    "    .agg({'Enrichment_Ratio': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Step 3: Sample counts (how many barcodes had this AA at this site per immunization)\n",
    "df_sample_counts = (\n",
    "    df_non_syn_agg\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "# Step 4: Barcode totals per immunization\n",
    "barcode_counts = df_total.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Step 5: Run Fisher's exact test for all immunization pairs\n",
    "freq_stats = []\n",
    "\n",
    "# Loop over all relevant AA-site combinations\n",
    "for (pos, aa), subdf in df_sample_counts.groupby(['Spike_AS_Position', 'Amino_Acid']):\n",
    "    immunizations = subdf['immunization'].unique()\n",
    "    if len(immunizations) < 2:\n",
    "        continue\n",
    "\n",
    "    # Compare each pair of immunizations\n",
    "    for imm1, imm2 in combinations(immunizations, 2):\n",
    "        count1 = subdf.loc[subdf['immunization'] == imm1, 'Sample_Count'].values\n",
    "        count2 = subdf.loc[subdf['immunization'] == imm2, 'Sample_Count'].values\n",
    "\n",
    "        # Handle missing values as 0\n",
    "        n_pos_1 = count1[0] if len(count1) > 0 else 0\n",
    "        n_pos_2 = count2[0] if len(count2) > 0 else 0\n",
    "\n",
    "        total1 = barcode_counts.get(imm1, 0)\n",
    "        total2 = barcode_counts.get(imm2, 0)\n",
    "\n",
    "        n_neg_1 = total1 - n_pos_1\n",
    "        n_neg_2 = total2 - n_pos_2\n",
    "\n",
    "        # 2x2 contingency table\n",
    "        table = [[n_pos_1, n_neg_1],\n",
    "                 [n_pos_2, n_neg_2]]\n",
    "\n",
    "        # Skip if total is too small\n",
    "        if total1 == 0 or total2 == 0:\n",
    "            continue\n",
    "\n",
    "        stat, p_val = fisher_exact(table)\n",
    "        freq_stats.append({\n",
    "            'Spike_AS_Position': pos,\n",
    "            'Amino_Acid': aa,\n",
    "            'Immunization_1': imm1,\n",
    "            'Immunization_2': imm2,\n",
    "            'n_pos_1': n_pos_1,\n",
    "            'n_neg_1': n_neg_1,\n",
    "            'n_pos_2': n_pos_2,\n",
    "            'n_neg_2': n_neg_2,\n",
    "            'p_value': p_val\n",
    "        })\n",
    "\n",
    "# Step 6: Create DataFrame with results\n",
    "df_freq_stats = pd.DataFrame(freq_stats)\n",
    "\n",
    "# Optional: Filter for significant values\n",
    "significant = df_freq_stats[df_freq_stats['p_value'] < 0.05]\n",
    "\n",
    "# Save or display results\n",
    "print(df_freq_stats.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Step 1: Filter relevant data\n",
    "non_syn_df = df_total[\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM') &\n",
    "    (df_total['Spike_AS_Position'].isin(sites_to_show)) &\n",
    "    (df_total['Enrichment_Ratio'] > 1)\n",
    "]\n",
    "\n",
    "# Step 2: Aggregate counts\n",
    "df_non_syn_agg = (\n",
    "    non_syn_df\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'])\n",
    "    .agg({'Enrichment_Ratio': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_sample_counts = (\n",
    "    df_non_syn_agg\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "barcode_counts = df_total.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Step 3: Fisher tests and print results\n",
    "freq_stats = []\n",
    "\n",
    "for (pos, aa), subdf in df_sample_counts.groupby(['Spike_AS_Position', 'Amino_Acid']):\n",
    "    immunizations = subdf['immunization'].unique()\n",
    "    if len(immunizations) < 2:\n",
    "        continue\n",
    "\n",
    "    for imm1, imm2 in combinations(immunizations, 2):\n",
    "        count1 = subdf.loc[subdf['immunization'] == imm1, 'Sample_Count'].values\n",
    "        count2 = subdf.loc[subdf['immunization'] == imm2, 'Sample_Count'].values\n",
    "\n",
    "        n_pos_1 = count1[0] if len(count1) > 0 else 0\n",
    "        n_pos_2 = count2[0] if len(count2) > 0 else 0\n",
    "\n",
    "        total1 = barcode_counts.get(imm1, 0)\n",
    "        total2 = barcode_counts.get(imm2, 0)\n",
    "\n",
    "        n_neg_1 = total1 - n_pos_1\n",
    "        n_neg_2 = total2 - n_pos_2\n",
    "\n",
    "        if total1 == 0 or total2 == 0:\n",
    "            continue\n",
    "\n",
    "        table = [[n_pos_1, n_neg_1], [n_pos_2, n_neg_2]]\n",
    "        stat, p_val = fisher_exact(table)\n",
    "\n",
    "        # Store results\n",
    "        result = {\n",
    "            'Spike_AS_Position': pos,\n",
    "            'Amino_Acid': aa,\n",
    "            'Immunization_1': imm1,\n",
    "            'Immunization_2': imm2,\n",
    "            'n_pos_1': n_pos_1,\n",
    "            'n_neg_1': n_neg_1,\n",
    "            'n_pos_2': n_pos_2,\n",
    "            'n_neg_2': n_neg_2,\n",
    "            'p_value': p_val\n",
    "        }\n",
    "        freq_stats.append(result)\n",
    "\n",
    "        # Print formatted summary\n",
    "        print(f\"\\n[Fisher's Exact Test] Site {pos}, AA {aa}\")\n",
    "        print(f\"Comparison: {imm1} vs {imm2}\")\n",
    "        print(f\"Table: [[{n_pos_1}, {n_neg_1}], [{n_pos_2}, {n_neg_2}]]\")\n",
    "        print(f\"P-value: {p_val:.4g}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_freq_stats = pd.DataFrame(freq_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define abbreviations for the immunization conditions\n",
    "abbr_map = {\n",
    "    'Library_ctrl': 'Lib',\n",
    "    'Polyclonal_Ab': 'pAB',\n",
    "    'Mutant_RBD': 'B.1.135',\n",
    "    'Neutralizing_Ab': 'mAB Neut',\n",
    "    'wildtype_RBD': 'WT',\n",
    "    # Add other mappings as needed\n",
    "}\n",
    "\n",
    "# Filter for significant results (p < 0.05)\n",
    "significant_results = df_freq_stats[df_freq_stats['p_value'] < 0.05].copy()\n",
    "\n",
    "if significant_results.empty:\n",
    "    print(\"No significant results found.\")\n",
    "else:\n",
    "    # Replace long names with abbreviations\n",
    "    significant_results['Immunization_1_abbr'] = significant_results['Immunization_1'].map(abbr_map).fillna(significant_results['Immunization_1'])\n",
    "    significant_results['Immunization_2_abbr'] = significant_results['Immunization_2'].map(abbr_map).fillna(significant_results['Immunization_2'])\n",
    "\n",
    "    # Create combined label with abbreviations\n",
    "    significant_results['Comparison_Label'] = (\n",
    "        significant_results['Spike_AS_Position'].astype(str) + \"\\n\" +\n",
    "        significant_results['Amino_Acid'] + \"\\n\" +\n",
    "        significant_results['Immunization_1_abbr'] + \"\\n\" +\n",
    "        \"vs.\" + \"\\n\" +\n",
    "        significant_results['Immunization_2_abbr']\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    sns.barplot(\n",
    "        data=significant_results,\n",
    "        x='Comparison_Label',\n",
    "        y='p_value',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.axhline(0.05, color='red', linestyle='--', label='Significance Threshold (0.05)')\n",
    "    plt.xticks(rotation=0, ha='center', fontsize=8)\n",
    "    plt.ylabel('P-value')\n",
    "    plt.title('Significant Fisher\\'s Exact Test Results')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_dir, \"pValue_FisherExactHist_.png\")\n",
    "    plt.savefig(output_path, format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Step 1: Filter relevant data\n",
    "non_syn_df = df_total[\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM') &\n",
    "    (df_total['Spike_AS_Position'].isin(sites_to_show)) &\n",
    "    (df_total['Enrichment_Ratio'] > 1)\n",
    "]\n",
    "\n",
    "# Step 2: Aggregate counts\n",
    "df_non_syn_agg = (\n",
    "    non_syn_df\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'])\n",
    "    .agg({'Enrichment_Ratio': 'sum'})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_sample_counts = (\n",
    "    df_non_syn_agg\n",
    "    .groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()\n",
    "    .reset_index(name='Sample_Count')\n",
    ")\n",
    "\n",
    "barcode_counts = df_total.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Step 3: Fisher tests and print results\n",
    "freq_stats = []\n",
    "\n",
    "for (pos, aa), subdf in df_sample_counts.groupby(['Spike_AS_Position', 'Amino_Acid']):\n",
    "    immunizations = subdf['immunization'].unique()\n",
    "    if len(immunizations) < 2:\n",
    "        continue\n",
    "\n",
    "    for imm1, imm2 in combinations(immunizations, 2):\n",
    "        count1 = subdf.loc[subdf['immunization'] == imm1, 'Sample_Count'].values\n",
    "        count2 = subdf.loc[subdf['immunization'] == imm2, 'Sample_Count'].values\n",
    "\n",
    "        n_pos_1 = count1[0] if len(count1) > 0 else 0\n",
    "        n_pos_2 = count2[0] if len(count2) > 0 else 0\n",
    "\n",
    "        total1 = barcode_counts.get(imm1, 0)\n",
    "        total2 = barcode_counts.get(imm2, 0)\n",
    "\n",
    "        n_neg_1 = total1 - n_pos_1\n",
    "        n_neg_2 = total2 - n_pos_2\n",
    "\n",
    "        if total1 == 0 or total2 == 0:\n",
    "            continue\n",
    "\n",
    "        table = [[n_pos_1, n_neg_1], [n_pos_2, n_neg_2]]\n",
    "        odds_ratio, p_val = fisher_exact(table)\n",
    "\n",
    "        # Determine direction\n",
    "        if odds_ratio > 1:\n",
    "            direction = f\"Higher in {imm1}\"\n",
    "        elif odds_ratio < 1:\n",
    "            direction = f\"Higher in {imm2}\"\n",
    "        else:\n",
    "            direction = \"No difference\"\n",
    "\n",
    "        # Store results\n",
    "        result = {\n",
    "            'Spike_AS_Position': pos,\n",
    "            'Amino_Acid': aa,\n",
    "            'Immunization_1': imm1,\n",
    "            'Immunization_2': imm2,\n",
    "            'n_pos_1': n_pos_1,\n",
    "            'n_neg_1': n_neg_1,\n",
    "            'n_pos_2': n_pos_2,\n",
    "            'n_neg_2': n_neg_2,\n",
    "            'odds_ratio': odds_ratio,\n",
    "            'p_value': p_val,\n",
    "            'direction': direction\n",
    "        }\n",
    "        freq_stats.append(result)\n",
    "\n",
    "        # Print formatted summary\n",
    "        print(f\"\\n[Fisher's Exact Test] Site {pos}, AA {aa}\")\n",
    "        print(f\"Comparison: {imm1} vs {imm2}\")\n",
    "        print(f\"Table: [[{n_pos_1}, {n_neg_1}], [{n_pos_2}, {n_neg_2}]]\")\n",
    "        print(f\"Odds ratio: {odds_ratio:.4g}\")\n",
    "        print(f\"P-value: {p_val:.4g}\")\n",
    "        print(f\"Direction: {direction}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_freq_stats = pd.DataFrame(freq_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define abbreviations for the immunization conditions\n",
    "abbr_map = {\n",
    "    'Library_ctrl': 'Lib',\n",
    "    'Polyclonal_Ab': 'pAB',\n",
    "    'Mutant_RBD': 'B.1.135',\n",
    "    'Neutralizing_Ab': 'mAB',\n",
    "    'wildtype_RBD': 'WT',\n",
    "    # Add other mappings as needed\n",
    "}\n",
    "\n",
    "# Filter for significant results (p < 0.05)\n",
    "\n",
    "\n",
    "significant_results = df_freq_stats[df_freq_stats['p_value'] < 0.05].copy()\n",
    "\n",
    "# Remove any comparisons involving 'Library_ctrl' (or its abbreviation 'Lib')\n",
    "significant_results = significant_results[\n",
    "    ~(significant_results['Immunization_1'].isin(['Library_ctrl']) |\n",
    "      significant_results['Immunization_2'].isin(['Library_ctrl']))\n",
    "]\n",
    "\n",
    "significant_results = significant_results[significant_results['Amino_Acid'] != '*']\n",
    "\n",
    "if significant_results.empty:\n",
    "    print(\"No significant results found after filtering Library_ctrl.\")\n",
    "else:\n",
    "    # Replace long names with abbreviations\n",
    "    significant_results['Immunization_1_abbr'] = significant_results['Immunization_1'].map(abbr_map).fillna(significant_results['Immunization_1'])\n",
    "    significant_results['Immunization_2_abbr'] = significant_results['Immunization_2'].map(abbr_map).fillna(significant_results['Immunization_2'])\n",
    "\n",
    "    # Reorder rows so that immunization with higher occurrence is always first\n",
    "    def reorder_row(row):\n",
    "        # Higher occurrence means direction says higher in Immunization_1 (odds_ratio > 1)\n",
    "        if row['odds_ratio'] < 1:\n",
    "            # swap immunizations and counts\n",
    "            return pd.Series({\n",
    "                'Spike_AS_Position': row['Spike_AS_Position'],\n",
    "                'Amino_Acid': row['Amino_Acid'],\n",
    "                'Immunization_1': row['Immunization_2'],\n",
    "                'Immunization_2': row['Immunization_1'],\n",
    "                'Immunization_1_abbr': row['Immunization_2_abbr'],\n",
    "                'Immunization_2_abbr': row['Immunization_1_abbr'],\n",
    "                'p_value': row['p_value']\n",
    "            })\n",
    "        else:\n",
    "            return pd.Series({\n",
    "                'Spike_AS_Position': row['Spike_AS_Position'],\n",
    "                'Amino_Acid': row['Amino_Acid'],\n",
    "                'Immunization_1': row['Immunization_1'],\n",
    "                'Immunization_2': row['Immunization_2'],\n",
    "                'Immunization_1_abbr': row['Immunization_1_abbr'],\n",
    "                'Immunization_2_abbr': row['Immunization_2_abbr'],\n",
    "                'p_value': row['p_value']\n",
    "            })\n",
    "\n",
    "    reordered = significant_results.apply(reorder_row, axis=1)\n",
    "\n",
    "    # Create combined label with abbreviations (higher occurrence first)\n",
    "    reordered['Comparison_Label'] = (\n",
    "        reordered['Spike_AS_Position'].astype(str) + \"\\n\" +\n",
    "        reordered['Amino_Acid'] + \"\\n\" +\n",
    "        reordered['Immunization_1_abbr'] + \"\\n\" +\n",
    "        \"vs.\" + \"\\n\" +\n",
    "        reordered['Immunization_2_abbr']\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    sns.barplot(\n",
    "        data=reordered,\n",
    "        x='Comparison_Label',\n",
    "        y='p_value',\n",
    "        palette='viridis'\n",
    "    )\n",
    "    plt.axhline(0.05, color='red', linestyle='--', label='Significance Threshold (0.05)')\n",
    "    plt.xticks(rotation=0, ha='center', fontsize=8)\n",
    "    plt.ylabel('P-value')\n",
    "    plt.title('Significant Fisher\\'s Exact Test Results (Higher occurrence first)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_dir, \"pValue_Occurence.png\")\n",
    "    plt.savefig(output_path, format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Filter relevant data: Non-syn mutations, selected sites, enrichment ratio >1\n",
    "non_syn_df = df_total[\n",
    "    (df_total['Type_of_Mutation'] == 'NON-SYNOM') &\n",
    "    (df_total['Spike_AS_Position'].isin(sites_to_show)) &\n",
    "    (df_total['Enrichment_Ratio'] > 1)\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop over each position and amino acid\n",
    "for (pos, aa), group_df in non_syn_df.groupby(['Spike_AS_Position', 'Amino_Acid']):\n",
    "    immunizations = group_df['immunization'].unique()\n",
    "    if len(immunizations) < 2:\n",
    "        continue\n",
    "    \n",
    "    # Compare all pairs of immunizations\n",
    "    for imm1, imm2 in combinations(immunizations, 2):\n",
    "        enr_1 = group_df.loc[group_df['immunization'] == imm1, 'Enrichment_Ratio']\n",
    "        enr_2 = group_df.loc[group_df['immunization'] == imm2, 'Enrichment_Ratio']\n",
    "\n",
    "        # Skip if either group has no data\n",
    "        if len(enr_1) == 0 or len(enr_2) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Mann-Whitney U test (two-sided)\n",
    "        stat, p_val = mannwhitneyu(enr_1, enr_2, alternative='two-sided')\n",
    "        \n",
    "        median_1 = enr_1.median()\n",
    "        median_2 = enr_2.median()\n",
    "        \n",
    "        # Determine direction based on median\n",
    "        if median_1 > median_2:\n",
    "            direction = f\"Higher median in {imm1}\"\n",
    "        elif median_2 > median_1:\n",
    "            direction = f\"Higher median in {imm2}\"\n",
    "        else:\n",
    "            direction = \"No median difference\"\n",
    "        \n",
    "        # Store results\n",
    "        result = {\n",
    "            'Spike_AS_Position': pos,\n",
    "            'Amino_Acid': aa,\n",
    "            'Immunization_1': imm1,\n",
    "            'Immunization_2': imm2,\n",
    "            'Median_Enrichment_1': median_1,\n",
    "            'Median_Enrichment_2': median_2,\n",
    "            'MannWhitneyU_stat': stat,\n",
    "            'p_value': p_val,\n",
    "            'Direction': direction\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "        # Print summary\n",
    "        print(f\"\\n[Median Enrichment Ratio Comparison] Site {pos}, AA {aa}\")\n",
    "        print(f\"Comparison: {imm1} vs {imm2}\")\n",
    "        print(f\"Median enrichment ratio: {median_1:.4f} vs {median_2:.4f}\")\n",
    "        print(f\"Mann-Whitney U stat: {stat:.4g}\")\n",
    "        print(f\"P-value: {p_val:.4g}\")\n",
    "        print(f\"Direction: {direction}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_enrichment_stats = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sites_to_show = [416,417, 418,419,420,421,422,439, 440,441, 450,451, 452,453, 475,476, 477,478, 484, 492,493,494,495,500,501, 502, 503,504,505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "abbr_map = {\n",
    "    'Library_ctrl': 'Lib',\n",
    "    'Polyclonal_Ab': 'pAB',\n",
    "    'Mutant_RBD': 'B.1.135',\n",
    "    'Neutralizing_Ab': 'mAB',\n",
    "    'wildtype_RBD': 'WT',\n",
    "}\n",
    "\n",
    "# Filter significant results and exclude library and stop codons (*)\n",
    "significant_enrich = df_enrichment_stats[\n",
    "    (df_enrichment_stats['p_value'] < 0.05) &\n",
    "    (~df_enrichment_stats['Immunization_1'].isin(['Library_ctrl'])) &\n",
    "    (~df_enrichment_stats['Immunization_2'].isin(['Library_ctrl'])) &\n",
    "    (df_enrichment_stats['Amino_Acid'] != '*')\n",
    "].copy()\n",
    "\n",
    "if significant_enrich.empty:\n",
    "    print(\"No significant median enrichment ratio differences found (after filtering).\")\n",
    "else:\n",
    "    significant_enrich['Imm1_abbr'] = significant_enrich['Immunization_1'].map(abbr_map).fillna(significant_enrich['Immunization_1'])\n",
    "    significant_enrich['Imm2_abbr'] = significant_enrich['Immunization_2'].map(abbr_map).fillna(significant_enrich['Immunization_2'])\n",
    "\n",
    "    def order_imm(row):\n",
    "        if row['Median_Enrichment_1'] >= row['Median_Enrichment_2']:\n",
    "            return (row['Imm1_abbr'], row['Imm2_abbr'], row['Median_Enrichment_1'], row['Median_Enrichment_2'])\n",
    "        else:\n",
    "            return (row['Imm2_abbr'], row['Imm1_abbr'], row['Median_Enrichment_2'], row['Median_Enrichment_1'])\n",
    "\n",
    "    ordered = significant_enrich.apply(order_imm, axis=1, result_type='expand')\n",
    "    significant_enrich['Imm_high'] = ordered[0]\n",
    "    significant_enrich['Imm_low'] = ordered[1]\n",
    "    significant_enrich['Median_high'] = ordered[2]\n",
    "    significant_enrich['Median_low'] = ordered[3]\n",
    "\n",
    "    significant_enrich['Comparison_Label'] = (\n",
    "        significant_enrich['Spike_AS_Position'].astype(str) + \"\\n\" +\n",
    "        significant_enrich['Amino_Acid'] + \"\\n\" +\n",
    "        significant_enrich['Imm_high'] + \"\\n\" +\n",
    "        \"vs.\\n\" +\n",
    "        significant_enrich['Imm_low']\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.barplot(\n",
    "        data=significant_enrich,\n",
    "        x='Comparison_Label',\n",
    "        y='p_value',\n",
    "        palette='mako_r'\n",
    "    )\n",
    "    plt.axhline(0.05, color='red', linestyle='--', label='Significance Threshold (0.05)')\n",
    "    plt.xticks(rotation=0, ha='right', fontsize=10)\n",
    "    plt.ylabel('P-value (Mann-Whitney U test)')\n",
    "    plt.title('Significant Median Enrichment Ratio Comparisons (Excluding Library and Stop Codons)')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    output_path = os.path.join(output_dir, \"pValue_ER_Ratio.png\")\n",
    "    plt.savefig(output_path, format='png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# Total barcodes per immunization\n",
    "barcode_counts = df_logo_agg.groupby('immunization')['barcode'].nunique().to_dict()\n",
    "\n",
    "# Store results\n",
    "freq_stats = []\n",
    "\n",
    "for (pos, aa), subdf in df_combined.groupby(['Spike_AS_Position', 'Amino_Acid']):\n",
    "    table = []\n",
    "    for imm in subdf['immunization'].unique():\n",
    "        n_pos = subdf[(subdf['immunization'] == imm)]['Sample_Count'].values[0]  # Count with that AA\n",
    "        total = barcode_counts.get(imm, 0)\n",
    "        n_neg = total - n_pos\n",
    "        table.append([n_pos, n_neg])\n",
    "    \n",
    "    # Only compare 2 groups (you can extend to Chi2 if needed)\n",
    "    if len(table) == 2:\n",
    "        stat, p_val = fisher_exact(table)\n",
    "        freq_stats.append({'Spike_AS_Position': pos, 'Amino_Acid': aa, 'Test': 'Fisher', 'p_value': p_val})\n",
    "\n",
    "df_freq_stats = pd.DataFrame(freq_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_logo_agg.groupby('immunization')['barcode'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Significant enrichment differences:\")\n",
    "print(sig_enrich)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total tests: {len(df_enrichment_stats)}\")\n",
    "print(f\"Significant (p < 0.05): {len(sig_enrich)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Aggregate enrichment ratio per barcode, amino acid, and position\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'sum'  # or 'mean' or 'max' depending on your preference\n",
    "})\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "\n",
    "# Filter for positions > 365\n",
    "df_filtered = df_filtered[df_filtered['Spike_AS_Position'] > 365]\n",
    "\n",
    "# Assign a fixed color for each Amino Acid (e.g., a color map keyed by AA letter)\n",
    "aa_list = sorted(df_filtered['Amino_Acid'].unique())\n",
    "# Use a categorical colormap or assign colors manually:\n",
    "colors = plt.cm.tab20.colors  # a palette with 20 distinct colors\n",
    "aa_colors = {aa: colors[i % len(colors)] for i, aa in enumerate(aa_list)}\n",
    "\n",
    "df_filtered['color'] = df_filtered['Amino_Acid'].map(aa_colors)\n",
    "\n",
    "# Prepare labels for logo plot\n",
    "df_filtered = df_filtered.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"barcode_logoplots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop by barcode (each plot includes immunization label)\n",
    "for barcode in df_filtered['barcode'].unique():\n",
    "    df_barcode = df_filtered[df_filtered['barcode'] == barcode]\n",
    "    if df_barcode.empty:\n",
    "        continue\n",
    "\n",
    "    immunization = df_barcode['immunization'].iloc[0]\n",
    "\n",
    "    print(f\"Generating plot for barcode {barcode} ({immunization})...\")\n",
    "\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_barcode,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Enrichment_Ratio\",  # Use enrichment ratio for height\n",
    "        color_col=\"color\",\n",
    "        title=f\"{immunization} - {barcode} logoplot (Enrichment Ratio-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    fig.set_size_inches(45, 4)\n",
    "\n",
    "    # Optionally: remove colorbar or create a legend for amino acid colors\n",
    "    # Here's a legend for amino acids\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [Patch(facecolor=col, label=aa) for aa, col in aa_colors.items()]\n",
    "    ax.legend(handles=legend_elements, title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # Save plot\n",
    "    safe_barcode = barcode.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")  # Sanitize filename\n",
    "    plot_filename = os.path.join(output_dir, f\"{safe_barcode}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "    print(f\"Plot saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Aggregate enrichment ratio per barcode, amino acid, and position\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False\n",
    ").agg({\n",
    "    'Enrichment_Ratio': 'median'  # or 'mean' or 'max'\n",
    "})\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "df_logo_agg = df_logo_agg.replace([np.inf, -np.inf], np.nan)\n",
    "df_logo_agg = df_logo_agg.dropna(subset=['Enrichment_Ratio'])\n",
    "\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 1]\n",
    "df_filtered = df_filtered[df_filtered['Spike_AS_Position'] > 365]\n",
    "\n",
    "print(df_filtered['Enrichment_Ratio'].min())  # Should be > 1\n",
    "\n",
    "# Add a new column with log10 of Enrichment_Ratio (safe transformation)\n",
    "def safe_log10(x):\n",
    "    return np.log10(x) if x > 0 else np.nan\n",
    "\n",
    "df_filtered['Enrichment_Ratio_log'] = df_filtered['Enrichment_Ratio'].apply(safe_log10)\n",
    "df_filtered = df_filtered.dropna(subset=['Enrichment_Ratio_log'])\n",
    "\n",
    "# Color assignment\n",
    "aa_list = sorted(df_filtered['Amino_Acid'].unique())\n",
    "colors = plt.cm.tab20.colors\n",
    "aa_colors = {aa: colors[i % len(colors)] for i, aa in enumerate(aa_list)}\n",
    "df_filtered['color'] = df_filtered['Amino_Acid'].map(aa_colors)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"barcode_logoplots_panels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Helper function to format y-axis ticks as 10^x\n",
    "def log_ticks(ax):\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f\"$10^{{{int(y)}}}$\"))\n",
    "\n",
    "# Loop over each immunization and create vertical panel of top 4 barcodes\n",
    "for immunization in df_filtered['immunization'].unique():\n",
    "    df_imm = df_filtered[df_filtered['immunization'] == immunization]\n",
    "    barcodes = df_imm['barcode'].unique()[:4]  # Top 4 barcodes only\n",
    "\n",
    "    if len(barcodes) == 0:\n",
    "        continue\n",
    "\n",
    "    print(f\"Generating panel for immunization: {immunization}\")\n",
    "\n",
    "    fig, axs = plt.subplots(len(barcodes), 1, figsize=(45, 4 * len(barcodes)))\n",
    "\n",
    "    if len(barcodes) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for i, barcode in enumerate(barcodes):\n",
    "        df_barcode = df_imm[(df_imm['barcode'] == barcode) & (df_imm['Enrichment_Ratio_log'].notna())]\n",
    "    \n",
    "        if df_barcode.empty:\n",
    "            continue\n",
    "    \n",
    "        fig_sub, ax = dmslogo.draw_logo(\n",
    "            df_barcode,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log\",  # Use log-transformed values\n",
    "            color_col=\"color\",\n",
    "            title=f\"{immunization} - {barcode} logoplot (log10 Enrichment Ratio)\",\n",
    "            addbreaks=True,\n",
    "            ax=axs[i]\n",
    "        )\n",
    "    \n",
    "        axs[i].set_ylabel('log10(Enrichment Ratio)')\n",
    "        log_ticks(axs[i])\n",
    "    \n",
    "        legend_elements = [Patch(facecolor=col, label=aa) for aa, col in aa_colors.items()]\n",
    "        axs[i].legend(handles=legend_elements, title='Amino Acid', bbox_to_anchor=(1.01, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    safe_immunization = immunization.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{safe_immunization}_top4_logoplots.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Panel saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd  # added for concat/copy\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "df_logo_agg = df_logo_agg.replace([np.inf, -np.inf], np.nan)\n",
    "df_logo_agg = df_logo_agg.dropna(subset=['Enrichment_Ratio'])\n",
    "\n",
    "df_filtered = df_logo_agg.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'])\n",
    "\n",
    "# Filter positions > 365\n",
    "df_filtered = df_filtered[df_filtered['Spike_AS_Position'] > 365]\n",
    "\n",
    "print(df_filtered['Enrichment_Ratio'].min())  # Should be > 1\n",
    "\n",
    "duplicates = df_barcode[df_barcode.duplicated(subset=['Spike_AS_Position', 'Amino_Acid'], keep=False)]\n",
    "print(duplicates)\n",
    "\n",
    "# Add a new column with log10 of Enrichment_Ratio (safe transformation)\n",
    "def safe_log10(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "df_filtered['Enrichment_Ratio_log'] = df_filtered['Enrichment_Ratio'].apply(safe_log10)\n",
    "df_filtered = df_filtered.dropna(subset=['Enrichment_Ratio_log'])\n",
    "\n",
    "# Color assignment\n",
    "aa_list = sorted(df_filtered['Amino_Acid'].unique())\n",
    "colors = plt.cm.tab20.colors\n",
    "aa_colors = {aa: colors[i % len(colors)] for i, aa in enumerate(aa_list)}\n",
    "df_filtered['color'] = df_filtered['Amino_Acid'].map(aa_colors)\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"barcode_logoplots_panels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Helper function for plain integer log ticks\n",
    "def log_ticks_plain(ax):\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f\"{int(y)}\"))\n",
    "\n",
    "# --- NEW: explicit positive/negative stacking like in your 2nd code ---\n",
    "def separate_stacked_heights(df, x_col='Spike_AS_Position', h_col='Enrichment_Ratio_log'):\n",
    "    # Sort primarily by position, then by height (largest first) for stable order\n",
    "    df_sorted = df.sort_values(by=[x_col, h_col], ascending=[True, False]).copy()\n",
    "\n",
    "    # Split by sign\n",
    "    df_positive = df_sorted[df_sorted[h_col] >= 0].copy()\n",
    "    df_negative = df_sorted[df_sorted[h_col] < 0].copy()\n",
    "\n",
    "    # Cumulative within each position gives where each letter should start\n",
    "    df_positive['stack_bottom'] = df_positive.groupby(x_col)[h_col].cumsum() - df_positive[h_col]\n",
    "    df_negative['stack_bottom'] = df_negative.groupby(x_col)[h_col].cumsum() - df_negative[h_col]\n",
    "\n",
    "    # Recombine; sort by baseline so draw order follows bottom→top within position\n",
    "    out = pd.concat([df_positive, df_negative], axis=0).sort_values(by=[x_col, 'stack_bottom'])\n",
    "    return out\n",
    "\n",
    "# Plot loop\n",
    "for immunization in df_filtered['immunization'].unique():\n",
    "    df_imm = df_filtered[df_filtered['immunization'] == immunization]\n",
    "    barcodes = df_imm['barcode'].unique()[:4]\n",
    "\n",
    "    if len(barcodes) == 0:\n",
    "        continue\n",
    "\n",
    "    print(f\"Generating panel for immunization: {immunization}\")\n",
    "\n",
    "    fig, axs = plt.subplots(len(barcodes), 1, figsize=(45, 4 * len(barcodes)),\n",
    "                             gridspec_kw={'hspace': 0.5})\n",
    "\n",
    "    if len(barcodes) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for i, barcode in enumerate(barcodes):\n",
    "        df_barcode = df_imm[(df_imm['barcode'] == barcode) &\n",
    "                            (df_imm['Enrichment_Ratio_log'].notna())]\n",
    "\n",
    "        if df_barcode.empty:\n",
    "            continue\n",
    "\n",
    "        # >>> apply explicit stacking so letters don't overlap\n",
    "        df_barcode = separate_stacked_heights(\n",
    "            df_barcode,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            h_col=\"Enrichment_Ratio_log\"\n",
    "        )\n",
    "\n",
    "        fig_sub, ax = dmslogo.draw_logo(\n",
    "            df_barcode,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log\",\n",
    "            color_col=\"color\",\n",
    "            title=f\"{immunization} - {barcode} logoplot (log10 Enrichment Ratio)\",\n",
    "            addbreaks=True,\n",
    "            ax=axs[i]\n",
    "        )\n",
    "\n",
    "        axs[i].set_title(f\"{immunization} - {barcode} logoplot (log10 Enrichment Ratio)\", pad=25)\n",
    "        axs[i].set_ylabel('log10 AB binding')\n",
    "        axs[i].yaxis.set_label_coords(-2, 0.5)\n",
    "        axs[i].set_ylim(-10, 6)\n",
    "        axs[i].yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "        log_ticks_plain(axs[i])\n",
    "\n",
    "    legend_elements = [Patch(facecolor=col, label=aa) for aa, col in aa_colors.items()]\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.legend(handles=legend_elements, title='Amino Acid', loc='center right', borderaxespad=0.1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 2])\n",
    "    safe_immunization = immunization.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{safe_immunization}_top4_logoplots.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Panel saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "df_logo_agg = df_logo_agg.replace([np.inf, -np.inf], np.nan)\n",
    "df_logo_agg = df_logo_agg.dropna(subset=['Enrichment_Ratio'])\n",
    "\n",
    "df_filtered = df_logo_agg.drop_duplicates(subset=['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'])\n",
    "\n",
    "# Filter positions > 365\n",
    "df_filtered = df_filtered[df_filtered['Spike_AS_Position'] > 365]\n",
    "\n",
    "print(df_filtered['Enrichment_Ratio'].min())  # Should be > 1\n",
    "\n",
    "duplicates = df_barcode[df_barcode.duplicated(subset=['Spike_AS_Position', 'Amino_Acid'], keep=False)]\n",
    "print(duplicates)\n",
    "\n",
    "# Add a new column with log10 of Enrichment_Ratio (safe transformation)\n",
    "def safe_log10(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "df_filtered['Enrichment_Ratio_log'] = df_filtered['Enrichment_Ratio'].apply(safe_log10)\n",
    "df_filtered = df_filtered.dropna(subset=['Enrichment_Ratio_log'])\n",
    "\n",
    "# Color assignment\n",
    "aa_list = sorted(df_filtered['Amino_Acid'].unique())\n",
    "colors = plt.cm.tab20.colors\n",
    "aa_colors = {aa: colors[i % len(colors)] for i, aa in enumerate(aa_list)}\n",
    "df_filtered['color'] = df_filtered['Amino_Acid'].map(aa_colors)\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"barcode_logoplots_panels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Helper function for plain integer log ticks\n",
    "def log_ticks_plain(ax):\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f\"{int(y)}\"))\n",
    "\n",
    "# Improved stacking function — letters sorted by height before drawing\n",
    "def improved_draw_logo(df, **kwargs):\n",
    "    # Sort within each x position so letters with greater height are on top\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[kwargs['x_col'], kwargs['letter_height_col']],\n",
    "        ascending=[True, True]\n",
    "    )\n",
    "    return dmslogo.draw_logo(df_sorted, **kwargs)\n",
    "\n",
    "# Plot loop\n",
    "for immunization in df_filtered['immunization'].unique():\n",
    "    df_imm = df_filtered[df_filtered['immunization'] == immunization]\n",
    "    barcodes = df_imm['barcode'].unique()[:4]\n",
    "\n",
    "    if len(barcodes) == 0:\n",
    "        continue\n",
    "\n",
    "    print(f\"Generating panel for immunization: {immunization}\")\n",
    "\n",
    "    fig, axs = plt.subplots(len(barcodes), 1, figsize=(45, 12 * len(barcodes)),\n",
    "                             gridspec_kw={'hspace': 2.5})\n",
    "\n",
    "    if len(barcodes) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for i, barcode in enumerate(barcodes):\n",
    "        df_barcode = df_imm[(df_imm['barcode'] == barcode) &\n",
    "                            (df_imm['Enrichment_Ratio_log'].notna())]\n",
    "\n",
    "        if df_barcode.empty:\n",
    "            continue\n",
    "\n",
    "        fig_sub, ax = improved_draw_logo(\n",
    "            df_barcode,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log\",\n",
    "            color_col=\"color\",\n",
    "            title=f\"{immunization} - {barcode} logoplot (log10 Enrichment Ratio)\",\n",
    "            addbreaks=True,\n",
    "            ax=axs[i]\n",
    "        )\n",
    "\n",
    "        axs[i].set_title(f\"{immunization} - {barcode} logoplot (log10 Enrichment Ratio)\", pad=25)\n",
    "        axs[i].set_ylabel('Log10 AB binding (median) \\u2190 Enrichment \\u2192', fontsize=10)\n",
    "        axs[i].yaxis.set_label_coords(-0.01, 0.5)\n",
    "        axs[i].set_ylim(-10, 6)\n",
    "        axs[i].yaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "        log_ticks_plain(axs[i])\n",
    "\n",
    "    legend_elements = [Patch(facecolor=col, label=aa) for aa, col in aa_colors.items()]\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.legend(handles=legend_elements, title='Amino Acid', loc='center right', borderaxespad=0.1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 2])\n",
    "    safe_immunization = immunization.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{safe_immunization}_top4_logoplots.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Panel saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "# -----------------------------\n",
    "# HEIGHT FUNCTION\n",
    "# -----------------------------\n",
    "def enrichment_height(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    \"\"\"\n",
    "    Safe log10 transformation of enrichment values.\n",
    "    Args:\n",
    "        enrichment (float or array-like): Enrichment value(s).\n",
    "        epsilon (float): Minimum enrichment value to avoid log10(0).\n",
    "        max_cap (float): Maximum value to cap extremely high enrichments.\n",
    "    Returns:\n",
    "        float or np.array: Transformed enrichment.\n",
    "    \"\"\"\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "# Aggregate enrichment ratio per barcode, amino acid, and position\n",
    "df_logo_agg = df_total.groupby(\n",
    "    ['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False\n",
    ").agg({'Enrichment_Ratio': 'sum'})  # or 'mean' or 'max'\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "df_logo_agg = df_logo_agg.replace([np.inf, -np.inf], np.nan)\n",
    "df_logo_agg = df_logo_agg.dropna(subset=['Enrichment_Ratio'])\n",
    "\n",
    "# Include all positive values (0 excluded)\n",
    "df_filtered = df_logo_agg[df_logo_agg['Spike_AS_Position'] > 365]\n",
    "\n",
    "# Add letter height using safe log10 transformation\n",
    "df_filtered['letter_height'] = df_filtered['Enrichment_Ratio'].apply(enrichment_height)\n",
    "df_filtered = df_filtered.dropna(subset=['letter_height'])\n",
    "\n",
    "# Color assignment\n",
    "aa_list = sorted(df_filtered['Amino_Acid'].unique())\n",
    "colors_list = plt.cm.tab20.colors\n",
    "aa_colors = {aa: colors_list[i % len(colors_list)] for i, aa in enumerate(aa_list)}\n",
    "df_filtered['color'] = df_filtered['Amino_Acid'].map(aa_colors)\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"barcode_logoplots_panels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Helper function to format y-axis ticks with log10 inverse style\n",
    "def log_ticks(ax):\n",
    "    \"\"\"Set y-axis to log10 scale with ticks as 10^x.\"\"\"\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f\"$10^{{{int(y)}}}$\"))\n",
    "\n",
    "# Loop over each immunization and create vertical panel of 4 random barcodes\n",
    "for immunization in df_filtered['immunization'].unique():\n",
    "    df_imm = df_filtered[df_filtered['immunization'] == immunization]\n",
    "    barcodes_all = df_imm['barcode'].unique()\n",
    "    \n",
    "    if len(barcodes_all) == 0:\n",
    "        continue\n",
    "\n",
    "    # Randomly select up to 4 barcodes\n",
    "    barcodes = random.sample(list(barcodes_all), min(4, len(barcodes_all)))\n",
    "\n",
    "    print(f\"Generating panel for immunization: {immunization} with barcodes: {barcodes}\")\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        len(barcodes), 1, figsize=(45, 4 * len(barcodes)),\n",
    "        gridspec_kw={'hspace': 0.5}\n",
    "    )\n",
    "\n",
    "    if len(barcodes) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for i, barcode in enumerate(barcodes):\n",
    "        df_barcode = df_imm[(df_imm['barcode'] == barcode) & (df_imm['letter_height'].notna())]\n",
    "\n",
    "        if df_barcode.empty:\n",
    "            continue\n",
    "\n",
    "        fig_sub, ax = dmslogo.draw_logo(\n",
    "            df_barcode,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"letter_height\",\n",
    "            color_col=\"color\",\n",
    "            title=f\"{immunization} - {barcode} logoplot (log10 Enrichment Ratio)\",\n",
    "            addbreaks=True,\n",
    "            ax=axs[i]\n",
    "        )\n",
    "\n",
    "        axs[i].set_ylabel('Enrichment Ratio (log10)')\n",
    "        axs[i].set_ylim(-10, 6)\n",
    "        axs[i].yaxis.set_major_locator(ticker.MultipleLocator(2))\n",
    "        log_ticks(axs[i])\n",
    "\n",
    "    # Add legend once\n",
    "    legend_elements = [Patch(facecolor=col, label=aa) for aa, col in aa_colors.items()]\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.legend(handles=legend_elements, title='Amino Acid', loc='center right', borderaxespad=0.1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "    safe_immunization = immunization.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{safe_immunization}_top4_random_logoplots.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    print(f\"Panel saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "print(scipy.__version__)\n",
    "\n",
    "from scipy.stats import binomtest\n",
    "help(binomtest)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import binomtest\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Start with df_total containing: ['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode']\n",
    "\n",
    "# Filter out stop codons and optionally positions <= 365 (adjust as you want)\n",
    "df_filtered = df_total[(df_total['Amino_Acid'] != '*') & (df_total['Spike_AS_Position'] > 365)]\n",
    "\n",
    "results = []\n",
    "\n",
    "for imm in df_filtered['immunization'].unique():\n",
    "    df_imm = df_filtered[df_filtered['immunization'] == imm]\n",
    "    barcodes = df_imm['barcode'].unique()\n",
    "    n_barcodes = len(barcodes)\n",
    "\n",
    "    # Build presence matrix for each (pos, aa) across barcodes\n",
    "    presence_dict = {}\n",
    "    for pos in df_imm['Spike_AS_Position'].unique():\n",
    "        df_pos = df_imm[df_imm['Spike_AS_Position'] == pos]\n",
    "        for aa in df_pos['Amino_Acid'].unique():\n",
    "            presence = df_pos[df_pos['Amino_Acid'] == aa].groupby('barcode').size()\n",
    "            presence = presence.apply(lambda x: 1 if x > 0 else 0)\n",
    "            presence = presence.reindex(barcodes, fill_value=0)\n",
    "            presence_dict[(pos, aa)] = presence.values\n",
    "\n",
    "    presence_df = pd.DataFrame.from_dict(presence_dict, orient='index', columns=barcodes)\n",
    "\n",
    "    # Calculate frequency\n",
    "    freq = presence_df.sum(axis=1) / n_barcodes\n",
    "\n",
    "    # Binomial test for enrichment with null hypothesis p0\n",
    "    p0 = 0.05  # Adjust this null frequency as appropriate\n",
    "\n",
    "    pvals = freq.apply(\n",
    "        lambda f: binomtest(int(f * n_barcodes), n_barcodes, p=p0, alternative='greater').pvalue\n",
    "    )\n",
    "\n",
    "    df_res = pd.DataFrame({\n",
    "        'immunization': imm,\n",
    "        'Spike_AS_Position': [pos for pos, aa in freq.index],\n",
    "        'Amino_Acid': [aa for pos, aa in freq.index],\n",
    "        'frequency': freq.values,\n",
    "        'p_value': pvals.values\n",
    "    })\n",
    "\n",
    "    results.append(df_res)\n",
    "\n",
    "# Combine all immunizations\n",
    "df_reproducibility = pd.concat(results)\n",
    "\n",
    "# Adjust p-values globally\n",
    "df_reproducibility['p_adj'] = multipletests(df_reproducibility['p_value'], method='fdr_bh')[1]\n",
    "\n",
    "# Merge adjusted p-values and frequencies back to df_filtered for plotting\n",
    "df_plot = pd.merge(\n",
    "    df_filtered,\n",
    "    df_reproducibility,\n",
    "    on=['immunization', 'Spike_AS_Position', 'Amino_Acid'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate -log10 adjusted p-values for plotting, handling zeros safely\n",
    "df_plot['log_p_adj'] = -np.log10(df_plot['p_adj'].replace(0, np.nextafter(0, 1)))\n",
    "\n",
    "# Plot combined scatterplot for all immunizations faceted by immunization\n",
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.FacetGrid(df_plot, col=\"immunization\", col_wrap=2, height=5, sharey=False)\n",
    "g.map_dataframe(\n",
    "    sns.scatterplot,\n",
    "    x='Spike_AS_Position',\n",
    "    y='log_p_adj',\n",
    "    hue='Amino_Acid',\n",
    "    palette='tab20',\n",
    "    edgecolor='black',\n",
    "    linewidth=0.5,\n",
    "    s=70\n",
    ")\n",
    "g.set_axis_labels(\"Spike Amino Acid Position\", \"-log10 Adjusted p-value\")\n",
    "g.add_legend(title='Amino Acid')\n",
    "for ax in g.axes.flat:\n",
    "    ax.axhline(-np.log10(0.05), color='red', linestyle='--')  # FDR 0.05 threshold\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "# Plot each immunization separately with a different color\n",
    "immunizations = df_reproducibility['immunization'].unique()\n",
    "\n",
    "for imm in immunizations:\n",
    "    df_sub = df_reproducibility[df_reproducibility['immunization'] == imm]\n",
    "\n",
    "    # Aggregate by position: take minimum p_adj (or mean, or median) across amino acids at the same position\n",
    "    # Using min here to highlight the strongest signal per position\n",
    "    pvals_by_pos = df_sub.groupby('Spike_AS_Position')['p_adj'].min()\n",
    "\n",
    "    plt.plot(\n",
    "        pvals_by_pos.index,\n",
    "        pvals_by_pos.values,\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        label=imm\n",
    "    )\n",
    "\n",
    "plt.axhline(0.05, color='red', linestyle='--', label='Significance threshold (0.05)')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Spike Amino Acid Position')\n",
    "plt.ylabel('Adjusted p-value (log scale)')\n",
    "plt.title('Adjusted p-values by Spike Position for each Immunization')\n",
    "plt.legend(title='Immunization')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Loop over each immunization and plot separately\n",
    "for imm in df_reproducibility['immunization'].unique():\n",
    "    df_imm = df_reproducibility[df_reproducibility['immunization'] == imm].copy()\n",
    "\n",
    "    # Compute -log10(p_adj) for plotting\n",
    "    df_imm['log_p_adj'] = -np.log10(df_imm['p_adj'])\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    scatter = sns.scatterplot(\n",
    "        data=df_imm,\n",
    "        x='Spike_AS_Position',\n",
    "        y='log_p_adj',\n",
    "        hue='Amino_Acid',\n",
    "        palette='tab20',\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5,\n",
    "        s=80\n",
    "    )\n",
    "\n",
    "    # Threshold line at p = 0.05 (adjusted)\n",
    "    plt.axhline(-np.log10(0.05), color='red', linestyle='--', label='FDR = 0.05')\n",
    "\n",
    "    plt.title(f'-log10 Adjusted p-values by Position and Amino Acid: {imm}')\n",
    "    plt.xlabel('Spike Amino Acid Position')\n",
    "    plt.ylabel('-log10(p_adj)')\n",
    "    plt.legend(title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Define bin edges for -log10(p_adj)\n",
    "bins = np.arange(0, 11, 1)  # bins: 0–1, 1–2, ..., 9–10\n",
    "bin_labels = [f\"{i}-{i+1}\" for i in bins[:-1]]\n",
    "\n",
    "# Loop over each immunization\n",
    "for imm in df_reproducibility['immunization'].unique():\n",
    "    df_imm = df_reproducibility[df_reproducibility['immunization'] == imm].copy()\n",
    "    df_imm['log_p_adj'] = -np.log10(df_imm['p_adj'])\n",
    "\n",
    "    # Bin the values\n",
    "    df_imm['log_p_bin'] = pd.cut(df_imm['log_p_adj'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "    # Count and percent\n",
    "    bin_counts = df_imm['log_p_bin'].value_counts(sort=False).fillna(0).astype(int)\n",
    "    bin_percent = (bin_counts / len(df_imm) * 100).round(2)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nImmunization: {imm}\")\n",
    "    print(\"Bin Range | Count | Percent\")\n",
    "    for b in bin_labels:\n",
    "        print(f\"{b:>8} | {bin_counts[b]:>5} | {bin_percent[b]:>6}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Loop over each immunization and plot separately\n",
    "for imm in df_reproducibility['immunization'].unique():\n",
    "    df_imm = df_reproducibility[df_reproducibility['immunization'] == imm].copy()\n",
    "\n",
    "    # Compute -log10(p_adj) for plotting\n",
    "    df_imm['log_p_adj'] = -np.log10(df_imm['p_adj'])\n",
    "\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    scatter = sns.scatterplot(\n",
    "        data=df_imm,\n",
    "        x='Spike_AS_Position',\n",
    "        y='log_p_adj',\n",
    "        hue='Amino_Acid',\n",
    "        palette='tab20',\n",
    "        edgecolor='black',\n",
    "        linewidth=0.5,\n",
    "        s=80\n",
    "    )\n",
    "\n",
    "    # Threshold line at p = 0.05 (adjusted)\n",
    "    plt.axhline(-np.log10(0.05), color='red', linestyle='--', label='FDR = 0.05')\n",
    "\n",
    "    plt.title(f'-log10 Adjusted p-values by Position and Amino Acid: {imm}')\n",
    "    plt.xlabel('Spike Amino Acid Position')\n",
    "    plt.ylabel('-log10(p_adj)')\n",
    "    plt.legend(title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    " # Define bin edges and labels\n",
    "bins = np.arange(0, 11, 1)\n",
    "bin_labels = [f\"{i}-{i+1}\" for i in bins[:-1]]\n",
    "\n",
    "# Loop over each immunization\n",
    "for imm in df_reproducibility['immunization'].unique():\n",
    "    df_imm = df_reproducibility[df_reproducibility['immunization'] == imm].copy()\n",
    "    df_imm['log_p_adj'] = -np.log10(df_imm['p_adj'])\n",
    "\n",
    "    # Drop rows with NaN values (these would not be plotted)\n",
    "    df_imm_valid = df_imm.dropna(subset=['log_p_adj'])\n",
    "\n",
    "    # Bin only valid values\n",
    "    df_imm_valid['log_p_bin'] = pd.cut(df_imm_valid['log_p_adj'], bins=bins, labels=bin_labels, right=False)\n",
    "\n",
    "    # Count and percent\n",
    "    bin_counts = df_imm_valid['log_p_bin'].value_counts(sort=False).fillna(0).astype(int)\n",
    "    bin_percent = (bin_counts / len(df_imm_valid) * 100).round(2)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nImmunization: {imm}\")\n",
    "    print(\"Bin Range | Count | Percent\")\n",
    "    for b in bin_labels:\n",
    "        print(f\"{b:>8} | {bin_counts[b]:>5} | {bin_percent[b]:>6}%\")\n",
    "    \n",
    "    print(f\"Total points plotted: {len(df_imm_valid)} — Sum of %: {bin_percent.sum()}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in df_reproducibility:\")\n",
    "print(df_reproducibility.columns.tolist())\n",
    "\n",
    "print(\"\\nSample data (first 5 rows):\")\n",
    "print(df_reproducibility.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Avoid SettingWithCopyWarning by creating a new column safely\n",
    "df_bootstrap = bootstrap_results.copy()\n",
    "\n",
    "\n",
    "df_bootstrap = pd.DataFrame(bootstrap_results)\n",
    "df_bootstrap['Pos'] = df_bootstrap['Spike_AS_Position'].astype(str)\n",
    "df_bootstrap = df_bootstrap[df_bootstrap['immunization'] != 'Library_ctrl']\n",
    "\n",
    "\n",
    "# Plot settings\n",
    "sns.set(style=\"whitegrid\")\n",
    "g = sns.FacetGrid(\n",
    "    df_bootstrap,\n",
    "    col=\"immunization\",\n",
    "    col_wrap=3,\n",
    "    height=5,\n",
    "    sharey=False\n",
    ")\n",
    "\n",
    "# Custom barplot function with error bars\n",
    "def plot_with_errorbars(data, color, **kwargs):\n",
    "    ax = plt.gca()\n",
    "    # Sort bars to keep order consistent\n",
    "    data = data.sort_values(by=['Spike_AS_Position', 'Amino_Acid'])\n",
    "    \n",
    "    sns.barplot(\n",
    "        data=data,\n",
    "        x='Pos',\n",
    "        y='freq_mean',\n",
    "        hue='Amino_Acid',\n",
    "        errorbar=None,\n",
    "        palette='tab20',\n",
    "        ax=ax,\n",
    "        **kwargs\n",
    "    )\n",
    "    # Add error bars\n",
    "    for i, row in data.iterrows():\n",
    "        xpos = list(data['Pos'].unique()).index(row['Pos'])\n",
    "        ax.errorbar(\n",
    "            x=xpos,\n",
    "            y=row['freq_mean'],\n",
    "            yerr=row['freq_se'],\n",
    "            fmt='none',\n",
    "            ecolor='gray',\n",
    "            elinewidth=1,\n",
    "            capsize=2\n",
    "        )\n",
    "\n",
    "# Apply plotting function\n",
    "g.map_dataframe(plot_with_errorbars)\n",
    "\n",
    "# Axis and legend cleanup\n",
    "g.set_axis_labels(\"Spike Amino Acid Position\", \"Mean Frequency\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "for ax in g.axes.flat:\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "\n",
    "g.set_axis_labels(\"Spike Amino Acid Position\", \"Mean Frequency\")\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "\n",
    "for ax in g.axes.flat:\n",
    "    ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "    # Ensure x-axis ticks every 10th position\n",
    "    positions = sorted(df_bootstrap['Spike_AS_Position'].unique())\n",
    "    positions_int = sorted([int(p) for p in positions])\n",
    "    tick_positions = [i for i, p in enumerate(positions_int) if p % 10 == 0]\n",
    "    tick_labels = [str(positions_int[i]) for i in tick_positions]\n",
    "    ax.set_xticks(tick_positions)\n",
    "    ax.set_xticklabels(tick_labels)\n",
    "\n",
    "g.add_legend(title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sort immunizations and bins for consistent order\n",
    "immunizations = sorted(df_bootstrap['immunization'].unique())\n",
    "enrich_bins = sorted(df_bootstrap['enrichment_bin'].unique(), key=lambda x: enrichment_labels.index(x))\n",
    "\n",
    "# Prepare figure height (e.g., 5 inches per plot)\n",
    "plot_height_per = 5\n",
    "total_plots = len(immunizations) * len(enrich_bins)\n",
    "fig_height = plot_height_per * total_plots\n",
    "fig_width = 16  # Wide to fit notebook width nicely\n",
    "\n",
    "fig, axes = plt.subplots(total_plots, 1, figsize=(fig_width, fig_height), squeeze=False)\n",
    "\n",
    "# Flatten axes for easy indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_i = 0\n",
    "for imm in immunizations:\n",
    "    for enrich_bin in enrich_bins:\n",
    "        ax = axes[plot_i]\n",
    "        data = df_bootstrap[\n",
    "            (df_bootstrap['immunization'] == imm) & \n",
    "            (df_bootstrap['enrichment_bin'] == enrich_bin)\n",
    "        ]\n",
    "\n",
    "        if data.empty:\n",
    "            ax.set_visible(False)\n",
    "            plot_i += 1\n",
    "            continue\n",
    "\n",
    "        # Sort data for nicer plotting\n",
    "        data = data.sort_values(['Spike_AS_Position', 'Amino_Acid'])\n",
    "\n",
    "        sns.barplot(\n",
    "            data=data,\n",
    "            x='Pos',\n",
    "            y='freq_mean',\n",
    "            hue='Amino_Acid',\n",
    "            palette='tab20',\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        # Add error bars manually\n",
    "        for i, row in data.iterrows():\n",
    "            xpos = list(data['Pos'].unique()).index(row['Pos'])\n",
    "            ax.errorbar(\n",
    "                x=xpos,\n",
    "                y=row['freq_mean'],\n",
    "                yerr=row['freq_se'],\n",
    "                fmt='none',\n",
    "                ecolor='gray',\n",
    "                elinewidth=1,\n",
    "                capsize=2\n",
    "            )\n",
    "        \n",
    "        ax.set_title(f\"Immunization: {imm} | Enrichment Bin: {enrich_bin}\", fontsize=14)\n",
    "        ax.set_xlabel(\"Spike Amino Acid Position\")\n",
    "        ax.set_ylabel(\"Mean Frequency\")\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "        \n",
    "        # Only show legend on first plot to avoid clutter\n",
    "        if plot_i == 0:\n",
    "            ax.legend(title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "        \n",
    "        plot_i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Find max y across all data for consistent y-axis scaling\n",
    "y_max = df_bootstrap['freq_mean'].max() * 1.05  # 5% padding on top\n",
    "\n",
    "immunizations = sorted(df_bootstrap['immunization'].unique())\n",
    "enrich_bins = sorted(df_bootstrap['enrichment_bin'].unique(), key=lambda x: enrichment_labels.index(x))\n",
    "\n",
    "plot_height_per = 5\n",
    "total_plots = len(immunizations) * len(enrich_bins)\n",
    "fig_height = plot_height_per * total_plots\n",
    "fig_width = 16\n",
    "\n",
    "fig, axes = plt.subplots(total_plots, 1, figsize=(fig_width, fig_height), squeeze=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_i = 0\n",
    "for imm in immunizations:\n",
    "    for enrich_bin in enrich_bins:\n",
    "        ax = axes[plot_i]\n",
    "        data = df_bootstrap[\n",
    "            (df_bootstrap['immunization'] == imm) & \n",
    "            (df_bootstrap['enrichment_bin'] == enrich_bin)\n",
    "        ]\n",
    "\n",
    "        if data.empty:\n",
    "            ax.set_visible(False)\n",
    "            plot_i += 1\n",
    "            continue\n",
    "\n",
    "        data = data.sort_values(['Spike_AS_Position', 'Amino_Acid'])\n",
    "        \n",
    "        sns.barplot(\n",
    "            data=data,\n",
    "            x='Pos',\n",
    "            y='freq_mean',\n",
    "            hue='Amino_Acid',\n",
    "            palette='tab20',\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        # Add error bars manually\n",
    "        for i, row in data.iterrows():\n",
    "            xpos = list(data['Pos'].unique()).index(row['Pos'])\n",
    "            ax.errorbar(\n",
    "                x=xpos,\n",
    "                y=row['freq_mean'],\n",
    "                yerr=row['freq_se'],\n",
    "                fmt='none',\n",
    "                ecolor='gray',\n",
    "                elinewidth=1,\n",
    "                capsize=2\n",
    "            )\n",
    "\n",
    "        # Fix y axis limits (same for all)\n",
    "        ax.set_ylim(0, y_max)\n",
    "        # Remove gaps on x axis (tight margins)\n",
    "        ax.margins(x=0)\n",
    "        \n",
    "        ax.set_title(f\"Immunization: {imm} | Enrichment Bin: {enrich_bin}\", fontsize=14)\n",
    "        ax.set_xlabel(\"Spike Amino Acid Position\")\n",
    "        ax.set_ylabel(\"Bootstrap Mean Frequency (AA Mutation per Binding-Ratio bin\")\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "        \n",
    "        # Legend only on first plot\n",
    "        if plot_i == 0:\n",
    "            ax.legend(title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "        \n",
    "        plot_i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of synthetic samples per data point for violin shape\n",
    "n_synthetic = 100\n",
    "\n",
    "fig, axes = plt.subplots(total_plots, 1, figsize=(fig_width, fig_height), squeeze=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_i = 0\n",
    "for imm in immunizations:\n",
    "    for enrich_bin in enrich_bins:\n",
    "        ax = axes[plot_i]\n",
    "        data = df_bootstrap[\n",
    "            (df_bootstrap['immunization'] == imm) & \n",
    "            (df_bootstrap['enrichment_bin'] == enrich_bin)\n",
    "        ]\n",
    "\n",
    "        if data.empty:\n",
    "            ax.set_visible(False)\n",
    "            plot_i += 1\n",
    "            continue\n",
    "\n",
    "        data = data.sort_values(['Spike_AS_Position', 'Amino_Acid'])\n",
    "\n",
    "        # Generate synthetic bootstrap samples for violin-like distribution\n",
    "        # For each row (mean, se), simulate n_synthetic samples\n",
    "        synthetic_samples = []\n",
    "        for _, row in data.iterrows():\n",
    "            # Use normal distribution, clip at 0 since freq can't be negative\n",
    "            samples = np.random.normal(loc=row['freq_mean'], scale=row['freq_se'], size=n_synthetic)\n",
    "            samples = np.clip(samples, a_min=0, a_max=None)\n",
    "            for s in samples:\n",
    "                synthetic_samples.append({\n",
    "                    'Pos': row['Pos'],\n",
    "                    'Amino_Acid': row['Amino_Acid'],\n",
    "                    'freq': s\n",
    "                })\n",
    "        df_synth = pd.DataFrame(synthetic_samples)\n",
    "\n",
    "        # Plot violin behind bars\n",
    "        sns.violinplot(\n",
    "            data=df_synth,\n",
    "            x='Pos',\n",
    "            y='freq',\n",
    "            hue='Amino_Acid',\n",
    "            palette='tab20',\n",
    "            cut=0,\n",
    "            scale='width',\n",
    "            inner=None,\n",
    "            linewidth=0,\n",
    "            ax=ax,\n",
    "            dodge=True\n",
    "        )\n",
    "\n",
    "        # Then plot your original barplot on top\n",
    "        sns.barplot(\n",
    "            data=data,\n",
    "            x='Pos',\n",
    "            y='freq_mean',\n",
    "            hue='Amino_Acid',\n",
    "            palette='tab20',\n",
    "            ax=ax,\n",
    "            edgecolor='black',\n",
    "            alpha=0.8,\n",
    "            dodge=True\n",
    "        )\n",
    "\n",
    "        # Add error bars manually\n",
    "        for i, row in data.iterrows():\n",
    "            xpos = list(data['Pos'].unique()).index(row['Pos'])\n",
    "            ax.errorbar(\n",
    "                x=xpos,\n",
    "                y=row['freq_mean'],\n",
    "                yerr=row['freq_se'],\n",
    "                fmt='none',\n",
    "                ecolor='gray',\n",
    "                elinewidth=1,\n",
    "                capsize=2\n",
    "            )\n",
    "\n",
    "        # Fix y axis limits (same for all)\n",
    "        ax.set_ylim(0, y_max)\n",
    "        ax.margins(x=0)\n",
    "\n",
    "        ax.set_title(f\"Immunization: {imm} | Enrichment Bin: {enrich_bin}\", fontsize=14)\n",
    "        ax.set_xlabel(\"Spike Amino Acid Position\")\n",
    "        ax.set_ylabel(\"Mean Frequency\")\n",
    "        ax.tick_params(axis='x', rotation=90)\n",
    "\n",
    "        # Legend only on first plot\n",
    "        if plot_i == 0:\n",
    "            ax.legend(title='Amino Acid', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        else:\n",
    "            ax.get_legend().remove()\n",
    "\n",
    "        plot_i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here are trying to compute bootstrapping sampling and at the same time compute p values to test if  when sampling a given amino-acid mutation \n",
    "#within a given enrichment bin (0-1, 1-10, 10-100, 100-500, >500) is purely random / by chance or if that is expected as it is represented \n",
    "#well in the repertoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute p-values by comparing observed vs bootstrapped frequencies\n",
    "p_values = []\n",
    "\n",
    "# Merge observed data (all barcodes per bin) with bootstrapped results\n",
    "for i, row in df_bootstrap.iterrows():\n",
    "    imm = row['immunization']\n",
    "    enrich_bin = row['enrichment_bin']\n",
    "    pos = row['Spike_AS_Position']\n",
    "    aa = row['Amino_Acid']\n",
    "\n",
    "    # Get all barcodes for this bin\n",
    "    df_imm = df_filtered[df_filtered['immunization'] == imm]\n",
    "    df_bin = df_imm[df_imm['enrichment_bin'] == enrich_bin]\n",
    "    barcodes = df_bin['barcode'].unique()\n",
    "\n",
    "    if len(barcodes) == 0:\n",
    "        p_values.append(np.nan)\n",
    "        continue\n",
    "\n",
    "    # Observed frequency\n",
    "    total_count = df_bin[\n",
    "        (df_bin['Spike_AS_Position'] == pos) &\n",
    "        (df_bin['Amino_Acid'] == aa)\n",
    "    ]['barcode'].nunique()\n",
    "\n",
    "    obs_freq = total_count / len(barcodes)\n",
    "\n",
    "    # Get bootstrap freq distribution\n",
    "    freq_array = df_bootstrap[\n",
    "        (df_bootstrap['immunization'] == imm) &\n",
    "        (df_bootstrap['enrichment_bin'] == enrich_bin) &\n",
    "        (df_bootstrap['Spike_AS_Position'] == pos) &\n",
    "        (df_bootstrap['Amino_Acid'] == aa)\n",
    "    ]['freq_mean'].values\n",
    "\n",
    "    # p-value: proportion of bootstrap freq >= observed freq\n",
    "    p_val = np.mean(freq_array >= obs_freq)\n",
    "    p_values.append(p_val)\n",
    "\n",
    "df_bootstrap['p_value'] = p_values\n",
    "df_bootstrap['log10_p'] = -np.log10(df_bootstrap['p_value'].replace(0, 1e-10))  # avoid -inf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to produce heatmaps of p-valeus from bootstrapping for each amino acid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loop over immunizations and enrichment bins\n",
    "for imm in df_bootstrap['immunization'].unique():\n",
    "    for enrich_bin in enrichment_labels:\n",
    "        df_plot = df_bootstrap[\n",
    "            (df_bootstrap['immunization'] == imm) &\n",
    "            (df_bootstrap['enrichment_bin'] == enrich_bin)\n",
    "        ]\n",
    "        if df_plot.empty:\n",
    "            continue\n",
    "\n",
    "        # Heatmap: mean frequency\n",
    "        pivot_freq = df_plot.pivot_table(\n",
    "            index='Amino_Acid',\n",
    "            columns='Spike_AS_Position',\n",
    "            values='freq_mean'\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        sns.heatmap(pivot_freq, cmap='magma', cbar_kws={'label': 'Mean AA Frequency'}, linewidths=0.1)\n",
    "        plt.title(f'{imm} | Bin: {enrich_bin} — Mean Amino Acid Frequency')\n",
    "        plt.xlabel('Spike Position')\n",
    "        plt.ylabel('Amino Acid')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Heatmap: log10 p-value\n",
    "        pivot_logp = df_plot.pivot_table(\n",
    "            index='Amino_Acid',\n",
    "            columns='Spike_AS_Position',\n",
    "            values='log10_p'\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        sns.heatmap(pivot_logp, cmap='viridis', cbar_kws={'label': '-log10(p-value)'}, linewidths=0.1)\n",
    "        plt.title(f'{imm} | Bin: {enrich_bin} — Significance of AA Enrichment')\n",
    "        plt.xlabel('Spike Position')\n",
    "        plt.ylabel('Amino Acid')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Parameters\n",
    "n_iter = 1000\n",
    "enrichment_bins = [0, 1, 10, 100, 500, np.inf]\n",
    "enrichment_labels = ['0–1', '1–10', '10–100', '100–500', '>500']\n",
    "\n",
    "df_filtered = df_total[\n",
    "    (df_total['Amino_Acid'] != '*') & (df_total['Spike_AS_Position'] > 365)\n",
    "].copy()\n",
    "\n",
    "# Bin ERs\n",
    "df_filtered['enrichment_bin'] = pd.cut(\n",
    "    df_filtered['Enrichment_Ratio'],\n",
    "    bins=enrichment_bins,\n",
    "    labels=enrichment_labels,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# Precompute null distributions per (immunization, position)\n",
    "null_distributions = {}\n",
    "\n",
    "for (imm, pos), df_pool in tqdm(df_filtered.groupby(['immunization', 'Spike_AS_Position']), desc='Precomputing nulls'):\n",
    "    er_values = df_pool['Enrichment_Ratio'].values\n",
    "    if len(er_values) < 2:\n",
    "        continue\n",
    "\n",
    "    # Bootstrapped bin counts\n",
    "    counts_array = np.zeros((n_iter, len(enrichment_labels)), dtype=np.float32)\n",
    "\n",
    "    counts_array = np.zeros((n_iter, len(enrichment_labels)))\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        sample = np.random.choice(er_values, size=len(er_values), replace=True)\n",
    "        sample_bins = pd.cut(sample, bins=enrichment_bins, labels=enrichment_labels, right=False)\n",
    "        counts = pd.Series(sample_bins).value_counts().reindex(enrichment_labels, fill_value=0).values\n",
    "        counts_array[i] = counts\n",
    "\n",
    "    null_distributions[(imm, pos)] = counts_array\n",
    "\n",
    "# Now test observed counts against nulls\n",
    "results = []\n",
    "\n",
    "for (imm, pos, aa), df_group in tqdm(df_filtered.groupby(['immunization', 'Spike_AS_Position', 'Amino_Acid']), desc=\"Testing enrichment\"):\n",
    "    if df_group.empty or (imm, pos) not in null_distributions:\n",
    "        continue\n",
    "\n",
    "    obs_bins = pd.cut(df_group['Enrichment_Ratio'], bins=enrichment_bins, labels=enrichment_labels, right=False)\n",
    "    obs_counts = pd.Series(obs_bins).value_counts().reindex(enrichment_labels, fill_value=0).values\n",
    "\n",
    "    null_counts = null_distributions[(imm, pos)]\n",
    "\n",
    "    for i, label in enumerate(enrichment_labels):\n",
    "        observed = obs_counts[i]\n",
    "        null = null_counts[:, i]\n",
    "        p_val = np.mean(null >= observed)\n",
    "        log10_p = -np.log10(p_val) if p_val > 0 else 10\n",
    "\n",
    "        results.append({\n",
    "            'immunization': imm,\n",
    "            'Spike_AS_Position': pos,\n",
    "            'Amino_Acid': aa,\n",
    "            'enrichment_bin': label,\n",
    "            'observed_count': observed,\n",
    "            'p_value': p_val,\n",
    "            'log10_p': log10_p\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Parameters\n",
    "n_iter = 1000\n",
    "chunk_size = 500  # tune based on available memory\n",
    "enrichment_bins = [0, 1, 10, 100, 500, np.inf]\n",
    "enrichment_labels = ['0–1', '1–10', '10–100', '100–500', '>500']\n",
    "\n",
    "df_filtered = df_total[\n",
    "    (df_total['Amino_Acid'] != '*') & (df_total['Spike_AS_Position'] > 365)\n",
    "].copy()\n",
    "\n",
    "# Bin ERs\n",
    "df_filtered['enrichment_bin'] = pd.cut(\n",
    "    df_filtered['Enrichment_Ratio'],\n",
    "    bins=enrichment_bins,\n",
    "    labels=enrichment_labels,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "# Step 1: Get group keys\n",
    "group_keys = list(df_filtered.groupby(['immunization', 'Spike_AS_Position']).groups.keys())\n",
    "\n",
    "# Step 2: Process null distributions in chunks\n",
    "null_distributions = {}\n",
    "\n",
    "for i in tqdm(range(0, len(group_keys), chunk_size), desc='Processing nulls in chunks'):\n",
    "    chunk_keys = group_keys[i:i+chunk_size]\n",
    "    for (imm, pos) in chunk_keys:\n",
    "        df_pool = df_filtered[(df_filtered['immunization'] == imm) & (df_filtered['Spike_AS_Position'] == pos)]\n",
    "        er_values = df_pool['Enrichment_Ratio'].values\n",
    "        if len(er_values) < 2:\n",
    "            continue\n",
    "\n",
    "        counts_array = np.zeros((n_iter, len(enrichment_labels)), dtype=np.float32)\n",
    "\n",
    "        for j in range(n_iter):\n",
    "            sample = np.random.choice(er_values, size=len(er_values), replace=True)\n",
    "            sample_bins = pd.cut(sample, bins=enrichment_bins, labels=enrichment_labels, right=False)\n",
    "            counts = pd.Series(sample_bins).value_counts().reindex(enrichment_labels, fill_value=0).values\n",
    "            counts_array[j] = counts\n",
    "\n",
    "        null_distributions[(imm, pos)] = counts_array\n",
    "\n",
    "# Step 3: Compute observed test results\n",
    "results = []\n",
    "\n",
    "group_keys_obs = list(df_filtered.groupby(['immunization', 'Spike_AS_Position', 'Amino_Acid']).groups.keys())\n",
    "\n",
    "for i in tqdm(range(0, len(group_keys_obs), chunk_size), desc='Testing observed groups'):\n",
    "    chunk_keys_obs = group_keys_obs[i:i+chunk_size]\n",
    "    for (imm, pos, aa) in chunk_keys_obs:\n",
    "        if (imm, pos) not in null_distributions:\n",
    "            continue\n",
    "\n",
    "        df_group = df_filtered[\n",
    "            (df_filtered['immunization'] == imm) &\n",
    "            (df_filtered['Spike_AS_Position'] == pos) &\n",
    "            (df_filtered['Amino_Acid'] == aa)\n",
    "        ]\n",
    "\n",
    "        if df_group.empty:\n",
    "            continue\n",
    "\n",
    "        obs_bins = pd.cut(df_group['Enrichment_Ratio'], bins=enrichment_bins, labels=enrichment_labels, right=False)\n",
    "        obs_counts = pd.Series(obs_bins).value_counts().reindex(enrichment_labels, fill_value=0).values\n",
    "\n",
    "        null_counts = null_distributions[(imm, pos)]\n",
    "\n",
    "        for k, label in enumerate(enrichment_labels):\n",
    "            observed = obs_counts[k]\n",
    "            null = null_counts[:, k]\n",
    "            p_val = np.mean(null >= observed)\n",
    "            log10_p = -np.log10(p_val) if p_val > 0 else 10\n",
    "\n",
    "            results.append({\n",
    "                'immunization': imm,\n",
    "                'Spike_AS_Position': pos,\n",
    "                'Amino_Acid': aa,\n",
    "                'enrichment_bin': label,\n",
    "                'observed_count': observed,\n",
    "                'p_value': p_val,\n",
    "                'log10_p': log10_p\n",
    "            })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data=df_results, x='enrichment_bin', y='log10_p', hue='immunization', inner=None, cut=0)\n",
    "sns.stripplot(data=df_results, x='enrichment_bin', y='log10_p', hue='immunization', dodge=True, jitter=True, alpha=0.5)\n",
    "\n",
    "plt.ylabel('-log10(p-value)')\n",
    "plt.title('Significance of Amino Acid Enrichment Ratios (per Immunization)')\n",
    "plt.axhline(-np.log10(0.005), linestyle='--', color='red', label='p = 0.005')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute stats + empirical p-value\n",
    "for (pos, aa), freqs in position_aa_freqs.items():\n",
    "    freq_array = np.array(freqs)\n",
    "\n",
    "    if len(barcodes) == 0:\n",
    "        continue  # Skip division by zero\n",
    "\n",
    "    # Compute observed frequency using all barcodes\n",
    "    total_count = df_bin[\n",
    "        (df_bin['Spike_AS_Position'] == pos) &\n",
    "        (df_bin['Amino_Acid'] == aa)\n",
    "    ]['barcode'].nunique()\n",
    "    obs_freq = total_count / len(barcodes)\n",
    "\n",
    "    # p-value: fraction of bootstraps where freq ≥ observed freq\n",
    "    p_value = np.sum(freq_array >= obs_freq) / n_iter\n",
    "\n",
    "    bootstrap_results.append({\n",
    "        'immunization': imm,\n",
    "        'Spike_AS_Position': pos,\n",
    "        'Amino_Acid': aa,\n",
    "        'enrichment_bin': enrich_bin,\n",
    "        'freq_mean': np.mean(freq_array),\n",
    "        'freq_std': np.std(freq_array),\n",
    "        'freq_se': np.std(freq_array) / np.sqrt(n_iter),\n",
    "        'obs_freq': obs_freq,\n",
    "        'p_value': p_value\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set p-value threshold\n",
    "p_thresh = 0.005\n",
    "\n",
    "# Count total and significant amino acids for each (immunization, enrichment_bin)\n",
    "summary = (\n",
    "    df_bootstrap\n",
    "    .groupby(['immunization', 'enrichment_bin'])\n",
    "    .apply(lambda g: pd.Series({\n",
    "        'n_total': len(g),\n",
    "        'n_significant': (g['p_value'] < p_thresh).sum()\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate percentage\n",
    "summary['percent_significant'] = 100 * summary['n_significant'] / summary['n_total']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Loop through all immunizations and enrichment bins\n",
    "for imm in df_bootstrap['immunization'].unique():\n",
    "    for enrich_bin in enrichment_labels:\n",
    "        df_plot = df_bootstrap[\n",
    "            (df_bootstrap['immunization'] == imm) &\n",
    "            (df_bootstrap['enrichment_bin'] == enrich_bin)\n",
    "        ]\n",
    "\n",
    "        if df_plot.empty:\n",
    "            continue  # Skip if there's no data for this combination\n",
    "\n",
    "        pivot = df_plot.pivot_table(\n",
    "            index='Amino_Acid',\n",
    "            columns='Spike_AS_Position',\n",
    "            values='log10_p',\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(20, 5))\n",
    "        sns.heatmap(\n",
    "            pivot,\n",
    "            cmap='viridis',\n",
    "            cbar_kws={'label': '-log10(p-value)'},\n",
    "            linewidths=0.1,\n",
    "            linecolor='gray'\n",
    "        )\n",
    "        plt.title(f'{imm} | Bin: {enrich_bin} — Amino Acid Reproducibility')\n",
    "        plt.xlabel('Spike Position')\n",
    "        plt.ylabel('Amino Acid')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check any correlation between chemical features. (charge of AA) and enrichment correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example AA properties dictionary (Kyte-Doolittle hydrophobicity, size, charge)\n",
    "aa_properties = {\n",
    "    'A': {'hydrophobicity': 1.8,  'size':  89, 'charge': 0},\n",
    "    'R': {'hydrophobicity': -4.5, 'size': 174, 'charge': 1},\n",
    "    'N': {'hydrophobicity': -3.5, 'size': 132, 'charge': 0},\n",
    "    'D': {'hydrophobicity': -3.5, 'size': 133, 'charge': -1},\n",
    "    'C': {'hydrophobicity': 2.5,  'size': 121, 'charge': 0},\n",
    "    'Q': {'hydrophobicity': -3.5, 'size': 146, 'charge': 0},\n",
    "    'E': {'hydrophobicity': -3.5, 'size': 147, 'charge': -1},\n",
    "    'G': {'hydrophobicity': -0.4, 'size':  75, 'charge': 0},\n",
    "    'H': {'hydrophobicity': -3.2, 'size': 155, 'charge': 0.1},  # Histidine partial charge\n",
    "    'I': {'hydrophobicity': 4.5,  'size': 131, 'charge': 0},\n",
    "    'L': {'hydrophobicity': 3.8,  'size': 131, 'charge': 0},\n",
    "    'K': {'hydrophobicity': -3.9, 'size': 146, 'charge': 1},\n",
    "    'M': {'hydrophobicity': 1.9,  'size': 149, 'charge': 0},\n",
    "    'F': {'hydrophobicity': 2.8,  'size': 165, 'charge': 0},\n",
    "    'P': {'hydrophobicity': -1.6, 'size': 115, 'charge': 0},\n",
    "    'S': {'hydrophobicity': -0.8, 'size': 105, 'charge': 0},\n",
    "    'T': {'hydrophobicity': -0.7, 'size': 119, 'charge': 0},\n",
    "    'W': {'hydrophobicity': -0.9, 'size': 204, 'charge': 0},\n",
    "    'Y': {'hydrophobicity': -1.3, 'size': 181, 'charge': 0},\n",
    "    'V': {'hydrophobicity': 4.2,  'size': 117, 'charge': 0},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_features = {\n",
    "    'A': {'size': 'Small', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Nonpolar'},\n",
    "    'R': {'size': 'Large', 'charge': 'Positive', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'N': {'size': 'Medium', 'charge': 'Neutral', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'D': {'size': 'Small', 'charge': 'Negative', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'C': {'size': 'Small', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Polar'},\n",
    "    'E': {'size': 'Medium', 'charge': 'Negative', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'Q': {'size': 'Medium', 'charge': 'Neutral', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'G': {'size': 'Small', 'charge': 'Neutral', 'hydro': 'Hydrophilic', 'polarity': 'Nonpolar'},\n",
    "    'H': {'size': 'Large', 'charge': 'Positive', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'I': {'size': 'Medium', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Nonpolar'},\n",
    "    'L': {'size': 'Medium', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Nonpolar'},\n",
    "    'K': {'size': 'Large', 'charge': 'Positive', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'M': {'size': 'Medium', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Nonpolar'},\n",
    "    'F': {'size': 'Large', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Nonpolar'},\n",
    "    'P': {'size': 'Small', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Nonpolar'},\n",
    "    'S': {'size': 'Small', 'charge': 'Neutral', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'T': {'size': 'Small', 'charge': 'Neutral', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'W': {'size': 'Large', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Nonpolar'},\n",
    "    'Y': {'size': 'Large', 'charge': 'Neutral', 'hydro': 'Hydrophilic', 'polarity': 'Polar'},\n",
    "    'V': {'size': 'Small', 'charge': 'Neutral', 'hydro': 'Hydrophobic', 'polarity': 'Nonpolar'}\n",
    "}\n",
    "\n",
    "# Map to df_bootstrap\n",
    "for feature in ['charge', 'size', 'hydro', 'polarity']:\n",
    "    df_bootstrap[f'{feature}_group'] = df_bootstrap['Amino_Acid'].map(lambda aa: aa_features.get(aa, {}).get(feature, np.nan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grouping_features = ['charge_group', 'size_group', 'hydro_group', 'polarity_group']\n",
    "enrichment_bins_ordered = ['0–1', '1–10', '10–100', '100–500', '>500']\n",
    "\n",
    "for group_feature in grouping_features:\n",
    "    for enrich_bin in enrichment_bins_ordered:\n",
    "        df_plot = df_bootstrap[df_bootstrap['enrichment_bin'] == enrich_bin]\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(\n",
    "            data=df_plot,\n",
    "            x=group_feature,\n",
    "            y='freq_mean',\n",
    "            hue='immunization'\n",
    "        )\n",
    "        plt.title(f'Bootstrap freq_mean by {group_feature} | Enrichment bin {enrich_bin}')\n",
    "        plt.ylabel('Bootstrap Frequency Mean')\n",
    "        plt.xlabel(group_feature.replace('_group', '').capitalize())\n",
    "        plt.legend(title='Immunization', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grouping_features = ['charge_group', 'size_group', 'hydro_group', 'polarity_group']\n",
    "enrichment_bins_ordered = ['0–1', '1–10', '10–100', '100–500', '>500']\n",
    "\n",
    "for group_feature in grouping_features:\n",
    "    for enrich_bin in enrichment_bins_ordered:\n",
    "        df_plot = df_bootstrap[df_bootstrap['enrichment_bin'] == enrich_bin].copy()\n",
    "\n",
    "        # Ensure the group values are treated as categorical (for color consistency)\n",
    "        df_plot[group_feature] = pd.Categorical(df_plot[group_feature])\n",
    "        immunization_order = sorted(df_plot['immunization'].unique())\n",
    "        group_order = sorted(df_plot[group_feature].unique())\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.boxplot(\n",
    "            data=df_plot,\n",
    "            x='immunization',\n",
    "            y='freq_mean',\n",
    "            hue=group_feature,\n",
    "            order=immunization_order,\n",
    "            hue_order=group_order\n",
    "        )\n",
    "        plt.title(f'{group_feature.replace(\"_group\", \"\").capitalize()} groups by Immunization | Enrichment bin {enrich_bin}')\n",
    "        plt.ylabel('Bootstrap Frequency Mean')\n",
    "        plt.xlabel('Immunization')\n",
    "        plt.legend(title=group_feature.replace('_group', '').capitalize(), bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grouping_features = ['charge_group', 'size_group', 'hydro_group', 'polarity_group']\n",
    "enrichment_bins_ordered = ['0–1', '1–10', '10–100', '100–500', '>500']\n",
    "\n",
    "for group_feature in grouping_features:\n",
    "    for enrich_bin in enrichment_bins_ordered:\n",
    "        df_plot = df_bootstrap[df_bootstrap['enrichment_bin'] == enrich_bin].copy()\n",
    "\n",
    "        # Ensure categorical types for consistency\n",
    "        df_plot[group_feature] = pd.Categorical(df_plot[group_feature])\n",
    "        immunization_order = sorted(df_plot['immunization'].unique())\n",
    "        group_order = sorted(df_plot[group_feature].unique())\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Boxplot (grouped by immunization, colored by feature)\n",
    "        sns.boxplot(\n",
    "            data=df_plot,\n",
    "            x='immunization',\n",
    "            y='freq_mean',\n",
    "            hue=group_feature,\n",
    "            order=immunization_order,\n",
    "            hue_order=group_order,\n",
    "            showfliers=False  # optional: hides outliers to reduce clutter\n",
    "        )\n",
    "\n",
    "        # Stripplot to show individual data points\n",
    "        sns.stripplot(\n",
    "            data=df_plot,\n",
    "            x='immunization',\n",
    "            y='freq_mean',\n",
    "            hue=group_feature,\n",
    "            order=immunization_order,\n",
    "            hue_order=group_order,\n",
    "            dodge=True,\n",
    "            jitter=True,\n",
    "            marker='o',\n",
    "            size=3,\n",
    "            color='black',\n",
    "            alpha=0.5\n",
    "        )\n",
    "\n",
    "        # Clean legend (avoid duplicate entries from both plots)\n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        n_groups = len(group_order)\n",
    "        plt.legend(handles[:n_groups], labels[:n_groups], title=group_feature.replace('_group', '').capitalize(), bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "        plt.title(f'{group_feature.replace(\"_group\", \"\").capitalize()} groups by Immunization | Enrichment bin {enrich_bin}')\n",
    "        plt.ylabel('Bootstrap Frequency Mean')\n",
    "        plt.xlabel('Immunization')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install statannotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statannotations.Annotator import Annotator\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grouping_features = ['charge_group', 'size_group', 'hydro_group', 'polarity_group']\n",
    "enrichment_bins_ordered = ['0–1', '1–10', '10–100', '100–500', '>500']\n",
    "\n",
    "for group_feature in grouping_features:\n",
    "    for enrich_bin in enrichment_bins_ordered:\n",
    "        df_plot = df_bootstrap[df_bootstrap['enrichment_bin'] == enrich_bin].copy()\n",
    "\n",
    "        # Drop NaN in y-value or group_feature\n",
    "        df_plot['freq_mean'] = pd.to_numeric(df_plot['freq_mean'], errors='coerce')\n",
    "        df_plot = df_plot.dropna(subset=['freq_mean', group_feature, 'immunization'])\n",
    "\n",
    "        if df_plot.empty:\n",
    "            continue\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        ax = sns.boxplot(\n",
    "            data=df_plot,\n",
    "            x=group_feature,\n",
    "            y='freq_mean',\n",
    "            hue='immunization'\n",
    "        )\n",
    "        plt.title(f'Bootstrap freq_mean by {group_feature} | Enrichment bin {enrich_bin}')\n",
    "        plt.ylabel('Bootstrap Frequency Mean')\n",
    "        plt.xlabel(group_feature.replace('_group', '').capitalize())\n",
    "\n",
    "        # Build valid group pairs\n",
    "        pairs = []\n",
    "        for immun in df_plot['immunization'].unique():\n",
    "            sub_df = df_plot[df_plot['immunization'] == immun]\n",
    "            levels = sub_df[group_feature].dropna().unique()\n",
    "            if len(levels) >= 2:\n",
    "                combos = list(itertools.combinations(sorted(levels), 2))\n",
    "                pairs += [((a, immun), (b, immun)) for a, b in combos]\n",
    "\n",
    "        # Validate pairs exist in the actual data\n",
    "        valid_groups = set(tuple(row) for row in df_plot[[group_feature, 'immunization']].dropna().values)\n",
    "        filtered_pairs = [pair for pair in pairs if pair[0] in valid_groups and pair[1] in valid_groups]\n",
    "\n",
    "        if filtered_pairs:\n",
    "            annotator = Annotator(ax, filtered_pairs, data=df_plot,\n",
    "                                  x=group_feature, y='freq_mean', hue='immunization')\n",
    "            annotator.configure(test='Mann-Whitney', text_format='star', loc='outside', verbose=0)\n",
    "            annotator.apply_and_annotate()\n",
    "        else:\n",
    "            print(f\"Skipped annotation for {group_feature} | {enrich_bin} (no valid pairs)\")\n",
    "\n",
    "        plt.legend(title='Immunization', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "# Ensure freq_mean is numeric and drop NaNs\n",
    "df_plot['freq_mean'] = pd.to_numeric(df_plot['freq_mean'], errors='coerce')\n",
    "df_plot = df_plot.dropna(subset=['freq_mean'])\n",
    "\n",
    "# Generate all possible pairs within each immunization group\n",
    "pairs = []\n",
    "for immun in df_plot['immunization'].unique():\n",
    "    sub_df = df_plot[df_plot['immunization'] == immun]\n",
    "    group_levels = sub_df[group_feature].unique()\n",
    "    if len(group_levels) >= 2:\n",
    "        # Get all pairwise combinations\n",
    "        pair_combos = list(itertools.combinations(group_levels, 2))\n",
    "        # Add immunization context to the pairs\n",
    "        pairs += [((immun, a), (immun, b)) for a, b in pair_combos]\n",
    "\n",
    "# Filter pairs to only keep those actually present in the data\n",
    "valid_groups = list(df_plot.groupby(['immunization', group_feature]).groups.keys())\n",
    "filtered_pairs = [pair for pair in pairs if pair[0] in valid_groups and pair[1] in valid_groups]\n",
    "\n",
    "# Add annotation only if there are valid pairs\n",
    "if filtered_pairs:\n",
    "    annotator = Annotator(ax, filtered_pairs, data=df_plot,\n",
    "                          x='immunization', y='freq_mean', hue=group_feature)\n",
    "    annotator.configure(test='Mann-Whitney', text_format='star', loc='outside', verbose=0)\n",
    "    annotator.apply_and_annotate()\n",
    "else:\n",
    "    print(\"No valid group pairs found for annotation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "# Ensure freq_mean is numeric and drop NaNs\n",
    "df_plot['freq_mean'] = pd.to_numeric(df_plot['freq_mean'], errors='coerce')\n",
    "df_plot = df_plot.dropna(subset=['freq_mean'])\n",
    "\n",
    "# Generate all possible pairs within each immunization group\n",
    "pairs = []\n",
    "for immun in df_plot['immunization'].unique():\n",
    "    sub_df = df_plot[df_plot['immunization'] == immun]\n",
    "    group_levels = sub_df[group_feature].unique()\n",
    "    if len(group_levels) >= 2:\n",
    "        # Get all pairwise combinations\n",
    "        pair_combos = list(itertools.combinations(group_levels, 2))\n",
    "        # Add immunization context to the pairs\n",
    "        pairs += [((immun, a), (immun, b)) for a, b in pair_combos]\n",
    "\n",
    "# Filter pairs to only keep those actually present in the data\n",
    "valid_groups = list(df_plot.groupby(['immunization', group_feature]).groups.keys())\n",
    "filtered_pairs = [pair for pair in pairs if pair[0] in valid_groups and pair[1] in valid_groups]\n",
    "\n",
    "# Add annotation only if there are valid pairs\n",
    "if filtered_pairs:\n",
    "    annotator = Annotator(ax, filtered_pairs, data=df_plot,\n",
    "                          x='immunization', y='freq_mean', hue=group_feature)\n",
    "    annotator.configure(test='Mann-Whitney', text_format='star', loc='outside', verbose=0)\n",
    "    annotator.apply_and_annotate()\n",
    "else:\n",
    "    print(\"No valid group pairs found for annotation.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bootstrap['hydrophobicity'] = df_bootstrap['Amino_Acid'].map(lambda aa: aa_properties.get(aa, {}).get('hydrophobicity', np.nan))\n",
    "df_bootstrap['size'] = df_bootstrap['Amino_Acid'].map(lambda aa: aa_properties.get(aa, {}).get('size', np.nan))\n",
    "df_bootstrap['charge'] = df_bootstrap['Amino_Acid'].map(lambda aa: aa_properties.get(aa, {}).get('charge', np.nan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "# For dimensionality reduction, build a feature matrix\n",
    "features = df_bootstrap[['freq_mean', 'freq_std', 'hydrophobicity', 'size', 'charge']].dropna()\n",
    "\n",
    "# PCA example:\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(features)\n",
    "\n",
    "df_bootstrap.loc[features.index, 'PCA1'] = pca_result[:,0]\n",
    "df_bootstrap.loc[features.index, 'PCA2'] = pca_result[:,1]\n",
    "\n",
    "# Or UMAP:\n",
    "# reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "# umap_result = reducer.fit_transform(features)\n",
    "# df_bootstrap.loc[features.index, 'UMAP1'] = umap_result[:,0]\n",
    "# df_bootstrap.loc[features.index, 'UMAP2'] = umap_result[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add biochemical properties as before\n",
    "df_bootstrap['hydrophobicity'] = df_bootstrap['Amino_Acid'].map(lambda aa: aa_properties.get(aa, {}).get('hydrophobicity', np.nan))\n",
    "df_bootstrap['charge'] = df_bootstrap['Amino_Acid'].map(lambda aa: aa_properties.get(aa, {}).get('charge', np.nan))\n",
    "\n",
    "# Categorize charge groups\n",
    "def charge_group(c):\n",
    "    if c > 0:\n",
    "        return 'Positive'\n",
    "    elif c < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "df_bootstrap['charge_group'] = df_bootstrap['charge'].apply(charge_group)\n",
    "\n",
    "# Similarly, you can bin hydrophobicity, e.g.:\n",
    "df_bootstrap['hydro_group'] = pd.cut(\n",
    "    df_bootstrap['hydrophobicity'],\n",
    "    bins=[-5, -0.5, 0.5, 5],\n",
    "    labels=['Hydrophilic', 'Neutral', 'Hydrophobic']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(\n",
    "    data=df_bootstrap,\n",
    "    x='charge_group',\n",
    "    y='freq_mean',\n",
    "    hue='immunization'\n",
    ")\n",
    "plt.title('Bootstrap frequency mean by amino acid charge group and immunization')\n",
    "plt.ylabel('Bootstrap Frequency Mean')\n",
    "plt.xlabel('Charge Group')\n",
    "plt.legend(title='Immunization', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "for imm in df_bootstrap['immunization'].unique():\n",
    "    subset = df_bootstrap[df_bootstrap['immunization'] == imm]\n",
    "    \n",
    "    groups = [group['freq_mean'].values for name, group in subset.groupby('charge_group')]\n",
    "    \n",
    "    stat, p = kruskal(*groups)\n",
    "    print(f\"Immunization {imm}: Kruskal-Wallis H-test across charge groups p-value = {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_reg = df_bootstrap.dropna(subset=['freq_mean', 'hydrophobicity', 'charge', 'immunization'])\n",
    "\n",
    "# Encode immunization as categorical variable\n",
    "df_reg['immunization'] = df_reg['immunization'].astype('category')\n",
    "\n",
    "# Fit linear model predicting freq_mean by hydrophobicity and immunization\n",
    "model = smf.ols('freq_mean ~ hydrophobicity + C(immunization)', data=df_reg).fit()\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing bootstrapping mean frequency as a logo plot. color by amino acid\n",
    "#this plot is not valdiated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_bootstrap['immunization'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viusalizing bootstrap sampling as pie charts: We want to know what proportion of the amino-acids/positions \n",
    "#are within each bootrapping mean frequency bin (0-0.1, 0.1-0.2, 0.2-0.3. and so on)\n",
    "# High proportion of mean frequencies > 0.8 could indicate that the sampling of aminoacids (mutations) is very robust in that sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define bins from 0 to 1 in 0.1 increments\n",
    "bins = np.arange(0, 1.1, 0.1)\n",
    "bin_labels = [f\"{bins[i]:.1f}-{bins[i+1]:.1f}\" for i in range(len(bins)-1)]\n",
    "\n",
    "immunizations = sorted(df_bootstrap['immunization'].unique())\n",
    "enrich_bins = sorted(df_bootstrap['enrichment_bin'].unique(), key=lambda x: enrichment_labels.index(x))\n",
    "\n",
    "fig_width = 3 * len(enrich_bins)  # 3 inches per enrichment bin\n",
    "fig_height = 4 * len(immunizations)  # 4 inches per immunization\n",
    "\n",
    "fig, axes = plt.subplots(len(immunizations), len(enrich_bins), figsize=(fig_width, fig_height))\n",
    "\n",
    "if len(immunizations) == 1 and len(enrich_bins) == 1:\n",
    "    axes = np.array([[axes]])\n",
    "elif len(immunizations) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "elif len(enrich_bins) == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "for i, imm in enumerate(immunizations):\n",
    "    for j, enrich_bin in enumerate(enrich_bins):\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        data = df_bootstrap[\n",
    "            (df_bootstrap['immunization'] == imm) & \n",
    "            (df_bootstrap['enrichment_bin'] == enrich_bin)\n",
    "        ]\n",
    "\n",
    "        if data.empty:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # Bin freq_mean values\n",
    "        counts, _ = np.histogram(data['freq_mean'], bins=bins)\n",
    "        proportions = counts / counts.sum()\n",
    "        \n",
    "        # Remove zero-prop bins for cleaner pie\n",
    "        nonzero_idx = proportions > 0\n",
    "        props_nonzero = proportions[nonzero_idx]\n",
    "        labels_nonzero = np.array(bin_labels)[nonzero_idx]\n",
    "        \n",
    "        # Pie chart with % labels\n",
    "        wedges, texts, autotexts = ax.pie(\n",
    "            props_nonzero,\n",
    "            labels=labels_nonzero,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            textprops={'fontsize': 8}\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f\"Imm: {imm}\\nEnrich bin: {enrich_bin}\", fontsize=10)\n",
    "        ax.axis('equal')\n",
    "\n",
    "# Global figure title\n",
    "plt.suptitle(\"Distribution of Bootstrap Mean Frequencies by Immunization and Enrichment Bin\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define bins from 0 to 1 in 0.1 increments\n",
    "bins = np.arange(0, 1.1, 0.1)\n",
    "bin_labels = [f\"{bins[i]:.1f}-{bins[i+1]:.1f}\" for i in range(len(bins)-1)]\n",
    "\n",
    "immunizations = sorted(df_bootstrap['immunization'].unique())\n",
    "enrich_bins = sorted(df_bootstrap['enrichment_bin'].unique(), key=lambda x: enrichment_labels.index(x))\n",
    "\n",
    "fig_width = 3 * len(enrich_bins)  # 3 inches per enrichment bin\n",
    "fig_height = 4 * len(immunizations)  # 4 inches per immunization\n",
    "\n",
    "fig, axes = plt.subplots(len(immunizations), len(enrich_bins), figsize=(fig_width, fig_height))\n",
    "\n",
    "if len(immunizations) == 1 and len(enrich_bins) == 1:\n",
    "    axes = np.array([[axes]])\n",
    "elif len(immunizations) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "elif len(enrich_bins) == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "# Create a fixed color map for bins\n",
    "# Using a seaborn or matplotlib colormap with 10 distinct colors\n",
    "import seaborn as sns\n",
    "palette = sns.color_palette(\"Spectral\", n_colors=len(bin_labels))\n",
    "color_map = dict(zip(bin_labels, palette))\n",
    "\n",
    "for i, imm in enumerate(immunizations):\n",
    "    for j, enrich_bin in enumerate(enrich_bins):\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        data = df_bootstrap[\n",
    "            (df_bootstrap['immunization'] == imm) & \n",
    "            (df_bootstrap['enrichment_bin'] == enrich_bin)\n",
    "        ]\n",
    "\n",
    "        if data.empty:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # Bin freq_mean values\n",
    "        counts, _ = np.histogram(data['freq_mean'], bins=bins)\n",
    "        proportions = counts / counts.sum()\n",
    "        \n",
    "        # Remove zero-prop bins for cleaner pie\n",
    "        nonzero_idx = proportions > 0\n",
    "        props_nonzero = proportions[nonzero_idx]\n",
    "        labels_nonzero = np.array(bin_labels)[nonzero_idx]\n",
    "\n",
    "        # Pick colors for the nonzero bins consistently from color_map\n",
    "        colors_nonzero = [color_map[label] for label in labels_nonzero]\n",
    "        \n",
    "        wedges, texts, autotexts = ax.pie(\n",
    "            props_nonzero,\n",
    "            labels=labels_nonzero,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=colors_nonzero,\n",
    "            textprops={'fontsize': 12},   # bin label font size\n",
    "            pctdistance=0.75,              # keeps percentages closer to center\n",
    "            labeldistance=1.05              # keeps labels close for big pies\n",
    "        )\n",
    "        \n",
    "        # Make percentage text bigger\n",
    "        for t in autotexts:\n",
    "            t.set_fontsize(12)\n",
    "        \n",
    "        ax.set_title(f\"Imm: {imm}\\nEnrich bin: {enrich_bin}\", fontsize=14)\n",
    "        ax.axis('equal')\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Distribution of Bootstrap Mean Frequencies by Immunization and Enrichment Bin\",\n",
    "    fontsize=20, y=1.02\n",
    ")\n",
    "plt.tight_layout()\n",
    "# Save the figure before displaying\n",
    "output_path = \"bootstrap_frequency_distribution.png\"  # Change filename if needed\n",
    "plt.savefig(output_path, format='png', bbox_inches='tight', dpi=300)  # High-res save\n",
    "print(f\"Figure saved as {output_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Filter out 'library_ctrl'\n",
    "df_plot = df_bootstrap[df_bootstrap['immunization'] != 'library_ctrl']\n",
    "\n",
    "# Define bins from 0 to 1 in 0.1 increments\n",
    "bins = np.arange(0, 1.1, 0.1)\n",
    "bin_labels = [f\"{bins[i]:.1f}-{bins[i+1]:.1f}\" for i in range(len(bins)-1)]\n",
    "\n",
    "immunizations = sorted(df_plot['immunization'].unique())\n",
    "enrich_bins = sorted(df_plot['enrichment_bin'].unique(), key=lambda x: enrichment_labels.index(x))\n",
    "\n",
    "fig_width = 3 * len(enrich_bins) + 2  # extra space for legend\n",
    "fig_height = 4 * len(immunizations)\n",
    "\n",
    "fig, axes = plt.subplots(len(immunizations), len(enrich_bins), figsize=(fig_width, fig_height))\n",
    "\n",
    "if len(immunizations) == 1 and len(enrich_bins) == 1:\n",
    "    axes = np.array([[axes]])\n",
    "elif len(immunizations) == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "elif len(enrich_bins) == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "# Color map for bins\n",
    "palette = sns.color_palette(\"Spectral\", n_colors=len(bin_labels))\n",
    "color_map = dict(zip(bin_labels, palette))\n",
    "\n",
    "for i, imm in enumerate(immunizations):\n",
    "    for j, enrich_bin in enumerate(enrich_bins):\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        data = df_plot[\n",
    "            (df_plot['immunization'] == imm) & \n",
    "            (df_plot['enrichment_bin'] == enrich_bin)\n",
    "        ]\n",
    "\n",
    "        if data.empty:\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # Bin freq_mean values\n",
    "        counts, _ = np.histogram(data['freq_mean'], bins=bins)\n",
    "        proportions = counts / counts.sum()\n",
    "        \n",
    "        # Remove zero-prop bins\n",
    "        nonzero_idx = proportions > 0\n",
    "        props_nonzero = proportions[nonzero_idx]\n",
    "        labels_nonzero = np.array(bin_labels)[nonzero_idx]\n",
    "\n",
    "        # Colors\n",
    "        colors_nonzero = [color_map[label] for label in labels_nonzero]\n",
    "        \n",
    "        wedges, _, autotexts = ax.pie(\n",
    "            props_nonzero,\n",
    "            labels=None,                 # no enrichment bin labels\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=colors_nonzero,\n",
    "            textprops={'fontsize': 12},\n",
    "            pctdistance=0.75\n",
    "        )\n",
    "        \n",
    "        for t in autotexts:\n",
    "            t.set_fontsize(12)\n",
    "        \n",
    "        ax.set_title(f\"Imm: {imm}\", fontsize=14)\n",
    "        ax.axis('equal')\n",
    "\n",
    "# Create legend for enrichment bins\n",
    "legend_elements = [Patch(facecolor=color_map[label], label=label) for label in bin_labels]\n",
    "fig.legend(\n",
    "    handles=legend_elements,\n",
    "    loc='center right',\n",
    "    title=\"Bootstrap Mean Bins\",\n",
    "    fontsize=12,\n",
    "    title_fontsize=14\n",
    ")\n",
    "\n",
    "plt.subplots_adjust(right=0.85)  # make space for legend\n",
    "\n",
    "plt.suptitle(\n",
    "    \"Distribution of Bootstrap Mean Frequencies by Immunization and Enrichment Bin\",\n",
    "    fontsize=20, y=1.02\n",
    ")\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 0.96])\n",
    "\n",
    "output_path = \"bootstrap_frequency_distribution.png\"\n",
    "plt.savefig(output_path, format='png', bbox_inches='tight', dpi=300)\n",
    "print(f\"Figure saved as {output_path}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install logomaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "df_logo_agg = df_logo_agg.replace([np.inf, -np.inf], np.nan)\n",
    "df_logo_agg = df_logo_agg.dropna(subset=['Enrichment_Ratio'])\n",
    "\n",
    "df_filtered = df_logo_agg.drop_duplicates(\n",
    "    subset=['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode']\n",
    ")\n",
    "\n",
    "# Filter positions > 365\n",
    "df_filtered = df_filtered[df_filtered['Spike_AS_Position'] > 365]\n",
    "\n",
    "print(df_filtered['Enrichment_Ratio'].min())  # Should be > 1\n",
    "\n",
    "duplicates = df_filtered[df_filtered.duplicated(\n",
    "    subset=['Spike_AS_Position', 'Amino_Acid'], keep=False)]\n",
    "print(duplicates)\n",
    "\n",
    "# Add a new column with log10 of Enrichment_Ratio (safe transformation)\n",
    "def safe_log10(enrichment, epsilon=1e-8, max_cap=1e8):\n",
    "    enrichment = np.clip(enrichment, epsilon, max_cap)\n",
    "    return np.log10(enrichment)\n",
    "\n",
    "df_filtered['Enrichment_Ratio_log'] = df_filtered['Enrichment_Ratio'].apply(safe_log10)\n",
    "df_filtered = df_filtered.dropna(subset=['Enrichment_Ratio_log'])\n",
    "\n",
    "# Color assignment\n",
    "aa_list = sorted(df_filtered['Amino_Acid'].unique())\n",
    "colors = plt.cm.tab20.colors\n",
    "aa_colors = {aa: colors[i % len(colors)] for i, aa in enumerate(aa_list)}\n",
    "df_filtered['color'] = df_filtered['Amino_Acid'].map(aa_colors)\n",
    "\n",
    "# Output directory\n",
    "output_dir = \"barcode_logoplots_panels\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Helper function for plain integer log ticks\n",
    "def log_ticks_plain(ax):\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda y, _: f\"{int(y)}\"))\n",
    "\n",
    "# Improved stacking function — letters sorted by height before drawing\n",
    "def improved_draw_logo(df, **kwargs):\n",
    "    # Sort within each x position so letters with greater height are on top\n",
    "    df_sorted = df.sort_values(\n",
    "        by=[kwargs['x_col'], kwargs['letter_height_col']],\n",
    "        ascending=[True, True]\n",
    "    )\n",
    "    return dmslogo.draw_logo(df_sorted, **kwargs)\n",
    "\n",
    "# Plot loop\n",
    "for immunization in df_filtered['immunization'].unique():\n",
    "    df_imm = df_filtered[df_filtered['immunization'] == immunization]\n",
    "    barcodes = df_imm['barcode'].unique()[:4]\n",
    "\n",
    "    if len(barcodes) == 0:\n",
    "        continue\n",
    "\n",
    "    print(f\"Generating panel for immunization: {immunization}\")\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        len(barcodes), 1,\n",
    "        figsize=(45, 12 * len(barcodes)),\n",
    "        gridspec_kw={'hspace': 2.5}\n",
    "    )\n",
    "\n",
    "    if len(barcodes) == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for i, barcode in enumerate(barcodes):\n",
    "        df_barcode = df_imm[\n",
    "            (df_imm['barcode'] == barcode) &\n",
    "            (df_imm['Enrichment_Ratio_log'].notna())\n",
    "        ]\n",
    "\n",
    "        if df_barcode.empty:\n",
    "            continue\n",
    "\n",
    "        # 🔑 Aggregate to avoid overlap\n",
    "        df_barcode_agg = (\n",
    "            df_barcode.groupby([\"Spike_AS_Position\", \"Amino_Acid\"], as_index=False)\n",
    "            .agg({\"Enrichment_Ratio_log\": \"mean\"})\n",
    "        )\n",
    "        df_barcode_agg[\"color\"] = df_barcode_agg[\"Amino_Acid\"].map(aa_colors)\n",
    "\n",
    "        fig_sub, ax = improved_draw_logo(\n",
    "            df_barcode_agg,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log\",\n",
    "            color_col=\"color\",\n",
    "            title=f\"{immunization} - {barcode} logoplot (log10 Enrichment Ratio)\",\n",
    "            addbreaks=True,\n",
    "            ax=axs[i]\n",
    "        )\n",
    "\n",
    "        axs[i].set_title(\n",
    "            f\"{immunization} - {barcode} logoplot (log10 Enrichment Ratio)\", pad=25\n",
    "        )\n",
    "        axs[i].set_ylabel('Log10 AB binding (median) \\u2190 Enrichment \\u2192', fontsize=10)\n",
    "        axs[i].yaxis.set_label_coords(-0.01, 0.5)\n",
    "        axs[i].set_ylim(-10, 6)\n",
    "        axs[i].yaxis.set_major_locator(ticker.MultipleLocator(4))\n",
    "        log_ticks_plain(axs[i])\n",
    "\n",
    "    legend_elements = [Patch(facecolor=col, label=aa) for aa, col in aa_colors.items()]\n",
    "    fig.subplots_adjust(right=0.85)\n",
    "    fig.legend(handles=legend_elements, title='Amino Acid',\n",
    "               loc='center right', borderaxespad=0.1)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.85, 2])\n",
    "    safe_immunization = immunization.replace(\"/\", \"_\").replace(\"\\\\\", \"_\")\n",
    "    plot_filename = os.path.join(\n",
    "        output_dir, f\"{safe_immunization}_top4_logoplots.png\"\n",
    "    )\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Panel saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import dmslogo\n",
    "\n",
    "# Assuming df_bootstrap is your DataFrame with the necessary data\n",
    "# and contains columns: 'immunization', 'Spike_AS_Position', 'Amino_Acid', 'freq_mean'\n",
    "\n",
    "output_dir = \"dmslogo_immunization_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for imm in df_bootstrap['immunization'].unique():\n",
    "    df_subset = df_bootstrap[df_bootstrap['immunization'] == imm].copy()\n",
    "    df_subset = df_subset.rename(columns={\n",
    "        'Spike_AS_Position': 'site',\n",
    "        'Amino_Acid': 'letter',\n",
    "        'freq_mean': 'height'\n",
    "    })\n",
    "\n",
    "    # Ensure 'site' is integer\n",
    "    df_subset['site'] = df_subset['site'].astype(int)\n",
    "\n",
    "    fig, ax = dmslogo.logo.draw_logo(\n",
    "        data=df_subset,\n",
    "        x_col='site',\n",
    "        letter_col='letter',\n",
    "        letter_height_col='height',\n",
    "        title=f\"Logo Plot — {imm}\"\n",
    "    )\n",
    "\n",
    "    plt.tight_layout()\n",
    "    filename = f\"{imm.replace('/', '_')}_logo_dms.png\"\n",
    "    fig.savefig(os.path.join(output_dir, filename), dpi=300)\n",
    "    plt.close(fig)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colored by Enrichment ratio, Y axis is how many samples support it\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high) using log scale\n",
    "def enrichment_color(enrichment):\n",
    "    # Set the max enrichment value for normalization\n",
    "    max_enrichment = 3000  # Adjust to the maximum value you want for color scaling\n",
    "    # Apply a logarithmic scale to the enrichment values\n",
    "    log_enrichment = np.log10(enrichment + 1)  # log(x+1) to avoid issues with zero or small values\n",
    "    max_log_enrichment = np.log10(max_enrichment + 1)\n",
    "    norm_value = log_enrichment / max_log_enrichment  # Normalize to range [0, 1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "df_logo_agg = df_logo_agg[df_logo_agg['Amino_Acid'] != \"*\"]\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 3\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 3]\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes\n",
    "    .reset_index(name='Sample_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on max enrichment ratio per amino acid at each site\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [416,417,418, 439, 440,441, 452,453, 476, 477,478,482,483, 484,485, 493,494,495,496,497,498,499,500, 501, 502, 503,504,505]\n",
    "\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Sample_Count\",  # Now using count instead of enrichment\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Occurrence-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add colorbar to the plot\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3 + 1), vmax=np.log10(3000 + 1)))  # Log scale for max\n",
    "    sm.set_array([])  # Required for the colorbar to work\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')  # Attach colorbar to the same axes as the plot\n",
    "    cbar.set_label('Log(Enrichment Ratio)', rotation=270, labelpad=15)  # Label the colorbar\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = r\"/Users/lucaschlotheuber/Desktop/immunization_csv_files\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Creates the directory if it doesn't exist\n",
    "    \n",
    "    # Set y-axis label\n",
    "    ax.set_ylabel('IgG Secreting cell [n]')\n",
    "    \n",
    "    # Define file paths\n",
    "    file_path = os.path.join(output_dir, f\"{barcode}_logoplots2.png\")\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logoplot2.png\")\n",
    "    \n",
    "    # Save the plot before showing it\n",
    "    plt.savefig(file_path, dpi=300, bbox_inches='tight')  # Save with high resolution\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "    \n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n",
    "    \n",
    "    # Show the plot in the notebook\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high) using log scale\n",
    "def enrichment_color(enrichment):\n",
    "    # Set the max enrichment value for normalization\n",
    "    max_enrichment = 3000  # Adjust to the maximum value you want for color scaling\n",
    "    # Apply a logarithmic scale to the enrichment values\n",
    "    log_enrichment = np.log10(enrichment + 1)  # log(x+1) to avoid issues with zero or small values\n",
    "    max_log_enrichment = np.log10(max_enrichment + 1)\n",
    "    norm_value = log_enrichment / max_log_enrichment  # Normalize to range [0, 1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 3\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 3]\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position (i.e., Barcode Count)\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes (this is the barcode count)\n",
    "    .reset_index(name='Barcode_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on max enrichment ratio per amino acid at each site\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Barcode_Count\",  # Now using 'Barcode_Count' for the y-axis\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Barcode Count-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add colorbar to the plot\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3 + 1), vmax=np.log10(3000 + 1)))  # Log scale for max\n",
    "    sm.set_array([])  # Required for the colorbar to work\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')  # Attach colorbar to the same axes as the plot\n",
    "    cbar.set_label('Log(Enrichment Ratio)', rotation=270, labelpad=15)  # Label the colorbar\n",
    "\n",
    "    # Set the y-axis label to 'Number of Barcodes Supporting Amino Acid'\n",
    "    ax.set_ylabel('Number of Barcodes')\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Aggregate enrichment ratio per barcode\n",
    "df_logo_agg = df_total.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization', 'barcode'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Function to assign enrichment-based colors (black = low, bright red = high) using log scale\n",
    "def enrichment_color(enrichment):\n",
    "    # Set the max enrichment value for normalization\n",
    "    max_enrichment = 3000  # Adjust to the maximum value you want for color scaling\n",
    "    # Apply a logarithmic scale to the enrichment values\n",
    "    log_enrichment = np.log10(enrichment + 1)  # log(x+1) to avoid issues with zero or small values\n",
    "    max_log_enrichment = np.log10(max_enrichment + 1)\n",
    "    norm_value = log_enrichment / max_log_enrichment  # Normalize to range [0, 1]\n",
    "    norm_value = np.clip(norm_value, 0, 1)  # Ensure values stay in range\n",
    "    return plt.cm.Reds(norm_value)  # Use 'Reds' colormap\n",
    "\n",
    "df_logo_agg['Amino_Acid'] = df_logo_agg['Amino_Acid'].str.upper()\n",
    "\n",
    "# Filter: Only keep amino acids with Enrichment_Ratio > 3\n",
    "df_filtered = df_logo_agg[df_logo_agg['Enrichment_Ratio'] > 3]\n",
    "\n",
    "# Count how often an amino acid appears across barcodes at each position (i.e., Barcode Count)\n",
    "df_combined = (\n",
    "    df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])\n",
    "    .size()  # Count occurrences across barcodes (this is the barcode count)\n",
    "    .reset_index(name='Barcode_Count')  # Rename count column\n",
    ")\n",
    "\n",
    "# Assign colors based on max enrichment ratio per amino acid at each site\n",
    "df_combined['Max_Enrichment'] = df_filtered.groupby(['Spike_AS_Position', 'Amino_Acid', 'immunization'])['Enrichment_Ratio'].max().reset_index(drop=True)\n",
    "df_combined['color'] = df_combined['Max_Enrichment'].apply(enrichment_color)\n",
    "\n",
    "df_combined = df_combined.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str)\n",
    ")\n",
    "\n",
    "# Select specific sites from Code 1 to plot (for example: positions 417, 439, 440, etc.)\n",
    "sites_to_show = [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]\n",
    "\n",
    "# Filter the df_combined to include only these sites\n",
    "df_combined = df_combined[df_combined['Spike_AS_Position'].isin(sites_to_show)]\n",
    "\n",
    "# Create a directory to save the PNG files (if it doesn't already exist)\n",
    "output_dir = \"logo_plots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Generate and save logo plots\n",
    "for immunization in df_combined['immunization'].unique():\n",
    "    print(f\"Generating plot for {immunization}...\")\n",
    "\n",
    "    # Create a filtered DataFrame for the current immunization group and specific sites\n",
    "    df_immunization = df_combined.query(f'immunization == \"{immunization}\"')\n",
    "\n",
    "    # Create the logo plot\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_immunization,  # Pass only the filtered data for specific sites\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Barcode_Count\",  # Now using 'Barcode_Count' for the y-axis\n",
    "        color_col=\"color\",  \n",
    "        title=f\"{immunization} logoplot (Barcode Count-based)\",\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "    # Add colorbar to the plot\n",
    "    sm = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=np.log10(3 + 1), vmax=np.log10(3000 + 1)))  # Log scale for max\n",
    "    sm.set_array([])  # Required for the colorbar to work\n",
    "    cbar = fig.colorbar(sm, ax=ax, orientation='vertical')  # Attach colorbar to the same axes as the plot\n",
    "    cbar.set_label('Log(Enrichment Ratio)', rotation=270, labelpad=15)  # Label the colorbar\n",
    "\n",
    "    # Set the y-axis label to 'Number of Barcodes Supporting Amino Acid'\n",
    "    ax.set_ylabel('Single Droplet')\n",
    "\n",
    "    # Show the plot in the notebook\n",
    "    plt.show()\n",
    "\n",
    "    # Save the plot as a PNG file\n",
    "    plot_filename = os.path.join(output_dir, f\"{immunization}_logoplot.png\")\n",
    "    plt.savefig(plot_filename, format='png', bbox_inches='tight')  # Save as PNG\n",
    "    print(f\"Plot saved as {plot_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating logoplots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will focus on escape mutations (i.e Enrichment ratios > 1). To visualize the most de-enriched positions, we need to invert the data, so that the lowest enrichment ratios are highlighted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only non-synonymous mutations are considered, due to the sensitivity of the analysis, and synomymus are unlikely to be of interest in an escape setting\n",
    "df_escape = df_total[(df_total['Enrichment_Ratio'] < 1) & (df_total['Type_of_Mutation'] == 'NON-SYNOM')]\n",
    "\n",
    "df_escape = df_escape[df_escape['Spike_AS_Position'] > 34+331] #Removes the first 34 positions due to bad read quality\n",
    "\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "#df_escape['Enrichment_Ratio_log2'] = df_escape['Enrichment_Ratio'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "df_escape_agg = df_escape.groupby(['Spike_AS_Position', 'Amino_Acid','immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio_inverted': 'sum'\n",
    "})\n",
    "\n",
    "#df_escape_agg['Enrichment_Ratio_log2'] = df_escape_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "#The positions that have showed high enrichment ratios in the library droplets are discarded from the analysis (pos 33, 72, 81 and 151)\n",
    "sites_to_show_escape = map(\n",
    "    str,\n",
    "    #[(i+336) for i in range(107, 114) if i not in [33, 72, 81, 151]] +\n",
    "    [455, 456, 472, 473, 484, 485, 486, 490, 496, 499] + # RBD-ACE2 interface according to article\n",
    "    list(range(394,414)) + # R21 peptide sequence with high affinity\n",
    "    list(range(484, 503)) # R13 peptide sequence with high affinity\n",
    ")\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show_escape)\n",
    ")\n",
    "\n",
    "output_dir = \"immunization_csv_files\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for immunization in df_escape_agg['immunization'].unique():\n",
    "    print(immunization)\n",
    "    df_filtered_escape = df_escape_agg.query(f'immunization == \"{immunization}\"')#.query(\"show_site\")\n",
    "    # Aggregate the data to ensure unique Spike_AS_Position values\n",
    "    df_filtered_escape = df_filtered_escape.groupby('Spike_AS_Position', as_index=False).agg({\n",
    "        'Enrichment_Ratio_inverted': 'sum',\n",
    "    }).drop_duplicates(subset=['Spike_AS_Position'])\n",
    "\n",
    "    csv_file_path = os.path.join(output_dir, f\"{immunization}_escape_data.csv\")\n",
    "    df_filtered_escape.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    # Merge the show_site column back into df_filtered\n",
    "    df_filtered_escape = df_filtered_escape.merge(df_escape_agg[['Spike_AS_Position', 'show_site']], on='Spike_AS_Position', how='left')\n",
    "    \n",
    "    # Ensure unique Spike_AS_Position values before reindexing\n",
    "    df_filtered_escape = df_filtered_escape.drop_duplicates(subset=['Spike_AS_Position'])\n",
    "    \n",
    "    # Reindex to ensure sequential unbroken integers in Spike_AS_Position\n",
    "    df_filtered_escape = df_filtered_escape.set_index('Spike_AS_Position').reindex(range(df_filtered_escape['Spike_AS_Position'].min(), df_filtered_escape['Spike_AS_Position'].max() + 1)).reset_index()\n",
    "    df_filtered_escape['Enrichment_Ratio_invertted'] = df_filtered_escape['Enrichment_Ratio_inverted'].fillna(0)\n",
    "    df_filtered_escape['show_site'] = df_filtered_escape['show_site'].fillna(False)\n",
    "    \n",
    "    fig, ax = dmslogo.line.draw_line(\n",
    "        df_filtered_escape,\n",
    "        x_col=\"Spike_AS_Position\",\n",
    "        height_col=\"Enrichment_Ratio_inverted\",\n",
    "        title=immunization + ' lineplot',\n",
    "        xlabel=\"Spike AA Position\",\n",
    "        ylabel=\"Enrichment Ratio log2\",\n",
    "        show_col=\"show_site\"\n",
    "    )\n",
    "    \n",
    "    # Save the figure\n",
    "    #file_path = os.path.join(r\"C:\\Users\\au649453\\OneDrive - Aarhus universitet\\PhD\\Luca\\DMS_plots\\Escape\", f\"{immunization}_lineplots.png\")\n",
    "    #plt.savefig(file_path, dpi = 300, bbox_inches = 'tight')\n",
    "    #plt.close(fig)\n",
    "    #plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_escape = df_total[df_total['Enrichment_Ratio'] < 1]\n",
    "\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "#df_escape['Enrichment_Ratio_log2'] = df_escape['Enrichment_Ratio'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "df_escape_agg = df_escape.groupby(['Spike_AS_Position', 'Amino_Acid','barcode','immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio_inverted': 'sum'\n",
    "})\n",
    "\n",
    "df_escape_agg['Enrichment_Ratio_log2'] = df_escape_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "# Aggregate to ensure unique values for each combination of Spike_AS_Position and Amino_Acid\n",
    "#df_escape_agg = df_escape_agg.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode'], as_index=False).agg({\n",
    "#    'Enrichment_Ratio_log2': 'mean'\n",
    "#})\n",
    "\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    #[(i+336) for i in range(107, 114) if i not in [33, 72, 81, 151]] +  \n",
    "    [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 50] # RBD-ACE2 interface according to article\n",
    ")\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "#Add the following before the \"barcode.unique\" to select various conditions\n",
    "# .query('immunization == \"Mutant_RBD\"')\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    if not df_filtered.empty:\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=barcode + 'Escape' + immunization,\n",
    "            addbreaks=True,\n",
    "            heightscale= 0.8\n",
    "        )\n",
    "        # Save the figure\n",
    "        #file_path = os.path.join(r\"C:\\Users\\au649453\\OneDrive - Aarhus universitet\\PhD\\Luca\\DMS_plots\\Escape\\NON-SYNOM changes\\Targeted\", f\"{barcode}_logoplot.png\", )\n",
    "        #plt.savefig(file_path, dpi = 300, bbox_inches = 'tight')\n",
    "        #plt.close(fig)\n",
    "\n",
    "        ax.set_title(f\"\")  # Change the title\n",
    "        ax.set_ylabel(\"Escape [Log2]\")  # Change the y-axis label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_escape = df_total[df_total['Enrichment_Ratio'] < 1]\n",
    "\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "df_escape_agg = df_escape.groupby(['Spike_AS_Position', 'Amino_Acid','barcode','immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio_inverted': 'sum'\n",
    "})\n",
    "\n",
    "df_escape_agg['Enrichment_Ratio_log2'] = df_escape_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 50]  # RBD-ACE2 interface according to article\n",
    ")\n",
    "\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Add the following before the \"barcode.unique\" to select various conditions\n",
    "# .query('immunization == \"Mutant_RBD\"')\n",
    "\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=barcode + '',\n",
    "            addbreaks=True,\n",
    "            heightscale=0.8\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f\"\")  # Change the title\n",
    "        ax.set_ylabel(\"Escape [Log2]\")  # Change the y-axis label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "df_escape = df_total[df_total['Enrichment_Ratio'] < 1]\n",
    "\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "df_escape_agg = df_escape.groupby(['Spike_AS_Position', 'Amino_Acid','barcode','immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio_inverted': 'first'\n",
    "})\n",
    "\n",
    "df_escape_agg['Enrichment_Ratio_log2'] = df_escape_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 50]  # RBD-ACE2 interface according to article\n",
    ")\n",
    "\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Add the following before the \"barcode.unique\" to select various conditions\n",
    "# .query('immunization == \"Mutant_RBD\"')\n",
    "\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "        \n",
    "        # Extract immunization condition from the filtered DataFrame\n",
    "        immunization_condition = df_filtered['immunization'].iloc[0]  # Assuming all rows for the barcode have the same immunization\n",
    "\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title=barcode + 'n \\n n',\n",
    "            addbreaks=True,\n",
    "            heightscale=0.8\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f\"\")  # Change the title\n",
    "        ax.set_ylabel(\"Escape [Log2]\")  # Change the y-axis label\n",
    "        \n",
    "\n",
    "        \n",
    "        # Add immunization info to the figure text\n",
    "        fig.text(1.05, 0.5, f\"Barcode: {barcode} and Immunization: {immunization_condition}\", ha='left', va='center', fontsize=14, rotation=90)\n",
    "        immunization_condition = df_filtered['immunization'].iloc[0]  # Assuming the immunization condition is the same for all rows in this barcode group\n",
    "        filename = f\"C:/Users/lschlotheube/Desktop/Thesis/LogoEscape/{barcode}_{immunization_condition}.png\"\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "        plt.draw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "df_escape = df_total[df_total['Enrichment_Ratio'] < 1]\n",
    "\n",
    "df_escape['Enrichment_Ratio_inverted'] = df_escape['Enrichment_Ratio'].apply(lambda x: 1 / x if x != 0 else x)\n",
    "\n",
    "df_escape_agg = df_escape.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio_inverted': 'sum'\n",
    "})\n",
    "\n",
    "df_escape_agg['Enrichment_Ratio_log2'] = df_escape_agg['Enrichment_Ratio_inverted'].apply(lambda x: np.log2(x) if x > 0 else x)\n",
    "\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 50]  # RBD-ACE2 interface according to article\n",
    ")\n",
    "\n",
    "df_escape_agg = df_escape_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Add the following before the \"barcode.unique\" to select various conditions\n",
    "# .query('immunization == \"Mutant_RBD\"')\n",
    "\n",
    "for barcode in df_escape_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_escape_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    \n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "        \n",
    "        # Create the plot\n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio_log2\",\n",
    "            title='',  # Empty title for now\n",
    "            addbreaks=True,\n",
    "            heightscale=0.8\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(\"Escape [Log2]\")  # Set the y-axis label\n",
    "        ax.set_xlabel(\"SARS-Cov-2 Spike AA Position\")  \n",
    "        \n",
    "        # Add title to the right side of the plot using fig.text()\n",
    "        fig.text(1.05, 0.5, f\"Barcode: {barcode}\", ha='left', va='center', fontsize=14, rotation=90)\n",
    "        \n",
    "        # Save the figure\n",
    "        immunization_condition = df_filtered['immunization'].iloc[0]  # Assuming the immunization condition is the same for all rows in this barcode group\n",
    "        filename = f\"C:/Users/lschlotheube/Desktop/Thesis/LogoEscape/{barcode}_{immunization_condition}.png\"\n",
    "        plt.savefig(filename, bbox_inches='tight')  # Save with tight bounding box\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "\n",
    "# No need for inversion or log2 transformation anymore\n",
    "df_binding_agg = df_binding.groupby(['Spike_AS_Position', 'Amino_Acid', 'barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'sum'\n",
    "})\n",
    "\n",
    "# Filter for sites to show\n",
    "sites_to_show = map(\n",
    "    str,\n",
    "    [417, 439, 440, 452, 476, 477, 484, 493, 501, 502, 505]  # RBD-ACE2 interface according to article\n",
    ")\n",
    "\n",
    "df_binding_agg = df_binding_agg.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"Spike_AS_Position\"].astype(str),\n",
    "    show_site=lambda x: x[\"Spike_AS_Position\"].astype(str).isin(sites_to_show)\n",
    ")\n",
    "\n",
    "# Add the following before the \"barcode.unique\" to select various conditions\n",
    "# .query('immunization == \"Mutant_RBD\"')\n",
    "\n",
    "for barcode in df_binding_agg['barcode'].unique():\n",
    "    print(barcode)\n",
    "    \n",
    "    # Filter based on barcode and selected sites\n",
    "    df_filtered = df_binding_agg.query(f'barcode == \"{barcode}\"').query(\"show_site\")\n",
    "    df_filtered = df_filtered[~df_filtered['Amino_Acid'].str.contains(r'[\\*\\-]', regex=True)]\n",
    "    if not df_filtered.empty:\n",
    "        # Exclude stop codons before plotting\n",
    "        df_filtered['Amino_Acid'] = df_filtered['Amino_Acid'].str.upper()\n",
    "        # Create the plot\n",
    "        print(f\"Enrichment_Ratio Range for Barcode {barcode}: {df_filtered['Enrichment_Ratio'].min()} to {df_filtered['Enrichment_Ratio'].max()}\")\n",
    "        print(f\"Enrichment_Ratio Distribution for Barcode {barcode} (first 10 values): {df_filtered['Enrichment_Ratio'].head(10).values}\")\n",
    "        \n",
    "        fig, ax = dmslogo.draw_logo(\n",
    "            df_filtered,\n",
    "            x_col=\"Spike_AS_Position\",\n",
    "            letter_col=\"Amino_Acid\",\n",
    "            letter_height_col=\"Enrichment_Ratio\",  # Plot the actual ratio (no log or inversion)\n",
    "            title='',  # Empty title for now\n",
    "            addbreaks=True,\n",
    "            heightscale=0.8\n",
    "        )\n",
    "        \n",
    "        ax.set_ylabel(\"Binding Ratio\")  # Set the y-axis label to Binding Ratio\n",
    "        \n",
    "        # Add title to the right side of the plot using fig.text()\n",
    "        fig.text(1.05, 0.5, f\"Barcode: {barcode}\", ha='left', va='center', fontsize=14, rotation=90)\n",
    "        \n",
    "        # Save the figure\n",
    "        immunization_condition = df_filtered['immunization'].iloc[0]  # Assuming the immunization condition is the same for all rows in this barcode group\n",
    "        filename = f\"C:/Users/lschlotheube/Desktop/Thesis/LogoBinding/{barcode}_{immunization_condition}.png\"\n",
    "        plt.savefig(filename, bbox_inches='tight')  # Save with tight bounding box\n",
    "        \n",
    "        plt.draw()\n",
    "        plt.pause(0.1)  # Give the plot time to render\n",
    "        plt.show()\n",
    "\n",
    "        # Optionally close the figure to free memory\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell can generate logoplots for sections which corresponds to the produced peptides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_logo_agg_test = df_total.groupby(['DMS_RBD_AS_position', 'Amino_Acid','barcode', 'immunization'], as_index=False).agg({\n",
    "    'Enrichment_Ratio': 'max'\n",
    "})\n",
    "\n",
    "\n",
    "sites_to_show_test = list(\n",
    "    map(\n",
    "        str,\n",
    "        list(range(73, 79)) +  # RBD-ACE2 interface according to article\n",
    "        list(range(87, 91)) +  # R21 peptide sequence with high affinity\n",
    "        list(range(125, 131)) +  # R13 peptide sequence with high affinity\n",
    "        list(range(143, 146)) +\n",
    "        list(range(157, 164)) +\n",
    "        list(range(174, 176))\n",
    "    )\n",
    ")\n",
    "df_logo_agg_test = df_logo_agg_test.assign(\n",
    "    site_label=lambda x: x[\"Amino_Acid\"] + \"_\" + x[\"DMS_RBD_AS_position\"].astype(str),\n",
    "    show_site=lambda x: x[\"DMS_RBD_AS_position\"].astype(str).isin(sites_to_show_test)\n",
    ")\n",
    "\n",
    "#The query can be changed to filter for specific barcodes or removed to get all barcodes\n",
    "#('immunization == \"wildtype_RBD\"')\n",
    "#\n",
    "for barcode in df_logo_agg_test.query('immunization == \"wildtype_RBD\"')['barcode'].unique():\n",
    "    print(barcode)\n",
    "    fig, ax = dmslogo.draw_logo(\n",
    "        df_logo_agg_test.query(f'barcode == \"{barcode}\"').query(\"show_site\"),\n",
    "        x_col=\"DMS_RBD_AS_position\",\n",
    "        letter_col=\"Amino_Acid\",\n",
    "        letter_height_col=\"Enrichment_Ratio\",\n",
    "        title=barcode + ' logoplot',\n",
    "        addbreaks=True\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the most enriched amino acid for each position for a given barcode. To use for AlphaFold structure prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
